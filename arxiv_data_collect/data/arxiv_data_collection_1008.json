{
  "2311.18587": {
    "title": "Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural Networks",
    "authors": [
      "Juyoung Yun"
    ],
    "abstract": "In the field of deep learning, the prevalence of models initially trained with 32-bit precision is a testament to its robustness and accuracy. However, the continuous evolution of these models often demands further training, which can be resource-intensive. This study introduces a novel approach where we continue the training of these pre-existing 32-bit models using 16-bit precision. This technique not only caters to the need for efficiency in computational resources but also significantly improves the speed of additional training phases. By adopting 16-bit precision for ongoing training, we are able to substantially decrease memory requirements and computational burden, thereby accelerating the training process in a resource-limited setting. Our experiments show that this method maintains the high standards of accuracy set by the original 32-bit training while providing a much-needed boost in training speed. This approach is especially pertinent in today's context, where most models are initially trained in 32-bit and require periodic updates and refinements. The findings from our research suggest that this strategy of 16-bit continuation training can be a key solution for sustainable and efficient deep learning, offering a practical way to enhance pre-trained models rapidly and in a resource-conscious manner.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18587"
  },
  "2311.18580": {
    "title": "FFT: Towards Harmlessness Evaluation and Analysis for LLMs with Factuality, Fairness, Toxicity",
    "authors": [
      "Shiyao Cui",
      "Zhenyu Zhang",
      "Yilong Chen",
      "Wenyuan Zhang",
      "Tianyun Liu",
      "Siqi Wang",
      "Tingwen Liu"
    ],
    "abstract": "The widespread of generative artificial intelligence has heightened concerns about the potential harms posed by AI-generated texts, primarily stemming from factoid, unfair, and toxic content. Previous researchers have invested much effort in assessing the harmlessness of generative language models. However, existing benchmarks are struggling in the era of large language models (LLMs), due to the stronger language generation and instruction following capabilities, as well as wider applications. In this paper, we propose FFT, a new benchmark with 2116 elaborated-designed instances, for LLM harmlessness evaluation with factuality, fairness, and toxicity. To investigate the potential harms of LLMs, we evaluate 9 representative LLMs covering various parameter scales, training stages, and creators. Experiments show that the harmlessness of LLMs is still under-satisfactory, and extensive analysis derives some insightful findings that could inspire future research for harmless LLM research.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18580"
  },
  "2311.18574": {
    "title": "Multi-scale Iterative Refinement towards Robust and Versatile Molecular Docking",
    "authors": [
      "Jiaxian Yan",
      "Zaixi Zhang",
      "Kai Zhang",
      "Qi Liu"
    ],
    "abstract": "Molecular docking is a key computational tool utilized to predict the binding conformations of small molecules to protein targets, which is fundamental in the design of novel drugs. Despite recent advancements in geometric deep learning-based approaches leading to improvements in blind docking efficiency, these methods have encountered notable challenges, such as limited generalization performance on unseen proteins, the inability to concurrently address the settings of blind docking and site-specific docking, and the frequent occurrence of physical implausibilities such as inter-molecular steric clash. In this study, we introduce DeltaDock, a robust and versatile framework designed for efficient molecular docking to overcome these challenges. DeltaDock operates in a two-step process: rapid initial complex structures sampling followed by multi-scale iterative refinement of the initial structures. In the initial stage, to sample accurate structures with high efficiency, we develop a ligand-dependent binding site prediction model founded on large protein models and graph neural networks. This model is then paired with GPU-accelerated sampling algorithms. The sampled structures are updated using a multi-scale iterative refinement module that captures both protein-ligand atom-atom interactions and residue-atom interactions in the following stage. Distinct from previous geometric deep learning methods that are conditioned on the blind docking setting, DeltaDock demonstrates superior performance in both blind docking and site-specific docking settings. Comprehensive experimental results reveal that DeltaDock consistently surpasses baseline methods in terms of docking accuracy. Furthermore, it displays remarkable generalization capabilities and proficiency for predicting physically valid structures, thereby attesting to its robustness and reliability in various scenarios.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18574"
  },
  "2311.18572": {
    "title": "Overcoming Label Noise for Source-free Unsupervised Video Domain Adaptation",
    "authors": [
      "Avijit Dasgupta",
      "C. V. Jawahar",
      "Karteek Alahari"
    ],
    "abstract": "Despite the progress seen in classification methods, current approaches for handling videos with distribution shifts in source and target domains remain source-dependent as they require access to the source data during the adaptation stage. In this paper, we present a self-training based source-free video domain adaptation approach to address this challenge by bridging the gap between the source and the target domains. We use the source pre-trained model to generate pseudo-labels for the target domain samples, which are inevitably noisy. Thus, we treat the problem of source-free video domain adaptation as learning from noisy labels and argue that the samples with correct pseudo-labels can help us in adaptation. To this end, we leverage the cross-entropy loss as an indicator of the correctness of the pseudo-labels and use the resulting small-loss samples from the target domain for fine-tuning the model. We further enhance the adaptation performance by implementing a teacher-student framework, in which the teacher, which is updated gradually, produces reliable pseudo-labels. Meanwhile, the student undergoes fine-tuning on the target domain videos using these generated pseudo-labels to improve its performance. Extensive experimental evaluations show that our methods, termed as CleanAdapt, CleanAdapt + TS, achieve state-of-the-art results, outperforming the existing approaches on various open datasets. Our source code is publicly available at https://avijit9.github.io/CleanAdapt.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18572"
  },
  "2311.18567": {
    "title": "Grammatical Gender's Influence on Distributional Semantics: A Causal Perspective",
    "authors": [
      "Karolina Sta\u0144czak",
      "Kevin Du",
      "Adina Williams",
      "Isabelle Augenstein",
      "Ryan Cotterell"
    ],
    "abstract": "How much meaning influences gender assignment across languages is an active area of research in modern linguistics and cognitive science. We can view current approaches as aiming to determine where gender assignment falls on a spectrum, from being fully arbitrarily determined to being largely semantically determined. For the latter case, there is a formulation of the neo-Whorfian hypothesis, which claims that even inanimate noun gender influences how people conceive of and talk about objects (using the choice of adjective used to modify inanimate nouns as a proxy for meaning). We offer a novel, causal graphical model that jointly represents the interactions between a noun's grammatical gender, its meaning, and adjective choice. In accordance with past results, we find a relationship between the gender of nouns and the adjectives which modify them. However, when we control for the meaning of the noun, we find that grammatical gender has a near-zero effect on adjective choice, thereby calling the neo-Whorfian hypothesis into question.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18567"
  },
  "2311.18565": {
    "title": "A Formulation of Structural Design Optimization Problems for Quantum Annealing",
    "authors": [
      "Fabian Key",
      "Lukas Freinberger"
    ],
    "abstract": "We present a novel formulation of structural design optimization problems specifically tailored to be solved by quantum annealing (QA). Structural design optimization aims to find the best, i.e., material-efficient yet high-performance, configuration of a structure. To this end, computational optimization strategies can be employed, where a recently evolving strategy based on quantum mechanical effects is QA. This approach requires the optimization problem to be present, e.g., as a quadratic unconstrained binary optimization (QUBO) model. Thus, we develop a novel formulation of the optimization problem. The latter typically involves an analysis model for the component. Here, we use energy minimization principles that govern the behavior of structures under applied loads. This allows us to state the optimization problem as one overall minimization problem. Next, we map this to a QUBO problem that can be immediately solved by QA. We validate the proposed approach using a size optimization problem of a compound rod under self-weight loading. To this end, we develop strategies to account for the limitations of currently available hardware and find that the presented formulation is suitable for solving structural design optimization problems through QA and, for small-scale problems, already works on today's hardware.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18565"
  },
  "2311.18564": {
    "title": "Seam-guided local alignment and stitching for large parallax images",
    "authors": [
      "Tianli Liao",
      "Chenyang Zhao",
      "Lei Li",
      "Heling Cao"
    ],
    "abstract": "Seam-cutting methods have been proven effective in the composition step of image stitching, especially for images with parallax. However, the effectiveness of seam-cutting usually depends on that images can be roughly aligned such that there exists a local region where a plausible seam can be found. For images with large parallax, current alignment methods often fall short of expectations. In this paper, we propose a local alignment and stitching method guided by seam quality evaluation. First, we use existing image alignment and seam-cutting methods to calculate an initial seam and evaluate the quality of pixels along the seam. Then, for pixels with low qualities, we separate their enclosing patches in the aligned images and locally align them by extracting modified dense correspondences via SIFT flow. Finally, we composite the aligned patches via seam-cutting and merge them into the original aligned result to generate the final mosaic. Experiments show that compared with the state-of-the-art seam-cutting methods, our result is more plausible and with fewer artifacts. The code will be available at https://github.com/tlliao/Seam-guided-local-alignment.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18564"
  },
  "2311.18559": {
    "title": "FediOS: Decoupling Orthogonal Subspaces for Personalization in Feature-skew Federated Learning",
    "authors": [
      "Lingzhi Gao",
      "Zexi Li",
      "Yang Lu",
      "Chao Wu"
    ],
    "abstract": "Personalized federated learning (pFL) enables collaborative training among multiple clients to enhance the capability of customized local models. In pFL, clients may have heterogeneous (also known as non-IID) data, which poses a key challenge in how to decouple the data knowledge into generic knowledge for global sharing and personalized knowledge for preserving local personalization. A typical way of pFL focuses on label distribution skew, and they adopt a decoupling scheme where the model is split into a common feature extractor and two prediction heads (generic and personalized). However, such a decoupling scheme cannot solve the essential problem of feature skew heterogeneity, because a common feature extractor cannot decouple the generic and personalized features. Therefore, in this paper, we rethink the architecture decoupling design for feature-skew pFL and propose an effective pFL method called FediOS. In FediOS, we reformulate the decoupling into two feature extractors (generic and personalized) and one shared prediction head. Orthogonal projections are used for clients to map the generic features into one common subspace and scatter the personalized features into different subspaces to achieve decoupling for them. In addition, a shared prediction head is trained to balance the importance of generic and personalized features during inference. Extensive experiments on four vision datasets demonstrate our method reaches state-of-the-art pFL performances under feature skew heterogeneity.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18559"
  },
  "2311.18558": {
    "title": "Learning Radio Environments by Differentiable Ray Tracing",
    "authors": [
      "Jakob Hoydis",
      "Fay\u00e7al A\u00eft Aoudia",
      "Sebastian Cammerer",
      "Florian Euchner",
      "Merlin Nimier-David",
      "Stephan ten Brink",
      "Alexander Keller"
    ],
    "abstract": "Ray tracing (RT) is instrumental in 6G research in order to generate spatially-consistent and environment-specific channel impulse responses (CIRs). While acquiring accurate scene geometries is now relatively straightforward, determining material characteristics requires precise calibration using channel measurements. We therefore introduce a novel gradient-based calibration method, complemented by differentiable parametrizations of material properties, scattering and antenna patterns. Our method seamlessly integrates with differentiable ray tracers that enable the computation of derivatives of CIRs with respect to these parameters. Essentially, we approach field computation as a large computational graph wherein parameters are trainable akin to weights of a neural network (NN). We have validated our method using both synthetic data and real-world indoor channel measurements, employing a distributed multiple-input multiple-output (MIMO) channel sounder.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18558"
  },
  "2311.18557": {
    "title": "Can semi-supervised learning use all the data effectively? A lower bound perspective",
    "authors": [
      "Alexandru \u0162ifrea",
      "Gizem Y\u00fcce",
      "Amartya Sanyal",
      "Fanny Yang"
    ],
    "abstract": "Prior works have shown that semi-supervised learning algorithms can leverage unlabeled data to improve over the labeled sample complexity of supervised learning (SL) algorithms. However, existing theoretical analyses focus on regimes where the unlabeled data is sufficient to learn a good decision boundary using unsupervised learning (UL) alone. This begs the question: Can SSL algorithms simultaneously improve upon both UL and SL? To this end, we derive a tight lower bound for 2-Gaussian mixture models that explicitly depends on the labeled and the unlabeled dataset size as well as the signal-to-noise ratio of the mixture distribution. Surprisingly, our result implies that no SSL algorithm can improve upon the minimax-optimal statistical error rates of SL or UL algorithms for these distributions. Nevertheless, we show empirically on real-world data that SSL algorithms can still outperform UL and SL methods. Therefore, our work suggests that, while proving performance gains for SSL algorithms is possible, it requires careful tracking of constants.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18557"
  },
  "2311.18553": {
    "title": "Heterogeneous Graph-based Trajectory Prediction using Local Map Context and Social Interactions",
    "authors": [
      "Daniel Grimm",
      "Maximilian Zipfl",
      "Felix Hertlein",
      "Alexander Naumann",
      "J\u00fcrgen L\u00fcttin",
      "Steffen Thoma",
      "Stefan Schmid",
      "Lavdim Halilaj",
      "Achim Rettinger",
      "J. Marius Z\u00f6llner"
    ],
    "abstract": "Precisely predicting the future trajectories of surrounding traffic participants is a crucial but challenging problem in autonomous driving, due to complex interactions between traffic agents, map context and traffic rules. Vector-based approaches have recently shown to achieve among the best performances on trajectory prediction benchmarks. These methods model simple interactions between traffic agents but don't distinguish between relation-type and attributes like their distance along the road. Furthermore, they represent lanes only by sequences of vectors representing center lines and ignore context information like lane dividers and other road elements. We present a novel approach for vector-based trajectory prediction that addresses these shortcomings by leveraging three crucial sources of information: First, we model interactions between traffic agents by a semantic scene graph, that accounts for the nature and important features of their relation. Second, we extract agent-centric image-based map features to model the local map context. Finally, we generate anchor paths to enforce the policy in multi-modal prediction to permitted trajectories only. Each of these three enhancements shows advantages over the baseline model HoliGraph.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18553"
  },
  "2311.18550": {
    "title": "Search Still Matters: Information Retrieval in the Era of Generative AI",
    "authors": [
      "William R. Hersh"
    ],
    "abstract": "Objective: Information retrieval (IR, also known as search) systems are ubiquitous in modern times. How does the emergence of generative artificial intelligence (AI), based on large language models (LLMs), fit into the IR process? Process: This perspective explores the use of generative AI in the context of the motivations, considerations, and outcomes of the IR process with a focus on the academic use of such systems. Conclusions: There are many information needs, from simple to complex, that motivate use of IR. Users of such systems, particularly academics, have concerns for authoritativeness, timeliness, and contextualization of search. While LLMs may provide functionality that aids the IR process, the continued need for search systems, and research into their improvement, remains essential.\n        \u25b3 Less",
    "submission_date": "17 December, 2023",
    "eprint_id": "2311.18550"
  },
  "2311.18547": {
    "title": "Real-Time Vibration-Based Bearing Fault Diagnosis Under Time-Varying Speed Conditions",
    "authors": [
      "Tuomas Jalonen",
      "Mohammad Al-Sa'd",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "abstract": "Detection of rolling-element bearing faults is crucial for implementing proactive maintenance strategies and for minimizing the economic and operational consequences of unexpected failures. However, many existing techniques are developed and tested under strictly controlled conditions, limiting their adaptability to the diverse and dynamic settings encountered in practical applications. This paper presents an efficient real-time convolutional neural network (CNN) for diagnosing multiple bearing faults under various noise levels and time-varying rotational speeds. Additionally, we propose a novel Fisher-based spectral separability analysis (SSA) method to elucidate the effectiveness of the designed CNN model. We conducted experiments on both healthy bearings and bearings afflicted with inner race, outer race, and roller ball faults. The experimental results show the superiority of our model over the current state-of-the-art approach in three folds: it achieves substantial accuracy gains of up to 15.8%, it is robust to noise with high performance across various signal-to-noise ratios, and it runs in real-time with processing durations five times less than acquisition. Additionally, by using the proposed SSA technique, we offer insights into the model's performance and underscore its effectiveness in tackling real-world challenges.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18547"
  },
  "2311.18545": {
    "title": "Decentralized Deepfake Detection Blockchain Network using Dynamic Algorithm management",
    "authors": [
      "Dipankar Sarkar"
    ],
    "abstract": "Deepfake technology is a major threat to the integrity of digital media. This paper presents a comprehensive framework for a blockchain-based decentralized system designed to tackle the escalating challenge of digital content integrity. The proposed system integrates advanced deep learning algorithms with the immutable and transparent nature of blockchain technology to create a trustless environment where authenticity can be verified without relying on a single centralized authority. Furthermore, the system utilizes smart contracts for dynamic algorithm management and token-based incentives further enhances the system's effectiveness and adaptability. The decentralized architecture of the system democratizes the process of verifying digital content and introduces a novel approach to combat deepfakes. The collaborative and adjustable nature of this system sets a new benchmark for digital media integrity, offering a more robust digital media environment.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2311.18545"
  },
  "2311.18543": {
    "title": "CrimeGraphNet: Link Prediction in Criminal Networks with Graph Convolutional Networks",
    "authors": [
      "Chen Yang"
    ],
    "abstract": "In this paper, we introduce CrimeGraphNet, a novel approach for link prediction in criminal networks utilizingGraph Convolutional Networks (GCNs). Criminal networks are intricate and dynamic, with covert links that are challenging to uncover. Accurate prediction of these links can aid in proactive crime prevention and investigation. Existing methods often fail to capture the complex interconnections in such networks. They also struggle in scenarios where only limited labeled data is available for training. To address these challenges, we propose CrimeGraphNet, which leverages the power of GCNs for link prediction in these networks. The GCNmodel effectively captures topological features and node characteristics, making it well-suited for this task. We evaluate CrimeGraphNet on several real-world criminal network datasets. Our results demonstrate that CrimeGraphNet outperforms existing methods in terms of prediction accuracy, robustness, and computational efAciency. Furthermore, our approach enables the extraction of meaningful insights from the predicted links, thereby contributing to a better understanding of the underlying criminal activities. Overall, CrimeGraphNet represents a signiAcant step forward in the use of deep learning for criminal network analysis.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18543"
  },
  "2311.18542": {
    "title": "RIS-Assisted Generalized Receive Quadrature Spatial Modulation",
    "authors": [
      "Mohamad H. Dinan",
      "Mark F. Flanagan"
    ],
    "abstract": "In this paper, reconfigurable intelligent surface (RIS)-assisted generalized receive quadrature spatial modulation (RIS-GRQSM) is proposed to improve the spectral efficiency of RIS-aided quadrature spatial modulation (QSM) systems by utilizing the concept of generalized spatial modulation (GSM). That is, multiple antennas are activated at the receiver independently for both the real and imaginary parts. We propose a max-min optimization problem to adjust the phase shifts of all RIS elements to maximize the relevant signal-to-noise ratios (SNRs) at all activated receive antennas. Using Lagrange duality, the non-convex optimization problem involving the phase shifts of all RIS elements reduces to a convex optimization involving a number of variables equal to the number of activated receive antennas. A successive greedy detector (GD) can be used at the receiver to detect the active antennas, which simplifies the detection process. The numerical results show that the proposed scheme outperforms the benchmark schemes in terms of error rate performance, especially in systems with a larger number of receive antennas. In the special case where each receive antenna corresponds to a user and is activated, the RIS-GRQSM system becomes a multicast communication system. In this context, in contrast to existing phase shift optimization algorithms which exhibit an impractical level of complexity, our proposed solution offers the advantage of low complexity and practical feasibility of implementation.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18542"
  },
  "2311.18540": {
    "title": "Match me if you can: Semantic Correspondence Learning with Unpaired Images",
    "authors": [
      "Jiwon Kim",
      "Byeongho Heo",
      "Sangdoo Yun",
      "Seungryong Kim",
      "Dongyoon Han"
    ],
    "abstract": "Recent approaches for semantic correspondence have focused on obtaining high-quality correspondences using a complicated network, refining the ambiguous or noisy matching points. Despite their performance improvements, they remain constrained by the limited training pairs due to costly point-level annotations. This paper proposes a simple yet effective method that performs training with unlabeled pairs to complement both limited image pairs and sparse point pairs, requiring neither extra labeled keypoints nor trainable modules. We fundamentally extend the data quantity and variety by augmenting new unannotated pairs not primitively provided as training pairs in benchmarks. Using a simple teacher-student framework, we offer reliable pseudo correspondences to the student network via machine supervision. Finally, the performance of our network is steadily improved by the proposed iterative training, putting back the student as a teacher to generate refined labels and train a new student repeatedly. Our models outperform the milestone baselines, including state-of-the-art methods on semantic correspondence benchmarks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18540"
  },
  "2311.18539": {
    "title": "Bridging Both Worlds in Semantics and Time: Domain Knowledge Based Analysis and Correlation of Industrial Process Attacks",
    "authors": [
      "Moses Ike",
      "Kandy Phan",
      "Anwesh Badapanda",
      "Matthew Landen",
      "Keaton Sadoski",
      "Wanda Guo",
      "Asfahan Shah",
      "Saman Zonouz",
      "Wenke Lee"
    ],
    "abstract": "Modern industrial control systems (ICS) attacks infect supervisory control and data acquisition (SCADA) hosts to stealthily alter industrial processes, causing damage. To detect attacks with low false alarms, recent work detects attacks in both SCADA and process data. Unfortunately, this led to the same problem - disjointed (false) alerts, due to the semantic and time gap in SCADA and process behavior, i.e., SCADA execution does not map to process dynamics nor evolve at similar time scales. We propose BRIDGE to analyze and correlate SCADA and industrial process attacks using domain knowledge to bridge their unique semantic and time evolution. This enables operators to tie malicious SCADA operations to their adverse process effects, which reduces false alarms and improves attack understanding. BRIDGE (i) identifies process constraints violations in SCADA by measuring actuation dependencies in SCADA process-control, and (ii) detects malicious SCADA effects in processes via a physics-informed neural network that embeds generic knowledge of inertial process dynamics. BRIDGE then dynamically aligns both analysis (i and ii) in a time-window that adjusts their time evolution based on process inertial delays. We applied BRIDGE to 11 diverse real-world industrial processes, and adaptive attacks inspired by past events. BRIDGE correlated 98.3% of attacks with 0.8% false positives (FP), compared to 78.3% detection accuracy and 13.7% FP of recent work.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2311.18539"
  },
  "2311.18533": {
    "title": "A knowledge-driven framework for synthesizing designs from modular components",
    "authors": [
      "Constantin Chaumet",
      "Jakob Rehof",
      "Thomas Schuster"
    ],
    "abstract": "Creating a design from modular components necessitates three steps: Acquiring knowledge about available components, conceiving an abstract design concept, and implementing that concept in a concrete design. The third step entails many repetitive and menial tasks, such as inserting parts and creating joints between them. Especially when comparing and implementing design alternatives, this issue is compounded. We propose a use-case agnostic knowledge-driven framework to automate the implementation step. In particular, the framework catalogues the acquired knowledge and the design concept, as well as utilizes Combinatory Logic Synthesis to synthesize concrete design alternatives. This minimizes the effort required to create designs, allowing the design space to be thoroughly explored. We implemented the framework as a plugin for the CAD software Autodesk Fusion 360. We conducted a case study in which robotic arms were synthesized from a set of 28 modular components. Based on the case study, the applicability of the framework is analyzed and discussed.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18533"
  },
  "2311.18525": {
    "title": "Detecting Anomalous Network Communication Patterns Using Graph Convolutional Networks",
    "authors": [
      "Yizhak Vaisman",
      "Gilad Katz",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "To protect an organizations' endpoints from sophisticated cyberattacks, advanced detection methods are required. In this research, we present GCNetOmaly: a graph convolutional network (GCN)-based variational autoencoder (VAE) anomaly detector trained on data that include connection events among internal and external machines. As input, the proposed GCN-based VAE model receives two matrices: (i) the normalized adjacency matrix, which represents the connections among the machines, and (ii) the feature matrix, which includes various features (demographic, statistical, process-related, and Node2vec structural features) that are used to profile the individual nodes/machines. After training the model on data collected for a predefined time window, the model is applied on the same data; the reconstruction score obtained by the model for a given machine then serves as the machine's anomaly score. GCNetOmaly was evaluated on real, large-scale data logged by Carbon Black EDR from a large financial organization's automated teller machines (ATMs) as well as communication with Active Directory (AD) servers in two setups: unsupervised and supervised. The results of our evaluation demonstrate GCNetOmaly's effectiveness in detecting anomalous behavior of machines on unsupervised data.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18525"
  },
  "2311.18524": {
    "title": "Matrix discrepancy and the log-rank conjecture",
    "authors": [
      "Benny Sudakov",
      "Istv\u00e1n Tomon"
    ],
    "abstract": "Given an $m\\times n$ binary matrix $M$ with $|M|=p\\cdot mn$ (where $|M|$ denotes the number of 1 entries), define the discrepancy of $M$ as $\\mbox{disc}(M)=\\displaystyle\\max_{X\\subset [m], Y\\subset [n]}\\big||M[X\\times Y]|-p|X|\\cdot |Y|\\big|$. Using semidefinite programming and spectral techniques, we prove that if $\\mbox{rank}(M)\\leq r$ and $p\\leq 1/2$, then\n  $$\\mbox{disc}(M)\\geq \u03a9(mn)\\cdot \\min\\left\\{p,\\frac{p^{1/2}}{\\sqrt{r}}\\right\\}.$$\n  We use this result to obtain a modest improvement of Lovett's best known upper bound on the log-rank conjecture. We prove that any $m\\times n$ binary matrix $M$ of rank at most $r$ contains an $(m\\cdot 2^{-O(\\sqrt{r})})\\times (n\\cdot 2^{-O(\\sqrt{r})})$ sized all-1 or all-0 submatrix, which implies that the deterministic communication complexity of any Boolean function of rank $r$ is at most $O(\\sqrt{r})$.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18524"
  },
  "2311.18521": {
    "title": "Combining deep generative models with extreme value theory for synthetic hazard simulation: a multivariate and spatially coherent approach",
    "authors": [
      "Alison Peard",
      "Jim Hall"
    ],
    "abstract": "Climate hazards can cause major disasters when they occur simultaneously as compound hazards. To understand the distribution of climate risk and inform adaptation policies, scientists need to simulate a large number of physically realistic and spatially coherent events. Current methods are limited by computational constraints and the probabilistic spatial distribution of compound events is not given sufficient attention. The bottleneck in current approaches lies in modelling the dependence structure between variables, as inference on parametric models suffers from the curse of dimensionality. Generative adversarial networks (GANs) are well-suited to such a problem due to their ability to implicitly learn the distribution of data in high-dimensional settings. We employ a GAN to model the dependence structure for daily maximum wind speed, significant wave height, and total precipitation over the Bay of Bengal, combining this with traditional extreme value theory for controlled extrapolation of the tails. Once trained, the model can be used to efficiently generate thousands of realistic compound hazard events, which can inform climate risk assessments for climate adaptation and disaster preparedness. The method developed is flexible and transferable to other multivariate and spatial climate datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18521"
  },
  "2311.18520": {
    "title": "Calibration-free online test-time adaptation for electroencephalography motor imagery decoding",
    "authors": [
      "Martin Wimpff",
      "Mario D\u00f6bler",
      "Bin Yang"
    ],
    "abstract": "Providing a promising pathway to link the human brain with external devices, Brain-Computer Interfaces (BCIs) have seen notable advancements in decoding capabilities, primarily driven by increasingly sophisticated techniques, especially deep learning. However, achieving high accuracy in real-world scenarios remains a challenge due to the distribution shift between sessions and subjects. In this paper we will explore the concept of online test-time adaptation (OTTA) to continuously adapt the model in an unsupervised fashion during inference time. Our approach guarantees the preservation of privacy by eliminating the requirement to access the source data during the adaptation process. Additionally, OTTA achieves calibration-free operation by not requiring any session- or subject-specific data. We will investigate the task of electroencephalography (EEG) motor imagery decoding using a lightweight architecture together with different OTTA techniques like alignment, adaptive batch normalization, and entropy minimization. We examine two datasets and three distinct data settings for a comprehensive analysis. Our adaptation methods produce state-of-the-art results, potentially instigating a shift in transfer learning for BCI decoding towards online adaptation.\n        \u25b3 Less",
    "submission_date": "8 January, 2024",
    "eprint_id": "2311.18520"
  },
  "2311.18518": {
    "title": "Color-Emotion Associations in Art: Fuzzy Approach",
    "authors": [
      "Muragul Muratbekova",
      "Pakizar Shamoi"
    ],
    "abstract": "Art objects can evoke certain emotions. Color is a fundamental element of visual art and plays a significant role in how art is perceived. This paper introduces a novel approach to classifying emotions in art using Fuzzy Sets. We employ a fuzzy approach because it aligns well with human judgments' imprecise and subjective nature. Extensive fuzzy colors (n=120) and a broad emotional spectrum (n=10) allow for a more human-consistent and context-aware exploration of emotions inherent in paintings. First, we introduce the fuzzy color representation model. Then, at the fuzzification stage, we process the Wiki Art Dataset of paintings tagged with emotions, extracting fuzzy dominant colors linked to specific emotions. This results in fuzzy color distributions for ten emotions. Finally, we convert them back to a crisp domain, obtaining a knowledge base of color-emotion associations in primary colors. Our findings reveal strong associations between specific emotions and colors; for instance, gratitude strongly correlates with green, brown, and orange. Other noteworthy associations include brown and anger, orange with shame, yellow with happiness, and gray with fear. Using these associations and Jaccard similarity, we can find the emotions in the arbitrary untagged image. We conducted a 2AFC experiment involving human subjects to evaluate the proposed method. The average hit rate of 0.77 indicates a significant correlation between the method's predictions and human perception. The proposed method is simple to adapt to art painting retrieval systems. The study contributes to the theoretical understanding of color-emotion associations in art, offering valuable insights for various practical applications besides art, like marketing, design, and psychology.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18518"
  },
  "2311.18512": {
    "title": "Revisiting Proposal-based Object Detection",
    "authors": [
      "Aritra Bhowmik",
      "Martin R. Oswald",
      "Pascal Mettes",
      "Cees G. M. Snoek"
    ],
    "abstract": "This paper revisits the pipeline for detecting objects in images with proposals. For any object detector, the obtained box proposals or queries need to be classified and regressed towards ground truth boxes. The common solution for the final predictions is to directly maximize the overlap between each proposal and the ground truth box, followed by a winner-takes-all ranking or non-maximum suppression. In this work, we propose a simple yet effective alternative. For proposal regression, we solve a simpler problem where we regress to the area of intersection between proposal and ground truth. In this way, each proposal only specifies which part contains the object, avoiding a blind inpainting problem where proposals need to be regressed beyond their visual scope. In turn, we replace the winner-takes-all strategy and obtain the final prediction by taking the union over the regressed intersections of a proposal group surrounding an object. Our revisited approach comes with minimal changes to the detection pipeline and can be plugged into any existing method. We show that our approach directly improves canonical object detection and instance segmentation architectures, highlighting the utility of intersection-based regression and grouping.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18512"
  },
  "2311.18508": {
    "title": "DifAugGAN: A Practical Diffusion-style Data Augmentation for GAN-based Single Image Super-resolution",
    "authors": [
      "Axi Niu",
      "Kang Zhang",
      "Joshua Tian Jin Tee",
      "Trung X. Pham",
      "Jinqiu Sun",
      "Chang D. Yoo",
      "In So Kweon",
      "Yanning Zhang"
    ],
    "abstract": "It is well known the adversarial optimization of GAN-based image super-resolution (SR) methods makes the preceding SR model generate unpleasant and undesirable artifacts, leading to large distortion. We attribute the cause of such distortions to the poor calibration of the discriminator, which hampers its ability to provide meaningful feedback to the generator for learning high-quality images. To address this problem, we propose a simple but non-travel diffusion-style data augmentation scheme for current GAN-based SR methods, known as DifAugGAN. It involves adapting the diffusion process in generative diffusion models for improving the calibration of the discriminator during training motivated by the successes of data augmentation schemes in the field to achieve good calibration. Our DifAugGAN can be a Plug-and-Play strategy for current GAN-based SISR methods to improve the calibration of the discriminator and thus improve SR performance. Extensive experimental evaluations demonstrate the superiority of DifAugGAN over state-of-the-art GAN-based SISR methods across both synthetic and real-world datasets, showcasing notable advancements in both qualitative and quantitative results.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18508"
  },
  "2311.18506": {
    "title": "Global Convergence of Online Identification for Mixed Linear Regression",
    "authors": [
      "Yujing Liu",
      "Zhixin Liu",
      "Lei Guo"
    ],
    "abstract": "Mixed linear regression (MLR) is a powerful model for characterizing nonlinear relationships by utilizing a mixture of linear regression sub-models. The identification of MLR is a fundamental problem, where most of the existing results focus on offline algorithms, rely on independent and identically distributed (i.i.d) data assumptions, and provide local convergence results only. This paper investigates the online identification and data clustering problems for two basic classes of MLRs, by introducing two corresponding new online identification algorithms based on the expectation-maximization (EM) principle. It is shown that both algorithms will converge globally without resorting to the traditional i.i.d data assumptions. The main challenge in our investigation lies in the fact that the gradient of the maximum likelihood function does not have a unique zero, and a key step in our analysis is to establish the stability of the corresponding differential equation in order to apply the celebrated Ljung's ODE method. It is also shown that the within-cluster error and the probability that the new data is categorized into the correct cluster are asymptotically the same as those in the case of known parameters. Finally, numerical simulations are provided to verify the effectiveness of our online algorithms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18506"
  },
  "2311.18505": {
    "title": "String Sound Synthesizer on GPU-accelerated Finite Difference Scheme",
    "authors": [
      "Jin Woo Lee",
      "Min Jun Choi",
      "Kyogu Lee"
    ],
    "abstract": "This paper introduces a nonlinear string sound synthesizer, based on a finite difference simulation of the dynamic behavior of strings under various excitations. The presented synthesizer features a versatile string simulation engine capable of stochastic parameterization, encompassing fundamental frequency modulation, stiffness, tension, frequency-dependent loss, and excitation control. This open-source physical model simulator not only benefits the audio signal processing community but also contributes to the burgeoning field of neural network-based audio synthesis by serving as a novel dataset construction tool. Implemented in PyTorch, this synthesizer offers flexibility, facilitating both CPU and GPU utilization, thereby enhancing its applicability as a simulator. GPU utilization expedites computation by parallelizing operations across spatial and batch dimensions, further enhancing its utility as a data generator.\n        \u25b3 Less",
    "submission_date": "8 January, 2024",
    "eprint_id": "2311.18505"
  },
  "2311.18503": {
    "title": "End-to-End Retrieval with Learned Dense and Sparse Representations Using Lucene",
    "authors": [
      "Haonan Chen",
      "Carlos Lassance",
      "Jimmy Lin"
    ],
    "abstract": "The bi-encoder architecture provides a framework for understanding machine-learned retrieval models based on dense and sparse vector representations. Although these representations capture parametric realizations of the same underlying conceptual framework, their respective implementations of top-$k$ similarity search require the coordination of different software components (e.g., inverted indexes, HNSW indexes, and toolkits for neural inference), often knitted together in complex architectures. In this work, we ask the following question: What's the simplest design, in terms of requiring the fewest changes to existing infrastructure, that can support end-to-end retrieval with modern dense and sparse representations? The answer appears to be that Lucene is sufficient, as we demonstrate in Anserini, a toolkit for reproducible information retrieval research. That is, effective retrieval with modern single-vector neural models can be efficiently performed directly in Java on the CPU. We examine the implications of this design for information retrieval researchers pushing the state of the art as well as for software engineers building production search systems.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18503"
  },
  "2311.18498": {
    "title": "Data-Agnostic Model Poisoning against Federated Learning: A Graph Autoencoder Approach",
    "authors": [
      "Kai Li",
      "Jingjing Zheng",
      "Xin Yuan",
      "Wei Ni",
      "Ozgur B. Akan",
      "H. Vincent Poor"
    ],
    "abstract": "This paper proposes a novel, data-agnostic, model poisoning attack on Federated Learning (FL), by designing a new adversarial graph autoencoder (GAE)-based framework. The attack requires no knowledge of FL training data and achieves both effectiveness and undetectability. By listening to the benign local models and the global model, the attacker extracts the graph structural correlations among the benign local models and the training data features substantiating the models. The attacker then adversarially regenerates the graph structural correlations while maximizing the FL training loss, and subsequently generates malicious local models using the adversarial graph structure and the training data features of the benign ones. A new algorithm is designed to iteratively train the malicious local models using GAE and sub-gradient descent. The convergence of FL under attack is rigorously proved, with a considerably large optimality gap. Experiments show that the FL accuracy drops gradually under the proposed attack and existing defense mechanisms fail to detect it. The attack can give rise to an infection across all benign devices, making it a serious threat to FL.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18498"
  },
  "2311.18494": {
    "title": "PRS: Sharp Feature Priors for Resolution-Free Surface Remeshing",
    "authors": [
      "Natalia Soboleva",
      "Olga Gorbunova",
      "Maria Ivanova",
      "Evgeny Burnaev",
      "Matthias Nie\u00dfner",
      "Denis Zorin",
      "Alexey Artemov"
    ],
    "abstract": "Surface reconstruction with preservation of geometric features is a challenging computer vision task. Despite significant progress in implicit shape reconstruction, state-of-the-art mesh extraction methods often produce aliased, perceptually distorted surfaces and lack scalability to high-resolution 3D shapes. We present a data-driven approach for automatic feature detection and remeshing that requires only a coarse, aliased mesh as input and scales to arbitrary resolution reconstructions. We define and learn a collection of surface-based fields to (1) capture sharp geometric features in the shape with an implicit vertexwise model and (2) approximate improvements in normals alignment obtained by applying edge-flips with an edgewise model. To support scaling to arbitrary complexity shapes, we learn our fields using local triangulated patches, fusing estimates on complete surface meshes. Our feature remeshing algorithm integrates the learned fields as sharp feature priors and optimizes vertex placement and mesh connectivity for maximum expected surface improvement. On a challenging collection of high-resolution shape reconstructions in the ABC dataset, our algorithm improves over state-of-the-art by 26% normals F-score and 42% perceptual $\\text{RMSE}_{\\text{v}}$.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18494"
  },
  "2311.18492": {
    "title": "CLS-CAD: Synthesizing CAD Assemblies in Fusion 360",
    "authors": [
      "Constantin Chaumet",
      "Jakob Rehof"
    ],
    "abstract": "The CAD design process includes a number of repetitive steps when creating assemblies. This issue is compounded when engineering whole product lines or design families, as steps like inserting parts common to all variations, such as fasteners and product-integral base parts, get repeated numerous times. This makes creating designs time-, and as a result, cost-intensive. While many CAD software packages have APIs, the effort of creating use-case specific plugins to automate creation of assemblies usually outweighs the benefit.\n  We developed a plugin for the CAD software package \"Fusion 360\" which tackles this issue. The plugin adds several graphical interfaces to Fusion 360 that allow parts to be annotated with types, subtype hierarchies to be managed, and requests to synthesize assembly programs for assemblies to be posed. The plugin is use-case agnostic and is able to generate arbitrary open kinematic chain structures. We envision engineers working with CAD software being able to make designed parts reusable and automate the generation of different design alternatives as well as whole product lines.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18492"
  },
  "2311.18491": {
    "title": "ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs",
    "authors": [
      "Violeta Men\u00e9ndez Gonz\u00e1lez",
      "Andrew Gilbert",
      "Graeme Phillipson",
      "Stephen Jolly",
      "Simon Hadfield"
    ],
    "abstract": "In the field of media production, video editing techniques play a pivotal role. Recent approaches have had great success at performing novel view image synthesis of static scenes. But adding temporal information adds an extra layer of complexity. Previous models have focused on implicitly representing static and dynamic scenes using NeRF. These models achieve impressive results but are costly at training and inference time. They overfit an MLP to describe the scene implicitly as a function of position. This paper proposes ZeST-NeRF, a new approach that can produce temporal NeRFs for new scenes without retraining. We can accurately reconstruct novel views using multi-view synthesis techniques and scene flow-field estimation, trained only with unrelated scenes. We demonstrate how existing state-of-the-art approaches from a range of fields cannot adequately solve this new task and demonstrate the efficacy of our solution. The resulting network improves quantitatively by 15% and produces significantly better visual results.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18491"
  },
  "2311.18488": {
    "title": "Low-Complexity Linear Programming Based Decoding of Quantum LDPC codes",
    "authors": [
      "Sana Javed",
      "Francisco Garcia-Herrero",
      "Bane Vasic",
      "Mark F. Flanagan"
    ],
    "abstract": "This paper proposes two approaches for reducing the impact of the error floor phenomenon when decoding quantum low-density parity-check codes with belief propagation based algorithms. First, a low-complexity syndrome-based linear programming (SB-LP) decoding algorithm is proposed, and second, the proposed SB-LP is applied as a post-processing step after syndrome-based min-sum (SB-MS) decoding. For the latter case, a new early stopping criterion is introduced to decide when to activate the SB-LP algorithm, avoiding executing a predefined maximum number of iterations for the SB-MS decoder. Simulation results show, for a sample hypergraph code, that the proposed decoder can lower the error floor by two to three orders of magnitude compared to SB-MS for the same total number of decoding iterations.\n        \u25b3 Less",
    "submission_date": "19 January, 2024",
    "eprint_id": "2311.18488"
  },
  "2311.18486": {
    "title": "New Perspectives on the Evaluation of Link Prediction Algorithms for Dynamic Graphs",
    "authors": [
      "Rapha\u00ebl Romero",
      "Tijl De Bie",
      "Jefrey Lijffijt"
    ],
    "abstract": "There is a fast-growing body of research on predicting future links in dynamic networks, with many new algorithms. Some benchmark data exists, and performance evaluations commonly rely on comparing the scores of observed network events (positives) with those of randomly generated ones (negatives). These evaluation measures depend on both the predictive ability of the model and, crucially, the type of negative samples used. Besides, as generally the case with temporal data, prediction quality may vary over time. This creates a complex evaluation space. In this work, we catalog the possibilities for negative sampling and introduce novel visualization methods that can yield insight into prediction performance and the dynamics of temporal networks. We leverage these visualization tools to investigate the effect of negative sampling on the predictive performance, at the node and edge level. We validate empirically, on datasets extracted from recent benchmarks that the error is typically not evenly distributed across different data segments. Finally, we argue that such visualization tools can serve as powerful guides to evaluate dynamic link prediction methods at different levels.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18486"
  },
  "2311.18484": {
    "title": "Nigerian Schizophrenia EEG Dataset (NSzED) Towards Data-Driven Psychiatry in Africa",
    "authors": [
      "E. O. Olateju",
      "K. P. Ayodele",
      "S. K. Mosaku"
    ],
    "abstract": "This work has been carried out to improve the dearth of high-quality EEG datasets used for schizophrenia diagnostic tools development and studies from populations of developing and underdeveloped regions of the world. To this aim, the presented dataset contains international 10/20 system EEG recordings from West African subjects of Nigerian origin in restful states, mental arithmetic task execution states and while passively reacting to auditory stimuli, the first of its kind from the region and continent. The subjects are divided into patients and healthy controls and recorded from 37 patients and 22 healthy control subjects identified by the Mini International Schizophrenia Interview (MINI) and also assessed by the Positive and Negative Symptoms Scale (PANSS) and the World Health Organization Disability Assessment Schedule (WHODAS). All patients are admitted schizophrenia patients of the Mental Health Ward, Medical Outpatient Department of the Obafemi Awolowo University Teaching Hospital Complex (OAUTHC, Ile-Ife) and its subsidiary Wesley Guild Hospital Unit (OAUTHC, Ilesa). Controls are drawn from students and clinicians who volunteered to participate in the study at the Mental Health Ward of OAUTHC and the Wesley Guild Hospital Unit. This dataset is the first version of the Nigerian schizophrenia dataset (NSzED) and can be used by the neuroscience and computational psychiatry research community studying the diagnosis and prognosis of schizophrenia using the electroencephalogram signal modality.\n        \u25b3 Less",
    "submission_date": "20 January, 2024",
    "eprint_id": "2311.18484"
  },
  "2311.18482": {
    "title": "Language Embedded 3D Gaussians for Open-Vocabulary Scene Understanding",
    "authors": [
      "Jin-Chuan Shi",
      "Miao Wang",
      "Hao-Bin Duan",
      "Shao-Hua Guan"
    ],
    "abstract": "Open-vocabulary querying in 3D space is challenging but essential for scene understanding tasks such as object localization and segmentation. Language-embedded scene representations have made progress by incorporating language features into 3D spaces. However, their efficacy heavily depends on neural networks that are resource-intensive in training and rendering. Although recent 3D Gaussians offer efficient and high-quality novel view synthesis, directly embedding language features in them leads to prohibitive memory usage and decreased performance. In this work, we introduce Language Embedded 3D Gaussians, a novel scene representation for open-vocabulary query tasks. Instead of embedding high-dimensional raw semantic features on 3D Gaussians, we propose a dedicated quantization scheme that drastically alleviates the memory requirement, and a novel embedding procedure that achieves smoother yet high accuracy query, countering the multi-view feature inconsistencies and the high-frequency inductive bias in point-based representations. Our comprehensive experiments show that our representation achieves the best visual quality and language querying accuracy across current language-embedded representations, while maintaining real-time rendering frame rates on a single desktop GPU.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18482"
  },
  "2311.18481": {
    "title": "ESG Accountability Made Easy: DocQA at Your Service",
    "authors": [
      "Lokesh Mishra",
      "Cesar Berrospi",
      "Kasper Dinkla",
      "Diego Antognini",
      "Francesco Fusco",
      "Benedikt Bothur",
      "Maksym Lysak",
      "Nikolaos Livathinos",
      "Ahmed Nassar",
      "Panagiotis Vagenas",
      "Lucas Morin",
      "Christoph Auer",
      "Michele Dolfi",
      "Peter Staar"
    ],
    "abstract": "We present Deep Search DocQA. This application enables information extraction from documents via a question-answering conversational assistant. The system integrates several technologies from different AI disciplines consisting of document conversion to machine-readable format (via computer vision), finding relevant data (via natural language processing), and formulating an eloquent response (via large language models). Users can explore over 10,000 Environmental, Social, and Governance (ESG) disclosure reports from over 2000 corporations. The Deep Search platform can be accessed at: https://ds4sd.github.io.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18481"
  },
  "2311.18480": {
    "title": "ESPiM: Eye-Strain Probation Model, An Eye-Tracking Analysis Measure for Digital Displays",
    "authors": [
      "Mohsen Parisay",
      "Negar Haghbin",
      "Charalambos Poullis",
      "Marta Kersten-Oertel"
    ],
    "abstract": "Eye-strain is a common issue among computer users due to the prolonged periods they spend working in front of digital displays. This can lead to vision problems, such as irritation and tiredness of the eyes and headaches. We propose the Eye-Strain Probation Model (ESPiM), a computational model based on eye-tracking data that measures eye-strain on digital displays based on the spatial properties of the user interface and display area for a required period of time. As well as measuring eye-strain, ESPiM can be applied to compare (a) different user interface designs, (b) different display devices, and (c) different interaction techniques. Two user studies were conducted to evaluate the effectiveness of ESPiM. The first was conducted in the form of an in-person study with an infrared eye-tracking sensor with 32 participants. The second was conducted in the form of an online study with a video-based eye-tracking technique via webcams on users' computers with 13 participants. Our analysis showed significantly different eye-strain patterns based on the video gameplay frequency of participants. Further, we found distinctive patterns among users on a regular 9-to-5 routine versus those with more flexible work hours in terms of (a) error rates and (b) reported eye-strain symptoms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18480"
  },
  "2311.18473": {
    "title": "DGMem: Learning Visual Navigation Policy without Any Labels by Dynamic Graph Memory",
    "authors": [
      "Wenzhe Cai",
      "Teng Wang",
      "Guangran Cheng",
      "Lele Xu",
      "Changyin Sun"
    ],
    "abstract": "In recent years, learning-based approaches have demonstrated significant promise in addressing intricate navigation tasks. Traditional methods for training deep neural network navigation policies rely on meticulously designed reward functions or extensive teleoperation datasets as navigation demonstrations. However, the former is often confined to simulated environments, and the latter demands substantial human labor, making it a time-consuming process. Our vision is for robots to autonomously learn navigation skills and adapt their behaviors to environmental changes without any human intervention. In this work, we discuss the self-supervised navigation problem and present Dynamic Graph Memory (DGMem), which facilitates training only with on-board observations. With the help of DGMem, agents can actively explore their surroundings, autonomously acquiring a comprehensive navigation policy in a data-efficient manner without external feedback. Our method is evaluated in photorealistic 3D indoor scenes, and empirical studies demonstrate the effectiveness of DGMem.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18473"
  },
  "2311.18471": {
    "title": "Enhancing the security of image transmission in Quantum era: A Chaos-Assisted QKD Approach using entanglement",
    "authors": [
      "Raiyan Rahman",
      "Md Shawmoon Azad",
      "Mohammed Rakibul Hasan",
      "Syed Emad Uddin Shubha",
      "M. R. C. Mahdy"
    ],
    "abstract": "The emergence of quantum computing has introduced unprecedented security challenges to conventional cryptographic systems, particularly in the domain of optical communications. This research addresses these challenges by innovatively combining quantum key distribution (QKD), specifically the E91 protocol, with logistic chaotic maps to establish a secure image transmission scheme. Our approach utilizes the unpredictability of chaotic systems alongside the robust security mechanisms inherent in quantum entanglement. The scheme is further fortified with an eavesdropping detection mechanism based on CHSH inequality, thereby enhancing its resilience against unauthorized access. Through quantitative simulations, we demonstrate the effectiveness of this scheme in encrypting images, achieving high entropy and sensitivity to the original images. The results indicate a significant improvement in encryption and decryption efficiency, showcasing the potential of the scheme as a viable solution against the vulnerabilities posed by quantum computing advancements. Our research offers a novel perspective in secure optical communications, blending the principles of chaos theory with QKD to create a more robust cryptographic framework.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18471"
  },
  "2311.18466": {
    "title": "Use of explicit replies as coordination mechanisms in online student debate",
    "authors": [
      "Bruno D. Ferreira-Saraiva",
      "Joao P. Matos-Carvalho",
      "Manuel Pita"
    ],
    "abstract": "People in conversation entrain their linguistic behaviours through spontaneous alignment mechanisms [7] - both in face-to-face and computer-mediated communication (CMC) [8]. In CMC, one of the mechanisms through which linguistic entrainment happens is through explicit replies. Indeed, the use of explicit replies influences the structure of conversations, favouring the formation of reply-trees typically delineated by topic shifts [5]. The interpersonal coordination mechanisms realized by how actors address each other have been studied using a probabilistic framework proposed by David Gibson [2,3]. Other recent approaches use computational methods and information theory to quantify changes in text. We explore coordination mechanisms concerned with some of the roles utterances play in dialogues - specifically in explicit replies. We identify these roles by finding community structure in the conversation's vocabulary using a non-parametric, hierarchical topic model. Some conversations may always stay on the ground, remaining at the level of general introductory chatter. Some others may develop a specific sub-topic in significant depth and detail. Even others may jump between general chatter, out-of-topic remarks and people agreeing or disagreeing without further elaboration.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18466"
  },
  "2311.18452": {
    "title": "Developer Experiences with a Contextualized AI Coding Assistant: Usability, Expectations, and Outcomes",
    "authors": [
      "Gustavo Pinto",
      "Cleidson de Souza",
      "Thayssa Rocha",
      "Igor Steinmacher",
      "Alberto de Souza",
      "Edward Monteiro"
    ],
    "abstract": "In the rapidly advancing field of artificial intelligence, software development has emerged as a key area of innovation. Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios. Noting this limitation, both the academic community and industry players are relying on contextualized coding AI assistants. These assistants surpass general-purpose AI tools by integrating proprietary, domain-specific knowledge, offering precise and relevant solutions. Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant -- named StackSpot AI -- in a controlled setting. According to the participants, the assistants' use resulted in significant time savings, easier access to documentation, and the generation of accurate codes for internal APIs. However, challenges associated with the knowledge sources necessary to make the coding assistant access more contextual information as well as variable responses and limitations in handling complex codes were observed. The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18452"
  },
  "2311.18451": {
    "title": "How Much Is Hidden in the NAS Benchmarks? Few-Shot Adaptation of a NAS Predictor",
    "authors": [
      "Hrushikesh Loya",
      "\u0141ukasz Dudziak",
      "Abhinav Mehrotra",
      "Royson Lee",
      "Javier Fernandez-Marques",
      "Nicholas D. Lane",
      "Hongkai Wen"
    ],
    "abstract": "Neural architecture search has proven to be a powerful approach to designing and refining neural networks, often boosting their performance and efficiency over manually-designed variations, but comes with computational overhead. While there has been a considerable amount of research focused on lowering the cost of NAS for mainstream tasks, such as image classification, a lot of those improvements stem from the fact that those tasks are well-studied in the broader context. Consequently, applicability of NAS to emerging and under-represented domains is still associated with a relatively high cost and/or uncertainty about the achievable gains. To address this issue, we turn our focus towards the recent growth of publicly available NAS benchmarks in an attempt to extract general NAS knowledge, transferable across different tasks and search spaces. We borrow from the rich field of meta-learning for few-shot adaptation and carefully study applicability of those methods to NAS, with a special focus on the relationship between task-level correlation (domain shift) and predictor transferability; which we deem critical for improving NAS on diverse tasks. In our experiments, we use 6 NAS benchmarks in conjunction, spanning in total 16 NAS settings -- our meta-learning approach not only shows superior (or matching) performance in the cross-validation experiments but also successful extrapolation to a new search space and tasks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18451"
  },
  "2311.18450": {
    "title": "Lessons from Building StackSpot AI: A Contextualized AI Coding Assistant",
    "authors": [
      "Gustavo Pinto",
      "Cleidson de Souza",
      "Jo\u00e3o Batista Neto",
      "Alberto de Souza",
      "Tarc\u00edsio Gotto",
      "Edward Monteiro"
    ],
    "abstract": "With their exceptional natural language processing capabilities, tools based on Large Language Models (LLMs) like ChatGPT and Co-Pilot have swiftly become indispensable resources in the software developer's toolkit. While recent studies suggest the potential productivity gains these tools can unlock, users still encounter drawbacks, such as generic or incorrect answers. Additionally, the pursuit of improved responses often leads to extensive prompt engineering efforts, diverting valuable time from writing code that delivers actual value. To address these challenges, a new breed of tools, built atop LLMs, is emerging. These tools aim to mitigate drawbacks by employing techniques like fine-tuning or enriching user prompts with contextualized information.\n  In this paper, we delve into the lessons learned by a software development team venturing into the creation of such a contextualized LLM-based application, using retrieval-based techniques, called CodeBuddy. Over a four-month period, the team, despite lacking prior professional experience in LLM-based applications, built the product from scratch. Following the initial product release, we engaged with the development team responsible for the code generative components. Through interviews and analysis of the application's issue tracker, we uncover various intriguing challenges that teams working on LLM-based applications might encounter. For instance, we found three main group of lessons: LLM-based lessons, User-based lessons, and Technical lessons. By understanding these lessons, software development teams could become better prepared to build LLM-based applications.\n        \u25b3 Less",
    "submission_date": "4 January, 2024",
    "eprint_id": "2311.18450"
  },
  "2311.18449": {
    "title": "Technical Debt Management Automation: State of the Art and Future Perspectives",
    "authors": [
      "Jo\u00e3o Paulo Biazotto",
      "Daniel Feitosa",
      "Paris Avgeriou",
      "Elisa Yumi Nakagawa"
    ],
    "abstract": "Technical Debt (TD) refers to non-optimal decisions made in software projects that may lead to short-term benefits, but potentially harm the system's maintenance in the long-term. Technical debt management (TDM) refers to a set of activities that are performed to handle TD, e.g., identification. These activities can entail tasks such as code and architectural analysis, which can be time-consuming if done manually. Thus, substantial research work has focused on automating TDM tasks (e.g., automatic identification of code smells). However, there is a lack of studies that summarize current approaches in TDM automation. This can hinder practitioners in selecting optimal automation strategies to efficiently manage TD. It can also prevent researchers from understanding the research landscape and addressing the research problems that matter the most. Thus, the main objective of this study is to provide an overview of the state of the art in TDM automation, analyzing the available tools, their use, and the challenges in automating TDM. For this, we conducted a systematic mapping study (SMS), and from an initial set of 1086 primary studies, 178 were selected to answer three research questions covering different facets of TDM automation. We found 121 automation artifacts, which were classified in 4 different types (i.e., tools, plugins, scripts, and bots); the inputs/outputs and interfaces were also collected and reported. Finally, a conceptual model is proposed that synthesizes the results and allows to discuss the current state of TDM automation and related challenges. The results show that the research community has investigated to a large extent how to perform various TDM activities automatically, considering the number of studies and automation artifacts we identified. More research is needed towards fully automated TDM, specially concerning the integration of the automation artifacts.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18449"
  },
  "2311.18448": {
    "title": "HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and Objects from Video",
    "authors": [
      "Zicong Fan",
      "Maria Parelli",
      "Maria Eleni Kadoglou",
      "Muhammed Kocabas",
      "Xu Chen",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "abstract": "Since humans interact with diverse objects every day, the holistic 3D capture of these interactions is important to understand and model human behaviour. However, most existing methods for hand-object reconstruction from RGB either assume pre-scanned object templates or heavily rely on limited 3D hand-object data, restricting their ability to scale and generalize to more unconstrained interaction settings. To this end, we introduce HOLD -- the first category-agnostic method that reconstructs an articulated hand and object jointly from a monocular interaction video. We develop a compositional articulated implicit model that can reconstruct disentangled 3D hand and object from 2D images. We also further incorporate hand-object constraints to improve hand-object poses and consequently the reconstruction quality. Our method does not rely on 3D hand-object annotations while outperforming fully-supervised baselines in both in-the-lab and challenging in-the-wild settings. Moreover, we qualitatively show its robustness in reconstructing from in-the-wild videos. Code: https://github.com/zc-alexfan/hold\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18448"
  },
  "2311.18445": {
    "title": "VTimeLLM: Empower LLM to Grasp Video Moments",
    "authors": [
      "Bin Huang",
      "Xin Wang",
      "Hong Chen",
      "Zihan Song",
      "Wenwu Zhu"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable text understanding capabilities, which have been extended as Video LLMs to handle video data for comprehending visual details. However, existing Video LLMs can only provide a coarse description of the entire video, failing to capture the precise start and end time boundary of specific events. In this paper, we solve this issue via proposing VTimeLLM, a novel Video LLM designed for fine-grained video moment understanding and reasoning with respect to time boundary. Specifically, our VTimeLLM adopts a boundary-aware three-stage training strategy, which respectively utilizes image-text pairs for feature alignment, multiple-event videos to increase temporal-boundary awareness, and high-quality video-instruction tuning to further improve temporal understanding ability as well as align with human intents. Extensive experiments demonstrate that in fine-grained time-related comprehension tasks for videos such as Temporal Video Grounding and Dense Video Captioning, VTimeLLM significantly outperforms existing Video LLMs. Besides, benefits from the fine-grained temporal understanding of the videos further enable VTimeLLM to beat existing Video LLMs in video dialogue benchmark, showing its superior cross-modal understanding and reasoning abilities.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18445"
  },
  "2311.18444": {
    "title": "Advancing Medical Education through the cINnAMON Web Application",
    "authors": [
      "Iuliana Marin"
    ],
    "abstract": "The cINnAMON EUREKA Traditional project endeavours to revolutionize indoor lighting positioning and monitoring through the integration of intelligent devices and advanced sensor technologies. This article presents the prototypes developed for various project components and explores their potential application in medical education, particularly for aspiring healthcare professionals. The current variant of the intelligent bulb prototype offers a comparative analysis of the project's bulb against commercially available smart bulbs, shedding light on its superior efficiency and capabilities. Furthermore, the initial smart bracelet prototype showcases its ability to collect and analyse data from an array of built-in sensors, empowering medical students to evaluate fragility levels based on accelerometer, gyroscope, orientation, and heart rate data. Leveraging trilateration and optimization algorithms, the intelligent location module enables precise monitoring of individuals' positions within a building, enhancing medical students' understanding of patient localization in healthcare settings. In addition, the recognition of human activity module harnesses data from the bracelet's sensors to classify different activities, providing medical students with invaluable insights into patients' daily routines and mobility patterns. The user's personal profile module facilitates seamless user registration and access to the comprehensive services offered by the cINnAMON system, empowering medical students to collect patient data for analysis and aiding doctors in making informed healthcare decisions. With the telemonitoring system, medical students can remotely monitor patients by configuring sensors in their homes, thus enabling a deeper understanding of remote patient management.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18444"
  },
  "2311.18440": {
    "title": "Autonomous Agents in Software Development: A Vision Paper",
    "authors": [
      "Zeeshan Rasheed",
      "Muhammad Waseem",
      "Kai-Kristian Kemell",
      "Wang Xiaofeng",
      "Anh Nguyen Duc",
      "Kari Syst\u00e4",
      "Pekka Abrahamsson"
    ],
    "abstract": "Large Language Models (LLM) and Generative Pre-trained Transformers (GPT), are reshaping the field of Software Engineering (SE). They enable innovative methods for executing many software engineering tasks, including automated code generation, debugging, maintenance, etc. However, only a limited number of existing works have thoroughly explored the potential of GPT agents in SE. This vision paper inquires about the role of GPT-based agents in SE. Our vision is to leverage the capabilities of multiple GPT agents to contribute to SE tasks and to propose an initial road map for future work. We argue that multiple GPT agents can perform creative and demanding tasks far beyond coding and debugging. GPT agents can also do project planning, requirements engineering, and software design. These can be done through high-level descriptions given by the human developer. We have shown in our initial experimental analysis for simple software (e.g., Snake Game, Tic-Tac-Toe, Notepad) that multiple GPT agents can produce high-quality code and document it carefully. We argue that it shows a promise of unforeseen efficiency and will dramatically reduce lead-times. To this end, we intend to expand our efforts to understand how we can scale these autonomous capabilities further.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18440"
  },
  "2311.18437": {
    "title": "The Sliding Regret in Stochastic Bandits: Discriminating Index and Randomized Policies",
    "authors": [
      "Victor Boone"
    ],
    "abstract": "This paper studies the one-shot behavior of no-regret algorithms for stochastic bandits. Although many algorithms are known to be asymptotically optimal with respect to the expected regret, over a single run, their pseudo-regret seems to follow one of two tendencies: it is either smooth or bumpy. To measure this tendency, we introduce a new notion: the sliding regret, that measures the worst pseudo-regret over a time-window of fixed length sliding to infinity. We show that randomized methods (e.g. Thompson Sampling and MED) have optimal sliding regret, while index policies, although possibly asymptotically optimal for the expected regret, have the worst possible sliding regret under regularity conditions on their index (e.g. UCB, UCB-V, KL-UCB, MOSS, IMED etc.). We further analyze the average bumpiness of the pseudo-regret of index policies via the regret of exploration, that we show to be suboptimal as well.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18437"
  },
  "2311.18436": {
    "title": "The Role of Visual Features in Text-Based CAPTCHAs: An fNIRS Study for Usable Security",
    "authors": [
      "Emre Mulazimoglu",
      "Murat P. Cakir",
      "Cengiz Acarturk"
    ],
    "abstract": "To mitigate dictionary attacks or similar undesirable automated attacks to information systems, developers mostly prefer using CAPTCHA challenges as Human Interactive Proofs (HIPs) to distinguish between human users and scripts. Appropriate use of CAPTCHA requires a setup that balances between robustness and usability during the design of a challenge. The previous research reveals that most usability studies have used accuracy and response time as measurement criteria for quantitative analysis. The present study aims at applying optical neuroimaging techniques for the analysis of CAPTCHA design. The functional Near-Infrared Spectroscopy technique was used to explore the hemodynamic responses in the prefrontal cortex elicited by CAPTCHA stimulus of varying types. )e findings suggest that regions in the left and right dorsolateral and right dorsomedial prefrontal cortex respond to the degrees of line occlusion, rotation, and wave distortions present in a CAPTCHA. The systematic addition of the visual effects introduced nonlinear effects on the behavioral and prefrontal oxygenation measures, indicative of the emergence of Gestalt effects that might have influenced the perception of the overall CAPTCHA figure.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18436"
  },
  "2311.18435": {
    "title": "Layered Rendering Diffusion Model for Zero-Shot Guided Image Synthesis",
    "authors": [
      "Zipeng Qi",
      "Guoxi Huang",
      "Zebin Huang",
      "Qin Guo",
      "Jinwen Chen",
      "Junyu Han",
      "Jian Wang",
      "Gang Zhang",
      "Lufei Liu",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "abstract": "This paper introduces innovative solutions to enhance spatial controllability in diffusion models reliant on text queries. We present two key innovations: Vision Guidance and the Layered Rendering Diffusion (LRDiff) framework. Vision Guidance, a spatial layout condition, acts as a clue in the perturbed distribution, greatly narrowing down the search space, to focus on the image sampling process adhering to the spatial layout condition. The LRDiff framework constructs an image-rendering process with multiple layers, each of which applies the vision guidance to instructively estimate the denoising direction for a single object. Such a layered rendering strategy effectively prevents issues like unintended conceptual blending or mismatches, while allowing for more coherent and contextually accurate image synthesis. The proposed method provides a more efficient and accurate means of synthesising images that align with specific spatial and contextual requirements. We demonstrate through our experiments that our method provides better results than existing techniques both quantitatively and qualitatively. We apply our method to three practical applications: bounding box-to-image, semantic mask-to-image and image editing.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18435"
  },
  "2311.18434": {
    "title": "Exploring the Temperature-Dependent Phase Transition in Modern Hopfield Networks",
    "authors": [
      "Felix Koulischer",
      "C\u00e9dric Goemaere",
      "Tom van der Meersch",
      "Johannes Deleu",
      "Thomas Demeester"
    ],
    "abstract": "The recent discovery of a connection between Transformers and Modern Hopfield Networks (MHNs) has reignited the study of neural networks from a physical energy-based perspective. This paper focuses on the pivotal effect of the inverse temperature hyperparameter $\u03b2$ on the distribution of energy minima of the MHN. To achieve this, the distribution of energy minima is tracked in a simplified MHN in which equidistant normalised patterns are stored. This network demonstrates a phase transition at a critical temperature $\u03b2_{\\text{c}}$, from a single global attractor towards highly pattern specific minima as $\u03b2$ is increased. Importantly, the dynamics are not solely governed by the hyperparameter $\u03b2$ but are instead determined by an effective inverse temperature $\u03b2_{\\text{eff}}$ which also depends on the distribution and size of the stored patterns. Recognizing the role of hyperparameters in the MHN could, in the future, aid researchers in the domain of Transformers to optimise their initial choices, potentially reducing the necessity for time and energy expensive hyperparameter fine-tuning.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18434"
  },
  "2311.18433": {
    "title": "E2PNet: Event to Point Cloud Registration with Spatio-Temporal Representation Learning",
    "authors": [
      "Xiuhong Lin",
      "Changjie Qiu",
      "Zhipeng Cai",
      "Siqi Shen",
      "Yu Zang",
      "Weiquan Liu",
      "Xuesheng Bian",
      "Matthias M\u00fcller",
      "Cheng Wang"
    ],
    "abstract": "Event cameras have emerged as a promising vision sensor in recent years due to their unparalleled temporal resolution and dynamic range. While registration of 2D RGB images to 3D point clouds is a long-standing problem in computer vision, no prior work studies 2D-3D registration for event cameras. To this end, we propose E2PNet, the first learning-based method for event-to-point cloud registration. The core of E2PNet is a novel feature representation network called Event-Points-to-Tensor (EP2T), which encodes event data into a 2D grid-shaped feature tensor. This grid-shaped feature enables matured RGB-based frameworks to be easily used for event-to-point cloud registration, without changing hyper-parameters and the training procedure. EP2T treats the event input as spatio-temporal point clouds. Unlike standard 3D learning architectures that treat all dimensions of point clouds equally, the novel sampling and information aggregation modules in EP2T are designed to handle the inhomogeneity of the spatial and temporal dimensions. Experiments on the MVSEC and VECtor datasets demonstrate the superiority of E2PNet over hand-crafted and other learning-based methods. Compared to RGB-based registration, E2PNet is more robust to extreme illumination or fast motion due to the use of event data. Beyond 2D-3D registration, we also show the potential of EP2T for other vision tasks such as flow estimation, event-to-image reconstruction and object recognition. The source code can be found at: https://github.com/Xmu-qcj/E2PNet.\n        \u25b3 Less",
    "submission_date": "27 December, 2023",
    "eprint_id": "2311.18433"
  },
  "2311.18432": {
    "title": "Three classes of new optimal cyclic $(r,\u03b4)$ locally recoverable codes",
    "authors": [
      "Yaozong Zhang",
      "Dabin Zheng",
      "Xiaoqiang Wang"
    ],
    "abstract": "An $(r, \u03b4)$-locally repairable code ($(r, \u03b4)$-LRC for short) was introduced by Prakash et al. for tolerating multiple failed nodes in distributed storage systems, and has garnered significant interest among researchers. An $(r,\u03b4)$-LRC is called an optimal code if its parameters achieve the Singleton-like bound. In this paper, we construct three classes of $q$-ary optimal cyclic $(r,\u03b4)$-LRCs with new parameters by investigating the defining sets of cyclic codes. Our results generalize the related work of \\cite{Chen2022,Qian2020}, and the obtained optimal cyclic $(r, \u03b4)$-LRCs have flexible parameters. A lot of numerical examples of optimal cyclic $(r, \u03b4)$-LRCs are given to show that our constructions are capable of generating new optimal cyclic $(r, \u03b4)$-LRCs.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18432"
  },
  "2311.18430": {
    "title": "Vehicular Cooperative Maneuvers -- Quo Vaditis?",
    "authors": [
      "Bernhard H\u00e4fner",
      "J\u00f6rg Ott",
      "Georg Albrecht Schmitt"
    ],
    "abstract": "Vehicles will not only get more and more automated, but they will also cooperate in new ways. Currently, human-driven vehicles begin to communicate with each other using vehicle-to-everything technology. Future vehicles will use communication to share sensor data and even negotiate cooperative maneuvers. This lets them learn more about the environment and improves traffic flow and passenger comfort as more predictable maneuvers are likely to lead to a smoother ride. This paper introduces the most important concepts around cooperative vehicular maneuvers. We also summarize currently open challenges and questions to answer before a deployment can begin. Afterward, we give some perspectives on the further evolution of cooperative maneuvers and beyond.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18430"
  },
  "2311.18425": {
    "title": "On the (In)approximability of Combinatorial Contracts",
    "authors": [
      "Tomer Ezra",
      "Michal Feldman",
      "Maya Schlesinger"
    ],
    "abstract": "We study two combinatorial contract design models -- multi-agent and multi-action -- where a principal delegates the execution of a costly project to others. In both settings, the principal cannot observe the choices of the agent(s), only the project's outcome (success or failure), and incentivizes the agent(s) using a contract, which is a payment scheme that specifies the payment to the agent(s) upon a project's success.\n  In the multi-agent setting, the project is delegated to a team of agents, and every agent chooses whether or not to exert effort. A success probability function specifies the probability of success for every subset of agents exerting effort. For the family of submodular success probability functions, Duetting et al. [2023] established a poly-time constant-factor approximation to the optimal contract, and left open whether this problem admits a PTAS. We show that no poly-time algorithm guarantees a better than $0.7$-approximation to the optimal contract. For XOS functions, Duetting et al. [2023] give a poly-time constant approximation with value and demand queries. We show that with value queries only, one cannot get any constant approximation.\n  In the multi-action setting, the project is delegated to a single agent, who can take any subset of a given set of actions. Here, a success probability function specifies the probability of success for any subset of actions. Duetting et al. [2021a] devised a poly-time algorithm for computing an optimal contract for gross substitutes success probability functions, and established NP-hardness with respect to submodular functions. We further strengthen this hardness result by showing that this problem does not admit any constant approximation either. For the broader class of XOS functions, we establish the hardness of obtaining a $n^{-1/2+\\varepsilon}$-approximation for any $\\varepsilon > 0$.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18425"
  },
  "2311.18424": {
    "title": "Investigating Collaborative Data Practices: a Case Study on Artificial Intelligence for Healthcare Research",
    "authors": [
      "Rafael Henkin",
      "Elizabeth Remfry",
      "Duncan J. Reynolds",
      "Megan Clinch",
      "Michael R. Barnes"
    ],
    "abstract": "Developing artificial intelligence (AI) tools for healthcare is a collaborative effort, bringing data scientists, clinicians, patients and other disciplines together. In this paper, we explore the collaborative data practices of research consortia tasked with applying AI tools to understand and manage multiple long-term conditions in the UK. Through an inductive thematic analysis of 13 semi-structured interviews with participants of these consortia, we aimed to understand how collaboration happens based on the tools used, communication processes and settings, as well as the conditions and obstacles for collaborative work. Our findings reveal the adaptation of tools that are used for sharing knowledge and the tailoring of information based on the audience, particularly those from a clinical or patient perspective. Limitations on the ability to do this were also found to be imposed by the use of electronic healthcare records and access to datasets. We identified meetings as the key setting for facilitating exchanges between disciplines and allowing for the blending and creation of knowledge. Finally, we bring to light the conditions needed to facilitate collaboration and discuss how some of the challenges may be navigated in future work.\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2311.18424"
  },
  "2311.18418": {
    "title": "Beamforming Design for Active RIS-Aided Over-the-Air Computation",
    "authors": [
      "Deyou Zhang",
      "Ming Xiao",
      "Mikael Skoglund",
      "H. Vincent Poor"
    ],
    "abstract": "Over-the-air computation (AirComp) is emerging as a promising technology for wireless data aggregation. However, its performance is hampered by users with poor channel conditions. To mitigate such a performance bottleneck, this paper introduces an active reconfigurable intelligence surface (RIS) into the AirComp system. Specifically, we begin by exploring the ideal RIS model and propose a joint optimization of the transceiver design and RIS configuration to minimize the mean squared error (MSE) between the target and estimated function values. To manage the resultant tri-convex optimization problem, we employ the alternating optimization (AO) technique to decompose it into three convex subproblems, each solvable optimally. Subsequently, we investigate two specific cases and analyze their respective asymptotic performance to reveal the superiority of the active RIS in mitigating the MSE relative to its passive counterpart. Lastly, we adapt our transceiver and RIS configuration design to account for the self-interference of the active RIS. To handle the resultant highly non-convex problem, we further devise a two-layer AO framework. Simulation results demonstrate the superiority of the active RIS in enhancing AirComp performance compared to its passive counterpart.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18418"
  },
  "2311.18406": {
    "title": "OpenMORE: an open-source tool for sampling-based path replanning in ROS",
    "authors": [
      "Cesare Tonola",
      "Manuel Beschi",
      "Marco Faroni",
      "Nicola Pedrocchi"
    ],
    "abstract": "With the spread of robots in unstructured, dynamic environments, the topic of path replanning has gained importance in the robotics community. Although the number of replanning strategies has significantly increased, there is a lack of agreed-upon libraries and tools, making the use, development, and benchmarking of new algorithms arduous. This paper introduces OpenMORE, a new open-source ROS-based C++ library for sampling-based path replanning algorithms. The library builds a framework that allows for continuous replanning and collision checking of the traversed path during the execution of the robot trajectory. Users can solve replanning tasks exploiting the already available algorithms and can easily integrate new ones, leveraging the library to manage the entire execution.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18406"
  },
  "2311.18399": {
    "title": "Audio Prompt Tuning for Universal Sound Separation",
    "authors": [
      "Yuzhuo Liu",
      "Xubo Liu",
      "Yan Zhao",
      "Yuanyuan Wang",
      "Rui Xia",
      "Pingchuan Tain",
      "Yuxuan Wang"
    ],
    "abstract": "Universal sound separation (USS) is a task to separate arbitrary sounds from an audio mixture. Existing USS systems are capable of separating arbitrary sources, given a few examples of the target sources as queries. However, separating arbitrary sounds with a single system is challenging, and the robustness is not always guaranteed. In this work, we propose audio prompt tuning (APT), a simple yet effective approach to enhance existing USS systems. Specifically, APT improves the separation performance of specific sources through training a small number of prompt parameters with limited audio samples, while maintaining the generalization of the USS model by keeping its parameters frozen. We evaluate the proposed method on MUSDB18 and ESC-50 datasets. Compared with the baseline model, APT can improve the signal-to-distortion ratio performance by 0.67 dB and 2.06 dB using the full training set of two datasets. Moreover, APT with only 5 audio samples even outperforms the baseline systems utilizing full training data on the ESC-50 dataset, indicating the great potential of few-shot APT.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18399"
  },
  "2311.18398": {
    "title": "RainAI -- Precipitation Nowcasting from Satellite Data",
    "authors": [
      "Rafael Pablos Sarabia",
      "Joachim Nyborg",
      "Morten Birk",
      "Ira Assent"
    ],
    "abstract": "This paper presents a solution to the Weather4Cast 2023 competition, where the goal is to forecast high-resolution precipitation with an 8-hour lead time using lower-resolution satellite radiance images. We propose a simple, yet effective method for spatiotemporal feature learning using a 2D U-Net model, that outperforms the official 3D U-Net baseline in both performance and efficiency. We place emphasis on refining the dataset, through importance sampling and dataset preparation, and show that such techniques have a significant impact on performance. We further study an alternative cross-entropy loss function that improves performance over the standard mean squared error loss, while also enabling models to produce probabilistic outputs. Additional techniques are explored regarding the generation of predictions at different lead times, specifically through Conditioning Lead Time. Lastly, to generate high-resolution forecasts, we evaluate standard and learned upsampling methods. The code and trained parameters are available at https://github.com/rafapablos/w4c23-rainai.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18398"
  },
  "2311.18397": {
    "title": "IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions",
    "authors": [
      "Zhebin Zhang",
      "Xinyu Zhang",
      "Yuanhang Ren",
      "Saijiang Shi",
      "Meng Han",
      "Yongkang Wu",
      "Ruofei Lai",
      "Zhao Cao"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG), by incorporating external knowledge with parametric memory of language models, has become the state-of-the-art architecture for open-domain QA tasks. However, common knowledge bases are inherently constrained by limited coverage and noisy information, making retrieval-based approaches inadequate to answer implicit reasoning questions. In this paper, we propose an Induction-Augmented Generation (IAG) framework that utilizes inductive knowledge along with the retrieved documents for implicit reasoning. We leverage large language models (LLMs) for deriving such knowledge via a novel prompting method based on inductive reasoning patterns. On top of this, we implement two versions of IAG named IAG-GPT and IAG-Student, respectively. IAG-GPT directly utilizes the knowledge generated by GPT-3 for answer prediction, while IAG-Student gets rid of dependencies on GPT service at inference time by incorporating a student inductor model. The inductor is firstly trained via knowledge distillation and further optimized by back-propagating the generator feedback via differentiable beam scores. Experimental results show that IAG outperforms RAG baselines as well as ChatGPT on two Open-Domain QA tasks. Notably, our best models have won the first place in the official leaderboards of CSQA2.0 (since Nov 1, 2022) and StrategyQA (since Jan 8, 2023).\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18397"
  },
  "2311.18394": {
    "title": "HMAS: enabling seamless collaboration between drones, quadruped robots, and human operators with efficient spatial awareness",
    "authors": [
      "Amaury Saint-Jore",
      "Ye-Qiong Song",
      "Laurent Ciarletta"
    ],
    "abstract": "Heterogeneous robots equipped with multi-modal sensors (e.g., UAV, wheeled and legged terrestrial robots) provide rich and complementary functions that may help human operators to accomplish complex tasks in unknown environments. However, seamlessly integrating heterogeneous agents and making them interact and collaborate still arise challenging issues. In this paper, we define a ROS 2 based software architecture that allows to build incarnated heterogeneous multi-agent systems (HMAS) in a generic way. We showcase its effectiveness through a scenario integrating aerial drones, quadruped robots, and human operators (see https://youtu.be/iOtCCticGuk). In addition, agent spatial awareness in unknown outdoor environments is a critical step for realizing autonomous individual movements, interactions, and collaborations. Through intensive experimental measurements, RTK-GPS is shown to be a suitable solution for achieving the required locating accuracy.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18394"
  },
  "2311.18393": {
    "title": "Data-efficient Deep Reinforcement Learning for Vehicle Trajectory Control",
    "authors": [
      "Bernd Frauenknecht",
      "Tobias Ehlgen",
      "Sebastian Trimpe"
    ],
    "abstract": "Advanced vehicle control is a fundamental building block in the development of autonomous driving systems. Reinforcement learning (RL) promises to achieve control performance superior to classical approaches while keeping computational demands low during deployment. However, standard RL approaches like soft-actor critic (SAC) require extensive amounts of training data to be collected and are thus impractical for real-world application. To address this issue, we apply recently developed data-efficient deep RL methods to vehicle trajectory control. Our investigation focuses on three methods, so far unexplored for vehicle control: randomized ensemble double Q-learning (REDQ), probabilistic ensembles with trajectory sampling and model predictive path integral optimizer (PETS-MPPI), and model-based policy optimization (MBPO). We find that in the case of trajectory control, the standard model-based RL formulation used in approaches like PETS-MPPI and MBPO is not suitable. We, therefore, propose a new formulation that splits dynamics prediction and vehicle localization. Our benchmark study on the CARLA simulator reveals that the three identified data-efficient deep RL approaches learn control strategies on a par with or better than SAC, yet reduce the required number of environment interactions by more than one order of magnitude.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18393"
  },
  "2311.18390": {
    "title": "Enhanced Cross Z-Complementary Set and Its Application in Generalized Spatial Modulation",
    "authors": [
      "Zhen-Ming Huang",
      "Cheng-Yu Pai",
      "Zilong Liu",
      "Chao-Yu Chen"
    ],
    "abstract": "Generalized spatial modulation (GSM) is a novel multiple-antenna technique offering flexibility among spectral efficiency, energy efficiency, and the cost of RF chains. In this paper, a novel class of sequence sets, called enhanced cross Zcomplementary set (E-CZCS), is proposed for efficient training sequence design in broadband GSM systems. Specifically, an E-CZCS consists of multiple CZCSs possessing front-end and tail-end zero-correlation zones (ZCZs), whereby any two distinct CZCSs have a tail-end ZCZ when a novel type of cross-channel aperiodic correlation sums is considered. The theoretical upper bound on the ZCZ width is first derived, upon which optimal E-CZCSs with flexible parameters are constructed. For optimal channel estimation over frequency-selective channels, we introduce and evaluate a novel GSM training framework employing the proposed E-CZCSs.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2311.18390"
  },
  "2311.18387": {
    "title": "On Exact Inversion of DPM-Solvers",
    "authors": [
      "Seongmin Hong",
      "Kyeonghyun Lee",
      "Suh Yoon Jeon",
      "Hyewon Bae",
      "Se Young Chun"
    ],
    "abstract": "Diffusion probabilistic models (DPMs) are a key component in modern generative models. DPM-solvers have achieved reduced latency and enhanced quality significantly, but have posed challenges to find the exact inverse (i.e., finding the initial noise from the given image). Here we investigate the exact inversions for DPM-solvers and propose algorithms to perform them when samples are generated by the first-order as well as higher-order DPM-solvers. For each explicit denoising step in DPM-solvers, we formulated the inversions using implicit methods such as gradient descent or forward step method to ensure the robustness to large classifier-free guidance unlike the prior approach using fixed-point iteration. Experimental results demonstrated that our proposed exact inversion methods significantly reduced the error of both image and noise reconstructions, greatly enhanced the ability to distinguish invisible watermarks and well prevented unintended background changes consistently during image editing. Project page: \\url{https://smhongok.github.io/inv-dpm.html}.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18387"
  },
  "2311.18376": {
    "title": "Age Effects on Decision-Making, Drift Diffusion Model",
    "authors": [
      "Zahra Kavian",
      "Kimia Hajisadeghi",
      "Yashar Rezazadeh",
      "Mehrbod Faraji",
      "Reza Ebrahimpour"
    ],
    "abstract": "Training can improve human decision-making performance. After several training sessions, a person can quickly and accurately complete a task. However, decision-making is always a trade-off between accuracy and response time. Factors such as age and drug abuse can affect the decision-making process. This study examines how training can improve the performance of different age groups in completing a random dot motion (RDM) task. The participants are divided into two groups: old and young. They undergo a three-phase training and then repeat the same RDM task. The hierarchical drift-diffusion model analyzes the subjects' responses and determines how the model's parameters change after training for both age groups. The results show that after training, the participants were able to accumulate sensory information faster, and the model drift rate increased. However, their decision boundary decreased as they became more confident and had a lower decision-making threshold. Additionally, the old group had a higher boundary and lower drift rate in both pre and post-training, and there was less difference between the two group parameters after training.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18376"
  },
  "2311.18368": {
    "title": "Sharing Experience Around Component Compositions",
    "authors": [
      "Gr\u00e9gory Bourguin",
      "Arnaud Lewandowski",
      "Myriam Lewkowicz"
    ],
    "abstract": "Society currently lives in a world of tailorable systems in which end-users are able to transform their working environment while achieving their tasks, day to day and over the time. Tailorability is most of the time achieved through dynamic component integration thanks to a huge number of components available over the Internet. In this context, the main problem for users is not anymore the integration of new components, but how to find the most interesting set of components that will fulfill their needs. Facing this issue, the authors' assumption is that it would be helpful for users to take benefit of the experience of other users and our work aims at enhancing current software ecosystems to support this sharing of experience. The authors have applied this approach in the context of software development while considering Eclipse as one of the most advanced and used software ecosystem. The authors then offer ShareXP, an Eclipse feature that allows members of a group to share their expertise, this expertise being embodied in the ``compositions'' each of them has built. ShareXP was already presented in (Bourguin et al., 2012). The current paper is an extension where the authors deeper show that ShareXP is only a first step in their global approach trying to enhance not only the Eclipse ecosystem, but software ecosystems in general.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18368"
  },
  "2311.18365": {
    "title": "Fully Dynamic Algorithms for Euclidean Steiner Tree",
    "authors": [
      "T-H. Hubert Chan",
      "Gramoz Goranci",
      "Shaofeng H. -C. Jiang",
      "Bo Wang",
      "Quan Xue"
    ],
    "abstract": "The Euclidean Steiner tree problem asks to find a min-cost metric graph that connects a given set of \\emph{terminal} points $X$ in $\\mathbb{R}^d$, possibly using points not in $X$ which are called Steiner points. Even though near-linear time $(1 + \u03b5)$-approximation was obtained in the offline setting in seminal works of Arora and Mitchell, efficient dynamic algorithms for Steiner tree is still open. We give the first algorithm that (implicitly) maintains a $(1 + \u03b5)$-approximate solution which is accessed via a set of tree traversal queries, subject to point insertion and deletions,  with amortized update and query time $O(\\poly\\log n)$ with high probability. Our approach is based on an Arora-style geometric dynamic programming, and our main technical contribution is to maintain the DP subproblems in the dynamic setting efficiently. We also need to augment the DP subproblems to support the tree traversal queries.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18365"
  },
  "2311.18364": {
    "title": "Hubness Reduction Improves Sentence-BERT Semantic Spaces",
    "authors": [
      "Beatrix M. G. Nielsen",
      "Lars Kai Hansen"
    ],
    "abstract": "Semantic representations of text, i.e. representations of natural language which capture meaning by geometry, are essential for areas such as information retrieval and document grouping. High-dimensional trained dense vectors have received much attention in recent years as such representations. We investigate the structure of semantic spaces that arise from embeddings made with Sentence-BERT and find that the representations suffer from a well-known problem in high dimensions called hubness. Hubness results in asymmetric neighborhood relations, such that some texts (the hubs) are neighbours of many other texts while most texts (so-called anti-hubs), are neighbours of few or no other texts. We quantify the semantic quality of the embeddings using hubness scores and error rate of a neighbourhood based classifier. We find that when hubness is high, we can reduce error rate and hubness using hubness reduction methods. We identify a combination of two methods as resulting in the best reduction. For example, on one of the tested pretrained models, this combined method can reduce hubness by about 75% and error rate by about 9%. Thus, we argue that mitigating hubness in the embedding space provides better semantic representations of text.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18364"
  },
  "2311.18361": {
    "title": "Automating lookahead planning using site appearance and space utilization",
    "authors": [
      "Eyob Mengiste",
      "Borja Garcia de Soto",
      "Timo Hartmann"
    ],
    "abstract": "This study proposes a method to automate the development of lookahead planning. The proposed method uses construction material conditions (i.e., appearances) and site space utilization to predict task completion rates. A Gated Recurrent Unit (GRU) based Recurrent Neural Network (RNN) model was trained using a segment of a construction project timeline to estimate completion rates of tasks and propose data-aware lookahead plans. The proposed method was evaluated in a sample construction project involving finishing works such as plastering, painting, and installing electrical fixtures. The results show that the proposed method can assist with developing automated lookahead plans. In doing so, this study links construction planning with actual events at the construction site. It extends the traditional scheduling techniques and integrates a broader spectrum of site spatial constraints into lookahead planning.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18361"
  },
  "2311.18358": {
    "title": "TIDE: Test Time Few Shot Object Detection",
    "authors": [
      "Weikai Li",
      "Hongfeng Wei",
      "Yanlai Wu",
      "Jie Yang",
      "Yudi Ruan",
      "Yuan Li",
      "Ying Tang"
    ],
    "abstract": "Few-shot object detection (FSOD) aims to extract semantic knowledge from limited object instances of novel categories within a target domain. Recent advances in FSOD focus on fine-tuning the base model based on a few objects via meta-learning or data augmentation. Despite their success, the majority of them are grounded with parametric readjustment to generalize on novel objects, which face considerable challenges in Industry 5.0, such as (i) a certain amount of fine-tuning time is required, and (ii) the parameters of the constructed model being unavailable due to the privilege protection, making the fine-tuning fail. Such constraints naturally limit its application in scenarios with real-time configuration requirements or within black-box settings. To tackle the challenges mentioned above, we formalize a novel FSOD task, referred to as Test TIme Few Shot DEtection (TIDE), where the model is un-tuned in the configuration procedure. To that end, we introduce an asymmetric architecture for learning a support-instance-guided dynamic category classifier. Further, a cross-attention module and a multi-scale resizer are provided to enhance the model performance. Experimental results on multiple few-shot object detection platforms reveal that the proposed TIDE significantly outperforms existing contemporary methods. The implementation codes are available at https://github.com/deku-0621/TIDE\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18358"
  },
  "2311.18356": {
    "title": "Towards Comparable Active Learning",
    "authors": [
      "Thorben Werner",
      "Johannes Burchert",
      "Lars Schmidt-Thieme"
    ],
    "abstract": "Active Learning has received significant attention in the field of machine learning for its potential in selecting the most informative samples for labeling, thereby reducing data annotation costs. However, we show that the reported lifts in recent literature generalize poorly to other domains leading to an inconclusive landscape in Active Learning research. Furthermore, we highlight overlooked problems for reproducing AL experiments that can lead to unfair comparisons and increased variance in the results. This paper addresses these issues by providing an Active Learning framework for a fair comparison of algorithms across different tasks and domains, as well as a fast and performant oracle algorithm for evaluation. To the best of our knowledge, we propose the first AL benchmark that tests algorithms in 3 major domains: Tabular, Image, and Text. We report empirical results for 6 widely used algorithms on 7 real-world and 2 synthetic datasets and aggregate them into a domain-specific ranking of AL algorithms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18356"
  },
  "2311.18355": {
    "title": "Guided Demonstrations Using Automated Excuse Generation",
    "authors": [
      "Maximilian Diehl",
      "Tathagata Chakraborti",
      "Karinne Ramirez-Amaro"
    ],
    "abstract": "Teaching task-level directives to robots via demonstration is a popular tool to expand the robot's capabilities to interact with its environment. While current learning from demonstration systems primarily focuses on abstracting the task-level knowledge to the robot, these systems lack the ability to understand which part of the task can be already solved given the robot's prior knowledge. Therefore, instead of only requiring demonstrations of the missing pieces, these systems will require a demonstration of the complete task, which is cumbersome, repetitive, and can discourage people from helping the robot by performing the demonstrations. Therefore, we propose to use the notion of \"excuses\" to identify the smallest change in the robot state that makes a task, currently not solvable by the robot, solvable -- as a means to solicit more targeted demonstrations from a human. These excuses are generated automatically using combinatorial search over possible changes that can be made to the robot's state and choosing the minimum changes that make it solvable. These excuses then serve as guidance for the demonstrator who can use it to decide what to demonstrate to the robot in order to make this requested change possible, thereby making the original task solvable for the robot without having to demonstrate it in its entirety. By working with symbolic state descriptions, the excuses can be directly communicated and intuitively understood by a human demonstrator. We show empirically and in a user study that the use of excuses reduces the demonstration time by 54% and leads to a 74% reduction in demonstration size.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18355"
  },
  "2311.18353": {
    "title": "Evaluating the Rationale Understanding of Critical Reasoning in Logical Reading Comprehension",
    "authors": [
      "Akira Kawabata",
      "Saku Sugawara"
    ],
    "abstract": "To precisely evaluate a language model's capability for logical reading comprehension, we present a dataset for testing the understanding of the rationale behind critical reasoning. For questions taken from an existing multiplechoice logical reading comprehension dataset, we crowdsource rationale texts that explain why we should select or eliminate answer options, resulting in 3,003 multiple-choice subquestions that are associated with 943 main questions. Experiments on our dataset show that recent large language models (e.g., InstructGPT) struggle to answer the subquestions even if they are able to answer the main questions correctly. We find that the models perform particularly poorly in answering subquestions written for the incorrect options of the main questions, implying that the models have a limited capability for explaining why incorrect alternatives should be eliminated. These results suggest that our dataset encourages further investigation into the critical reasoning ability of language models while focusing on the elimination process of relevant alternatives.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18353"
  },
  "2311.18350": {
    "title": "Unveiling Backdoor Risks Brought by Foundation Models in Heterogeneous Federated Learning",
    "authors": [
      "Xi Li",
      "Chen Wu",
      "Jiaqi Wang"
    ],
    "abstract": "The foundation models (FMs) have been used to generate synthetic public datasets for the heterogeneous federated learning (HFL) problem where each client uses a unique model architecture. However, the vulnerabilities of integrating FMs, especially against backdoor attacks, are not well-explored in the HFL contexts. In this paper, we introduce a novel backdoor attack mechanism for HFL that circumvents the need for client compromise or ongoing participation in the FL process. This method plants and transfers the backdoor through a generated synthetic public dataset, which could help evade existing backdoor defenses in FL by presenting normal client behaviors. Empirical experiments across different HFL configurations and benchmark datasets demonstrate the effectiveness of our attack compared to traditional client-based attacks. Our findings reveal significant security risks in developing robust FM-assisted HFL systems. This research contributes to enhancing the safety and integrity of FL systems, highlighting the need for advanced security measures in the era of FMs.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18350"
  },
  "2311.18348": {
    "title": "Reconstructing Historical Climate Fields With Deep Learning",
    "authors": [
      "Nils Bochow",
      "Anna Poltronieri",
      "Martin Rypdal",
      "Niklas Boers"
    ],
    "abstract": "Historical records of climate fields are often sparse due to missing measurements, especially before the introduction of large-scale satellite missions. Several statistical and model-based methods have been introduced to fill gaps and reconstruct historical records. Here, we employ a recently introduced deep-learning approach based on Fourier convolutions, trained on numerical climate model output, to reconstruct historical climate fields. Using this approach we are able to realistically reconstruct large and irregular areas of missing data, as well as reconstruct known historical events such as strong El Ni\u00f1o and La Ni\u00f1a with very little given information. Our method outperforms the widely used statistical kriging method as well as other recent machine learning approaches. The model generalizes to higher resolutions than the ones it was trained on and can be used on a variety of climate fields. Moreover, it allows inpainting of masks never seen before during the model training.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18348"
  },
  "2311.18344": {
    "title": "DSeg: Direct Line Segments Detection",
    "authors": [
      "Berger Cyrille",
      "Lacroix Simon"
    ],
    "abstract": "This paper presents a model-driven approach to detect image line segments. The approach incrementally detects segments on the gradient image using a linear Kalman filter that estimates the supporting line parameters and their associated variances. The algorithm is fast and robust with respect to image noise and illumination variations, it allows the detection of longer line segments than data-driven approaches, and does not require any tedious parameters tuning. An extension of the algorithm that exploits a pyramidal approach to enhance the quality of results is proposed. Results with varying scene illumination and comparisons to classic existing approaches are presented.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18344"
  },
  "2311.18343": {
    "title": "STAR-RIS Assisted Cell-Free Massive MIMO System Under Spatially-Correlated Channels",
    "authors": [
      "Anastasios Papazafeiropoulos",
      "Hien Quoc Ngo",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas"
    ],
    "abstract": "This paper investigates the performance of downlink simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-assisted cell-free (CF) massive multiple-input multiple-output (mMIMO) systems, where user equipments (UEs) are located on both sides of the RIS.\n  We account for correlated Rayleigh fading and multiple antennas per access point (AP), while the maximum ratio (MR) beamforming is applied for the design of the active beamforming in terms of instantaneous channel state information (CSI). Firstly, we rely on an aggregated channel estimation approach that reduces the overhead required for channel estimation while providing sufficient information for data processing. We obtain the normalized mean square error (NMSE) of the channel estimate per AP, and design the passive beamforming (PB) of the surface based on the long-time statistical CSI. Next, we derive the received signal in the asymptotic regime of numbers of APs and surface elements. Then, we obtain a closed-form expression of the downlink achievable rate for arbitrary numbers of APs and STAR-RIS elements under statistical CSI. Finally, based on the derived expressions, the numerical results show the feasibility and the advantages of deploying a STAR-RIS into conventional CF mMIMO systems. In particular, we theoretically analyze the properties of STAR-RIS-assisted CF mMIMO systems and reveal explicit insights in terms of the impact of channel correlation, the number of surface elements, and the pilot contamination on the achievable rate.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18343"
  },
  "2311.18341": {
    "title": "Learning Robust Precipitation Forecaster by Temporal Frame Interpolation",
    "authors": [
      "Lu Han",
      "Xu-Yang Chen",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "abstract": "Recent advances in deep learning have significantly elevated weather prediction models. However, these models often falter in real-world scenarios due to their sensitivity to spatial-temporal shifts. This issue is particularly acute in weather forecasting, where models are prone to overfit to local and temporal variations, especially when tasked with fine-grained predictions. In this paper, we address these challenges by developing a robust precipitation forecasting model that demonstrates resilience against such spatial-temporal discrepancies. We introduce Temporal Frame Interpolation (TFI), a novel technique that enhances the training dataset by generating synthetic samples through interpolating adjacent frames from satellite imagery and ground radar data, thus improving the model's robustness against frame noise. Moreover, we incorporate a unique Multi-Level Dice (ML-Dice) loss function, leveraging the ordinal nature of rainfall intensities to improve the model's performance. Our approach has led to significant improvements in forecasting precision, culminating in our model securing \\textit{1st place} in the transfer learning leaderboard of the \\textit{Weather4cast'23} competition. This achievement not only underscores the effectiveness of our methodologies but also establishes a new standard for deep learning applications in weather forecasting. Our code and weights have been public on \\url{https://github.com/Secilia-Cxy/UNetTFI}.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2311.18341"
  },
  "2311.18340": {
    "title": "Neuromorphic Incremental on-chip Learning with Hebbian Weight Consolidation",
    "authors": [
      "Zifan Ning",
      "Chaojin Chen",
      "Xiang Cheng",
      "Wangzi Yao",
      "Tielin Zhang",
      "Bo Xu"
    ],
    "abstract": "As next-generation implantable brain-machine interfaces become pervasive on edge device, incrementally learning new tasks in bio-plasticity ways is urgently demanded for Neuromorphic chips. Due to the inherent characteristics of its structure, spiking neural networks are naturally well-suited for BMI-chips. Here we propose Hebbian Weight Consolidation, as well as an on-chip learning framework. HWC selectively masks synapse modifications for previous tasks, retaining them to store new knowledge from subsequent tasks while preserving the old knowledge. Leveraging the bio-plasticity of dendritic spines, the intrinsic self-organizing nature of Hebbian Weight Consolidation aligns naturally with the incremental learning paradigm, facilitating robust learning outcomes. By reading out spikes layer by layer and performing back-propagation on the external micro-controller unit, MLoC can efficiently accomplish on-chip learning. Experiments show that our HWC algorithm up to 23.19% outperforms lower bound that without incremental learning algorithm, particularly in more challenging monkey behavior decoding scenarios. Taking into account on-chip computing on Synsense Speck 2e chip, our proposed algorithm exhibits an improvement of 11.06%. This study demonstrates the feasibility of employing incremental learning for high-performance neural signal decoding in next-generation brain-machine interfaces.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18340"
  },
  "2311.18339": {
    "title": "Tight Bounds for The Price of Fairness",
    "authors": [
      "Yifeng Cao",
      "Yichuan Ding",
      "Daniel Granot"
    ],
    "abstract": "A central decision maker (CDM), who seeks an efficient allocation of scarce resources among a finite number of players, often has to incorporate fairness criteria to avoid unfair outcomes. Indeed, the Price of Fairness (POF), a term coined in Bertsimas et al. (2011), refers to the efficiency loss due to the incorporation of fairness criteria into the allocation method. Quantifying the POF would help the CDM strike an appropriate balance between efficiency and fairness. In this paper we improve upon existing results in the literature, by providing tight bounds for the POF for the proportional fairness criterion for any $n$, when the maximum achievable utilities of the players are equal or are not equal. Further, while Bertsimas et al. (2011) have already derived a tight bound for the max-min fairness criterion for the case that all players have equal maximum achievable utilities, we also provide a tight bound in scenarios where these utilities are not equal. Finally, we investigate the sensitivity of our bounds and Bertsimas et al. (2011) bounds for the POF to the variability of the maximum achievable utilities.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18339"
  },
  "2311.18334": {
    "title": "Near-Field Beamfocusing with Polarized Antennas",
    "authors": [
      "Adrian Agustin",
      "Xavier Mestre"
    ],
    "abstract": "One of the most relevant challenges in future 6G wireless networks is how to support a massive spatial multiplexing of a large number of user terminals. Recently, extremely large antenna arrays (ELAAs), also referred to as extra-large MIMO (XL-MIMO), have emerged as an potential enabler of this type of spatially multiplexed transmission. These massive configurations substantially increase the number of available spatial degrees of freedom (transmission modes) while also enabling to spatially focus the transmitted energy into a very small region, thanks to the properties of near-field propagation and the large number of transmitters. This work explores whether multiplexing of multiple orthogonal polarizations can enhance the system performance in the near-field. We concentrate on a simple scenario consisting of a Uniform Linear Array (ULA) and a single antenna element user equipment (UE). We demonstrate that the number of spatial degrees of freedom can be as large as 3 in the near-field of a Line of Sight (LoS) channel when both transmitter and receiver employ three orthogonal linear polarizations. In the far-field, however, the maximum number of spatial degrees of freedom tends to be only 2, due to the fact that the equivalent MIMO channel becomes rank deficient. We provide an analytical approximation to the achievable rate, which allows us to derive approximations to the optimal antenna spacing and array size that maximize the achievable rate\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18334"
  },
  "2311.18332": {
    "title": "Multilevel Saliency-Guided Self-Supervised Learning for Image Anomaly Detection",
    "authors": [
      "Jianjian Qin",
      "Chunzhi Gu",
      "Jun Yu",
      "Chao Zhang"
    ],
    "abstract": "Anomaly detection (AD) is a fundamental task in computer vision. It aims to identify incorrect image data patterns which deviate from the normal ones. Conventional methods generally address AD by preparing augmented negative samples to enforce self-supervised learning. However, these techniques typically do not consider semantics during augmentation, leading to the generation of unrealistic or invalid negative samples. Consequently, the feature extraction network can be hindered from embedding critical features. In this study, inspired by visual attention learning approaches, we propose CutSwap, which leverages saliency guidance to incorporate semantic cues for augmentation. Specifically, we first employ LayerCAM to extract multilevel image features as saliency maps and then perform clustering to obtain multiple centroids. To fully exploit saliency guidance, on each map, we select a pixel pair from the cluster with the highest centroid saliency to form a patch pair. Such a patch pair includes highly similar context information with dense semantic correlations. The resulting negative sample is created by swapping the locations of the patch pair. Compared to prior augmentation methods, CutSwap generates more subtle yet realistic negative samples to facilitate quality feature learning. Extensive experimental and ablative evaluations demonstrate that our method achieves state-of-the-art AD performance on two mainstream AD benchmark datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18332"
  },
  "2311.18329": {
    "title": "Instructing Hierarchical Tasks to Robots by Verbal Commands",
    "authors": [
      "P. Telkes",
      "A. Angleraud",
      "R. Pieters"
    ],
    "abstract": "Natural language is an effective tool for communication, as information can be expressed in different ways and at different levels of complexity. Verbal commands, utilized for instructing robot tasks, can therefor replace traditional robot programming techniques, and provide a more expressive means to assign actions and enable collaboration. However, the challenge of utilizing speech for robot programming is how actions and targets can be grounded to physical entities in the world. In addition, to be time-efficient, a balance needs to be found between fine- and course-grained commands and natural language phrases. In this work we provide a framework for instructing tasks to robots by verbal commands. The framework includes functionalities for single commands to actions and targets, as well as longer-term sequences of actions, thereby providing a hierarchical structure to the robot tasks. Experimental evaluation demonstrates the functionalities of the framework by human collaboration with a robot in different tasks, with different levels of complexity. The tools are provided open-source at https://petim44.github.io/voice-jogger/\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18329"
  },
  "2311.18318": {
    "title": "Unclonable Cryptography with Unbounded Collusions",
    "authors": [
      "Alper \u00c7akan",
      "Vipul Goyal"
    ],
    "abstract": "Quantum no-cloning theorem gives rise to the intriguing possibility of quantum copy protection where we encode a program in a quantum state such that a user in possession of k such states cannot create k + 1 working copies. Introduced by Aaronson (CCC 09) over a decade ago, copy protection has proven to be notoriously hard to achieve.\n  In this work, we construct public-key encryption and functional encryption schemes whose secret keys are copy-protected against unbounded collusions in the plain model (i.e. without any idealized oracles), assuming (post-quantum) subexponentially secure iO, one-way functions and LWE. This resolves a long-standing open question of constructing fully collusion-resistant copy-protected functionalities raised by multiple previous works.\n  Prior to our work, copy-protected functionalities were known only in restricted collusion models where either an a-priori bound on the collusion size was needed, in the plain model with the same assumptions as ours (Liu, Liu, Qian, Zhandry [TCC 22]), or adversary was only prevented from doubling their number of working programs, in a structured quantum oracle model (Aaronson [CCC 09]).\n  We obtain our results through a novel technique which uses identity-based encryption to construct unbounded collusion resistant copy-protection schemes from 1-to-2 secure schemes. This is analogous to the technique of using digital signatures to construct full-fledged quantum money from single banknote schemes1 (Lutomirski et al. [ICS 09], Farhi et al. [ITCS 12], Aaronson and Christiano [STOC 12]). We believe our technique is of independent interest.\n  Along the way, we also construct a puncturable functional encryption scheme whose master secret key can be punctured at all functions f such that f (m0) != f (m1). This might also be of independent interest.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18318"
  },
  "2311.18316": {
    "title": "Learning for Semantic Knowledge Base-Guided Online Feature Transmission in Dynamic Channels",
    "authors": [
      "Xiangyu Gao",
      "Yaping Sun",
      "Dongyu Wei",
      "Xiaodong Xu",
      "Hao Chen",
      "Hao Yin",
      "Shuguang Cui"
    ],
    "abstract": "With the proliferation of edge computing, efficient AI inference on edge devices has become essential for intelligent applications such as autonomous vehicles and VR/AR. In this context, we address the problem of efficient remote object recognition by optimizing feature transmission between mobile devices and edge servers. We propose an online optimization framework to address the challenge of dynamic channel conditions and device mobility in an end-to-end communication system. Our approach builds upon existing methods by leveraging a semantic knowledge base to drive multi-level feature transmission, accounting for temporal factors and dynamic elements throughout the transmission process. To solve the online optimization problem, we design a novel soft actor-critic-based deep reinforcement learning system with a carefully designed reward function for real-time decision-making, overcoming the optimization difficulty of the NP-hard problem and achieving the minimization of semantic loss while respecting latency constraints. Numerical results showcase the superiority of our approach compared to traditional greedy methods under various system setups.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18316"
  },
  "2311.18313": {
    "title": "Automatic Implementation of Neural Networks through Reaction Networks -- Part I: Circuit Design and Convergence Analysis",
    "authors": [
      "Yuzhen Fan",
      "Xiaoyu Zhang",
      "Chuanhou Gao",
      "Denis Dochain"
    ],
    "abstract": "Information processing relying on biochemical interactions in the cellular environment is essential for biological organisms. The implementation of molecular computational systems holds significant interest and potential in the fields of synthetic biology and molecular computation. This two-part article aims to introduce a programmable biochemical reaction network (BCRN) system endowed with mass action kinetics that realizes the fully connected neural network (FCNN) and has the potential to act automatically in vivo. In part I, the feedforward propagation computation, the backpropagation component, and all bridging processes of FCNN are ingeniously designed as specific BCRN modules based on their dynamics. This approach addresses a design gap in the biochemical assignment module and judgment termination module and provides a novel precise and robust realization of bi-molecular reactions for the learning process. Through equilibrium approaching, we demonstrate that the designed BCRN system achieves FCNN functionality with exponential convergence to target computational results, thereby enhancing the theoretical support for such work. Finally, the performance of this construction is further evaluated on two typical logic classification problems.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18313"
  },
  "2311.18307": {
    "title": "Categorical Traffic Transformer: Interpretable and Diverse Behavior Prediction with Tokenized Latent",
    "authors": [
      "Yuxiao Chen",
      "Sander Tonkens",
      "Marco Pavone"
    ],
    "abstract": "Adept traffic models are critical to both planning and closed-loop simulation for autonomous vehicles (AV), and key design objectives include accuracy, diverse multimodal behaviors, interpretability, and downstream compatibility. Recently, with the advent of large language models (LLMs), an additional desirable feature for traffic models is LLM compatibility. We present Categorical Traffic Transformer (CTT), a traffic model that outputs both continuous trajectory predictions and tokenized categorical predictions (lane modes, homotopies, etc.). The most outstanding feature of CTT is its fully interpretable latent space, which enables direct supervision of the latent variable from the ground truth during training and avoids mode collapse completely. As a result, CTT can generate diverse behaviors conditioned on different latent modes with semantic meanings while beating SOTA on prediction accuracy. In addition, CTT's ability to input and output tokens enables integration with LLMs for common-sense reasoning and zero-shot generalization.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18307"
  },
  "2311.18306": {
    "title": "PAUNet: Precipitation Attention-based U-Net for rain prediction from satellite radiance data",
    "authors": [
      "P. Jyoteeshkumar Reddy",
      "Harish Baki",
      "Sandeep Chinta",
      "Richard Matear",
      "John Taylor"
    ],
    "abstract": "This paper introduces Precipitation Attention-based U-Net (PAUNet), a deep learning architecture for predicting precipitation from satellite radiance data, addressing the challenges of the Weather4cast 2023 competition. PAUNet is a variant of U-Net and Res-Net, designed to effectively capture the large-scale contextual information of multi-band satellite images in visible, water vapor, and infrared bands through encoder convolutional layers with center cropping and attention mechanisms. We built upon the Focal Precipitation Loss including an exponential component (e-FPL), which further enhanced the importance across different precipitation categories, particularly medium and heavy rain. Trained on a substantial dataset from various European regions, PAUNet demonstrates notable accuracy with a higher Critical Success Index (CSI) score than the baseline model in predicting rainfall over multiple time slots. PAUNet's architecture and training methodology showcase improvements in precipitation forecasting, crucial for sectors like emergency services and retail and supply chain management.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18306"
  },
  "2311.18303": {
    "title": "OmniMotionGPT: Animal Motion Generation with Limited Data",
    "authors": [
      "Zhangsihao Yang",
      "Mingyuan Zhou",
      "Mengyi Shan",
      "Bingbing Wen",
      "Ziwei Xuan",
      "Mitch Hill",
      "Junjie Bai",
      "Guo-Jun Qi",
      "Yalin Wang"
    ],
    "abstract": "Our paper aims to generate diverse and realistic animal motion sequences from textual descriptions, without a large-scale animal text-motion dataset. While the task of text-driven human motion synthesis is already extensively studied and benchmarked, it remains challenging to transfer this success to other skeleton structures with limited data. In this work, we design a model architecture that imitates Generative Pretraining Transformer (GPT), utilizing prior knowledge learned from human data to the animal domain. We jointly train motion autoencoders for both animal and human motions and at the same time optimize through the similarity scores among human motion encoding, animal motion encoding, and text CLIP embedding. Presenting the first solution to this problem, we are able to generate animal motions with high diversity and fidelity, quantitatively and qualitatively outperforming the results of training human motion generation baselines on animal data. Additionally, we introduce AnimalML3D, the first text-animal motion dataset with 1240 animation sequences spanning 36 different animal identities. We hope this dataset would mediate the data scarcity problem in text-driven animal motion generation, providing a new playground for the research community.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18303"
  },
  "2311.18300": {
    "title": "Multi-label Annotation for Visual Multi-Task Learning Models",
    "authors": [
      "G. Sharma",
      "A. Angleraud",
      "R. Pieters"
    ],
    "abstract": "Deep learning requires large amounts of data, and a well-defined pipeline for labeling and augmentation. Current solutions support numerous computer vision tasks with dedicated annotation types and formats, such as bounding boxes, polygons, and key points. These annotations can be combined into a single data format to benefit approaches such as multi-task models. However, to our knowledge, no available labeling tool supports the export functionality for a combined benchmark format, and no augmentation library supports transformations for the combination of all. In this work, these functionalities are presented, with visual data annotation and augmentation to train a multi-task model (object detection, segmentation, and key point extraction). The tools are demonstrated in two robot perception use cases.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18300"
  },
  "2311.18299": {
    "title": "Reconstructing the normal and shape at specularities in endoscopy",
    "authors": [
      "Karim Makki",
      "Adrien Bartoli"
    ],
    "abstract": "Specularities are numerous in endoscopic images. They occur as many white small elliptic spots, which are generally ruled out as nuisance in image analysis and computer vision methods. Instead, we propose to use specularities as cues for 3D perception. Specifically, we propose a new method to reconstruct, at each specularity, the observed tissue's normal direction (i.e., its orientation) and shape (i.e., its curvature) from a single image. We show results on simulated and real interventional images.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18299"
  },
  "2311.18297": {
    "title": "TrustMark: Universal Watermarking for Arbitrary Resolution Images",
    "authors": [
      "Tu Bui",
      "Shruti Agarwal",
      "John Collomosse"
    ],
    "abstract": "Imperceptible digital watermarking is important in copyright protection, misinformation prevention, and responsible generative AI. We propose TrustMark - a GAN-based watermarking method with novel design in architecture and spatio-spectra losses to balance the trade-off between watermarked image quality with the watermark recovery accuracy. Our model is trained with robustness in mind, withstanding various in- and out-place perturbations on the encoded image. Additionally, we introduce TrustMark-RM - a watermark remover method useful for re-watermarking. Our methods achieve state-of-art performance on 3 benchmarks comprising arbitrary resolution images.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18297"
  },
  "2311.18295": {
    "title": "Almost-Linear Time Algorithms for Incremental Graphs: Cycle Detection, SCCs, $s$-$t$ Shortest Path, and Minimum-Cost Flow",
    "authors": [
      "Li Chen",
      "Rasmus Kyng",
      "Yang P. Liu",
      "Simon Meierhans",
      "Maximilian Probst Gutenberg"
    ],
    "abstract": "We give the first almost-linear time algorithms for several problems in incremental graphs including cycle detection, strongly connected component maintenance, $s$-$t$ shortest path, maximum flow, and minimum-cost flow. To solve these problems, we give a deterministic data structure that returns a $m^{o(1)}$-approximate minimum-ratio cycle in fully dynamic graphs in amortized $m^{o(1)}$ time per update. Combining this with the interior point method framework of Brand-Liu-Sidford (STOC 2023) gives the first almost-linear time algorithm for deciding the first update in an incremental graph after which the cost of the minimum-cost flow attains value at most some given threshold $F$. By rather direct reductions to minimum-cost flow, we are then able to solve the problems in incremental graphs mentioned above.\n  At a high level, our algorithm dynamizes the $\\ell_1$ oblivious routing of Rozho\u0148-Grunau-Haeupler-Zuzic-Li (STOC 2022), and develops a method to extract an approximate minimum ratio cycle from the structure of the oblivious routing. To maintain the oblivious routing, we use tools from concurrent work of Kyng-Meierhans-Probst Gutenberg which designed vertex sparsifiers for shortest paths, in order to maintain a sparse neighborhood cover in fully dynamic graphs.\n  To find a cycle, we first show that an approximate minimum ratio cycle can be represented as a fundamental cycle on a small set of trees resulting from the oblivious routing. Then, we find a cycle whose quality is comparable to the best tree cycle. This final cycle query step involves vertex and edge sparsification procedures reminiscent of previous works, but crucially requires a more powerful dynamic spanner which can handle far more edge insertions. We build such a spanner via a construction that hearkens back to the classic greedy spanner algorithm.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18295"
  },
  "2311.18291": {
    "title": "TLDR: Text Based Last-layer Retraining for Debiasing Image Classifiers",
    "authors": [
      "Juhyeon Park",
      "Seokhyeon Jeong",
      "Taesup Moon"
    ],
    "abstract": "A classifier may depend on incidental features stemming from a strong correlation between the feature and the classification target in the training dataset. Recently, Last Layer Retraining (LLR) with group-balanced datasets is known to be efficient in mitigating the spurious correlation of classifiers. However, the acquisition of group-balanced datasets is costly, which hinders the applicability of the LLR method. In this work, we propose to perform LLR based on text datasets built with large language models for a general image classifier. We demonstrate that text can be a proxy for its corresponding image beyond the image-text joint embedding space, such as CLIP. Based on this, we use generated texts to train the final layer in the embedding space of the arbitrary image classifier. In addition, we propose a method of filtering the generated words to get rid of noisy, imprecise words, which reduces the effort of inspecting each word. We dub these procedures as TLDR (\\textbf{T}ext-based \\textbf{L}ast layer retraining for \\textbf{D}ebiasing image classifie\\textbf{R}s) and show our method achieves the performance that is comparable to those of the LLR methods that also utilize group-balanced image dataset for retraining. Furthermore, TLDR outperforms other baselines that involve training the last linear layer without a group annotated dataset.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18291"
  },
  "2311.18288": {
    "title": "CosAvatar: Consistent and Animatable Portrait Video Tuning with Text Prompt",
    "authors": [
      "Haiyao Xiao",
      "Chenglai Zhong",
      "Xuan Gao",
      "Yudong Guo",
      "Juyong Zhang"
    ],
    "abstract": "Recently, text-guided digital portrait editing has attracted more and more attentions. However, existing methods still struggle to maintain consistency across time, expression, and view or require specific data prerequisites. To solve these challenging problems, we propose CosAvatar, a high-quality and user-friendly framework for portrait tuning. With only monocular video and text instructions as input, we can produce animatable portraits with both temporal and 3D consistency. Different from methods that directly edit in the 2D domain, we employ a dynamic NeRF-based 3D portrait representation to model both the head and torso. We alternate between editing the video frames' dataset and updating the underlying 3D portrait until the edited frames reach 3D consistency. Additionally, we integrate the semantic portrait priors to enhance the edited results, allowing precise modifications in specified semantic areas. Extensive results demonstrate that our proposed method can not only accurately edit portrait styles or local attributes based on text instructions but also support expressive animation driven by a source video.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18288"
  },
  "2311.18286": {
    "title": "SimulFlow: Simultaneously Extracting Feature and Identifying Target for Unsupervised Video Object Segmentation",
    "authors": [
      "Lingyi Hong",
      "Wei Zhang",
      "Shuyong Gao",
      "Hong Lu",
      "WenQiang Zhang"
    ],
    "abstract": "Unsupervised video object segmentation (UVOS) aims at detecting the primary objects in a given video sequence without any human interposing. Most existing methods rely on two-stream architectures that separately encode the appearance and motion information before fusing them to identify the target and generate object masks. However, this pipeline is computationally expensive and can lead to suboptimal performance due to the difficulty of fusing the two modalities properly. In this paper, we propose a novel UVOS model called SimulFlow that simultaneously performs feature extraction and target identification, enabling efficient and effective unsupervised video object segmentation. Concretely, we design a novel SimulFlow Attention mechanism to bridege the image and motion by utilizing the flexibility of attention operation, where coarse masks predicted from fused feature at each stage are used to constrain the attention operation within the mask area and exclude the impact of noise. Because of the bidirectional information flow between visual and optical flow features in SimulFlow Attention, no extra hand-designed fusing module is required and we only adopt a light decoder to obtain the final prediction. We evaluate our method on several benchmark datasets and achieve state-of-the-art results. Our proposed approach not only outperforms existing methods but also addresses the computational complexity and fusion difficulties caused by two-stream architectures. Our models achieve 87.4% J & F on DAVIS-16 with the highest speed (63.7 FPS on a 3090) and the lowest parameters (13.7 M). Our SimulFlow also obtains competitive results on video salient object detection datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18286"
  },
  "2311.18285": {
    "title": "Co-speech gestures for human-robot collaboration",
    "authors": [
      "A. Ekrekli",
      "A. Angleraud",
      "G. Sharma",
      "R. Pieters"
    ],
    "abstract": "Collaboration between human and robot requires effective modes of communication to assign robot tasks and coordinate activities. As communication can utilize different modalities, a multi-modal approach can be more expressive than single modal models alone. In this work we propose a co-speech gesture model that can assign robot tasks for human-robot collaboration. Human gestures and speech, detected by computer vision and speech recognition, can thus refer to objects in the scene and apply robot actions to them. We present an experimental evaluation of the multi-modal co-speech model with a real-world industrial use case. Results demonstrate that multi-modal communication is easy to achieve and can provide benefits for collaboration with respect to single modal tools.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18285"
  },
  "2311.18284": {
    "title": "The Complement of the Djokovic-Winkler Relation",
    "authors": [
      "Marc Hellmuth",
      "Bruno J. Schmidt",
      "Guillaume E. Scholz",
      "Sandhya Thekkumpadan Puthiyaveedu"
    ],
    "abstract": "The Djokovi\u0107-Winkler relation $\u0398$ is a binary relation defined on the edge set of a given graph that is based on the distances of certain vertices and which plays a prominent role in graph theory. In this paper, we explore the relatively uncharted ``reflexive complement'' $\\overline\u0398$ of $\u0398$, where $(e,f)\\in \\overline\u0398$ if and only if $e=f$ or $(e,f)\\notin \u0398$ for edges $e$ and $f$. We establish the relationship between $\\overline\u0398$ and the set $\u0394_{ef}$, comprising the distances between the vertices of $e$ and $f$ and shed some light on the intricacies of its transitive closure $\\overline\u0398^*$. Notably, we demonstrate that $\\overline\u0398^*$ exhibits multiple equivalence classes only within a restricted subclass of complete multipartite graphs. In addition, we characterize non-trivial relations $R$ that coincide with $\\overline\u0398$ as those where the graph representation is disconnected, with each connected component being the (join of) Cartesian product of complete graphs. The latter results imply, somewhat surprisingly, that knowledge about the distances between vertices is not required to determine $\\overline\u0398^*$. Moreover, $\\overline\u0398^*$ has either exactly one or three equivalence classes.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18284"
  },
  "2311.18281": {
    "title": "Utilizing Radiomic Feature Analysis For Automated MRI Keypoint Detection: Enhancing Graph Applications",
    "authors": [
      "Sahar Almahfouz Nasser",
      "Shashwat Pathak",
      "Keshav Singhal",
      "Mohit Meena",
      "Nihar Gupte",
      "Ananya Chinmaya",
      "Prateek Garg",
      "Amit Sethi"
    ],
    "abstract": "Graph neural networks (GNNs) present a promising alternative to CNNs and transformers in certain image processing applications due to their parameter-efficiency in modeling spatial relationships. Currently, a major area of research involves the converting non-graph input data for GNN-based models, notably in scenarios where the data originates from images. One approach involves converting images into nodes by identifying significant keypoints within them. Super-Retina, a semi-supervised technique, has been utilized for detecting keypoints in retinal images. However, its limitations lie in the dependency on a small initial set of ground truth keypoints, which is progressively expanded to detect more keypoints. Having encountered difficulties in detecting consistent initial keypoints in brain images using SIFT and LoFTR, we proposed a new approach: radiomic feature-based keypoint detection. Demonstrating the anatomical significance of the detected keypoints was achieved by showcasing their efficacy in improving registration processes guided by these keypoints. Subsequently, these keypoints were employed as the ground truth for the keypoint detection method (LK-SuperRetina). Furthermore, the study showcases the application of GNNs in image matching, highlighting their superior performance in terms of both the number of good matches and confidence scores. This research sets the stage for expanding GNN applications into various other applications, including but not limited to image classification, segmentation, and registration.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18281"
  },
  "2311.18273": {
    "title": "HKUST at SemEval-2023 Task 1: Visual Word Sense Disambiguation with Context Augmentation and Visual Assistance",
    "authors": [
      "Zhuohao Yin",
      "Xin Huang"
    ],
    "abstract": "Visual Word Sense Disambiguation (VWSD) is a multi-modal task that aims to select, among a batch of candidate images, the one that best entails the target word's meaning within a limited context. In this paper, we propose a multi-modal retrieval framework that maximally leverages pretrained Vision-Language models, as well as open knowledge bases and datasets. Our system consists of the following key components: (1) Gloss matching: a pretrained bi-encoder model is used to match contexts with proper senses of the target words; (2) Prompting: matched glosses and other textual information, such as synonyms, are incorporated using a prompting template; (3) Image retrieval: semantically matching images are retrieved from large open datasets using prompts as queries; (4) Modality fusion: contextual information from different modalities are fused and used for prediction. Although our system does not produce the most competitive results at SemEval-2023 Task 1, we are still able to beat nearly half of the teams. More importantly, our experiments reveal acute insights for the field of Word Sense Disambiguation (WSD) and multi-modal learning. Our code is available on GitHub.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18273"
  },
  "2311.18270": {
    "title": "Beyond Entropy: Style Transfer Guided Single Image Continual Test-Time Adaptation",
    "authors": [
      "Younggeol Cho",
      "Youngrae Kim",
      "Dongman Lee"
    ],
    "abstract": "Continual test-time adaptation (cTTA) methods are designed to facilitate the continual adaptation of models to dynamically changing real-world environments where computational resources are limited. Due to this inherent limitation, existing approaches fail to simultaneously achieve accuracy and efficiency. In detail, when using a single image, the instability caused by batch normalization layers and entropy loss significantly destabilizes many existing methods in real-world cTTA scenarios. To overcome these challenges, we present BESTTA, a novel single image continual test-time adaptation method guided by style transfer, which enables stable and efficient adaptation to the target environment by transferring the style of the input image to the source style. To implement the proposed method, we devise BeIN, a simple yet powerful normalization method, along with the style-guided losses. We demonstrate that BESTTA effectively adapts to the continually changing target environment, leveraging only a single image on both semantic segmentation and image classification tasks. Remarkably, despite training only two parameters in a BeIN layer consuming the least memory, BESTTA outperforms existing state-of-the-art methods in terms of performance.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18270"
  },
  "2311.18268": {
    "title": "An Explorative Study on Document Type Assignment of Review Articles in Web of Science, Scopus and Journals' Website",
    "authors": [
      "Manman Zhu",
      "Xinyue Lu",
      "Fuyou Chen",
      "Liying Yang",
      "Zhesi Shen"
    ],
    "abstract": "Accurately assigning the document type of review articles in citation index databases like Web of Science(WoS) and Scopus is important. This study aims to investigate the document type assignation of review articles in web of Science, Scopus and Journals' website in a large scale. 27,616 papers from 160 journals from 10 review journal series indexed in SCI are analyzed. The document types of these papers labeled on journals' website, and assigned by WoS and Scopus are retrieved and compared to determine the assigning accuracy and identify the possible reasons of wrongly assigning. For the document type labeled on the website, we further differentiate them into explicit review and implicit review based on whether the website directly indicating it is review or not. We find that WoS and Scopus performed similarly, with an average precision of about 99% and recall of about 80%. However, there were some differences between WoS and Scopus across different journal series and within the same journal series. The assigning accuracy of WoS and Scopus for implicit reviews dropped significantly. This study provides a reference for the accuracy of document type assigning of review articles in WoS and Scopus, and the identified pattern for assigning implicit reviews may be helpful to better labeling on website, WoS and Scopus.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18268"
  },
  "2311.18266": {
    "title": "Prompt-Based Exemplar Super-Compression and Regeneration for Class-Incremental Learning",
    "authors": [
      "Ruxiao Duan",
      "Yaoyao Liu",
      "Jieneng Chen",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "abstract": "Replay-based methods in class-incremental learning (CIL) have attained remarkable success, as replaying the exemplars of old classes can significantly mitigate catastrophic forgetting. Despite their effectiveness, the inherent memory restrictions of CIL result in saving a limited number of exemplars with poor diversity, leading to data imbalance and overfitting issues. In this paper, we introduce a novel exemplar super-compression and regeneration method, ESCORT, which substantially increases the quantity and enhances the diversity of exemplars. Rather than storing past images, we compress images into visual and textual prompts, e.g., edge maps and class tags, and save the prompts instead, reducing the memory usage of each exemplar to 1/24 of the original size. In subsequent learning phases, diverse high-resolution exemplars are generated from the prompts by a pre-trained diffusion model, e.g., ControlNet. To minimize the domain gap between generated exemplars and real images, we propose partial compression and diffusion-based data augmentation, allowing us to utilize an off-the-shelf diffusion model without fine-tuning it on the target dataset. Therefore, the same diffusion model can be downloaded whenever it is needed, incurring no memory consumption. Comprehensive experiments demonstrate that our method significantly improves model performance across multiple CIL benchmarks, e.g., 5.0 percentage points higher than the previous state-of-the-art on 10-phase Caltech-256 dataset.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18266"
  },
  "2311.18265": {
    "title": "MCI Detection using fMRI time series embeddings of Recurrence plots",
    "authors": [
      "Ninad Aithal",
      "Chakka Sai Pradeep",
      "Neelam Sinha"
    ],
    "abstract": "The human brain can be conceptualized as a dynamical system. Utilizing resting state fMRI time series imaging, we can study the underlying dynamics at ear-marked Regions of Interest (ROIs) to understand structure or lack thereof. This differential behavior could be key to understanding the neurodegeneration and also to classify between healthy and Mild Cognitive Impairment (MCI) subjects. In this study, we consider 6 brain networks spanning over 160 ROIs derived from Dosenbach template, where each network consists of 25-30 ROIs. Recurrence plot, extensively used to understand evolution of time series, is employed. Representative time series at each ROI is converted to its corresponding recurrence plot visualization, which is subsequently condensed to low-dimensional feature embeddings through Autoencoders. The performance of the proposed method is shown on fMRI volumes of 100 subjects (balanced data), taken from publicly available ADNI dataset. Results obtained show peak classification accuracy of 93% among the 6 brain networks, mean accuracy of 89.3% thereby illustrating promise in the proposed approach.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18265"
  },
  "2311.18261": {
    "title": "Learning Exactly Linearizable Deep Dynamics Models",
    "authors": [
      "Ryuta Moriyasu",
      "Masayuki Kusunoki",
      "Kenji Kashima"
    ],
    "abstract": "Research on control using models based on machine-learning methods has now shifted to the practical engineering stage. Achieving high performance and theoretically guaranteeing the safety of the system is critical for such applications. In this paper, we propose a learning method for exactly linearizable dynamical models that can easily apply various control theories to ensure stability, reliability, etc., and to provide a high degree of freedom of expression. As an example, we present a design that combines simple linear control and control barrier functions. The proposed model is employed for the real-time control of an automotive engine, and the results demonstrate good predictive performance and stable control under constraints.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18261"
  },
  "2311.18260": {
    "title": "Consensus, dissensus and synergy between clinicians and specialist foundation models in radiology report generation",
    "authors": [
      "Ryutaro Tanno",
      "David G. T. Barrett",
      "Andrew Sellergren",
      "Sumedh Ghaisas",
      "Sumanth Dathathri",
      "Abigail See",
      "Johannes Welbl",
      "Karan Singhal",
      "Shekoofeh Azizi",
      "Tao Tu",
      "Mike Schaekermann",
      "Rhys May",
      "Roy Lee",
      "SiWai Man",
      "Zahra Ahmed",
      "Sara Mahdavi",
      "Yossi Matias",
      "Joelle Barral",
      "Ali Eslami",
      "Danielle Belgrave",
      "Vivek Natarajan",
      "Shravya Shetty",
      "Pushmeet Kohli",
      "Po-Sen Huang",
      "Alan Karthikesalingam",
      "et al. (1 additional authors not shown)"
    ],
    "abstract": "Radiology reports are an instrumental part of modern medicine, informing key clinical decisions such as diagnosis and treatment. The worldwide shortage of radiologists, however, restricts access to expert care and imposes heavy workloads, contributing to avoidable errors and delays in report delivery. While recent progress in automated report generation with vision-language models offer clear potential in ameliorating the situation, the path to real-world adoption has been stymied by the challenge of evaluating the clinical quality of AI-generated reports. In this study, we build a state-of-the-art report generation system for chest radiographs, $\\textit{Flamingo-CXR}$, by fine-tuning a well-known vision-language foundation model on radiology data. To evaluate the quality of the AI-generated reports, a group of 16 certified radiologists provide detailed evaluations of AI-generated and human written reports for chest X-rays from an intensive care setting in the United States and an inpatient setting in India. At least one radiologist (out of two per case) preferred the AI report to the ground truth report in over 60$\\%$ of cases for both datasets. Amongst the subset of AI-generated reports that contain errors, the most frequently cited reasons were related to the location and finding, whereas for human written reports, most mistakes were related to severity and finding. This disparity suggested potential complementarity between our AI system and human experts, prompting us to develop an assistive scenario in which Flamingo-CXR generates a first-draft report, which is subsequently revised by a clinician. This is the first demonstration of clinician-AI collaboration for report writing, and the resultant reports are assessed to be equivalent or preferred by at least one radiologist to reports written by experts alone in 80$\\%$ of in-patient cases and 60$\\%$ of intensive care cases.\n        \u25b3 Less",
    "submission_date": "20 December, 2023",
    "eprint_id": "2311.18260"
  },
  "2311.18257": {
    "title": "Diffusion Models Without Attention",
    "authors": [
      "Jing Nathan Yan",
      "Jiatao Gu",
      "Alexander M. Rush"
    ],
    "abstract": "In recent advancements in high-fidelity image generation, Denoising Diffusion Probabilistic Models (DDPMs) have emerged as a key player. However, their application at high resolutions presents significant computational challenges. Current methods, such as patchifying, expedite processes in UNet and Transformer architectures but at the expense of representational capacity. Addressing this, we introduce the Diffusion State Space Model (DiffuSSM), an architecture that supplants attention mechanisms with a more scalable state space model backbone. This approach effectively handles higher resolutions without resorting to global compression, thus preserving detailed image representation throughout the diffusion process. Our focus on FLOP-efficient architectures in diffusion training marks a significant step forward. Comprehensive evaluations on both ImageNet and LSUN datasets at two resolutions demonstrate that DiffuSSMs are on par or even outperform existing diffusion models with attention modules in FID and Inception Score metrics while significantly reducing total FLOP usage.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18257"
  },
  "2311.18252": {
    "title": "Navigating Privacy and Copyright Challenges Across the Data Lifecycle of Generative AI",
    "authors": [
      "Dawen Zhang",
      "Boming Xia",
      "Yue Liu",
      "Xiwei Xu",
      "Thong Hoang",
      "Zhenchang Xing",
      "Mark Staples",
      "Qinghua Lu",
      "Liming Zhu"
    ],
    "abstract": "The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI.\n        \u25b3 Less",
    "submission_date": "10 January, 2024",
    "eprint_id": "2311.18252"
  },
  "2311.18251": {
    "title": "Can Large Language Models Be Good Companions? An LLM-Based Eyewear System with Conversational Common Ground",
    "authors": [
      "Zhenyu Xu",
      "Hailin Xu",
      "Zhouyang Lu",
      "Yingying Zhao",
      "Rui Zhu",
      "Yujiang Wang",
      "Mingzhi Dong",
      "Yuhu Chang",
      "Qin Lv",
      "Robert P. Dick",
      "Fan Yang",
      "Tun Lu",
      "Ning Gu",
      "Li Shang"
    ],
    "abstract": "Developing chatbots as personal companions has long been a goal of artificial intelligence researchers. Recent advances in Large Language Models (LLMs) have delivered a practical solution for endowing chatbots with anthropomorphic language capabilities. However, it takes more than LLMs to enable chatbots that can act as companions. Humans use their understanding of individual personalities to drive conversations. Chatbots also require this capability to enable human-like companionship. They should act based on personalized, real-time, and time-evolving knowledge of their owner. We define such essential knowledge as the \\textit{common ground} between chatbots and their owners, and we propose to build a common-ground-aware dialogue system from an LLM-based module, named \\textit{OS-1}, to enable chatbot companionship. Hosted by eyewear, OS-1 can sense the visual and audio signals the user receives and extract real-time contextual semantics. Those semantics are categorized and recorded to formulate historical contexts from which the user's profile is distilled and evolves over time, i.e., OS-1 gradually learns about its user. OS-1 combines knowledge from real-time semantics, historical contexts, and user-specific profiles to produce a common-ground-aware prompt input into the LLM module. The LLM's output is converted to audio, spoken to the wearer when appropriate.We conduct laboratory and in-field studies to assess OS-1's ability to build common ground between the chatbot and its user. The technical feasibility and capabilities of the system are also evaluated. OS-1, with its common-ground awareness, can significantly improve user satisfaction and potentially lead to downstream tasks such as personal emotional support and assistance.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18251"
  },
  "2311.18248": {
    "title": "mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model",
    "authors": [
      "Anwen Hu",
      "Yaya Shi",
      "Haiyang Xu",
      "Jiabo Ye",
      "Qinghao Ye",
      "Ming Yan",
      "Chenliang Li",
      "Qi Qian",
      "Ji Zhang",
      "Fei Huang"
    ],
    "abstract": "Recently, the strong text creation ability of Large Language Models(LLMs) has given rise to many tools for assisting paper reading or even writing. However, the weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit their application scenarios, especially for scientific academic paper writing. In this work, towards a more versatile copilot for academic paper writing, we mainly focus on strengthening the multi-modal diagram analysis ability of Multimodal LLMs. By parsing Latex source files of high-quality papers, we carefully build a multi-modal diagram understanding dataset M-Paper. By aligning diagrams in the paper with related paragraphs, we construct professional diagram analysis samples for training and evaluation. M-Paper is the first dataset to support joint comprehension of multiple scientific diagrams, including figures and tables in the format of images or Latex codes. Besides, to better align the copilot with the user's intention, we introduce the `outline' as the control signal, which could be directly given by the user or revised based on auto-generated ones. Comprehensive experiments with a state-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows stronger scientific diagram understanding performance, including diagram captioning, diagram analysis, and outline recommendation. The dataset, code, and model are available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2311.18248"
  },
  "2311.18246": {
    "title": "Combined Scheduling, Memory Allocation and Tensor Replacement for Minimizing Off-Chip Data Accesses of DNN Accelerators",
    "authors": [
      "Yi Li",
      "Aarti Gupta",
      "Sharad Malik"
    ],
    "abstract": "Specialized hardware accelerators have been extensively used for Deep Neural Networks (DNNs) to provide power/performance benefits. These accelerators contain specialized hardware that supports DNN operators, and scratchpad memory for storing the tensor operands. Often, the size of the scratchpad is insufficient to store all the tensors needed for the computation, and additional data accesses are needed to move tensors back and forth from host memory during the computation with significant power/performance overhead. The volume of these additional data accesses depends on the operator schedule, and memory allocation (specific locations selected for the tensors in the scratchpad). We propose an optimization framework, named COSMA, for mapping DNNs to an accelerator that finds the optimal operator schedule, memory allocation and tensor replacement that minimizes the additional data accesses. COSMA provides an Integer Linear Programming (ILP) formulation to generate the optimal solution for mapping a DNN to the accelerator for a given scratchpad size. We demonstrate that, using an off-the-shelf ILP solver, COSMA obtains the optimal solution in seconds for a wide-range of state-of-the-art DNNs for different applications. Further, it out-performs existing methods by reducing on average 84% of the non-compulsory data accesses. We further propose a divide-and-conquer heuristic to scale up to certain complex DNNs generated by Neural Architecture Search, and this heuristic solution reduces on average 85% data accesses compared with other works.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18246"
  },
  "2311.18245": {
    "title": "Automatic Detection of Alzheimer's Disease with Multi-Modal Fusion of Clinical MRI Scans",
    "authors": [
      "Long Chen",
      "Liben Chen",
      "Binfeng Xu",
      "Wenxin Zhang",
      "Narges Razavian"
    ],
    "abstract": "The aging population of the U.S. drives the prevalence of Alzheimer's disease. Brookmeyer et al. forecasts approximately 15 million Americans will have either clinical AD or mild cognitive impairment by 2060. In response to this urgent call, methods for early detection of Alzheimer's disease have been developed for prevention and pre-treatment. Notably, literature on the application of deep learning in the automatic detection of the disease has been proliferating. This study builds upon previous literature and maintains a focus on leveraging multi-modal information to enhance automatic detection. We aim to predict the stage of the disease - Cognitively Normal (CN), Mildly Cognitive Impairment (MCI), and Alzheimer's Disease (AD), based on two different types of brain MRI scans. We design an AlexNet-based deep learning model that learns the synergy of complementary information from both T1 and FLAIR MRI scans.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18245"
  },
  "2311.18243": {
    "title": "DKiS: Decay weight invertible image steganography with private key",
    "authors": [
      "Hang Yang",
      "Yitian Xu",
      "Xuhua Liu"
    ],
    "abstract": "Image steganography, defined as the practice of concealing information within another image, traditionally encounters security challenges when its methods become publicly known or are under attack. To address this, a novel private key-based image steganography technique has been introduced. This approach ensures the security of the hidden information, as access requires a corresponding private key, regardless of the public knowledge of the steganography method. Experimental evidence has been presented, demonstrating the effectiveness of our method and showcasing its real-world applicability. Furthermore, a critical challenge in the invertible image steganography process has been identified by us: the transfer of non-essential, or `garbage', information from the secret to the host pipeline. To tackle this issue, the decay weight has been introduced to control the information transfer, effectively filtering out irrelevant data and enhancing the performance of image steganography. The code for this technique is publicly accessible at https://github.com/yanghangAI/DKiS, and a practical demonstration can be found at http://yanghang.site/hidekey.\n        \u25b3 Less",
    "submission_date": "18 January, 2024",
    "eprint_id": "2311.18243"
  },
  "2311.18241": {
    "title": "LLVMs4Protest: Harnessing the Power of Large Language and Vision Models for Deciphering Protests in the News",
    "authors": [
      "Yongjun Zhang"
    ],
    "abstract": "Large language and vision models have transformed how social movements scholars identify protest and extract key protest attributes from multi-modal data such as texts, images, and videos. This article documents how we fine-tuned two large pretrained transformer models, including longformer and swin-transformer v2, to infer potential protests in news articles using textual and imagery data. First, the longformer model was fine-tuned using the Dynamic of Collective Action (DoCA) Corpus. We matched the New York Times articles with the DoCA database to obtain a training dataset for downstream tasks. Second, the swin-transformer v2 models was trained on UCLA-protest imagery data. UCLA-protest project contains labeled imagery data with information such as protest, violence, and sign. Both fine-tuned models will be available via \\url{https://github.com/Joshzyj/llvms4protest}. We release this short technical report for social movement scholars who are interested in using LLVMs to infer protests in textual and imagery data.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18241"
  },
  "2311.18233": {
    "title": "Semantic Bound and Multi Types, Revisited",
    "authors": [
      "Beniamino Accattoli"
    ],
    "abstract": "Intersection types are a standard tool in operational and semantical studies of the lambda calculus. De Carvalho showed how multi types, a quantitative variant of intersection types providing a handy presentation of the relational denotational model, allows one to extract precise bounds on the number of $\u03b2$-steps and the size of normal forms.\n  In the last few years, de Carvalho's work has been extended and adapted to a number of lambda calculi, evaluation strategies, and abstract machines. These works, however, only adapt the first part of his work, that extracts bounds from multi type derivations, while never consider the second part, which deals with extracting bounds from the multi types themselves. The reason is that this second part is more technical, and requires to reason up to type substitutions. It is however also the most interesting, because it shows that the bounding power is inherent to the relational model (which is induced by the types, without the derivations), independently of its presentation as a type system.\n  Here we dissect and clarify the second part of de Carvalho's work, establishing a link with principal multi types, and isolating a key property independent of type substitutions.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2311.18233"
  },
  "2311.18232": {
    "title": "LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models",
    "authors": [
      "Marwa Abdulhai",
      "Isadora White",
      "Charlie Snell",
      "Charles Sun",
      "Joey Hong",
      "Yuexiang Zhai",
      "Kelvin Xu",
      "Sergey Levine"
    ],
    "abstract": "Large language models (LLMs) provide excellent text-generation capabilities, but standard prompting and generation methods generally do not lead to intentional or goal-directed agents and might necessitate considerable prompt tuning. This becomes particularly apparent in multi-turn conversations: even the best current LLMs rarely ask clarifying questions, engage in explicit information gathering, or take actions now that lead to better decisions after multiple turns. Reinforcement learning has the potential to leverage the powerful modeling capabilities of LLMs, as well as their internal representation of textual interactions, to create capable goal-directed language agents. This can enable intentional and temporally extended interactions, such as with humans, through coordinated persuasion and carefully crafted questions, or in goal-directed play through text games to bring about desired final outcomes. However, enabling this requires the community to develop stable and reliable reinforcement learning algorithms that can effectively train LLMs. Developing such algorithms requires tasks that can gauge progress on algorithm design, provide accessible and reproducible evaluations for multi-turn interactions, and cover a range of task properties and challenges in improving reinforcement learning algorithms. Our paper introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs, together with an open-source research framework containing a basic toolkit for getting started on multi-turn RL with offline value-based and policy-based RL methods. Our benchmark consists of 8 different language tasks, which require multiple rounds of language interaction and cover a range of tasks in open-ended dialogue and text games.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18232"
  },
  "2311.18224": {
    "title": "Reasoning with the Theory of Mind for Pragmatic Semantic Communication",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Emilio Calvanese Strinati",
      "Walid Saad"
    ],
    "abstract": "In this paper, a pragmatic semantic communication framework that enables effective goal-oriented information sharing between two-intelligent agents is proposed. In particular, semantics is defined as the causal state that encapsulates the fundamental causal relationships and dependencies among different features extracted from data. The proposed framework leverages the emerging concept in machine learning (ML) called theory of mind (ToM). It employs a dynamic two-level (wireless and semantic) feedback mechanism to continuously fine-tune neural network components at the transmitter. Thanks to the ToM, the transmitter mimics the actual mental state of the receiver's reasoning neural network operating semantic interpretation. Then, the estimated mental state at the receiver is dynamically updated thanks to the proposed dynamic two-level feedback mechanism. At the lower level, conventional channel quality metrics are used to optimize the channel encoding process based on the wireless communication channel's quality, ensuring an efficient mapping of semantic representations to a finite constellation. Additionally, a semantic feedback level is introduced, providing information on the receiver's perceived semantic effectiveness with minimal overhead. Numerical evaluations demonstrate the framework's ability to achieve efficient communication with a reduced amount of bits while maintaining the same semantics, outperforming conventional systems that do not exploit the ToM-based reasoning.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18224"
  },
  "2311.18220": {
    "title": "Lifting query complexity to time-space complexity for two-way finite automata",
    "authors": [
      "Shenggen Zheng",
      "Yaqiao Li",
      "Minghua Pan",
      "Jozef Gruska",
      "Lvzhou Li"
    ],
    "abstract": "Time-space tradeoff has been studied in a variety of models, such as Turing machines, branching programs, and finite automata, etc. While communication complexity as a technique has been applied to study finite automata, it seems it has not been used to study time-space tradeoffs of finite automata. We design a new technique showing that separations of query complexity can be lifted, via communication complexity, to separations of time-space complexity of two-way finite automata. As an application, one of our main results exhibits the first example of a language $L$ such that the time-space complexity of two-way probabilistic finite automata with a bounded error (2PFA) is $\\widetilde\u03a9(n^2)$, while of exact two-way quantum finite automata with classical states (2QCFA) is $\\widetilde{O}(n^{5/3})$, that is, we demonstrate for the first time that exact quantum computing has an advantage in time-space complexity comparing to classical computing.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18220"
  },
  "2311.18216": {
    "title": "FS-BAND: A Frequency-Sensitive Banding Detector",
    "authors": [
      "Zijian Chen",
      "Wei Sun",
      "Zicheng Zhang",
      "Ru Huang",
      "Fangfang Lu",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Wenjun Zhang"
    ],
    "abstract": "Banding artifact, as known as staircase-like contour, is a common quality annoyance that happens in compression, transmission, etc. scenarios, which largely affects the user's quality of experience (QoE). The banding distortion typically appears as relatively small pixel-wise variations in smooth backgrounds, which is difficult to analyze in the spatial domain but easily reflected in the frequency domain. In this paper, we thereby study the banding artifact from the frequency aspect and propose a no-reference banding detection model to capture and evaluate banding artifacts, called the Frequency-Sensitive BANding Detector (FS-BAND). The proposed detector is able to generate a pixel-wise banding map with a perception correlated quality score. Experimental results show that the proposed FS-BAND method outperforms state-of-the-art image quality assessment (IQA) approaches with higher accuracy in banding classification task.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18216"
  },
  "2311.18215": {
    "title": "Automatic Construction of a Korean Toxic Instruction Dataset for Ethical Tuning of Large Language Models",
    "authors": [
      "Sungjoo Byun",
      "Dongjun Jang",
      "Hyemi Jo",
      "Hyopil Shin"
    ],
    "abstract": "Caution: this paper may include material that could be offensive or distressing.\n  The advent of Large Language Models (LLMs) necessitates the development of training approaches that mitigate the generation of unethical language and aptly manage toxic user queries. Given the challenges related to human labor and the scarcity of data, we present KoTox, comprising 39K unethical instruction-output pairs. This collection of automatically generated toxic instructions refines the training of LLMs and establishes a foundational framework for improving LLMs' ethical awareness and response to various toxic inputs, promoting more secure and responsible interactions in Natural Language Processing (NLP) applications.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18215"
  },
  "2311.18214": {
    "title": "Perception of Misalignment States for Sky Survey Telescopes with the Digital Twin and the Deep Neural Networks",
    "authors": [
      "Miao Zhang",
      "Peng Jia",
      "Zhengyang Li",
      "Wennan Xiang",
      "Jiameng Lv",
      "Rui Sun"
    ],
    "abstract": "Sky survey telescopes play a critical role in modern astronomy, but misalignment of their optical elements can introduce significant variations in point spread functions, leading to reduced data quality. To address this, we need a method to obtain misalignment states, aiding in the reconstruction of accurate point spread functions for data processing methods or facilitating adjustments of optical components for improved image quality. Since sky survey telescopes consist of many optical elements, they result in a vast array of potential misalignment states, some of which are intricately coupled, posing detection challenges. However, by continuously adjusting the misalignment states of optical elements, we can disentangle coupled states. Based on this principle, we propose a deep neural network to extract misalignment states from continuously varying point spread functions in different field of views. To ensure sufficient and diverse training data, we recommend employing a digital twin to obtain data for neural network training. Additionally, we introduce the state graph to store misalignment data and explore complex relationships between misalignment states and corresponding point spread functions, guiding the generation of training data from experiments. Once trained, the neural network estimates misalignment states from observation data, regardless of the impacts caused by atmospheric turbulence, noise, and limited spatial sampling rates in the detector. The method proposed in this paper could be used to provide prior information for the active optics system and the optical system alignment.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18214"
  },
  "2311.18213": {
    "title": "Beyond Two-Tower Matching: Learning Sparse Retrievable Cross-Interactions for Recommendation",
    "authors": [
      "Liangcai Su",
      "Fan Yan",
      "Jieming Zhu",
      "Xi Xiao",
      "Haoyi Duan",
      "Zhou Zhao",
      "Zhenhua Dong",
      "Ruiming Tang"
    ],
    "abstract": "Two-tower models are a prevalent matching framework for recommendation, which have been widely deployed in industrial applications. The success of two-tower matching attributes to its efficiency in retrieval among a large number of items, since the item tower can be precomputed and used for fast Approximate Nearest Neighbor (ANN) search. However, it suffers two main challenges, including limited feature interaction capability and reduced accuracy in online serving. Existing approaches attempt to design novel late interactions instead of dot products, but they still fail to support complex feature interactions or lose retrieval efficiency. To address these challenges, we propose a new matching paradigm named SparCode, which supports not only sophisticated feature interactions but also efficient retrieval. Specifically, SparCode introduces an all-to-all interaction module to model fine-grained query-item interactions. Besides, we design a discrete code-based sparse inverted index jointly trained with the model to achieve effective and efficient model inference. Extensive experiments have been conducted on open benchmark datasets to demonstrate the superiority of our framework. The results show that SparCode significantly improves the accuracy of candidate item matching while retaining the same level of retrieval efficiency with two-tower models. Our source code will be available at MindSpore/models.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18213"
  },
  "2311.18212": {
    "title": "Whole-body Dynamic Collision Avoidance with Time-varying Control Barrier Functions",
    "authors": [
      "Jihao Huang",
      "Xuemin Chi",
      "Zhitao Liu",
      "Hongye Su"
    ],
    "abstract": "Recently, there has been increasing attention in robot research towards the whole-body collision avoidance. In this paper, we propose a safety-critical controller that utilizes time-varying control barrier functions (time varying CBFs) constructed by Robo-centric Euclidean Signed Distance Field (RC-ESDF) to achieve dynamic collision avoidance. The RC-ESDF is constructed in the robot body frame and solely relies on the robot's shape, eliminating the need for real-time updates to save computational resources. Additionally, we design two control Lyapunov functions (CLFs) to ensure that the robot can reach its destination. To enable real-time application, our safety-critical controller which incorporates CLFs and CBFs as constraints is formulated as a quadratic program (QP) optimization problem. We conducted numerical simulations on two different dynamics of an L-shaped robot to verify the effectiveness of our proposed approach.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18212"
  },
  "2311.18210": {
    "title": "Distributed Adaptive Greedy Quasi-Newton Methods with Explicit Non-asymptotic Convergence Bounds",
    "authors": [
      "Yubo Du",
      "Keyou You"
    ],
    "abstract": "Though quasi-Newton methods have been extensively studied in the literature, they either suffer from local convergence or use a series of line searches for global convergence which is not acceptable in the distributed setting. In this work, we first propose a line search free greedy quasi-Newton (GQN) method with adaptive steps and establish explicit non-asymptotic bounds for both the global convergence rate and local superlinear rate. Our novel idea lies in the design of multiple greedy quasi-Newton updates, which involves computing Hessian-vector products, to control the Hessian approximation error, and a simple mechanism to adjust stepsizes to ensure the objective function improvement per iterate. Then, we extend it to the master-worker framework and propose a distributed adaptive GQN method whose communication cost is comparable with that of first-order methods, yet it retains the superb convergence property of its centralized counterpart. Finally, we demonstrate the advantages of our methods via numerical experiments.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18210"
  },
  "2311.18200": {
    "title": "INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion",
    "authors": [
      "Hengchao Shang",
      "Zongyao Li",
      "Daimeng Wei",
      "Jiaxin Guo",
      "Minghan Wang",
      "Xiaoyu Chen",
      "Lizhi Lei",
      "Hao Yang"
    ],
    "abstract": "Computer-aided translation (CAT) aims to enhance human translation efficiency and is still important in scenarios where machine translation cannot meet quality requirements. One fundamental task within this field is Word-Level Auto Completion (WLAC). WLAC predicts a target word given a source sentence, translation context, and a human typed character sequence. Previous works either employ word classification models to exploit contextual information from both sides of the target word or directly disregarded the dependencies from the right-side context. Furthermore, the key information, i.e. human typed sequences, is only used as prefix constraints in the decoding module. In this paper, we propose the INarIG (Iterative Non-autoregressive Instruct Generation) model, which constructs the human typed sequence into Instruction Unit and employs iterative decoding with subwords to fully utilize input information given in the task. Our model is more competent in dealing with low-frequency words (core scenario of this task), and achieves state-of-the-art results on the WMT22 and benchmark datasets, with a maximum increase of over 10% prediction accuracy.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18200"
  },
  "2311.18199": {
    "title": "Hy-Tracker: A Novel Framework for Enhancing Efficiency and Accuracy of Object Tracking in Hyperspectral Videos",
    "authors": [
      "Mohammad Aminul Islam",
      "Wangzhi Xing",
      "Jun Zhou",
      "Yongsheng Gao",
      "Kuldip K. Paliwal"
    ],
    "abstract": "Hyperspectral object tracking has recently emerged as a topic of great interest in the remote sensing community. The hyperspectral image, with its many bands, provides a rich source of material information of an object that can be effectively used for object tracking. While most hyperspectral trackers are based on detection-based techniques, no one has yet attempted to employ YOLO for detecting and tracking the object. This is due to the presence of multiple spectral bands, the scarcity of annotated hyperspectral videos, and YOLO's performance limitation in managing occlusions, and distinguishing object in cluttered backgrounds. Therefore, in this paper, we propose a novel framework called Hy-Tracker, which aims to bridge the gap between hyperspectral data and state-of-the-art object detection methods to leverage the strengths of YOLOv7 for object tracking in hyperspectral videos. Hy-Tracker not only introduces YOLOv7 but also innovatively incorporates a refined tracking module on top of YOLOv7. The tracker refines the initial detections produced by YOLOv7, leading to improved object-tracking performance. Furthermore, we incorporate Kalman-Filter into the tracker, which addresses the challenges posed by scale variation and occlusion. The experimental results on hyperspectral benchmark datasets demonstrate the effectiveness of Hy-Tracker in accurately tracking objects across frames.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18199"
  },
  "2311.18198": {
    "title": "S-T CRF: Spatial-Temporal Conditional Random Field for Human Trajectory Prediction",
    "authors": [
      "Pengqian Han",
      "Jiamou Liu",
      "Jialing He",
      "Zeyu Zhang",
      "Song Yang",
      "Yanni Tang",
      "Partha Roop"
    ],
    "abstract": "Trajectory prediction is of significant importance in computer vision. Accurate pedestrian trajectory prediction benefits autonomous vehicles and robots in planning their motion. Pedestrians' trajectories are greatly influenced by their intentions. Prior studies having introduced various deep learning methods only pay attention to the spatial and temporal information of trajectory, overlooking the explicit intention information. In this study, we introduce a novel model, termed the \\textbf{S-T CRF}: \\textbf{S}patial-\\textbf{T}emporal \\textbf{C}onditional \\textbf{R}andom \\textbf{F}ield, which judiciously incorporates intention information besides spatial and temporal information of trajectory. This model uses a Conditional Random Field (CRF) to generate a representation of future intentions, greatly improving the prediction of subsequent trajectories when combined with spatial-temporal representation. Furthermore, the study innovatively devises a space CRF loss and a time CRF loss, meticulously designed to enhance interaction constraints and temporal dynamics, respectively. Extensive experimental evaluations on dataset ETH/UCY and SDD demonstrate that the proposed method surpasses existing baseline approaches.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18198"
  },
  "2311.18195": {
    "title": "COVID-19 Vaccine Misinformation in Middle Income Countries",
    "authors": [
      "Jongin Kim",
      "Byeo Rhee Bak",
      "Aditya Agrawal",
      "Jiaxi Wu",
      "Veronika J. Wirtz",
      "Traci Hong",
      "Derry Wijaya"
    ],
    "abstract": "This paper introduces a multilingual dataset of COVID-19 vaccine misinformation, consisting of annotated tweets from three middle-income countries: Brazil, Indonesia, and Nigeria. The expertly curated dataset includes annotations for 5,952 tweets, assessing their relevance to COVID-19 vaccines, presence of misinformation, and the themes of the misinformation. To address challenges posed by domain specificity, the low-resource setting, and data imbalance, we adopt two approaches for developing COVID-19 vaccine misinformation detection models: domain-specific pre-training and text augmentation using a large language model. Our best misinformation detection models demonstrate improvements ranging from 2.7 to 15.9 percentage points in macro F1-score compared to the baseline models. Additionally, we apply our misinformation detection models in a large-scale study of 19 million unlabeled tweets from the three countries between 2020 and 2022, showcasing the practical application of our dataset and models for detecting and analyzing vaccine misinformation in multiple countries and languages. Our analysis indicates that percentage changes in the number of new COVID-19 cases are positively associated with COVID-19 vaccine misinformation rates in a staggered manner for Brazil and Indonesia, and there are significant positive associations between the misinformation rates across the three countries.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18195"
  },
  "2311.18194": {
    "title": "Positional Information Matters for Invariant In-Context Learning: A Case Study of Simple Function Classes",
    "authors": [
      "Yongqiang Chen",
      "Binghui Xie",
      "Kaiwen Zhou",
      "Bo Han",
      "Yatao Bian",
      "James Cheng"
    ],
    "abstract": "In-context learning (ICL) refers to the ability of a model to condition on a few in-context demonstrations (input-output examples of the underlying task) to generate the answer for a new query input, without updating parameters. Despite the impressive ICL ability of LLMs, it has also been found that ICL in LLMs is sensitive to input demonstrations and limited to short context lengths. To understand the limitations and principles for successful ICL, we conduct an investigation with ICL linear regression of transformers. We characterize several Out-of-Distribution (OOD) cases for ICL inspired by realistic LLM ICL failures and compare transformers with DeepSet, a simple yet powerful architecture for ICL. Surprisingly, DeepSet outperforms transformers across a variety of distribution shifts, implying that preserving permutation invariance symmetry to input demonstrations is crucial for OOD ICL. The phenomenon specifies a fundamental requirement by ICL, which we termed as ICL invariance. Nevertheless, the positional encodings in LLMs will break ICL invariance. To this end, we further evaluate transformers with identical positional encodings and find preserving ICL invariance in transformers achieves state-of-the-art performance across various ICL distribution shifts\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18194"
  },
  "2311.18193": {
    "title": "Persistent Test-time Adaptation in Episodic Testing Scenarios",
    "authors": [
      "Trung-Hieu Hoang",
      "Duc Minh Vo",
      "Minh N. Do"
    ],
    "abstract": "Current test-time adaptation (TTA) approaches aim to adapt to environments that change continuously. Yet, when the environments not only change but also recur in a correlated manner over time, such as in the case of day-night surveillance cameras, it is unclear whether the adaptability of these methods is sustained after a long run. This study aims to examine the error accumulation of TTA models when they are repeatedly exposed to previous testing environments, proposing a novel testing setting called episodic TTA. To study this phenomenon, we design a simulation of TTA process on a simple yet representative $\u03b5$-perturbed Gaussian Mixture Model Classifier and derive the theoretical findings revealing the dataset- and algorithm-dependent factors that contribute to the gradual degeneration of TTA methods through time. Our investigation has led us to propose a method, named persistent TTA (PeTTA). PeTTA senses the model divergence towards a collapsing and adjusts the adaptation strategy of TTA, striking a balance between two primary objectives: adaptation and preventing model collapse. The stability of PeTTA in the face of episodic TTA scenarios has been demonstrated through a set of comprehensive experiments on various benchmarks.\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2311.18193"
  },
  "2311.18190": {
    "title": "Toward the Tradeoffs between Privacy, Fairness and Utility in Federated Learning",
    "authors": [
      "Kangkang Sun",
      "Xiaojin Zhang",
      "Xi Lin",
      "Gaolei Li",
      "Jing Wang",
      "Jianhua Li"
    ],
    "abstract": "Federated Learning (FL) is a novel privacy-protection distributed machine learning paradigm that guarantees user privacy and prevents the risk of data leakage due to the advantage of the client's local training. Researchers have struggled to design fair FL systems that ensure fairness of results. However, the interplay between fairness and privacy has been less studied. Increasing the fairness of FL systems can have an impact on user privacy, while an increase in user privacy can affect fairness. In this work, on the client side, we use fairness metrics, such as Demographic Parity (DemP), Equalized Odds (EOs), and Disparate Impact (DI), to construct the local fair model. To protect the privacy of the client model, we propose a privacy-protection fairness FL method. The results show that the accuracy of the fair model with privacy increases because privacy breaks the constraints of the fairness metrics. In our experiments, we conclude the relationship between privacy, fairness and utility, and there is a tradeoff between these.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18190"
  },
  "2311.18182": {
    "title": "PEOPLEx: PEdestrian Opportunistic Positioning LEveraging IMU, UWB, BLE and WiFi",
    "authors": [
      "Pierre-Yves Lajoie",
      "Bobak Hamed Baghi",
      "Sachini Herath",
      "Francois Hogan",
      "Xue Liu",
      "Gregory Dudek"
    ],
    "abstract": "This paper advances the field of pedestrian localization by introducing a unifying framework for opportunistic positioning based on nonlinear factor graph optimization. While many existing approaches assume constant availability of one or multiple sensing signals, our methodology employs IMU-based pedestrian inertial navigation as the backbone for sensor fusion, opportunistically integrating Ultra-Wideband (UWB), Bluetooth Low Energy (BLE), and WiFi signals when they are available in the environment. The proposed PEOPLEx framework is designed to incorporate sensing data as it becomes available, operating without any prior knowledge about the environment (e.g. anchor locations, radio frequency maps, etc.). Our contributions are twofold: 1) we introduce an opportunistic multi-sensor and real-time pedestrian positioning framework fusing the available sensor measurements; 2) we develop novel factors for adaptive scaling and coarse loop closures, significantly improving the precision of indoor positioning. Experimental validation confirms that our approach achieves accurate localization estimates in real indoor scenarios using commercial smartphones.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18182"
  },
  "2311.18175": {
    "title": "STL4IoT: A Statechart Template Library for IoT System Design",
    "authors": [
      "Clyde Rempillo",
      "Sadaf Mustafiz"
    ],
    "abstract": "The engineering of IoT systems brings about various challenges due to the inherent complexities associated with such heterogeneous systems. In this paper, we propose a library of statechart templates, STL4IoT, for designing complex IoT systems. We have developed atomic statechart components modelling the heterogeneous aspects of IoT systems including sensors, actuators, physical entities, network, and controller. Base system units for smart systems have also been designed. A component for calculating power usage is available in the library. Additionally, a smart hub template that controls interactions among multiple IoT systems and manages power consumption has also been proposed. The templates aim to facilitate the modelling and simulation of IoT systems. Our work is demonstrated with a smart home system consisting of a smart hub of lights, a smart microwave, a smart TV, and a smart fire alarm system. We have created a multi statechart with itemis CREATE based on the proposed templates and components. A smart home simulator has been developed by generating controller code from the statechart and integrating it with a user interface.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18175"
  },
  "2311.18174": {
    "title": "Packrat: Automatic Reconfiguration for Latency Minimization in CPU-based DNN Serving",
    "authors": [
      "Ankit Bhardwaj",
      "Amar Phanishayee",
      "Deepak Narayanan",
      "Mihail Tarta",
      "Ryan Stutsman"
    ],
    "abstract": "In this paper, we investigate how to push the performance limits of serving Deep Neural Network (DNN) models on CPU-based servers. Specifically, we observe that while intra-operator parallelism across multiple threads is an effective way to reduce inference latency, it provides diminishing returns. Our primary insight is that instead of running a single instance of a model with all available threads on a server, running multiple instances each with smaller batch sizes and fewer threads for intra-op parallelism can provide lower inference latency. However, the right configuration is hard to determine manually since it is workload- (DNN model and batch size used by the serving system) and deployment-dependent (number of CPU cores on server). We present Packrat, a new serving system for online inference that given a model and batch size ($B$) algorithmically picks the optimal number of instances ($i$), the number of threads each should be allocated ($t$), and the batch sizes each should operate on ($b$) that minimizes latency. Packrat is built as an extension to TorchServe and supports online reconfigurations to avoid serving downtime. Averaged across a range of batch sizes, Packrat improves inference latency by 1.43$\\times$ to 1.83$\\times$ on a range of commonly used DNNs.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18174"
  },
  "2311.18173": {
    "title": "Quantification of cardiac capillarization in single-immunostained myocardial slices using weakly supervised instance segmentation",
    "authors": [
      "Zhao Zhang",
      "Xiwen Chen",
      "William Richardson",
      "Bruce Z. Gao",
      "Abolfazl Razi",
      "Tong Ye"
    ],
    "abstract": "Decreased myocardial capillary density has been reported as an important histopathological feature associated with various heart disorders. Quantitative assessment of cardiac capillarization typically involves double immunostaining of cardiomyocytes (CMs) and capillaries in myocardial slices. In contrast, single immunostaining of basement membrane components is a straightforward approach to simultaneously label CMs and capillaries, presenting fewer challenges in background staining. However, subsequent image analysis always requires manual work in identifying and segmenting CMs and capillaries. Here, we developed an image analysis tool, AutoQC, to automatically identify and segment CMs and capillaries in immunofluorescence images of collagen type IV, a predominant basement membrane protein within the myocardium. In addition, commonly used capillarization-related measurements can be derived from segmentation masks. AutoQC features a weakly supervised instance segmentation algorithm by leveraging the power of a pre-trained segmentation model via prompt engineering. AutoQC outperformed YOLOv8-Seg, a state-of-the-art instance segmentation model, in both instance segmentation and capillarization assessment. Furthermore, the training of AutoQC required only a small dataset with bounding box annotations instead of pixel-wise annotations, leading to a reduced workload during network training. AutoQC provides an automated solution for quantifying cardiac capillarization in basement-membrane-immunostained myocardial slices, eliminating the need for manual image analysis once it is trained.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18173"
  },
  "2311.18172": {
    "title": "Multi-Rate Variable-Length CSI Compression for FDD Massive MIMO",
    "authors": [
      "Bumsu Park",
      "Heedong Do",
      "Namyoon Lee"
    ],
    "abstract": "For frequency-division-duplexing (FDD) systems, channel state information (CSI) should be fed back from the user terminal to the base station. This feedback overhead becomes problematic as the number of antennas grows. To alleviate this issue, we propose a flexible CSI compression method using variational autoencoder (VAE) with an entropy bottleneck structure, which can support multi-rate and variable-length operation. Numerical study confirms that the proposed method outperforms the existing CSI compression techniques in terms of normalized mean squared error.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18172"
  },
  "2311.18170": {
    "title": "Odor Intensity Shift Keying (OISK) and Channel Capacity of Odor-based Molecular Communications in Internet of Everything",
    "authors": [
      "Aditya Powari",
      "Ozgur B. Akan"
    ],
    "abstract": "Molecular communication is a new, active area of research that has created a paradigm shift in the way a communication system is perceived. An artificial molecular communication network is created using biological molecules for encoding, transmitting and decoding the symbols to convey information. In addition to typical biological molecules, we are also exploring other classes of molecules that possess unique distinctive features which can be potentially exploited for establishing reliable communications. Odor molecules are one such class of molecules which possess several distinctive features such as Intensity, Headonic tone which provides a basis to convey the information in an olfactory communication system. In our work, we investigate the ICT (information and communication theory) perspective of the olfactory communications by evaluating the channel capacity of an odor molecular communication (OMC) system with the help of a novel modulation scheme viz. odor intensity shift keying (OISK), where information is being conveyed from the intensity level of an odor. Furthermore, we also analyse the effects of critical parameters like temperature and noise on the achievable channel capacity to provide an insight about the resilience of the proposed OMC system towards any such anomaly faced by it.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18170"
  },
  "2311.18169": {
    "title": "Few-shot Image Generation via Style Adaptation and Content Preservation",
    "authors": [
      "Xiaosheng He",
      "Fan Yang",
      "Fayao Liu",
      "Guosheng Lin"
    ],
    "abstract": "Training a generative model with limited data (e.g., 10) is a very challenging task. Many works propose to fine-tune a pre-trained GAN model. However, this can easily result in overfitting. In other words, they manage to adapt the style but fail to preserve the content, where \\textit{style} denotes the specific properties that defines a domain while \\textit{content} denotes the domain-irrelevant information that represents diversity. Recent works try to maintain a pre-defined correspondence to preserve the content, however, the diversity is still not enough and it may affect style adaptation. In this work, we propose a paired image reconstruction approach for content preservation. We propose to introduce an image translation module to GAN transferring, where the module teaches the generator to separate style and content, and the generator provides training data to the translation module in return. Qualitative and quantitative experiments show that our method consistently surpasses the state-of-the-art methods in few shot setting.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18169"
  },
  "2311.18168": {
    "title": "Probabilistic Speech-Driven 3D Facial Motion Synthesis: New Benchmarks, Methods, and Applications",
    "authors": [
      "Karren D. Yang",
      "Anurag Ranjan",
      "Jen-Hao Rick Chang",
      "Raviteja Vemulapalli",
      "Oncel Tuzel"
    ],
    "abstract": "We consider the task of animating 3D facial geometry from speech signal. Existing works are primarily deterministic, focusing on learning a one-to-one mapping from speech signal to 3D face meshes on small datasets with limited speakers. While these models can achieve high-quality lip articulation for speakers in the training set, they are unable to capture the full and diverse distribution of 3D facial motions that accompany speech in the real world. Importantly, the relationship between speech and facial motion is one-to-many, containing both inter-speaker and intra-speaker variations and necessitating a probabilistic approach. In this paper, we identify and address key challenges that have so far limited the development of probabilistic models: lack of datasets and metrics that are suitable for training and evaluating them, as well as the difficulty of designing a model that generates diverse results while remaining faithful to a strong conditioning signal as speech. We first propose large-scale benchmark datasets and metrics suitable for probabilistic modeling. Then, we demonstrate a probabilistic model that achieves both diversity and fidelity to speech, outperforming other methods across the proposed benchmarks. Finally, we showcase useful applications of probabilistic models trained on these large-scale datasets: we can generate diverse speech-driven 3D facial motion that matches unseen speaker styles extracted from reference clips; and our synthetic meshes can be used to improve the performance of downstream audio-visual models.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18168"
  },
  "2311.18167": {
    "title": "Throughput Maximization for Intelligent Refracting Surface Assisted mmWave High-Speed Train Communications",
    "authors": [
      "Jing Li",
      "Yong Niu",
      "Hao Wu",
      "Bo Ai",
      "Ruisi He",
      "Ning Wang",
      "Sheng Chen"
    ],
    "abstract": "With the increasing demands from passengers for data-intensive services, millimeter-wave (mmWave) communication is considered as an effective technique to release the transmission pressure on high speed train (HST) networks. However, mmWave signals ncounter severe losses when passing through the carriage, which decreases the quality of services on board. In this paper, we investigate an intelligent refracting surface (IRS)-assisted HST communication system. Herein, an IRS is deployed on the train window to dynamically reconfigure the propagation environment, and a hybrid time division multiple access-nonorthogonal multiple access scheme is leveraged for interference mitigation. We aim to maximize the overall throughput while taking into account the constraints imposed by base station beamforming, IRS discrete phase shifts and transmit power. To obtain a practical solution, we employ an alternating optimization method and propose a two-stage algorithm. In the first stage, the successive convex approximation method and branch and bound algorithm are leveraged for IRS phase shift design. In the second stage, the Lagrangian multiplier method is utilized for power allocation. Simulation results demonstrate the benefits of IRS adoption and power allocation for throughput improvement in mmWave HST networks.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18167"
  },
  "2311.18166": {
    "title": "A-Scan2BIM: Assistive Scan to Building Information Modeling",
    "authors": [
      "Weilian Song",
      "Jieliang Luo",
      "Dale Zhao",
      "Yan Fu",
      "Chin-Yi Cheng",
      "Yasutaka Furukawa"
    ],
    "abstract": "This paper proposes an assistive system for architects that converts a large-scale point cloud into a standardized digital representation of a building for Building Information Modeling (BIM) applications. The process is known as Scan-to-BIM, which requires many hours of manual work even for a single building floor by a professional architect. Given its challenging nature, the paper focuses on helping architects on the Scan-to-BIM process, instead of replacing them. Concretely, we propose an assistive Scan-to-BIM system that takes the raw sensor data and edit history (including the current BIM model), then auto-regressively predicts a sequence of model editing operations as APIs of a professional BIM software (i.e., Autodesk Revit). The paper also presents the first building-scale Scan2BIM dataset that contains a sequence of model editing operations as the APIs of Autodesk Revit. The dataset contains 89 hours of Scan2BIM modeling processes by professional architects over 16 scenes, spanning over 35,000 m^2. We report our system's reconstruction quality with standard metrics, and we introduce a novel metric that measures how natural the order of reconstructed operations is. A simple modification to the reconstruction module helps improve performance, and our method is far superior to two other baselines in the order metric. We will release data, code, and models at a-scan2bim.github.io.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18166"
  },
  "2311.18165": {
    "title": "Variations in Web of Science and Scopus Journal Coverage, Visibility and Prestige between 2001 and 2020",
    "authors": [
      "Toluwase Victor Asubiaro"
    ],
    "abstract": "Purpose: This study focuses on the changes in differences in the journal coverage, visibility and prestige of journals from top twenty countries in Web of Science and Scopus in the twenty-year timeframe-2001-2020. Methodology: Using Web of Science and Scopus journal data from Journal Citation Reports and Scimago Journal Rank, respectively, top twenty countries by number of journals indexed in the two databases were identified. Analysis of the changes that occurred in the number of journals from the top twenty countries, the citations they received and their prestige were analyzed. Findings: USA and UK continued their dominance of the journals indexed in Web of Science and Scopus, but their dominance waned gradually in the course of the twenty-year period. The rate of growth of journals indexed by the databases is steeper among the countries outside the top. In Web of Science, journals from the UK were the most prestigious until 2010 when China emerged as the most prestigious journals. USA continues to take the leading spot in terms of most prestigious journals in Scopus, followed by UK. Research Limitations: This investigation relied on third-party datasets sourced from the Scimago Journal Rank repository for the compilation of the Scopus journal list. Practical implications: This study suggests an inclination towards diversity by Web of Science and Scopus, though North America and Europe continue to dominate journal coverage. However, the gulf in the prestige and visibility of journals from North America, Europe and other parts of the world remains, suggesting the researchers from the peripheral may continue to gravitate towards the core. Originality/Value: While studies have provided singular-year analyses of journal coverages of Web of Science and Scopus, this study provides an analysis of 20 years.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18165"
  },
  "2311.18158": {
    "title": "HiPA: Enabling One-Step Text-to-Image Diffusion Models via High-Frequency-Promoting Adaptation",
    "authors": [
      "Yifan Zhang",
      "Bryan Hooi"
    ],
    "abstract": "Diffusion models have revolutionized text-to-image generation, but their real-world applications are hampered by the extensive time needed for hundreds of diffusion steps. Although progressive distillation has been proposed to speed up diffusion sampling to 2-8 steps, it still falls short in one-step generation, and necessitates training multiple student models, which is highly parameter-extensive and time-consuming. To overcome these limitations, we introduce High-frequency-Promoting Adaptation (HiPA), a parameter-efficient approach to enable one-step text-to-image diffusion. Grounded in the insight that high-frequency information is essential but highly lacking in one-step diffusion, HiPA focuses on training one-step, low-rank adaptors to specifically enhance the under-represented high-frequency abilities of advanced diffusion models. The learned adaptors empower these diffusion models to generate high-quality images in just a single step. Compared with progressive distillation, HiPA achieves much better performance in one-step text-to-image generation (37.3 $\\rightarrow$ 23.8 in FID-5k on MS-COCO 2017) and 28.6x training speed-up (108.8 $\\rightarrow$ 3.8 A100 GPU days), requiring only 0.04% training parameters (7,740 million $\\rightarrow$ 3.3 million). We also demonstrate HiPA's effectiveness in text-guided image editing, inpainting and super-resolution tasks, where our adapted models consistently deliver high-quality outputs in just one diffusion step. The source code will be released.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18158"
  },
  "2311.18154": {
    "title": "Data-Driven Shape Sensing in Continuum Manipulators via Sliding Resistive Flex Sensors",
    "authors": [
      "Chenhan Zhang",
      "Shaopeng Jiang",
      "Heyun Wang",
      "Joshua Liu",
      "Amit Jain",
      "Mehran Armand"
    ],
    "abstract": "We introduce a novel shape-sensing method using Resistive Flex Sensors (RFS) embedded in cable-driven Continuum Dexterous Manipulators (CDMs). The RFS is predominantly sensitive to deformation rather than direct forces, making it a distinctive tool for shape sensing. The RFS unit we designed is a considerably less expensive and robust alternative, offering comparable accuracy and real-time performance to existing shape sensing methods used for the CDMs proposed for minimally-invasive surgery. Our design allows the RFS to move along and inside the CDM conforming to its curvature, offering the ability to capture resistance metrics from various bending positions without the need for elaborate sensor setups. The RFS unit is calibrated using an overhead camera and a ResNet machine learning framework. Experiments using a 3D printed prototype of the CDM achieved an average shape estimation error of 0.968 mm with a standard error of 0.275 mm. The response time of the model was approximately 1.16 ms, making real-time shape sensing feasible. While this preliminary study successfully showed the feasibility of our approach for C-shape CDM deformations with non-constant curvatures, we are currently extending the results to show the feasibility for adapting to more complex CDM configurations such as S-shape created in obstructed environments or in presence of the external forces.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18154"
  },
  "2311.18151": {
    "title": "Uncertainty Guided Global Memory Improves Multi-Hop Question Answering",
    "authors": [
      "Alsu Sagirova",
      "Mikhail Burtsev"
    ],
    "abstract": "Transformers have become the gold standard for many natural language processing tasks and, in particular, for multi-hop question answering (MHQA). This task includes processing a long document and reasoning over the multiple parts of it. The landscape of MHQA approaches can be classified into two primary categories. The first group focuses on extracting supporting evidence, thereby constraining the QA model's context to predicted facts. Conversely, the second group relies on the attention mechanism of the long input encoding model to facilitate multi-hop reasoning. However, attention-based token representations lack explicit global contextual information to connect reasoning steps. To address these issues, we propose GEMFormer, a two-stage method that first collects relevant information over the entire document to the memory and then combines it with local context to solve the task. Our experimental results show that fine-tuning a pre-trained model with memory-augmented input, including the most certain global elements, improves the model's performance on three MHQA datasets compared to the baseline. We also found that the global explicit memory contains information from supporting facts required for the correct answer.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18151"
  },
  "2311.18149": {
    "title": "STF: Spatial Temporal Fusion for Trajectory Prediction",
    "authors": [
      "Pengqian Han",
      "Partha Roop",
      "Jiamou Liu",
      "Tianzhe Bao",
      "Yifei Wang"
    ],
    "abstract": "Trajectory prediction is a challenging task that aims to predict the future trajectory of vehicles or pedestrians over a short time horizon based on their historical positions. The main reason is that the trajectory is a kind of complex data, including spatial and temporal information, which is crucial for accurate prediction. Intuitively, the more information the model can capture, the more precise the future trajectory can be predicted. However, previous works based on deep learning methods processed spatial and temporal information separately, leading to inadequate spatial information capture, which means they failed to capture the complete spatial information. Therefore, it is of significance to capture information more fully and effectively on vehicle interactions. In this study, we introduced an integrated 3D graph that incorporates both spatial and temporal edges. Based on this, we proposed the integrated 3D graph, which considers the cross-time interaction information. In specific, we design a Spatial-Temporal Fusion (STF) model including Multi-layer perceptions (MLP) and Graph Attention (GAT) to capture the spatial and temporal information historical trajectories simultaneously on the 3D graph. Our experiment on the ApolloScape Trajectory Datasets shows that the proposed STF outperforms several baseline methods, especially on the long-time-horizon trajectory prediction.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18149"
  },
  "2311.18147": {
    "title": "DisCGen: A Framework for Discourse-Informed Counterspeech Generation",
    "authors": [
      "Sabit Hassan",
      "Malihe Alikhani"
    ],
    "abstract": "Counterspeech can be an effective method for battling hateful content on social media. Automated counterspeech generation can aid in this process. Generated counterspeech, however, can be viable only when grounded in the context of topic, audience and sensitivity as these factors influence both the efficacy and appropriateness. In this work, we propose a novel framework based on theories of discourse to study the inferential links that connect counter speeches to the hateful comment. Within this framework, we propose: i) a taxonomy of counterspeech derived from discourse frameworks, and ii) discourse-informed prompting strategies for generating contextually-grounded counterspeech. To construct and validate this framework, we present a process for collecting an in-the-wild dataset of counterspeech from Reddit. Using this process, we manually annotate a dataset of 3.9k Reddit comment pairs for the presence of hatespeech and counterspeech. The positive pairs are annotated for 10 classes in our proposed taxonomy. We annotate these pairs with paraphrased counterparts to remove offensiveness and first-person references. We show that by using our dataset and framework, large language models can generate contextually-grounded counterspeech informed by theories of discourse. According to our human evaluation, our approaches can act as a safeguard against critical failures of discourse-agnostic models.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18147"
  },
  "2311.18145": {
    "title": "Sparsifying generalized linear models",
    "authors": [
      "Arun Jambulapati",
      "James R. Lee",
      "Yang P. Liu",
      "Aaron Sidford"
    ],
    "abstract": "We consider the sparsification of sums $F : \\mathbb{R}^n \\to \\mathbb{R}$ where $F(x) = f_1(\\langle a_1,x\\rangle) + \\cdots + f_m(\\langle a_m,x\\rangle)$ for vectors $a_1,\\ldots,a_m \\in \\mathbb{R}^n$ and functions $f_1,\\ldots,f_m : \\mathbb{R} \\to \\mathbb{R}_+$. We show that $(1+\\varepsilon)$-approximate sparsifiers of $F$ with support size $\\frac{n}{\\varepsilon^2} (\\log \\frac{n}{\\varepsilon})^{O(1)}$ exist whenever the functions $f_1,\\ldots,f_m$ are symmetric, monotone, and satisfy natural growth bounds. Additionally, we give efficient algorithms to compute such a sparsifier assuming each $f_i$ can be evaluated efficiently.\n  Our results generalize the classic case of $\\ell_p$ sparsification, where $f_i(z) = |z|^p$, for $p \\in (0, 2]$, and give the first near-linear size sparsifiers in the well-studied setting of the Huber loss function and its generalizations, e.g., $f_i(z) = \\min\\{|z|^p, |z|^2\\}$ for $0 < p \\leq 2$. Our sparsification algorithm can be applied to give near-optimal reductions for optimizing a variety of generalized linear models including $\\ell_p$ regression for $p \\in (1, 2]$ to high accuracy, via solving $(\\log n)^{O(1)}$ sparse regression instances with $m \\le n(\\log n)^{O(1)}$, plus runtime proportional to the number of nonzero entries in the vectors $a_1, \\dots, a_m$.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18145"
  },
  "2311.18144": {
    "title": "Dynamical phase transition in quantum neural networks with large depth",
    "authors": [
      "Bingzhi Zhang",
      "Junyu Liu",
      "Xiao-Chuan Wu",
      "Liang Jiang",
      "Quntao Zhuang"
    ],
    "abstract": "Understanding the training dynamics of quantum neural networks is a fundamental task in quantum information science with wide impact in physics, chemistry and machine learning. In this work, we show that the late-time training dynamics of quantum neural networks can be described by the generalized Lotka-Volterra equations, which lead to a dynamical phase transition. When the targeted value of cost function crosses the minimum achievable value from above to below, the dynamics evolve from a frozen-kernel phase to a frozen-error phase, showing a duality between the quantum neural tangent kernel and the total error. In both phases, the convergence towards the fixed point is exponential, while at the critical point becomes polynomial. Via mapping the Hessian of the training dynamics to a Hamiltonian in the imaginary time, we reveal the nature of the phase transition to be second-order with the exponent $\u03bd=1$, where scale invariance and closing gap are observed at critical point. We also provide a non-perturbative analytical theory to explain the phase transition via a restricted Haar ensemble at late time, when the output state approaches the steady state. The theory findings are verified experimentally on IBM quantum devices.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18144"
  },
  "2311.18140": {
    "title": "ROBBIE: Robust Bias Evaluation of Large Generative Language Models",
    "authors": [
      "David Esiobu",
      "Xiaoqing Tan",
      "Saghar Hosseini",
      "Megan Ung",
      "Yuchen Zhang",
      "Jude Fernandes",
      "Jane Dwivedi-Yu",
      "Eleonora Presani",
      "Adina Williams",
      "Eric Michael Smith"
    ],
    "abstract": "As generative large language models (LLMs) grow more performant and prevalent, we must develop comprehensive enough tools to measure and improve their fairness. Different prompt-based datasets can be used to measure social bias across multiple text domains and demographic axes, meaning that testing LLMs on more datasets can potentially help us characterize their biases more fully, and better ensure equal and equitable treatment of marginalized demographic groups. In this work, our focus is two-fold:\n  (1) Benchmarking: a comparison of 6 different prompt-based bias and toxicity metrics across 12 demographic axes and 5 families of generative LLMs. Out of those 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in the paper. The comparison of those benchmarks gives us insights about the bias and toxicity of the compared models. Therefore, we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases.\n  (2) Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity mitigation techniques perform across our suite of measurements. ROBBIE aims to provide insights for practitioners while deploying a model, emphasizing the need to not only measure potential harms, but also understand how they arise by characterizing the data, mitigate harms once found, and balance any trade-offs. We open-source our analysis code in hopes of encouraging broader measurements of bias in future LLMs.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18140"
  },
  "2311.18130": {
    "title": "The Trifecta: Three simple techniques for training deeper Forward-Forward networks",
    "authors": [
      "Thomas Dooms",
      "Ing Jyh Tsang",
      "Jose Oramas"
    ],
    "abstract": "Modern machine learning models are able to outperform humans on a variety of non-trivial tasks. However, as the complexity of the models increases, they consume significant amounts of power and still struggle to generalize effectively to unseen data. Local learning, which focuses on updating subsets of a model's parameters at a time, has emerged as a promising technique to address these issues. Recently, a novel local learning algorithm, called Forward-Forward, has received widespread attention due to its innovative approach to learning. Unfortunately, its application has been limited to smaller datasets due to scalability issues. To this end, we propose The Trifecta, a collection of three simple techniques that synergize exceptionally well and drastically improve the Forward-Forward algorithm on deeper networks. Our experiments demonstrate that our models are on par with similarly structured, backpropagation-based models in both training speed and test accuracy on simple datasets. This is achieved by the ability to learn representations that are informative locally, on a layer-by-layer basis, and retain their informativeness when propagated to deeper layers in the architecture. This leads to around 84% accuracy on CIFAR-10, a notable improvement (25%) over the original FF algorithm. These results highlight the potential of Forward-Forward as a genuine competitor to backpropagation and as a promising research avenue.\n        \u25b3 Less",
    "submission_date": "12 December, 2023",
    "eprint_id": "2311.18130"
  },
  "2311.18129": {
    "title": "Mixed-Precision Quantization for Federated Learning on Resource-Constrained Heterogeneous Devices",
    "authors": [
      "Huancheng Chen",
      "Haris Vikalo"
    ],
    "abstract": "While federated learning (FL) systems often utilize quantization to battle communication and computational bottlenecks, they have heretofore been limited to deploying fixed-precision quantization schemes. Meanwhile, the concept of mixed-precision quantization (MPQ), where different layers of a deep learning model are assigned varying bit-width, remains unexplored in the FL settings. We present a novel FL algorithm, FedMPQ, which introduces mixed-precision quantization to resource-heterogeneous FL systems. Specifically, local models, quantized so as to satisfy bit-width constraint, are trained by optimizing an objective function that includes a regularization term which promotes reduction of precision in some of the layers without significant performance degradation. The server collects local model updates, de-quantizes them into full-precision models, and then aggregates them into a global model. To initialize the next round of local training, the server relies on the information learned in the previous training round to customize bit-width assignments of the models delivered to different clients. In extensive benchmarking experiments on several model architectures and different datasets in both iid and non-iid settings, FedMPQ outperformed the baseline FL schemes that utilize fixed-precision quantization while incurring only a minor computational overhead on the participating devices.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18129"
  },
  "2311.18128": {
    "title": "Dynamic Scheduling of a Multiclass Queue in the Halfin-Whitt Regime: A Computational Approach for High-Dimensional Problems",
    "authors": [
      "Bar\u0131\u015f Ata",
      "Ebru Ka\u015f\u0131karalar"
    ],
    "abstract": "We consider a multi-class queueing model of a telephone call center, in which a system manager dynamically allocates available servers to customer calls. Calls can terminate through either service completion or customer abandonment, and the manager strives to minimize the expected total of holding costs plus abandonment costs over a finite horizon. Focusing on the Halfin-Whitt heavy traffic regime, we derive an approximating diffusion control problem, and building on earlier work by Han et al. (2018), develop a simulation-based computational method for solution of such problems, one that relies heavily on deep neural network technology. Using this computational method, we propose a policy for the original (pre-limit) call center scheduling problem. Finally, the performance of this policy is assessed using test problems based on publicly available call center data. For the test problems considered so far, our policy does as well as the best benchmark we could find. Moreover, our method is computationally feasible at least up to dimension 100, that is, for call centers with 100 or more distinct customer classes.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18128"
  },
  "2311.18118": {
    "title": "AnonPSI: An Anonymity Assessment Framework for PSI",
    "authors": [
      "Bo Jiang",
      "Jian Du",
      "Qiang Yan"
    ],
    "abstract": "Private Set Intersection (PSI) is a widely used protocol that enables two parties to securely compute a function over the intersected part of their shared datasets and has been a significant research focus over the years. However, recent studies have highlighted its vulnerability to Set Membership Inference Attacks (SMIA), where an adversary might deduce an individual's membership by invoking multiple PSI protocols. This presents a considerable risk, even in the most stringent versions of PSI, which only return the cardinality of the intersection. This paper explores the evaluation of anonymity within the PSI context. Initially, we highlight the reasons why existing works fall short in measuring privacy leakage, and subsequently propose two attack strategies that address these deficiencies. Furthermore, we provide theoretical guarantees on the performance of our proposed methods. In addition to these, we illustrate how the integration of auxiliary information, such as the sum of payloads associated with members of the intersection (PSI-SUM), can enhance attack efficiency. We conducted a comprehensive performance evaluation of various attack strategies proposed utilizing two real datasets. Our findings indicate that the methods we propose markedly enhance attack efficiency when contrasted with previous research endeavors. {The effective attacking implies that depending solely on existing PSI protocols may not provide an adequate level of privacy assurance. It is recommended to combine privacy-enhancing technologies synergistically to enhance privacy protection even further.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18118"
  },
  "2311.18116": {
    "title": "Multi-round Dynamic Group Decision Making Method On 2-Dimension Uncertain Linguistic Variables",
    "authors": [
      "Yukun Zhang"
    ],
    "abstract": "The language evaluation information of the interactive group decision method at present is based on the one-dimension language variable. At the same time, multi-attribute group decision making method based on two-dimension linguistic information only use single-stage and static evaluation method. In this paper, we propose a dynamic group decision making method based on two-dimension linguistic information, combining dynamic interactive group decision making methods with two-dimensional language evaluation information The method first use Two-Dimensional Uncertain Linguistic Generalized Weighted Aggregation (DULGWA) Operators to aggregate the preference information of each decision maker, then adopting dynamic information entropy method to obtain weights of attributes at each stage. Finally we propose the group consistency index to quantify the termination conditions of group interaction. One example is given to verify the developed approach and to demonstrate its effectiveness.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18116"
  },
  "2311.18115": {
    "title": "Understanding the Effects of Using Parsons Problems to Scaffold Code Writing for Students with Varying CS Self-Efficacy Levels",
    "authors": [
      "Xinying Hou",
      "Barbara J. Ericson",
      "Xu Wang"
    ],
    "abstract": "Introductory programming courses aim to teach students to write code independently. However, transitioning from studying worked examples to generating their own code is often difficult and frustrating for students, especially those with lower CS self-efficacy in general. Therefore, we investigated the impact of using Parsons problems as a code-writing scaffold for students with varying levels of CS self-efficacy. Parsons problems are programming tasks where students arrange mixed-up code blocks in the correct order. We conducted a between-subjects study with undergraduate students (N=89) on a topic where students have limited code-writing expertise. Students were randomly assigned to one of two conditions. Students in one condition practiced writing code without any scaffolding, while students in the other condition were provided with scaffolding in the form of an equivalent Parsons problem. We found that, for students with low CS self-efficacy levels, those who received scaffolding achieved significantly higher practice performance and in-practice problem-solving efficiency compared to those without any scaffolding. Furthermore, when given Parsons problems as scaffolding during practice, students with lower CS self-efficacy were more likely to solve them. In addition, students with higher pre-practice knowledge on the topic were more likely to effectively use the Parsons scaffolding. This study provides evidence for the benefits of using Parsons problems to scaffold students' write-code activities. It also has implications for optimizing the Parsons scaffolding experience for students, including providing personalized and adaptive Parsons problems based on the student's current problem-solving status.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18115"
  },
  "2311.18114": {
    "title": "Composition of Nondeterministic and Stochastic Services for LTLf Task Specifications",
    "authors": [
      "Giuseppe De Giacomo",
      "Marco Favorito",
      "Luciana Silo"
    ],
    "abstract": "In this paper, we study the composition of services so as to obtain runs satisfying a task specification in Linear Temporal Logic on finite traces (LTLf). We study the problem in the case services are nondeterministic and the LTLf specification can be exactly met, and in the case services are stochastic, where we are interested in maximizing the probability of satisfaction of the LTLf specification and, simultaneously, minimizing the utilization cost of the services. To do so, we combine techniques from LTLf synthesis, service composition \u00e0 la Roman Model, reactive synthesis, and bi-objective lexicographic optimization on MDPs. This framework has several interesting applications, including Smart Manufacturing and Digital Twins.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18114"
  },
  "2311.18106": {
    "title": "Generic proving of replica symmetry breaking",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "We study the replica symmetry breaking (rsb) concepts on a generic level through the prism of recently introduced interpolating/comparison mechanisms for bilinearly indexed (bli) random processes. In particular, \\cite{Stojnicnflgscompyx23} introduced a \\emph{fully lifted} (fl) interpolating mechanism and \\cite{Stojnicsflgscompyx23} developed its a \\emph{stationarized fully lifted} (sfl) variant. Here, we present a sfl \\emph{matching} mechanism that shows that the results obtained in \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23} completely correspond to the ones obtained by a statistical physics replica tool with the replica symmetry breaking (rsb) form suggested by Parisi in \\cite{Par79,Parisi80,Par80}. The results are very generic as they allow to handle pretty much all bilinear models at once. Moreover, given that the results of \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23} are extendable to many other forms, the concepts presented here automatically extend to any such forms as well.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18106"
  },
  "2311.18103": {
    "title": "Corner-to-Center Long-range Context Model for Efficient Learned Image Compression",
    "authors": [
      "Yang Sui",
      "Ding Ding",
      "Xiang Pan",
      "Xiaozhong Xu",
      "Shan Liu",
      "Bo Yuan",
      "Zhenzhong Chen"
    ],
    "abstract": "In the framework of learned image compression, the context model plays a pivotal role in capturing the dependencies among latent representations. To reduce the decoding time resulting from the serial autoregressive context model, the parallel context model has been proposed as an alternative that necessitates only two passes during the decoding phase, thus facilitating efficient image compression in real-world scenarios. However, performance degradation occurs due to its incomplete casual context. To tackle this issue, we conduct an in-depth analysis of the performance degradation observed in existing parallel context models, focusing on two aspects: the Quantity and Quality of information utilized for context prediction and decoding. Based on such analysis, we propose the \\textbf{Corner-to-Center transformer-based Context Model (C$^3$M)} designed to enhance context and latent predictions and improve rate-distortion performance. Specifically, we leverage the logarithmic-based prediction order to predict more context features from corner to center progressively. In addition, to enlarge the receptive field in the analysis and synthesis transformation, we use the Long-range Crossing Attention Module (LCAM) in the encoder/decoder to capture the long-range semantic information by assigning the different window shapes in different channels. Extensive experimental evaluations show that the proposed method is effective and outperforms the state-of-the-art parallel methods. Finally, according to the subjective analysis, we suggest that improving the detailed representation in transformer-based image compression is a promising direction to be explored.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18103"
  },
  "2311.18102": {
    "title": "PatchBMI-Net: Lightweight Facial Patch-based Ensemble for BMI Prediction",
    "authors": [
      "Parshuram N. Aarotale",
      "Twyla Hill",
      "Ajita Rattani"
    ],
    "abstract": "Due to an alarming trend related to obesity affecting 93.3 million adults in the United States alone, body mass index (BMI) and body weight have drawn significant interest in various health monitoring applications. Consequently, several studies have proposed self-diagnostic facial image-based BMI prediction methods for healthy weight monitoring. These methods have mostly used convolutional neural network (CNN) based regression baselines, such as VGG19, ResNet50, and Efficient-NetB0, for BMI prediction from facial images. However, the high computational requirement of these heavy-weight CNN models limits their deployment to resource-constrained mobile devices, thus deterring weight monitoring using smartphones. This paper aims to develop a lightweight facial patch-based ensemble (PatchBMI-Net) for BMI prediction to facilitate the deployment and weight monitoring using smartphones. Extensive experiments on BMI-annotated facial image datasets suggest that our proposed PatchBMI-Net model can obtain Mean Absolute Error (MAE) in the range [3.58, 6.51] with a size of about 3.3 million parameters. On cross-comparison with heavyweight models, such as ResNet-50 and Xception, trained for BMI prediction from facial images, our proposed PatchBMI-Net obtains equivalent MAE along with the model size reduction of about 5.4x and the average inference time reduction of about 3x when deployed on Apple-14 smartphone. Thus, demonstrating performance efficiency as well as low latency for on-device deployment and weight monitoring using smartphone applications.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18102"
  },
  "2311.18098": {
    "title": "Adaptive Early Exiting for Collaborative Inference over Noisy Wireless Channels",
    "authors": [
      "Mikolaj Jankowski",
      "Deniz Gunduz",
      "Krystian Mikolajczyk"
    ],
    "abstract": "Collaborative inference systems are one of the emerging solutions for deploying deep neural networks (DNNs) at the wireless network edge. Their main idea is to divide a DNN into two parts, where the first is shallow enough to be reliably executed at edge devices of limited computational power, while the second part is executed at an edge server with higher computational capabilities. The main advantage of such systems is that the input of the DNN gets compressed as the subsequent layers of the shallow part extract only the information necessary for the task. As a result, significant communication savings can be achieved compared to transmitting raw input samples. In this work, we study early exiting in the context of collaborative inference, which allows obtaining inference results at the edge device for certain samples, without the need to transmit the partially processed data to the edge server at all, leading to further communication savings. The central part of our system is the transmission-decision (TD) mechanism, which, given the information from the early exit, and the wireless channel conditions, decides whether to keep the early exit prediction or transmit the data to the edge server for further processing. In this paper, we evaluate various TD mechanisms and show experimentally, that for an image classification task over the wireless edge, proper utilization of early exits can provide both performance gains and significant communication savings.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18098"
  },
  "2311.18097": {
    "title": "Bilinearly indexed random processes -- \\emph{stationarization} of fully lifted interpolation",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "Our companion paper \\cite{Stojnicnflgscompyx23} introduced a very powerful \\emph{fully lifted} (fl) statistical interpolating/comparison mechanism for bilinearly indexed random processes. Here, we present a particular realization of such fl mechanism that relies on a stationarization along the interpolating path concept. A collection of very fundamental relations among the interpolating parameters is uncovered, contextualized, and presented. As a nice bonus, in particular special cases, we show that the introduced machinery allows various simplifications to forms readily usable in practice. Given how many well known random structures and optimization problems critically rely on the results of the type considered here, the range of applications is pretty much unlimited. We briefly point to some of these opportunities as well.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18097"
  },
  "2311.18094": {
    "title": "Self-Driving Telescopes: Autonomous Scheduling of Astronomical Observation Campaigns with Offline Reinforcement Learning",
    "authors": [
      "Franco Terranova",
      "M. Voetberg",
      "Brian Nord",
      "Amanda Pagul"
    ],
    "abstract": "Modern astronomical experiments are designed to achieve multiple scientific goals, from studies of galaxy evolution to cosmic acceleration. These goals require data of many different classes of night-sky objects, each of which has a particular set of observational needs. These observational needs are typically in strong competition with one another. This poses a challenging multi-objective optimization problem that remains unsolved. The effectiveness of Reinforcement Learning (RL) as a valuable paradigm for training autonomous systems has been well-demonstrated, and it may provide the basis for self-driving telescopes capable of optimizing the scheduling for astronomy campaigns. Simulated datasets containing examples of interactions between a telescope and a discrete set of sky locations on the celestial sphere can be used to train an RL model to sequentially gather data from these several locations to maximize a cumulative reward as a measure of the quality of the data gathered. We use simulated data to test and compare multiple implementations of a Deep Q-Network (DQN) for the task of optimizing the schedule of observations from the Stone Edge Observatory (SEO). We combine multiple improvements on the DQN and adjustments to the dataset, showing that DQNs can achieve an average reward of 87%+-6% of the maximum achievable reward in each state on the test set. This is the first comparison of offline RL algorithms for a particular astronomical challenge and the first open-source framework for performing such a comparison and assessment task.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18094"
  },
  "2311.18092": {
    "title": "Fully lifted interpolating comparisons of bilinearly indexed random processes",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "A powerful statistical interpolating concept, which we call \\emph{fully lifted} (fl), is introduced and presented while establishing a connection between bilinearly indexed random processes and their corresponding fully decoupled (linearly indexed) comparative alternatives. Despite on occasion very involved technical considerations, the final interpolating forms and their underlying relations admit rather elegant expressions that provide conceivably highly desirable and useful tool for further studying various different aspects of random processes and their applications. We also discuss the generality of the considered models and show that they encompass many well known random structures and optimization problems to which then the obtained results automatically apply.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18092"
  },
  "2311.18085": {
    "title": "Leveraging a Randomized Key Matrix to Enhance the Security of Symmetric Substitution Ciphers",
    "authors": [
      "Shubham Gandhi",
      "Om Khare",
      "Mihika Dravid",
      "Mihika Sanghvi",
      "Sunil Mane",
      "Aadesh Gajaralwar",
      "Saloni Gandhi"
    ],
    "abstract": "An innovative strategy to enhance the security of symmetric substitution ciphers is presented, through the implementation of a randomized key matrix suitable for various file formats, including but not limited to binary and text files. Despite their historical relevance, symmetric substitution ciphers have been limited by vulnerabilities to cryptanalytic methods like frequency analysis and known plaintext attacks. The aim of our research is to mitigate these vulnerabilities by employing a polyalphabetic substitution strategy that incorporates a distinct randomized key matrix. This matrix plays a pivotal role in generating a unique random key, comprising characters, encompassing both uppercase and lowercase letters, numeric, and special characters, to derive the corresponding ciphertext. The effectiveness of the proposed methodology in enhancing the security of conventional substitution methods for file encryption and decryption is supported by comprehensive testing and analysis, which encompass computational speed, frequency analysis, keyspace examination, Kasiski test, entropy analysis, and the utilization of a large language model.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18085"
  },
  "2311.18082": {
    "title": "Zooming Out on Zooming In: Advancing Super-Resolution for Remote Sensing",
    "authors": [
      "Piper Wolters",
      "Favyen Bastani",
      "Aniruddha Kembhavi"
    ],
    "abstract": "Super-Resolution for remote sensing has the potential for huge impact on planet monitoring by producing accurate and realistic high resolution imagery on a frequent basis and a global scale. Despite a lot of attention, several inconsistencies and challenges have prevented it from being deployed in practice. These include the lack of effective metrics, fragmented and relatively small-scale datasets for training, insufficient comparisons across a suite of methods, and unclear evidence for the use of super-resolution outputs for machine consumption. This work presents a new metric for super-resolution, CLIPScore, that corresponds far better with human judgments than previous metrics on an extensive study. We use CLIPScore to evaluate four standard methods on a new large-scale dataset, S2-NAIP, and three existing benchmark datasets, and find that generative adversarial networks easily outperform more traditional L2 loss-based models and are more semantically accurate than modern diffusion models. We also find that using CLIPScore as an auxiliary loss can speed up the training of GANs by 18x and lead to improved outputs, resulting in an effective model in diverse geographies across the world which we will release publicly. The dataset, pre-trained model weights, and code are available at https://github.com/allenai/satlas-super-resolution/.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18082"
  },
  "2311.18078": {
    "title": "The Forecastability of Underlying Building Electricity Demand from Time Series Data",
    "authors": [
      "Mohamad Khalil",
      "A. Stephen McGough",
      "Hussain Kazmi",
      "Sara Walker"
    ],
    "abstract": "Forecasting building energy consumption has become a promising solution in Building Energy Management Systems for energy saving and optimization. Furthermore, it can play an important role in the efficient management of the operation of a smart grid. Different data-driven approaches to forecast the future energy demand of buildings at different scale, and over various time horizons, can be found in the scientific literature, including extensive Machine Learning and Deep Learning approaches. However, the identification of the most accurate forecaster model which can be utilized to predict the energy demand of such a building is still challenging.In this paper, the design and implementation of a data-driven approach to predict how forecastable the future energy demand of a building is, without first utilizing a data-driven forecasting model, is presented. The investigation utilizes a historical electricity consumption time series data set with a half-hour interval that has been collected from a group of residential buildings located in the City of London, United Kingdom\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18078"
  },
  "2311.18077": {
    "title": "LiDAR-based Outdoor Crowd Management for Smart Campus on the Edge",
    "authors": [
      "Yitao Chen",
      "Krishna Gundu",
      "Zohair Zaidi",
      "Ming Zhao"
    ],
    "abstract": "Crowd management is crucial for a smart campus. Popular methods are camera-based. However, conventional camera-based approaches may leak users' personally identifiable features, jeopardizing user's privacy, which limits its application. In this work, we investigate using affordable light detection and ranging (LiDAR) technology to perform outdoor crowd management leveraging edge computing. Specifically, we aim to count the number of people on a walkway of a university campus. Besides privacy protection, LiDAR sensors are superior to cameras since their performance will not be compromised when the campus is not well-illuminated. We deploy LiDAR sensors on light poles to collect data from the crowd on the campus and leverage edge accelerators to process data locally. We proposed two different methodologies in this work: 1) a non-convolutional neural network (CNN)-based approach, using clustering and autoencoder, and 2) a CNN-based approach that first projects point clouds to 2D planes and then processes the projection with conventional CNNs. Our first approach relies on careful feature engineering, whereas our second approach does not require such effort. However, the CNN-based approach requires more computational power than our non-CNN-based approach. We evaluate both approaches comprehensively with our hand-labeled real-life data collected from campus. Our evaluation results show that the first method achieves an accuracy of 85.4%, whereas the second method achieves 95.8%. Our CNN-based method outperforms existing solutions significantly. We also deploy our two models on an edge accelerator, TPU, to measure the speedup, leveraging this specialized accelerator.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18077"
  },
  "2311.18075": {
    "title": "Bevel-Tip Needle Deflection Modeling, Simulation, and Validation in Multi-Layer Tissues",
    "authors": [
      "Yanzhou Wang",
      "Lidia Al-Zogbi",
      "Guanyun Liu",
      "Jiawei Liu",
      "Junichi Tokuda",
      "Axel Krieger",
      "Iulian Iordachita"
    ],
    "abstract": "Percutaneous needle insertions are commonly performed for diagnostic and therapeutic purposes as an effective alternative to more invasive surgical procedures. However, the outcome of needle-based approaches relies heavily on the accuracy of needle placement, which remains a challenge even with robot assistance and medical imaging guidance due to needle deflection caused by contact with soft tissues. In this paper, we present a novel mechanics-based 2D bevel-tip needle model that can account for the effect of nonlinear strain-dependent behavior of biological soft tissues under compression. Real-time finite element simulation allows multiple control inputs along the length of the needle with full three-degree-of-freedom (DOF) planar needle motions. Cross-validation studies using custom-designed multi-layer tissue phantoms as well as heterogeneous chicken breast tissues result in less than 1mm in-plane errors for insertions reaching depths of up to 61 mm, demonstrating the validity and generalizability of the proposed method.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18075"
  },
  "2311.18071": {
    "title": "Turn Down the Noise: Leveraging Diffusion Models for Test-time Adaptation via Pseudo-label Ensembling",
    "authors": [
      "Mrigank Raman",
      "Rohan Shah",
      "Akash Kannan",
      "Pranit Chawla"
    ],
    "abstract": "The goal of test-time adaptation is to adapt a source-pretrained model to a continuously changing target domain without relying on any source data. Typically, this is either done by updating the parameters of the model (model adaptation) using inputs from the target domain or by modifying the inputs themselves (input adaptation). However, methods that modify the model suffer from the issue of compounding noisy updates whereas methods that modify the input need to adapt to every new data point from scratch while also struggling with certain domain shifts. We introduce an approach that leverages a pre-trained diffusion model to project the target domain images closer to the source domain and iteratively updates the model via pseudo-label ensembling. Our method combines the advantages of model and input adaptations while mitigating their shortcomings. Our experiments on CIFAR-10C demonstrate the superiority of our approach, outperforming the strongest baseline by an average of 1.7% across 15 diverse corruptions and surpassing the strongest input adaptation baseline by an average of 18%.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18071"
  },
  "2311.18070": {
    "title": "Using LoRa communication for Urban VANETs: Feasibility and Challenges",
    "authors": [
      "Thenuka Karunathilake",
      "Anna F\u00f6rster"
    ],
    "abstract": "Vehicular Ad-Hoc Networks (VANETs) were introduced mainly to increase vehicular safety by enabling communication between vehicles and infrastructure to improve overall awareness. The vehicles in a VANET are expected to exchange numerous messages generated by multiple applications, but mainly, these applications can be subdivided into safety and non-safety. The main communication technologies designed for VANETs, DSRC (Dedicated Short Range Communication) and C-V2X (Cellular V2X), mainly focus on delay-sensitive safety-related applications. However, sharing the same bandwidth for safety and non-safety applications will increase the burden on the communication channel and can cause an increase in the overall latencies. Therefore, this work analyses the feasibility of using LoRa communication for non-safety-related urban VANET applications. We conducted multiple real-world experiments to analyse the performance of LoRa communication in various urban VANET scenarios. Our results show that LoRa communication handles the Dopper shifts caused by the urban VANET speeds with both Spreading Factor (SF) 7 and 12. However, higher SF was more vulnerable to Doppler shifts than lower SF. Furthermore, the results illustrate that the Line-of-Sight (LoS) condition significantly affects the LoRa communication, especially in the case of lower SF.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18070"
  },
  "2311.18068": {
    "title": "ALSTER: A Local Spatio-Temporal Expert for Online 3D Semantic Reconstruction",
    "authors": [
      "Silvan Weder",
      "Francis Engelmann",
      "Johannes L. Sch\u00f6nberger",
      "Akihito Seki",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "abstract": "We propose an online 3D semantic segmentation method that incrementally reconstructs a 3D semantic map from a stream of RGB-D frames. Unlike offline methods, ours is directly applicable to scenarios with real-time constraints, such as robotics or mixed reality. To overcome the inherent challenges of online methods, we make two main contributions. First, to effectively extract information from the input RGB-D video stream, we jointly estimate geometry and semantic labels per frame in 3D. A key focus of our approach is to reason about semantic entities both in the 2D input and the local 3D domain to leverage differences in spatial context and network architectures. Our method predicts 2D features using an off-the-shelf segmentation network. The extracted 2D features are refined by a lightweight 3D network to enable reasoning about the local 3D structure. Second, to efficiently deal with an infinite stream of input RGB-D frames, a subsequent network serves as a temporal expert predicting the incremental scene updates by leveraging 2D, 3D, and past information in a learned manner. These updates are then integrated into a global scene representation. Using these main contributions, our method can enable scenarios with real-time constraints and can scale to arbitrary scene sizes by processing and updating the scene only in a local region defined by the new measurement. Our experiments demonstrate improved results compared to existing online methods that purely operate in local regions and show that complementary sources of information can boost the performance. We provide a thorough ablation study on the benefits of different architectural as well as algorithmic design decisions. Our method yields competitive results on the popular ScanNet benchmark and SceneNN dataset.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2311.18068"
  },
  "2311.18064": {
    "title": "GELDA: A generative language annotation framework to reveal visual biases in datasets",
    "authors": [
      "Krish Kabra",
      "Kathleen M. Lewis",
      "Guha Balakrishnan"
    ],
    "abstract": "Bias analysis is a crucial step in the process of creating fair datasets for training and evaluating computer vision models. The bottleneck in dataset analysis is annotation, which typically requires: (1) specifying a list of attributes relevant to the dataset domain, and (2) classifying each image-attribute pair. While the second step has made rapid progress in automation, the first has remained human-centered, requiring an experimenter to compile lists of in-domain attributes. However, an experimenter may have limited foresight leading to annotation \"blind spots,\" which in turn can lead to flawed downstream dataset analyses. To combat this, we propose GELDA, a nearly automatic framework that leverages large generative language models (LLMs) to propose and label various attributes for a domain. GELDA takes a user-defined domain caption (e.g., \"a photo of a bird,\" \"a photo of a living room\") and uses an LLM to hierarchically generate attributes. In addition, GELDA uses the LLM to decide which of a set of vision-language models (VLMs) to use to classify each attribute in images. Results on real datasets show that GELDA can generate accurate and diverse visual attribute suggestions, and uncover biases such as confounding between class labels and background features. Results on synthetic datasets demonstrate that GELDA can be used to evaluate the biases of text-to-image diffusion models and generative adversarial networks. Overall, we show that while GELDA is not accurate enough to replace human annotators, it can serve as a complementary tool to help humans analyze datasets in a cheap, low-effort, and flexible manner.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18064"
  },
  "2311.18063": {
    "title": "TurkishBERTweet: Fast and Reliable Large Language Model for Social Media Analysis",
    "authors": [
      "Ali Najafi",
      "Onur Varol"
    ],
    "abstract": "Turkish is one of the most popular languages in the world. Wide us of this language on social media platforms such as Twitter, Instagram, or Tiktok and strategic position of the country in the world politics makes it appealing for the social network researchers and industry. To address this need, we introduce TurkishBERTweet, the first large scale pre-trained language model for Turkish social media built using almost 900 million tweets. The model shares the same architecture as base BERT model with smaller input length, making TurkishBERTweet lighter than BERTurk and can have significantly lower inference time. We trained our model using the same approach for RoBERTa model and evaluated on two text classification tasks: Sentiment Classification and Hate Speech Detection. We demonstrate that TurkishBERTweet outperforms the other available alternatives on generalizability and its lower inference time gives significant advantage to process large-scale datasets. We also compared our models with the commercial OpenAI solutions in terms of cost and performance to demonstrate TurkishBERTweet is scalable and cost-effective solution. As part of our research, we released TurkishBERTweet and fine-tuned LoRA adapters for the mentioned tasks under the MIT License to facilitate future research and applications on Turkish social media. Our TurkishBERTweet model is available at: https://github.com/ViralLab/TurkishBERTweet\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18063"
  },
  "2311.18062": {
    "title": "Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation",
    "authors": [
      "Xijia Zhang",
      "Yue Guo",
      "Simon Stepputtis",
      "Katia Sycara",
      "Joseph Campbell"
    ],
    "abstract": "Intelligent agents such as robots are increasingly deployed in real-world, safety-critical settings. It is vital that these agents are able to explain the reasoning behind their decisions to human counterparts; however, their behavior is often produced by uninterpretable models such as deep neural networks. We propose an approach to generate natural language explanations for an agent's behavior based only on observations of states and actions, thus making our method independent from the underlying model's representation. For such models, we first learn a behavior representation and subsequently use it to produce plausible explanations with minimal hallucination while affording user interaction with a pre-trained large language model. We evaluate our method in a multi-agent search-and-rescue environment and demonstrate the effectiveness of our explanations for agents executing various behaviors. Through user studies and empirical experiments, we show that our approach generates explanations as helpful as those produced by a human domain expert while enabling beneficial interactions such as clarification and counterfactual queries.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18062"
  },
  "2311.18057": {
    "title": "Non Linear Software Documentation with Interactive Code Examples",
    "authors": [
      "Mathieu Nassif",
      "Martin P. Robillard"
    ],
    "abstract": "Documentation enables sharing knowledge between the developers of a technology and its users. Creating quality documents, however, is challenging: Documents must satisfy the needs of a large audience without being overwhelming for individuals. We address this challenge with a new document format, named Casdoc. Casdoc documents are interactive resources centered around code examples for programmers. Explanations of the code elements are presented as annotations that the readers reveal based on their needs. We evaluated Casdoc in a field study with over 300 participants who used 126 documents as part of a software design course. The majority of participants adopted Casdoc instead of a baseline format during the study. We observed that interactive documents can contain more information than static documents without being distracting to readers. We also gathered insights into five aspects of Casdoc that can be applied to other formats, and propose five guidelines to improve navigability in online documents.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18057"
  },
  "2311.18056": {
    "title": "ReLU-QP: A GPU-Accelerated Quadratic Programming Solver for Model-Predictive Control",
    "authors": [
      "Arun L. Bishop",
      "John Z. Zhang",
      "Swaminathan Gurumurthy",
      "Kevin Tracy",
      "Zachary Manchester"
    ],
    "abstract": "We present ReLU-QP, a GPU-accelerated solver for quadratic programs (QPs) that is capable of solving high-dimensional control problems at real-time rates. ReLU-QP is derived by exactly reformulating the Alternating Direction Method of Multipliers (ADMM) algorithm for solving QPs as a deep, weight-tied neural network with rectified linear unit (ReLU) activations. This reformulation enables the deployment of ReLU-QP on GPUs using standard machine-learning toolboxes. We evaluate the performance of ReLU-QP across three model-predictive control (MPC) benchmarks: stabilizing random linear dynamical systems with control limits, balancing an Atlas humanoid robot on a single foot, and tracking whole-body reference trajectories on a quadruped equipped with a six-degree-of-freedom arm. These benchmarks indicate that ReLU-QP is competitive with state-of-the-art CPU-based solvers for small-to-medium-scale problems and offers order-of-magnitude speed improvements for larger-scale problems.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18056"
  },
  "2311.18055": {
    "title": "Adaptive Hierarchical Origami Metastructures",
    "authors": [
      "Yanbin Li",
      "Antonio Di Lallo",
      "Junxi Zhu",
      "Yinding Chi",
      "Hao Su",
      "Jie Yin"
    ],
    "abstract": "Shape-morphing capabilities are crucial for enabling multifunctionality in both biological and artificial systems. Various strategies for shape morphing have been proposed for applications in metamaterials and robotics. However, few of these approaches have achieved the ability to seamlessly transform into a multitude of volumetric shapes post-fabrication using a relatively simple actuation and control mechanism. Taking inspiration from thick origami and hierarchies in nature, we present a new hierarchical construction method based on polyhedrons to create an extensive library of compact origami metastructures. We show that a single hierarchical origami structure can autonomously adapt to over 103 versatile architectural configurations, achieved with the utilization of fewer than 3 actuation degrees of freedom and employing simple transition kinematics. We uncover the fundamental principles governing theses shape transformation through theoretical models. Furthermore, we also demonstrate the wide-ranging potential applications of these transformable hierarchical structures. These include their uses as untethered and autonomous robotic transformers capable of various gait-shifting and multidirectional locomotion, as well as rapidly self-deployable and self-reconfigurable architecture, exemplifying its scalability up to the meter scale. Lastly, we introduce the concept of multitask reconfigurable and deployable space robots and habitats, showcasing the adaptability and versatility of these metastructures.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18055"
  },
  "2311.18054": {
    "title": "I Know You Did Not Write That! A Sampling Based Watermarking Method for Identifying Machine Generated Text",
    "authors": [
      "Kaan Efe Kele\u015f",
      "\u00d6mer Kaan G\u00fcrb\u00fcz",
      "Mucahid Kutlu"
    ],
    "abstract": "Potential harms of Large Language Models such as mass misinformation and plagiarism can be partially mitigated if there exists a reliable way to detect machine generated text. In this paper, we propose a new watermarking method to detect machine-generated texts. Our method embeds a unique pattern within the generated text, ensuring that while the content remains coherent and natural to human readers, it carries distinct markers that can be identified algorithmically. Specifically, we intervene with the token sampling process in a way which enables us to trace back our token choices during the detection phase. We show how watermarking affects textual quality and compare our proposed method with a state-of-the-art watermarking method in terms of robustness and detectability. Through extensive experiments, we demonstrate the effectiveness of our watermarking scheme in distinguishing between watermarked and non-watermarked text, achieving high detection rates while maintaining textual quality.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2311.18054"
  },
  "2311.18047": {
    "title": "Validation of Collision Detection and Avoidance Methods for Urban Air Mobility through Simulation",
    "authors": [
      "Isha Panchal",
      "Sophie F. Armanini",
      "Isabel C. Metz"
    ],
    "abstract": "Urban Air Mobility is a new concept of regional aviation that has been growing in popularity as a solution to the issue of ever-increasing ground traffic. Electric vehicles with vertical take-off and landing capabilities are being developed by numerous market companies as a result of the push toward environmentally sustainable aviation. The next stage in the eVTOL development process would be to define the concept of operation of these conceptual aircraft and then to integrate them with the existing airspace once they are airborne. In addition to coordinating with conventional air traffic and other Urban Air Mobility (UAM) vehicles, collision avoidance with uncooperative airspace users has to be addressed. Birds and drones of all sizes could be dangerous for these low-flying aircraft. Innovative collision detection and avoidance techniques need to be employed due to the uncooperative nature of these airspace users and different performance characteristics of urban air mobility vehicles compared to classical fixed-wing aircraft. The aim of this study is to validate one such system by means of fast-time solutions. This system uses a decision tree and safety envelopes to prevent collisions with non-cooperative airspace members. The system is designed to work with different aircraft configurations used for Urban Air Mobility (UAM) operations. Various scenarios are modelled by varying intruder type, location, flight path among others. Changes in flight time and closest point of approach are assessed to evaluate the system with regard to safety and efficiency.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18047"
  },
  "2311.18046": {
    "title": "Making Data Work Count",
    "authors": [
      "Srravya Chandhiramowuli",
      "Alex Taylor",
      "Sara Heitlinger",
      "Ding Wang"
    ],
    "abstract": "In this paper, we examine the work of data annotation. Specifically, we focus on the role of counting or quantification in organising annotation work. Based on an ethnographic study of data annotation in two outsourcing centres in India, we observe that counting practices and its associated logics are an integral part of day-to-day annotation activities. In particular, we call attention to the presumption of total countability observed in annotation - the notion that everything, from tasks, datasets and deliverables, to workers, work time, quality and performance, can be managed by applying the logics of counting. To examine this, we draw on sociological and socio-technical scholarship on quantification and develop the lens of a 'regime of counting' that makes explicit the specific counts, practices, actors and structures that underpin the pervasive counting in annotation. We find that within the AI supply chain and data work, counting regimes aid the assertion of authority by the AI clients (also called requesters) over annotation processes, constituting them as reductive, standardised, and homogenous. We illustrate how this has implications for i) how annotation work and workers get valued, ii) the role human discretion plays in annotation, and iii) broader efforts to introduce accountable and more just practices in AI. Through these implications, we illustrate the limits of operating within the logic of total countability. Instead, we argue for a view of counting as partial - located in distinct geographies, shaped by specific interests and accountable in only limited ways. This, we propose, sets the stage for a fundamentally different orientation to counting and what counts in data annotation.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18046"
  },
  "2311.18042": {
    "title": "Compilation for Surface Code Quantum Computers",
    "authors": [
      "Abtin Molavi",
      "Amanda Xu",
      "Swamit Tannu",
      "Aws Albarghouthi"
    ],
    "abstract": "Practical applications of quantum computing depend on fault-tolerant devices with error correction. Today, the most promising approach is a class of error-correcting codes called surface codes. In this paper, we study the problem of compiling quantum circuits for quantum computers implementing surface codes. The problem involves (1) mapping circuit qubits to the device qubits and (2) routing execution paths between pairs of interacting qubits. We call this the surface code mapping and routing problem (SCMR).\n  Solving SCMR near-optimally is critical for both efficiency and correctness. An optimal solution limits the cost of a computation in terms of precious quantum resources and also minimizes the probability of incurring an undetected logical error, which increases with each additional time step.\n  We study SCMR from a theoretical and practical perspective. First, we prove that SCMR, as well as a constrained version of the problem, is NP-complete. Second, we present a optimal algorithm for solving SCMR that is based on a SAT encoding. Third, we present a spectrum of efficient relaxations of SCMR, for example, by exploiting greedy algorithms for solving the problem of node-disjoint paths. Finally, we implement and evaluate our algorithms on a large suite of real and synthetic circuits. Our results suggest that our relaxations are a powerful tool for compiling realistic workloads. The relaxation-based algorithms are orders of magnitude faster than the optimal algorithm (solving instances with tens of thousands of gates in minutes), while still finding high-quality solutions, achieving the theoretical lower bound on up to 55 out of 168 circuits from a diverse benchmark suite.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18042"
  },
  "2311.18041": {
    "title": "Zero-shot Conversational Summarization Evaluations with small Large Language Models",
    "authors": [
      "Ramesh Manuvinakurike",
      "Saurav Sahay",
      "Sangeeta Manepalli",
      "Lama Nachman"
    ],
    "abstract": "Large Language Models (LLMs) exhibit powerful summarization abilities. However, their capabilities on conversational summarization remains under explored. In this work we evaluate LLMs (approx. 10 billion parameters) on conversational summarization and showcase their performance on various prompts. We show that the summaries generated by models depend on the instructions and the performance of LLMs vary with different instructions sometimes resulting steep drop in ROUGE scores if prompts are not selected carefully. We also evaluate the models with human evaluations and discuss the limitations of the models on conversational summarization\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18041"
  },
  "2311.18040": {
    "title": "Evaluating Trustworthiness of AI-Enabled Decision Support Systems: Validation of the Multisource AI Scorecard Table (MAST)",
    "authors": [
      "Pouria Salehi",
      "Yang Ba",
      "Nayoung Kim",
      "Ahmadreza Mosallanezhad",
      "Anna Pan",
      "Myke C. Cohen",
      "Yixuan Wang",
      "Jieqiong Zhao",
      "Shawaiz Bhatti",
      "James Sung",
      "Erik Blasch",
      "Michelle V. Mancenido",
      "Erin K. Chiou"
    ],
    "abstract": "The Multisource AI Scorecard Table (MAST) is a checklist tool based on analytic tradecraft standards to inform the design and evaluation of trustworthy AI systems. In this study, we evaluate whether MAST is associated with people's trust perceptions in AI-enabled decision support systems (AI-DSSs). Evaluating trust in AI-DSSs poses challenges to researchers and practitioners. These challenges include identifying the components, capabilities, and potential of these systems, many of which are based on the complex deep learning algorithms that drive DSS performance and preclude complete manual inspection. We developed two interactive, AI-DSS test environments using the MAST criteria. One emulated an identity verification task in security screening, and another emulated a text summarization system to aid in an investigative reporting task. Each test environment had one version designed to match low-MAST ratings, and another designed to match high-MAST ratings, with the hypothesis that MAST ratings would be positively related to the trust ratings of these systems. A total of 177 subject matter experts were recruited to interact with and evaluate these systems. Results generally show higher MAST ratings for the high-MAST conditions compared to the low-MAST groups, and that measures of trust perception are highly correlated with the MAST ratings. We conclude that MAST can be a useful tool for designing and evaluating systems that will engender high trust perceptions, including AI-DSS that may be used to support visual screening and text summarization tasks. However, higher MAST ratings may not translate to higher joint performance.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18040"
  },
  "2311.18035": {
    "title": "TransOpt: Transformer-based Representation Learning for Optimization Problem Classification",
    "authors": [
      "Gjorgjina Cenikj",
      "Ga\u0161per Petelin",
      "Tome Eftimov"
    ],
    "abstract": "We propose a representation of optimization problem instances using a transformer-based neural network architecture trained for the task of problem classification of the 24 problem classes from the Black-box Optimization Benchmarking (BBOB) benchmark. We show that transformer-based methods can be trained to recognize problem classes with accuracies in the range of 70\\%-80\\% for different problem dimensions, suggesting the possible application of transformer architectures in acquiring representations for black-box optimization problems.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18035"
  },
  "2311.18034": {
    "title": "Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings",
    "authors": [
      "Andrea W Wen-Yi",
      "David Mimno"
    ],
    "abstract": "Cross-lingual transfer learning is an important property of multilingual large language models (LLMs). But how do LLMs represent relationships between languages? Every language model has an input layer that maps tokens to vectors. This ubiquitous layer of language models is often overlooked. We find that similarities between these input embeddings are highly interpretable and that the geometry of these embeddings differs between model families. In one case (XLM-RoBERTa), embeddings encode language: tokens in different writing systems can be linearly separated with an average of 99.2% accuracy. Another family (mT5) represents cross-lingual semantic similarity: the 50 nearest neighbors for any token represent an average of 7.61 writing systems, and are frequently translations. This result is surprising given that there is no explicit parallel cross-lingual training corpora and no explicit incentive for translations in pre-training objectives. Our research opens the door for investigations in 1) The effect of pre-training and model architectures on representations of languages and 2) The applications of cross-lingual representations embedded in language models.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18034"
  },
  "2311.18029": {
    "title": "A Bag of Receptive Fields for Time Series Extrinsic Predictions",
    "authors": [
      "Francesco Spinnato",
      "Riccardo Guidotti",
      "Anna Monreale",
      "Mirco Nanni"
    ],
    "abstract": "High-dimensional time series data poses challenges due to its dynamic nature, varying lengths, and presence of missing values. This kind of data requires extensive preprocessing, limiting the applicability of existing Time Series Classification and Time Series Extrinsic Regression techniques. For this reason, we propose BORF, a Bag-Of-Receptive-Fields model, which incorporates notions from time series convolution and 1D-SAX to handle univariate and multivariate time series with varying lengths and missing values. We evaluate BORF on Time Series Classification and Time Series Extrinsic Regression tasks using the full UEA and UCR repositories, demonstrating its competitive performance against state-of-the-art methods. Finally, we outline how this representation can naturally provide saliency and feature-based explanations.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18029"
  },
  "2311.18028": {
    "title": "Filtered Semi-Markov CRF",
    "authors": [
      "Urchade Zaratiana",
      "Nadi Tomeh",
      "Niama El Khbir",
      "Pierre Holat",
      "Thierry Charnois"
    ],
    "abstract": "Semi-Markov CRF has been proposed as an alternative to the traditional Linear Chain CRF for text segmentation tasks such as Named Entity Recognition (NER). Unlike CRF, which treats text segmentation as token-level prediction, Semi-CRF considers segments as the basic unit, making it more expressive. However, Semi-CRF suffers from two major drawbacks: (1) quadratic complexity over sequence length, as it operates on every span of the input sequence, and (2) inferior performance compared to CRF for sequence labeling tasks like NER. In this paper, we introduce Filtered Semi-Markov CRF, a variant of Semi-CRF that addresses these issues by incorporating a filtering step to eliminate irrelevant segments, reducing complexity and search space. Our approach is evaluated on several NER benchmarks, where it outperforms both CRF and Semi-CRF while being significantly faster. The implementation of our method is available on \\href{https://github.com/urchade/Filtered-Semi-Markov-CRF}{Github}.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18028"
  },
  "2311.18027": {
    "title": "Enhancing Data-Assimilation in CFD using Graph Neural Networks",
    "authors": [
      "Michele Quattromini",
      "Michele Alessandro Bucci",
      "Stefania Cherubini",
      "Onofrio Semeraro"
    ],
    "abstract": "We present a novel machine learning approach for data assimilation applied in fluid mechanics, based on adjoint-optimization augmented by Graph Neural Networks (GNNs) models. We consider as baseline the Reynolds-Averaged Navier-Stokes (RANS) equations, where the unknown is the meanflow and a closure model based on the Reynolds-stress tensor is required for correctly computing the solution. An end-to-end process is cast; first, we train a GNN model for the closure term. Second, the GNN model is introduced in the training process of data assimilation, where the RANS equations act as a physics constraint for a consistent prediction. We obtain our results using direct numerical simulations based on a Finite Element Method (FEM) solver; a two-fold interface between the GNN model and the solver allows the GNN's predictions to be incorporated into post-processing steps of the FEM analysis. The proposed scheme provides an excellent reconstruction of the meanflow without any features selection; preliminary results show promising generalization properties over unseen flow configurations.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18027"
  },
  "2311.18025": {
    "title": "A Probabilistic Method to Predict Classifier Accuracy on Larger Datasets given Small Pilot Data",
    "authors": [
      "Ethan Harvey",
      "Wansu Chen",
      "David M. Kent",
      "Michael C. Hughes"
    ],
    "abstract": "Practitioners building classifiers often start with a smaller pilot dataset and plan to grow to larger data in the near future. Such projects need a toolkit for extrapolating how much classifier accuracy may improve from a 2x, 10x, or 50x increase in data size. While existing work has focused on finding a single \"best-fit\" curve using various functional forms like power laws, we argue that modeling and assessing the uncertainty of predictions is critical yet has seen less attention. In this paper, we propose a Gaussian process model to obtain probabilistic extrapolations of accuracy or similar performance metrics as dataset size increases. We evaluate our approach in terms of error, likelihood, and coverage across six datasets. Though we focus on medical tasks and image modalities, our open source approach generalizes to any kind of classifier.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18025"
  },
  "2311.18021": {
    "title": "Understanding and Improving In-Context Learning on Vision-language Models",
    "authors": [
      "Shuo Chen",
      "Zhen Han",
      "Bailan He",
      "Mark Buckley",
      "Philip Torr",
      "Volker Tresp",
      "Jindong Gu"
    ],
    "abstract": "Recently, in-context learning (ICL) on large language models (LLMs) has received great attention, and this technique can also be applied to vision-language models (VLMs) built upon LLMs. These VLMs can respond to queries by conditioning responses on a series of multimodal demonstrations, which comprise images, queries, and answers. Though ICL has been extensively studied on LLMs, its research on VLMs remains limited. The inclusion of additional visual information in the demonstrations motivates the following research questions: which of the two modalities in the demonstration is more significant? How can we select effective multimodal demonstrations to enhance ICL performance? This study investigates the significance of both visual and language information. Our findings indicate that ICL in VLMs is predominantly driven by the textual information in the demonstrations whereas the visual information in the demonstrations barely affects the ICL performance. Subsequently, we provide an understanding of the findings by analyzing the model information flow and comparing model inner states given different ICL settings. Motivated by our analysis, we propose a simple yet effective approach, termed Mixed Modality In-Context Example Selection (MMICES), which considers both visual and language modalities when selecting demonstrations and shows better ICL performance. Extensive experiments are conducted to support our findings, understanding, and improvement of the ICL performance of VLMs.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18021"
  },
  "2311.18012": {
    "title": "Bayesian Imaging for Radio Interferometry with Score-Based Priors",
    "authors": [
      "Noe Dia",
      "M. J. Yantovski-Barth",
      "Alexandre Adam",
      "Micah Bowles",
      "Pablo Lemos",
      "Anna M. M. Scaife",
      "Yashar Hezaveh",
      "Laurence Perreault-Levasseur"
    ],
    "abstract": "The inverse imaging task in radio interferometry is a key limiting factor to retrieving Bayesian uncertainties in radio astronomy in a computationally effective manner. We use a score-based prior derived from optical images of galaxies to recover images of protoplanetary disks from the DSHARP survey. We demonstrate that our method produces plausible posterior samples despite the misspecified galaxy prior. We show that our approach produces results which are competitive with existing radio interferometry imaging algorithms.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2311.18012"
  },
  "2312.03288": {
    "title": "STEP CATFormer: Spatial-Temporal Effective Body-Part Cross Attention Transformer for Skeleton-based Action Recognition",
    "authors": [
      "Nguyen Huu Bao Long"
    ],
    "abstract": "Graph convolutional networks (GCNs) have been widely used and achieved remarkable results in skeleton-based action recognition. We think the key to skeleton-based action recognition is a skeleton hanging in frames, so we focus on how the Graph Convolutional Convolution networks learn different topologies and effectively aggregate joint features in the global temporal and local temporal. In this work, we propose three Channel-wise Tolopogy Graph Convolution based on Channel-wise Topology Refinement Graph Convolution (CTR-GCN). Combining CTR-GCN with two joint cross-attention modules can capture the upper-lower body part and hand-foot relationship skeleton features. After that, to capture features of human skeletons changing in frames we design the Temporal Attention Transformers to extract skeletons effectively. The Temporal Attention Transformers can learn the temporal features of human skeleton sequences. Finally, we fuse the temporal features output scale with MLP and classification. We develop a powerful graph convolutional network named Spatial Temporal Effective Body-part Cross Attention Transformer which notably high-performance on the NTU RGB+D, NTU RGB+D 120 datasets. Our code and models are available at https://github.com/maclong01/STEP-CATFormer\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03288"
  },
  "2312.03286": {
    "title": "Indirect Gradient Matching for Adversarial Robust Distillation",
    "authors": [
      "Hongsin Lee",
      "Seungju Cho",
      "Changick Kim"
    ],
    "abstract": "Adversarial training significantly improves adversarial robustness, but superior performance is primarily attained with large models. This substantial performance gap for smaller models has spurred active research into adversarial distillation (AD) to mitigate the difference. Existing AD methods leverage the teacher's logits as a guide. In contrast to these approaches, we aim to transfer another piece of knowledge from the teacher, the input gradient. In this paper, we propose a distillation module termed Indirect Gradient Distillation Module (IGDM) that indirectly matches the student's input gradient with that of the teacher. We hypothesize that students can better acquire the teacher's knowledge by matching the input gradient. Leveraging the observation that adversarial training renders the model locally linear on the input space, we employ Taylor approximation to effectively align gradients without directly calculating them. Experimental results show that IGDM seamlessly integrates with existing AD methods, significantly enhancing the performance of all AD methods. Particularly, utilizing IGDM on the CIFAR-100 dataset improves the AutoAttack accuracy from 28.06% to 30.32% with the ResNet-18 model and from 26.18% to 29.52% with the MobileNetV2 model when integrated into the SOTA method without additional data augmentation. The code will be made available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03286"
  },
  "2312.03282": {
    "title": "Monte Carlo Optimization for Solving Multilevel Stackelberg Games",
    "authors": [
      "Pravesh Koirala",
      "Forrest Laine"
    ],
    "abstract": "Stackelberg games originate where there are market leaders and followers, and the actions of leaders influence the behavior of the followers. Mathematical modelling of such games results in what's called a Bilevel Optimization problem. There is an entire area of research dedicated to analyzing and solving Bilevel Optimization problems which are often complex, and finding solutions for such problems is known to be NP-Hard. A generalization of Stackelberg games is a Multilevel Stackelberg game where we may have nested leaders and followers, such that a follower is, in turn, a leader for all lower-level players. These problems are much more difficult to solve, and existing solution approaches typically require extensive cooperation between the players (which generally can't be assumed) or make restrictive assumptions about the structure of the problem. In this paper, we present a stochastic algorithm to approximate the local equilibrium solutions for these Multilevel games. We then construct a few examples of such Multilevel problems, including: a) a nested toll-setting problem; and b) an adversarial initial condition determination problem for Robust Trajectory Optimization. We test our algorithm on our constructed problems as well as some trilevel problems from the literature, and show that it is able to approximate the optimum solutions for these problems within a reasonable error margin. We also provide an asymptotic proof for the convergence of the algorithm and empirically analyze its accuracy and convergence speed for different parameters. Lastly, we compare it with existing solution strategies from the literature and demonstrate that it outperforms them.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03282"
  },
  "2312.03278": {
    "title": "Almanac: An API for Recommending Text Annotations For Time-Series Charts Using News Headlines",
    "authors": [
      "Terrell Ibanez",
      "Vidya Setlur",
      "Maneesh Agrawala"
    ],
    "abstract": "Authors often add text annotations to charts to provide additional context for visually prominent features such as peaks, valleys, and trends. However, writing annotations that provide contextual information, such as descriptions of temporal events, often requires considerable manual effort. To address this problem, we introduce Almanac, a JavaScript API that recommends annotations sourced from the New York Times Archive of news headlines. Almanac consists of two independent parts: (1) a prominence feature detector and (2) a contextual annotation recommender. We demonstrate the utility of the API using D3.js and Vega-Lite to annotate a variety of time-series charts covering many different data domains. Preliminary user feedback shows that Almanac is useful to support the authoring of charts with more descriptive annotations.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03278"
  },
  "2312.03277": {
    "title": "Anomaly Detection for Scalable Task Grouping in Reinforcement Learning-based RAN Optimization",
    "authors": [
      "Jimmy Li",
      "Igor Kozlov",
      "Di Wu",
      "Xue Liu",
      "Gregory Dudek"
    ],
    "abstract": "The use of learning-based methods for optimizing cellular radio access networks (RAN) has received increasing attention in recent years. This coincides with a rapid increase in the number of cell sites worldwide, driven largely by dramatic growth in cellular network traffic. Training and maintaining learned models that work well across a large number of cell sites has thus become a pertinent problem. This paper proposes a scalable framework for constructing a reinforcement learning policy bank that can perform RAN optimization across a large number of cell sites with varying traffic patterns. Central to our framework is a novel application of anomaly detection techniques to assess the compatibility between sites (tasks) and the policy bank. This allows our framework to intelligently identify when a policy can be reused for a task, and when a new policy needs to be trained and added to the policy bank. Our results show that our approach to compatibility assessment leads to an efficient use of computational resources, by allowing us to construct a performant policy bank without exhaustively training on all tasks, which makes it applicable under real-world constraints.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03277"
  },
  "2312.03275": {
    "title": "VLFM: Vision-Language Frontier Maps for Zero-Shot Semantic Navigation",
    "authors": [
      "Naoki Yokoyama",
      "Sehoon Ha",
      "Dhruv Batra",
      "Jiuguang Wang",
      "Bernadette Bucher"
    ],
    "abstract": "Understanding how humans leverage semantic knowledge to navigate unfamiliar environments and decide where to explore next is pivotal for developing robots capable of human-like search behaviors. We introduce a zero-shot navigation approach, Vision-Language Frontier Maps (VLFM), which is inspired by human reasoning and designed to navigate towards unseen semantic objects in novel environments. VLFM builds occupancy maps from depth observations to identify frontiers, and leverages RGB observations and a pre-trained vision-language model to generate a language-grounded value map. VLFM then uses this map to identify the most promising frontier to explore for finding an instance of a given target object category. We evaluate VLFM in photo-realistic environments from the Gibson, Habitat-Matterport 3D (HM3D), and Matterport 3D (MP3D) datasets within the Habitat simulator. Remarkably, VLFM achieves state-of-the-art results on all three datasets as measured by success weighted by path length (SPL) for the Object Goal Navigation task. Furthermore, we show that VLFM's zero-shot nature enables it to be readily deployed on real-world robots such as the Boston Dynamics Spot mobile manipulation platform. We deploy VLFM on Spot and demonstrate its capability to efficiently navigate to target objects within an office building in the real world, without any prior knowledge of the environment. The accomplishments of VLFM underscore the promising potential of vision-language models in advancing the field of semantic navigation. Videos of real-world deployment can be viewed at naoki.io/vlfm.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03275"
  },
  "2312.03266": {
    "title": "SO-NeRF: Active View Planning for NeRF using Surrogate Objectives",
    "authors": [
      "Keifer Lee",
      "Shubham Gupta",
      "Sunglyoung Kim",
      "Bhargav Makwana",
      "Chao Chen",
      "Chen Feng"
    ],
    "abstract": "Despite the great success of Neural Radiance Fields (NeRF), its data-gathering process remains vague with only a general rule of thumb of sampling as densely as possible. The lack of understanding of what actually constitutes good views for NeRF makes it difficult to actively plan a sequence of views that yield the maximal reconstruction quality. We propose Surrogate Objectives for Active Radiance Fields (SOAR), which is a set of interpretable functions that evaluates the goodness of views using geometric and photometric visual cues - surface coverage, geometric complexity, textural complexity, and ray diversity. Moreover, by learning to infer the SOAR scores from a deep network, SOARNet, we are able to effectively select views in mere seconds instead of hours, without the need for prior visits to all the candidate views or training any radiance field during such planning. Our experiments show SOARNet outperforms the baselines with $\\sim$80x speed-up while achieving better or comparable reconstruction qualities. We finally show that SOAR is model-agnostic, thus it generalizes across fully neural-implicit to fully explicit approaches.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03266"
  },
  "2312.03255": {
    "title": "Densifying MIMO: Channel Modeling, Physical Constraints, and Performance Evaluation for Holographic Communications",
    "authors": [
      "Y. Liu",
      "M. Zhang",
      "T. Wang",
      "A. Zhang",
      "M. Debbah"
    ],
    "abstract": "As the backbone of the fifth-generation (5G) cellular network, massive multiple-input multiple-output (MIMO) encounters a significant challenge in practical applications: how to deploy a large number of antenna elements within limited spaces. Recently, holographic communication has emerged as a potential solution to this issue. It employs dense antenna arrays and provides a tractable model. Nevertheless, some challenges must be addressed to actualize this innovative concept. One is the mutual coupling among antenna elements within an array. When the element spacing is small, near-field coupling becomes the dominant factor that strongly restricts the array performance. Another is the polarization of electromagnetic waves. As an intrinsic property, it was not fully considered in the previous channel modeling of holographic communication. The third is the lack of real-world experiments to show the potential and possible defects of a holographic communication system. In this paper, we propose an electromagnetic channel model based on the characteristics of electromagnetic waves. This model encompasses the impact of mutual coupling in the transceiver sides and the depolarization in the propagation environment. Furthermore, by approximating an infinite array, the performance restrictions of large-scale dense antenna arrays are also studied theoretically to exploit the potential of the proposed channel. In addition, numerical simulations and a channel measurement experiment are conducted. The findings reveal that within limited spaces, the coupling effect, particularly for element spacing smaller than half of the wavelength, is the primary factor leading to the inflection point for the performance of holographic communications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03255"
  },
  "2312.03253": {
    "title": "Seller-side Outcome Fairness in Online Marketplaces",
    "authors": [
      "Zikun Ye",
      "Reza Yousefi Maragheh",
      "Lalitesh Morishetti",
      "Shanu Vashishtha",
      "Jason Cho",
      "Kaushiki Nag",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "abstract": "This paper aims to investigate and achieve seller-side fairness within online marketplaces, where many sellers and their items are not sufficiently exposed to customers in an e-commerce platform. This phenomenon raises concerns regarding the potential loss of revenue associated with less exposed items as well as less marketplace diversity. We introduce the notion of seller-side outcome fairness and build an optimization model to balance collected recommendation rewards and the fairness metric. We then propose a gradient-based data-driven algorithm based on the duality and bandit theory. Our numerical experiments on real e-commerce data sets show that our algorithm can lift seller fairness measures while not hurting metrics like collected Gross Merchandise Value (GMV) and total purchases.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03253"
  },
  "2312.03252": {
    "title": "Privacy-Preserving Task-Oriented Semantic Communications Against Model Inversion Attacks",
    "authors": [
      "Yanhu Wang",
      "Shuaishuai Guo",
      "Yiqin Deng",
      "Haixia Zhang",
      "Yuguang Fang"
    ],
    "abstract": "Semantic communication has been identified as a core technology for the sixth generation (6G) of wireless networks. Recently, task-oriented semantic communications have been proposed for low-latency inference with limited bandwidth. Although transmitting only task-related information does protect a certain level of user privacy, adversaries could apply model inversion techniques to reconstruct the raw data or extract useful information, thereby infringing on users' privacy. To mitigate privacy infringement, this paper proposes an information bottleneck and adversarial learning (IBAL) approach to protect users' privacy against model inversion attacks. Specifically, we extract task-relevant features from the input based on the information bottleneck (IB) theory. To overcome the difficulty in calculating the mutual information in high-dimensional space, we derive a variational upper bound to estimate the true mutual information. To prevent data reconstruction from task-related features by adversaries, we leverage adversarial learning to train encoder to fool adversaries by maximizing reconstruction distortion. Furthermore, considering the impact of channel variations on privacy-utility trade-off and the difficulty in manually tuning the weights of each loss, we propose an adaptive weight adjustment method. Numerical results demonstrate that the proposed approaches can effectively protect privacy without significantly affecting task performance and achieve better privacy-utility trade-offs than baseline methods.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03252"
  },
  "2312.03248": {
    "title": "Customizable Combination of Parameter-Efficient Modules for Multi-Task Learning",
    "authors": [
      "Haowen Wang",
      "Tao Sun",
      "Cong Fan",
      "Jinjie Gu"
    ],
    "abstract": "Modular and composable transfer learning is an emerging direction in the field of Parameter Efficient Fine-Tuning, as it enables neural networks to better organize various aspects of knowledge, leading to improved cross-task generalization. In this paper, we introduce a novel approach Customized Polytropon C-Poly that combines task-common skills and task-specific skills, while the skill parameters being highly parameterized using low-rank techniques. Each task is associated with a customizable number of exclusive specialized skills and also benefits from skills shared with peer tasks. A skill assignment matrix is jointly learned. To evaluate our approach, we conducted extensive experiments on the Super-NaturalInstructions and the SuperGLUE benchmarks. Our findings demonstrate that C-Poly outperforms fully-shared, task-specific, and skill-indistinguishable baselines, significantly enhancing the sample efficiency in multi-task learning scenarios.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03248"
  },
  "2312.03246": {
    "title": "On Topological Conditions for Enabling Transient Control in Leader-follower Networks",
    "authors": [
      "Fei Chen",
      "Dimos V. Dimarogonas"
    ],
    "abstract": "We derive necessary and sufficient conditions for leader-follower multi-agent systems such that we can further apply prescribed performance control to achieve the desired formation while satisfying certain transient constraints. A leader-follower framework is considered in the sense that a group of agents with external inputs are selected as leaders in order to drive the group of followers in a way that the entire system can achieve target formation within certain prescribed performance transient bounds. We first derive necessary conditions on the leader-follower graph topology under which the target formation together with the prescribed performance guarantees can be fulfilled. Afterwards, the derived necessary conditions are extended to necessary and sufficient conditions for leader-follower formation control under transient constraints. Finally, the proposed results are illustrated with simulation examples.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03246"
  },
  "2312.03245": {
    "title": "A Simple Framework to Enhance the Adversarial Robustness of Deep Learning-based Intrusion Detection System",
    "authors": [
      "Xinwei Yuan",
      "Shu Han",
      "Wei Huang",
      "Hongliang Ye",
      "Xianglong Kong",
      "Fan Zhang"
    ],
    "abstract": "Deep learning based intrusion detection systems (DL-based IDS) have emerged as one of the best choices for providing security solutions against various network intrusion attacks. However, due to the emergence and development of adversarial deep learning technologies, it becomes challenging for the adoption of DL models into IDS. In this paper, we propose a novel IDS architecture that can enhance the robustness of IDS against adversarial attacks by combining conventional machine learning (ML) models and Deep Learning models. The proposed DLL-IDS consists of three components: DL-based IDS, adversarial example (AE) detector, and ML-based IDS. We first develop a novel AE detector based on the local intrinsic dimensionality (LID). Then, we exploit the low attack transferability between DL models and ML models to find a robust ML model that can assist us in determining the maliciousness of AEs. If the input traffic is detected as an AE, the ML-based IDS will predict the maliciousness of input traffic, otherwise the DL-based IDS will work for the prediction. The fusion mechanism can leverage the high prediction accuracy of DL models and low attack transferability between DL models and ML models to improve the robustness of the whole system. In our experiments, we observe a significant improvement in the prediction performance of the IDS when subjected to adversarial attack, achieving high accuracy with low resource consumption.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03245"
  },
  "2312.03243": {
    "title": "Generalizable Neural Physics Solvers by Baldwinian Evolution",
    "authors": [
      "Jian Cheng Wong",
      "Chin Chun Ooi",
      "Abhishek Gupta",
      "Pao-Hsiung Chiu",
      "Joshua Shao Zheng Low",
      "My Ha Dao",
      "Yew-Soon Ong"
    ],
    "abstract": "Physics-informed neural networks (PINNs) are at the forefront of scientific machine learning, making possible the creation of machine intelligence that is cognizant of physical laws and able to accurately simulate them. In this paper, the potential of discovering PINNs that generalize over an entire family of physics tasks is studied, for the first time, through a biological lens of the Baldwin effect. Drawing inspiration from the neurodevelopment of precocial species that have evolved to learn, predict and react quickly to their environment, we envision PINNs that are pre-wired with connection strengths inducing strong biases towards efficient learning of physics. To this end, evolutionary selection pressure (guided by proficiency over a family of tasks) is coupled with lifetime learning (to specialize on a smaller subset of those tasks) to produce PINNs that demonstrate fast and physics-compliant prediction capabilities across a range of empirically challenging problem instances. The Baldwinian approach achieves an order of magnitude improvement in prediction accuracy at a fraction of the computation cost compared to state-of-the-art results with PINNs meta-learned by gradient descent. This paper marks a leap forward in the meta-learning of PINNs as generalizable physics solvers.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03243"
  },
  "2312.03236": {
    "title": "Multicoated and Folded Graph Neural Networks with Strong Lottery Tickets",
    "authors": [
      "Jiale Yan",
      "Hiroaki Ito",
      "\u00c1ngel L\u00f3pez Garc\u00eda-Arias",
      "Yasuyuki Okoshi",
      "Hikari Otsuka",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Masato Motomura"
    ],
    "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) demonstrates the existence of high-performing subnetworks within a randomly initialized model, discoverable through pruning a convolutional neural network (CNN) without any weight training. A recent study, called Untrained GNNs Tickets (UGT), expanded SLTH from CNNs to shallow graph neural networks (GNNs). However, discrepancies persist when comparing baseline models with learned dense weights. Additionally, there remains an unexplored area in applying SLTH to deeper GNNs, which, despite delivering improved accuracy with additional layers, suffer from excessive memory requirements. To address these challenges, this work utilizes Multicoated Supermasks (M-Sup), a scalar pruning mask method, and implements it in GNNs by proposing a strategy for setting its pruning thresholds adaptively. In the context of deep GNNs, this research uncovers the existence of untrained recurrent networks, which exhibit performance on par with their trained feed-forward counterparts. This paper also introduces the Multi-Stage Folding and Unshared Masks methods to expand the search space in terms of both architecture and parameters. Through the evaluation of various datasets, including the Open Graph Benchmark (OGB), this work establishes a triple-win scenario for SLTH-based GNNs: by achieving high sparsity, competitive performance, and high memory efficiency with up to 98.7\\% reduction, it demonstrates suitability for energy-efficient graph processing.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03236"
  },
  "2312.03235": {
    "title": "HEET: A Heterogeneity Measure to Quantify the Difference across Distributed Computing Systems",
    "authors": [
      "Ali Mokhtari",
      "Saeid Ghafouri",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Although system heterogeneity has been extensively studied in the past, there is yet to be a study on measuring the impact of heterogeneity on system performance. For this purpose, we propose a heterogeneity measure that can characterize the impact of the heterogeneity of a system on its performance behavior in terms of throughput or makespan. We develop a mathematical model to characterize a heterogeneous system in terms of its task and machine heterogeneity dimensions and then reduce it to a single value, called Homogeneous Equivalent Execution Time (HEET), which represents the execution time behavior of the entire system. We used AWS EC2 instances to implement a real-world machine learning inference system. Performance evaluation of the HEET score across different heterogeneous system configurations demonstrates that HEET can accurately characterize the performance behavior of these systems. In particular, the results show that our proposed method is capable of predicting the true makespan of heterogeneous systems without online evaluations with an average precision of 84%. This heterogeneity measure is instrumental for solution architects to configure their systems proactively to be sufficiently heterogeneous to meet their desired performance objectives.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03235"
  },
  "2312.03231": {
    "title": "Deep Multimodal Fusion for Surgical Feedback Classification",
    "authors": [
      "Rafal Kocielnik",
      "Elyssa Y. Wong",
      "Timothy N. Chu",
      "Lydia Lin",
      "De-An Huang",
      "Jiayun Wang",
      "Anima Anandkumar",
      "Andrew J. Hung"
    ],
    "abstract": "Quantification of real-time informal feedback delivered by an experienced surgeon to a trainee during surgery is important for skill improvements in surgical training. Such feedback in the live operating room is inherently multimodal, consisting of verbal conversations (e.g., questions and answers) as well as non-verbal elements (e.g., through visual cues like pointing to anatomic elements). In this work, we leverage a clinically-validated five-category classification of surgical feedback: \"Anatomic\", \"Technical\", \"Procedural\", \"Praise\" and \"Visual Aid\". We then develop a multi-label machine learning model to classify these five categories of surgical feedback from inputs of text, audio, and video modalities. The ultimate goal of our work is to help automate the annotation of real-time contextual surgical feedback at scale. Our automated classification of surgical feedback achieves AUCs ranging from 71.5 to 77.6 with the fusion improving performance by 3.1%. We also show that high-quality manual transcriptions of feedback audio from experts improve AUCs to between 76.5 and 96.2, which demonstrates a clear path toward future improvements. Empirically, we find that the Staged training strategy, with first pre-training each modality separately and then training them jointly, is more effective than training different modalities altogether. We also present intuitive findings on the importance of modalities for different feedback categories. This work offers an important first look at the feasibility of automated classification of real-world live surgical feedback based on text, audio, and video modalities.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03231"
  },
  "2312.03229": {
    "title": "Attaining Equilibria Using Control Sets",
    "authors": [
      "Gleb Polevoy",
      "Jonas Schweichhart"
    ],
    "abstract": "Many interactions result in a socially suboptimal equilibrium, or in a non-equilibrium state, from which arriving at an equilibrium through simple dynamics can be impossible of too long. Aiming to achieve a certain equilibrium, we persuade, bribe, or coerce a group of participants to make them act in a way that will motivate the rest of the players to act accordingly to the desired equilibrium. Formally, we ask which subset of the players can adopt the goal equilibrium strategies that will make acting according to the desired equilibrium a best response for the other players. We call such a subset a direct control set, prove some connections to strength of equilibrium, and study the hardness to find such lightest sets, even approximately. We then solve important subcases and provide approximation algorithms, assuming monotonicity. Next, we concentrate on potential games and prove that, while the problem of finding such a set is \\NP-hard, even for constant-factor approximation, we can still solve the problem approximately or even precisely in relevant special cases. We approximately solve this problem for singleton potential games and treat more closely specific potential games, such as symmetric games and coordination games on graphs.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03229"
  },
  "2312.03227": {
    "title": "Human Body Model based ID using Shape and Pose Parameters",
    "authors": [
      "Aravind Sundaresan",
      "Brian Burns",
      "Indranil Sur",
      "Yi Yao",
      "Xiao Lin",
      "Sujeong Kim"
    ],
    "abstract": "We present a Human Body model based IDentification system (HMID) system that is jointly trained for shape, pose and biometric identification. HMID is based on the Human Mesh Recovery (HMR) network and we propose additional losses to improve and stabilize shape estimation and biometric identification while maintaining the pose and shape output. We show that when our HMID network is trained using additional shape and pose losses, it shows a significant improvement in biometric identification performance when compared to an identical model that does not use such losses. The HMID model uses raw images instead of silhouettes and is able to perform robust recognition on images collected at range and altitude as many anthropometric properties are reasonably invariant to clothing, view and range. We show results on the USF dataset as well as the BRIAR dataset which includes probes with both clothing and view changes. Our approach (using body model losses) shows a significant improvement in Rank20 accuracy and True Accuracy Rate on the BRIAR evaluation dataset.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03227"
  },
  "2312.03226": {
    "title": "Rethinking Object Saliency Ranking: A Novel Whole-flow Processing Paradigm",
    "authors": [
      "Mengke Song",
      "Linfeng Li",
      "Dunquan Wu",
      "Wenfeng Song",
      "Chenglizhao Chen"
    ],
    "abstract": "Existing salient object detection methods are capable of predicting binary maps that highlight visually salient regions. However, these methods are limited in their ability to differentiate the relative importance of multiple objects and the relationships among them, which can lead to errors and reduced accuracy in downstream tasks that depend on the relative importance of multiple objects. To conquer, this paper proposes a new paradigm for saliency ranking, which aims to completely focus on ranking salient objects by their \"importance order\". While previous works have shown promising performance, they still face ill-posed problems. First, the saliency ranking ground truth (GT) orders generation methods are unreasonable since determining the correct ranking order is not well-defined, resulting in false alarms. Second, training a ranking model remains challenging because most saliency ranking methods follow the multi-task paradigm, leading to conflicts and trade-offs among different tasks. Third, existing regression-based saliency ranking methods are complex for saliency ranking models due to their reliance on instance mask-based saliency ranking orders. These methods require a significant amount of data to perform accurately and can be challenging to implement effectively. To solve these problems, this paper conducts an in-depth analysis of the causes and proposes a whole-flow processing paradigm of saliency ranking task from the perspective of \"GT data generation\", \"network structure design\" and \"training protocol\". The proposed approach outperforms existing state-of-the-art methods on the widely-used SALICON set, as demonstrated by extensive experiments with fair and reasonable comparisons. The saliency ranking task is still in its infancy, and our proposed unified framework can serve as a fundamental strategy to guide future work.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03226"
  },
  "2312.03225": {
    "title": "Snake Robot with Tactile Perception Navigates on Large-scale Challenging Terrain",
    "authors": [
      "Shuo Jiang",
      "Adarsh Salagame",
      "Alireza Ramezani",
      "Lawson Wong"
    ],
    "abstract": "Along with the advancement of robot skin technology, there has been notable progress in the development of snake robots featuring body-surface tactile perception. In this study, we proposed a locomotion control framework for snake robots that integrates tactile perception to augment their adaptability to various terrains. Our approach embraces a hierarchical reinforcement learning (HRL) architecture, wherein the high-level orchestrates global navigation strategies while the low-level uses curriculum learning for local navigation maneuvers. Due to the significant computational demands of collision detection in whole-body tactile sensing, the efficiency of the simulator is severely compromised. Thus a distributed training pattern to mitigate the efficiency reduction was adopted. We evaluated the navigation performance of the snake robot in complex large-scale cave exploration with challenging terrains to exhibit improvements in motion efficiency, evidencing the efficacy of tactile perception in terrain-adaptive locomotion of snake robots.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03225"
  },
  "2312.03223": {
    "title": "Hierarchical RL-Guided Large-scale Navigation of a Snake Robot",
    "authors": [
      "Shuo Jiang",
      "Adarsh Salagame",
      "Alireza Ramezani",
      "Lawson Wong"
    ],
    "abstract": "Classical snake robot control leverages mimicking snake-like gaits tuned for specific environments. However, to operate adaptively in unstructured environments, gait generation must be dynamically scheduled. In this work, we present a four-layer hierarchical control scheme to enable the snake robot to navigate freely in large-scale environments. The proposed model decomposes navigation into global planning, local planning, gait generation, and gait tracking. Using reinforcement learning (RL) and a central pattern generator (CPG), our method learns to navigate in complex mazes within hours and can be directly deployed to arbitrary new environments in a zero-shot fashion. We use the high-fidelity model of Northeastern's slithering robot COBRA to test the effectiveness of the proposed hierarchical control approach.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03223"
  },
  "2312.03222": {
    "title": "Predicting Scores of Various Aesthetic Attribute Sets by Learning from Overall Score Labels",
    "authors": [
      "Heng Huang",
      "Xin Jin",
      "Yaqi Liu",
      "Hao Lou",
      "Chaoen Xiao",
      "Shuai Cui",
      "Xinning Li",
      "Dongqing Zou"
    ],
    "abstract": "Now many mobile phones embed deep-learning models for evaluation or guidance on photography. These models cannot provide detailed results like human pose scores or scene color scores because of the rare of corresponding aesthetic attribute data. However, the annotation of image aesthetic attribute scores requires experienced artists and professional photographers, which hinders the collection of large-scale fully-annotated datasets. In this paper, we propose to replace image attribute labels with feature extractors. First, a novel aesthetic attribute evaluation framework based on attribute features is proposed to predict attribute scores and overall scores. We call it the F2S (attribute features to attribute scores) model. We use networks from different tasks to provide attribute features to our F2S models. Then, we define an aesthetic attribute contribution to describe the role of aesthetic attributes throughout an image and use it with the attribute scores and the overall scores to train our F2S model. Sufficient experiments on publicly available datasets demonstrate that our F2S model achieves comparable performance with those trained on the datasets with fully-annotated aesthetic attribute score labels. Our method makes it feasible to learn meaningful attribute scores for various aesthetic attribute sets in different types of images with only overall aesthetic scores.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03222"
  },
  "2312.03218": {
    "title": "Accelerated Gradient Algorithms with Adaptive Subspace Search for Instance-Faster Optimization",
    "authors": [
      "Yuanshi Liu",
      "Hanzhen Zhao",
      "Yang Xu",
      "Pengyun Yue",
      "Cong Fang"
    ],
    "abstract": "Gradient-based minimax optimal algorithms have greatly promoted the development of continuous optimization and machine learning. One seminal work due to Yurii Nesterov [Nes83a] established $\\tilde{\\mathcal{O}}(\\sqrt{L/\u03bc})$ gradient complexity for minimizing an $L$-smooth $\u03bc$-strongly convex objective. However, an ideal algorithm would adapt to the explicit complexity of a particular objective function and incur faster rates for simpler problems, triggering our reconsideration of two defeats of existing optimization modeling and analysis. (i) The worst-case optimality is neither the instance optimality nor such one in reality. (ii) Traditional $L$-smoothness condition may not be the primary abstraction/characterization for modern practical problems.\n  In this paper, we open up a new way to design and analyze gradient-based algorithms with direct applications in machine learning, including linear regression and beyond. We introduce two factors $(\u03b1, \u03c4_\u03b1)$ to refine the description of the degenerated condition of the optimization problems based on the observation that the singular values of Hessian often drop sharply. We design adaptive algorithms that solve simpler problems without pre-known knowledge with reduced gradient or analogous oracle accesses. The algorithms also improve the state-of-art complexities for several problems in machine learning, thereby solving the open problem of how to design faster algorithms in light of the known complexity lower bounds. Specially, with the $\\mathcal{O}(1)$-nuclear norm bounded, we achieve an optimal $\\tilde{\\mathcal{O}}(\u03bc^{-1/3})$ (v.s. $\\tilde{\\mathcal{O}}(\u03bc^{-1/2})$) gradient complexity for linear regression. We hope this work could invoke the rethinking for understanding the difficulty of modern problems in optimization.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03218"
  },
  "2312.03217": {
    "title": "Rethinking E-Commerce Search",
    "authors": [
      "Haixun Wang",
      "Taesik Na"
    ],
    "abstract": "E-commerce search and recommendation usually operate on structured data such as product catalogs and taxonomies. However, creating better search and recommendation systems often requires a large variety of unstructured data including customer reviews and articles on the web. Traditionally, the solution has always been converting unstructured data into structured data through information extraction, and conducting search over the structured data. However, this is a costly approach that often has low quality. In this paper, we envision a solution that does entirely the opposite. Instead of converting unstructured data (web pages, customer reviews, etc) to structured data, we instead convert structured data (product inventory, catalogs, taxonomies, etc) into textual data, which can be easily integrated into the text corpus that trains LLMs. Then, search and recommendation can be performed through a Q/A mechanism through an LLM instead of using traditional information retrieval methods over structured data.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03217"
  },
  "2312.03216": {
    "title": "SDSRA: A Skill-Driven Skill-Recombination Algorithm for Efficient Policy Learning",
    "authors": [
      "Eric H. Jiang",
      "Andrew Lizarraga"
    ],
    "abstract": "In this paper, we introduce a novel algorithm - the Skill-Driven Skill Recombination Algorithm (SDSRA) - an innovative framework that significantly enhances the efficiency of achieving maximum entropy in reinforcement learning tasks. We find that SDSRA achieves faster convergence compared to the traditional Soft Actor-Critic (SAC) algorithm and produces improved policies. By integrating skill-based strategies within the robust Actor-Critic framework, SDSRA demonstrates remarkable adaptability and performance across a wide array of complex and diverse benchmarks.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03216"
  },
  "2312.03214": {
    "title": "Optimistic Global Function Merger",
    "authors": [
      "Kyungwoo Lee",
      "Manman Ren",
      "Ellis Hoag"
    ],
    "abstract": "Function merging is a pivotal technique for reducing code size by combining identical or similar functions into a single function. While prior research has extensively explored this technique, it has not been assessed in conjunction with function outlining and linker's identical code folding, despite substantial common ground. The traditional approaches necessitate the complete intermediate representation to compare functions. Consequently, none of these approaches offer a scalable solution compatible with separate compilations while achieving global function merging, which is critical for large app development. In this paper, we introduce our global function merger, leveraging global merge information from previous code generation runs to optimistically create merging instances within each module context independently. Notably, our approach remains sound even when intermediate representations change, making it well-suited for distributed build environments. We present a comprehensive code generation framework that can run both the state-of-the-art global function outliner and our global function merger. These components complement each other, resulting in a positive impact on code size reduction. Our evaluation demonstrates that when integrating the global function merger with a state-of-the-art global function outliner that is fully optimized with ThinLTO, a further reduction of up to 3.5% in code size can be attained. This is in addition to the initial average reduction of 17.3% achieved through global function outlining for real-world iOS apps, all with minimal extra build time.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03214"
  },
  "2312.03213": {
    "title": "Bootstrap Your Own Variance",
    "authors": [
      "Polina Turishcheva",
      "Jason Ramapuram",
      "Sinead Williamson",
      "Dan Busbridge",
      "Eeshan Dhekane",
      "Russ Webb"
    ],
    "abstract": "Understanding model uncertainty is important for many applications. We propose Bootstrap Your Own Variance (BYOV), combining Bootstrap Your Own Latent (BYOL), a negative-free Self-Supervised Learning (SSL) algorithm, with Bayes by Backprop (BBB), a Bayesian method for estimating model posteriors. We find that the learned predictive std of BYOV vs. a supervised BBB model is well captured by a Gaussian distribution, providing preliminary evidence that the learned parameter posterior is useful for label free uncertainty estimation. BYOV improves upon the deterministic BYOL baseline (+2.83% test ECE, +1.03% test Brier) and presents better calibration and reliability when tested with various augmentations (eg: +2.4% test ECE, +1.2% test Brier for Salt & Pepper noise).\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03213"
  },
  "2312.03212": {
    "title": "Constrained Bayesian Optimization Under Partial Observations: Balanced Improvements and Provable Convergence",
    "authors": [
      "Shengbo Wang",
      "Ke Li"
    ],
    "abstract": "The partially observable constrained optimization problems (POCOPs) impede data-driven optimization techniques since an infeasible solution of POCOPs can provide little information about the objective as well as the constraints. We endeavor to design an efficient and provable method for expensive POCOPs under the framework of constrained Bayesian optimization. Our method consists of two key components. Firstly, we present an improved design of the acquisition functions that introduces balanced exploration during optimization. We rigorously study the convergence properties of this design to demonstrate its effectiveness. Secondly, we propose a Gaussian process embedding different likelihoods as the surrogate model for a partially observable constraint. This model leads to a more accurate representation of the feasible regions compared to traditional classification-based models. Our proposed method is empirically studied on both synthetic and real-world problems. The results demonstrate the competitiveness of our method for solving POCOPs.\n        \u25b3 Less",
    "submission_date": "22 December, 2023",
    "eprint_id": "2312.03212"
  },
  "2312.03209": {
    "title": "Cache Me if You Can: Accelerating Diffusion Models through Block Caching",
    "authors": [
      "Felix Wimbauer",
      "Bichen Wu",
      "Edgar Schoenfeld",
      "Xiaoliang Dai",
      "Ji Hou",
      "Zijian He",
      "Artsiom Sanakoyeu",
      "Peizhao Zhang",
      "Sam Tsai",
      "Jonas Kohler",
      "Christian Rupprecht",
      "Daniel Cremers",
      "Peter Vajda",
      "Jialiang Wang"
    ],
    "abstract": "Diffusion models have recently revolutionized the field of image synthesis due to their ability to generate photorealistic images. However, one of the major drawbacks of diffusion models is that the image generation process is costly. A large image-to-image network has to be applied many times to iteratively refine an image from random noise. While many recent works propose techniques to reduce the number of required steps, they generally treat the underlying denoising network as a black box. In this work, we investigate the behavior of the layers within the network and find that 1) the layers' output changes smoothly over time, 2) the layers show distinct patterns of change, and 3) the change from step to step is often very small. We hypothesize that many layer computations in the denoising network are redundant. Leveraging this, we introduce block caching, in which we reuse outputs from layer blocks of previous steps to speed up inference. Furthermore, we propose a technique to automatically determine caching schedules based on each block's changes over timesteps. In our experiments, we show through FID, human evaluation and qualitative analysis that Block Caching allows to generate images with higher visual quality at the same computational cost. We demonstrate this for different state-of-the-art models (LDM and EMU) and solvers (DDIM and DPM).\n        \u25b3 Less",
    "submission_date": "12 January, 2024",
    "eprint_id": "2312.03209"
  },
  "2312.03207": {
    "title": "Satellite Imagery and AI: A New Era in Ocean Conservation, from Research to Deployment and Impact",
    "authors": [
      "Patrick Beukema",
      "Favyen Bastani",
      "Piper Wolters",
      "Henry Herzog",
      "Joe Ferdinando"
    ],
    "abstract": "Illegal, unreported, and unregulated (IUU) fishing poses a global threat to ocean habitats. Publicly available satellite data offered by NASA and the European Space Agency (ESA) provide an opportunity to actively monitor this activity. Effectively leveraging satellite data for maritime conservation requires highly reliable machine learning models operating globally with minimal latency. This paper introduces three specialized computer vision models designed for synthetic aperture radar (Sentinel-1), optical imagery (Sentinel-2), and nighttime lights (Suomi-NPP/NOAA-20). It also presents best practices for developing and delivering real-time computer vision services for conservation. These models have been deployed in Skylight, a real time maritime monitoring platform, which is provided at no cost to users worldwide.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03207"
  },
  "2312.03205": {
    "title": "Who Leaked the Model? Tracking IP Infringers in Accountable Federated Learning",
    "authors": [
      "Shuyang Yu",
      "Junyuan Hong",
      "Yi Zeng",
      "Fei Wang",
      "Ruoxi Jia",
      "Jiayu Zhou"
    ],
    "abstract": "Federated learning (FL) emerges as an effective collaborative learning framework to coordinate data and computation resources from massive and distributed clients in training. Such collaboration results in non-trivial intellectual property (IP) represented by the model parameters that should be protected and shared by the whole party rather than an individual user. Meanwhile, the distributed nature of FL endorses a malicious client the convenience to compromise IP through illegal model leakage to unauthorized third parties. To block such IP leakage, it is essential to make the IP identifiable in the shared model and locate the anonymous infringer who first leaks it. The collective challenges call for \\emph{accountable federated learning}, which requires verifiable ownership of the model and is capable of revealing the infringer's identity upon leakage. In this paper, we propose Decodable Unique Watermarking (DUW) for complying with the requirements of accountable FL. Specifically, before a global model is sent to a client in an FL round, DUW encodes a client-unique key into the model by leveraging a backdoor-based watermark injection. To identify the infringer of a leaked model, DUW examines the model and checks if the triggers can be decoded as the corresponding keys. Extensive empirical results show that DUW is highly effective and robust, achieving over $99\\%$ watermark success rate for Digits, CIFAR-10, and CIFAR-100 datasets under heterogeneous FL settings, and identifying the IP infringer with $100\\%$ accuracy even after common watermark removal attempts.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03205"
  },
  "2312.03196": {
    "title": "Domain Invariant Representation Learning and Sleep Dynamics Modeling for Automatic Sleep Staging",
    "authors": [
      "Seungyeon Lee",
      "Thai-Hoang Pham",
      "Zhao Cheng",
      "Ping Zhang"
    ],
    "abstract": "Sleep staging has become a critical task in diagnosing and treating sleep disorders to prevent sleep related diseases. With growing large scale sleep databases, significant progress has been made toward automatic sleep staging. However, previous studies face critical problems in sleep studies; the heterogeneity of subjects' physiological signals, the inability to extract meaningful information from unlabeled data to improve predictive performances, the difficulty in modeling correlations between sleep stages, and the lack of an effective mechanism to quantify predictive uncertainty. In this study, we propose a neural network based sleep staging model, DREAM, to learn domain generalized representations from physiological signals and models sleep dynamics. DREAM learns sleep related and subject invariant representations from diverse subjects' sleep signals and models sleep dynamics by capturing interactions between sequential signal segments and between sleep stages. We conducted a comprehensive empirical study to demonstrate the superiority of DREAM, including sleep stage prediction experiments, a case study, the usage of unlabeled data, and uncertainty. Notably, the case study validates DREAM's ability to learn generalized decision function for new subjects, especially in case there are differences between testing and training subjects. Uncertainty quantification shows that DREAM provides prediction uncertainty, making the model reliable and helping sleep experts in real world applications.\n        \u25b3 Less",
    "submission_date": "9 December, 2023",
    "eprint_id": "2312.03196"
  },
  "2312.03195": {
    "title": "Detecting Rumor Veracity with Only Textual Information by Double-Channel Structure",
    "authors": [
      "Alex Kim",
      "Sangwon Yoon"
    ],
    "abstract": "Kyle (1985) proposes two types of rumors: informed rumors which are based on some private information and uninformed rumors which are not based on any information (i.e. bluffing). Also, prior studies find that when people have credible source of information, they are likely to use a more confident textual tone in their spreading of rumors. Motivated by these theoretical findings, we propose a double-channel structure to determine the ex-ante veracity of rumors on social media. Our ultimate goal is to classify each rumor into true, false, or unverifiable category. We first assign each text into either certain (informed rumor) or uncertain (uninformed rumor) category. Then, we apply lie detection algorithm to informed rumors and thread-reply agreement detection algorithm to uninformed rumors. Using the dataset of SemEval 2019 Task 7, which requires ex-ante threefold classification (true, false, or unverifiable) of social media rumors, our model yields a macro-F1 score of 0.4027, outperforming all the baseline models and the second-place winner (Gorrell et al., 2019). Furthermore, we empirically validate that the double-channel structure outperforms single-channel structures which use either lie detection or agreement detection algorithm to all posts.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03195"
  },
  "2312.03194": {
    "title": "Corporate Bankruptcy Prediction with Domain-Adapted BERT",
    "authors": [
      "Alex Kim",
      "Sangwon Yoon"
    ],
    "abstract": "This study performs BERT-based analysis, which is a representative contextualized language model, on corporate disclosure data to predict impending bankruptcies. Prior literature on bankruptcy prediction mainly focuses on developing more sophisticated prediction methodologies with financial variables. However, in our study, we focus on improving the quality of input dataset. Specifically, we employ BERT model to perform sentiment analysis on MD&A disclosures. We show that BERT outperforms dictionary-based predictions and Word2Vec-based predictions in terms of adjusted R-square in logistic regression, k-nearest neighbor (kNN-5), and linear kernel support vector machine (SVM). Further, instead of pre-training the BERT model from scratch, we apply self-learning with confidence-based filtering to corporate disclosure data (10-K). We achieve the accuracy rate of 91.56% and demonstrate that the domain adaptation procedure brings a significant improvement in prediction accuracy.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03194"
  },
  "2312.03193": {
    "title": "Conceptualizing the Relationship between AI Explanations and User Agency",
    "authors": [
      "Iyadunni Adenuga",
      "Jonathan Dodge"
    ],
    "abstract": "We grapple with the question: How, for whom and why should explainable artificial intelligence (XAI) aim to support the user goal of agency? In particular, we analyze the relationship between agency and explanations through a user-centric lens through case studies and thought experiments. We find that explanation serves as one of several possible first steps for agency by allowing the user convert forethought to outcome in a more effective manner in future interactions. Also, we observe that XAI systems might better cater to laypersons, particularly \"tinkerers\", when combining explanations and user control, so they can make meaningful changes.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03193"
  },
  "2312.03186": {
    "title": "Data-Driven Traffic Reconstruction and Kernel Methods for Identifying Stop-and-Go Congestion",
    "authors": [
      "Edgar Ramirez Sanchez",
      "Shreyaa Raghavan",
      "Cathy Wu"
    ],
    "abstract": "Identifying stop-and-go events (SAGs) in traffic flow presents an important avenue for advancing data-driven research for climate change mitigation and sustainability, owing to their substantial impact on carbon emissions, travel time, fuel consumption, and roadway safety. In fact, SAGs are estimated to account for 33-50% of highway driving externalities. However, insufficient attention has been paid to precisely quantifying where, when, and how much these SAGs take place -necessary for downstream decision making, such as intervention design and policy analysis. A key challenge is that the data available to researchers and governments are typically sparse and aggregated to a granularity that obscures SAGs. To overcome such data limitations, this study thus explores the use of traffic reconstruction techniques for SAG identification. In particular, we introduce a kernel-based method for identifying spatio-temporal features in traffic and leverage bootstrapping to quantify the uncertainty of the reconstruction process. Experimental results on California highway data demonstrate the promise of the method for capturing SAGs. This work contributes to a foundation for data-driven decision making to advance sustainability of traffic systems.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03186"
  },
  "2312.03182": {
    "title": "Investigating Technology Usage Span by Analyzing Users' Q&A Traces in Stack Overflow",
    "authors": [
      "Saikat Mondal",
      "Debajyoti Mondal",
      "Chanchal K. Roy"
    ],
    "abstract": "Choosing an appropriate software development technology (e.g., programming language) is challenging due to the proliferation of diverse options. The selection of inappropriate technologies for development may have a far-reaching effect on software developers' career growth. Switching to a different technology after working with one may lead to a complex learning curve and, thus, be more challenging. Therefore, it is crucial for software developers to find technologies that have a high usage span. Intuitively, the usage span of a technology can be determined by the time span developers have used that technology. Existing literature focuses on the technology landscape to explore the complex and implicit dependencies among technologies but lacks formal studies to draw insights about their usage span. This paper investigates the technology usage span by analyzing the question and answering (Q&A) traces of Stack Overflow (SO), the largest technical Q&A website available to date. In particular, we analyze 6.7 million Q&A traces posted by about 97K active SO users and see what technologies have appeared in their questions or answers over 15 years. According to our analysis, C# and Java programming languages have a high usage span, followed by JavaScript. Besides, developers used the .NET framework, iOS & Windows Operating Systems (OS), and SQL query language for a long time (on average). Our study also exposes the emerging (i.e., newly growing) technologies. For example, usages of technologies such as SwiftUI, .NET-6.0, Visual Studio 2022, and Blazor WebAssembly framework are increasing. The findings from our study can assist novice developers, startup software industries, and software users in determining appropriate technologies. This also establishes an initial benchmark for future investigation on the use span of software technologies.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03182"
  },
  "2312.03177": {
    "title": "Using Curiosity for an Even Representation of Tasks in Continual Offline Reinforcement Learning",
    "authors": [
      "Pankayaraj Pathmanathan",
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Javier Del Ser"
    ],
    "abstract": "In this work, we investigate the means of using curiosity on replay buffers to improve offline multi-task continual reinforcement learning when tasks, which are defined by the non-stationarity in the environment, are non labeled and not evenly exposed to the learner in time. In particular, we investigate the use of curiosity both as a tool for task boundary detection and as a priority metric when it comes to retaining old transition tuples, which we respectively use to propose two different buffers. Firstly, we propose a Hybrid Reservoir Buffer with Task Separation (HRBTS), where curiosity is used to detect task boundaries that are not known due to the task agnostic nature of the problem. Secondly, by using curiosity as a priority metric when it comes to retaining old transition tuples, a Hybrid Curious Buffer (HCB) is proposed. We ultimately show that these buffers, in conjunction with regular reinforcement learning algorithms, can be used to alleviate the catastrophic forgetting issue suffered by the state of the art on replay buffers when the agent's exposure to tasks is not equal along time. We evaluate catastrophic forgetting and the efficiency of our proposed buffers against the latest works such as the Hybrid Reservoir Buffer (HRB) and the Multi-Time Scale Replay Buffer (MTR) in three different continual reinforcement learning settings. Experiments were done on classical control tasks and Metaworld environment. Experiments show that our proposed replay buffers display better immunity to catastrophic forgetting compared to existing works in most of the settings.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03177"
  },
  "2312.03176": {
    "title": "Active Learning for Abrupt Shifts Change-point Detection via Derivative-Aware Gaussian Processes",
    "authors": [
      "Hao Zhao",
      "Rong Pan"
    ],
    "abstract": "Change-point detection (CPD) is crucial for identifying abrupt shifts in data, which influence decision-making and efficient resource allocation across various domains. To address the challenges posed by the costly and time-intensive data acquisition in CPD, we introduce the Derivative-Aware Change Detection (DACD) method. It leverages the derivative process of a Gaussian process (GP) for Active Learning (AL), aiming to pinpoint change-point locations effectively. DACD balances the exploitation and exploration of derivative processes through multiple data acquisition functions (AFs). By utilizing GP derivative mean and variance as criteria, DACD sequentially selects the next sampling data point, thus enhancing algorithmic efficiency and ensuring reliable and accurate results. We investigate the effectiveness of DACD method in diverse scenarios and show it outperforms other active learning change-point detection approaches.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03176"
  },
  "2312.03173": {
    "title": "A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education",
    "authors": [
      "Jacob Doughty",
      "Zipiao Wan",
      "Anishka Bompelli",
      "Jubahed Qayum",
      "Taozhi Wang",
      "Juran Zhang",
      "Yujia Zheng",
      "Aidan Doyle",
      "Pragnya Sridhar",
      "Arav Agarwal",
      "Christopher Bogart",
      "Eric Keylor",
      "Can Kultur",
      "Jaromir Savelka",
      "Majd Sakr"
    ],
    "abstract": "There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models (LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03173"
  },
  "2312.03171": {
    "title": "Combining Counting Processes and Classification Improves a Stopping Rule for Technology Assisted Review",
    "authors": [
      "Reem Bin-Hezam",
      "Mark Stevenson"
    ],
    "abstract": "Technology Assisted Review (TAR) stopping rules aim to reduce the cost of manually assessing documents for relevance by minimising the number of documents that need to be examined to ensure a desired level of recall. This paper extends an effective stopping rule using information derived from a text classifier that can be trained without the need for any additional annotation. Experiments on multiple data sets (CLEF e-Health, TREC Total Recall, TREC Legal and RCV1) showed that the proposed approach consistently improves performance and outperforms several alternative methods.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03171"
  },
  "2312.03167": {
    "title": "Adaptive spectral graph wavelets for collaborative filtering",
    "authors": [
      "Osama Alshareet",
      "A. Ben Hamza"
    ],
    "abstract": "Collaborative filtering is a popular approach in recommender systems, whose objective is to provide personalized item suggestions to potential users based on their purchase or browsing history. However, personalized recommendations require considerable amount of behavioral data on users, which is usually unavailable for new users, giving rise to the cold-start problem. To help alleviate this challenging problem, we introduce a spectral graph wavelet collaborative filtering framework for implicit feedback data, where users, items and their interactions are represented as a bipartite graph. Specifically, we first propose an adaptive transfer function by leveraging a power transform with the goal of stabilizing the variance of graph frequencies in the spectral domain. Then, we design a deep recommendation model for efficient learning of low-dimensional embeddings of users and items using spectral graph wavelets in an end-to-end fashion. In addition to capturing the graph's local and global structures, our approach yields localization of graph signals in both spatial and spectral domains, and hence not only learns discriminative representations of users and items, but also promotes the recommendation quality. The effectiveness of our proposed model is demonstrated through extensive experiments on real-world benchmark datasets, achieving better recommendation performance compared with strong baseline methods.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03167"
  },
  "2312.03166": {
    "title": "Deep Learning for Fast Inference of Mechanistic Models' Parameters",
    "authors": [
      "Maxim Borisyak",
      "Stefan Born",
      "Peter Neubauer",
      "Mariano Nicolas Cruz-Bournazou"
    ],
    "abstract": "Inferring parameters of macro-kinetic growth models, typically represented by Ordinary Differential Equations (ODE), from the experimental data is a crucial step in bioprocess engineering. Conventionally, estimates of the parameters are obtained by fitting the mechanistic model to observations. Fitting, however, requires a significant computational power. Specifically, during the development of new bioprocesses that use previously unknown organisms or strains, efficient, robust, and computationally cheap methods for parameter estimation are of great value. In this work, we propose using Deep Neural Networks (NN) for directly predicting parameters of mechanistic models given observations. The approach requires spending computational resources for training a NN, nonetheless, once trained, such a network can provide parameter estimates orders of magnitude faster than conventional methods. We consider a training procedure that combines Neural Networks and mechanistic models. We demonstrate the performance of the proposed algorithms on data sampled from several mechanistic models used in bioengineering describing a typical industrial batch process and compare the proposed method, a typical gradient-based fitting procedure, and the combination of the two. We find that, while Neural Network estimates are slightly improved by further fitting, these estimates are measurably better than the fitting procedure alone.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03166"
  },
  "2312.03147": {
    "title": "Neural parameter calibration and uncertainty quantification for epidemic forecasting",
    "authors": [
      "Thomas Gaskin",
      "Tim Conrad",
      "Grigorios A. Pavliotis",
      "Christof Sch\u00fctte"
    ],
    "abstract": "The recent COVID-19 pandemic has thrown the importance of accurately forecasting contagion dynamics and learning infection parameters into sharp focus. At the same time, effective policy-making requires knowledge of the uncertainty on such predictions, in order, for instance, to be able to ready hospitals and intensive care units for a worst-case scenario without needlessly wasting resources. In this work, we apply a novel and powerful computational method to the problem of learning probability densities on contagion parameters and providing uncertainty quantification for pandemic projections. Using a neural network, we calibrate an ODE model to data of the spread of COVID-19 in Berlin in 2020, achieving both a significantly more accurate calibration and prediction than Markov-Chain Monte Carlo (MCMC)-based sampling schemes. The uncertainties on our predictions provide meaningful confidence intervals e.g. on infection figures and hospitalisation rates, while training and running the neural scheme takes minutes where MCMC takes hours. We show convergence of our method to the true posterior on a simplified SIR model of epidemics, and also demonstrate our method's learning capabilities on a reduced dataset, where a complex model is learned from a small number of compartments for which data is available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03147"
  },
  "2312.03146": {
    "title": "LRMP: Layer Replication with Mixed Precision for Spatial In-memory DNN Accelerators",
    "authors": [
      "Abinand Nallathambi",
      "Christin David Bose",
      "Wilfried Haensch",
      "Anand Raghunathan"
    ],
    "abstract": "In-memory computing (IMC) with non-volatile memories (NVMs) has emerged as a promising approach to address the rapidly growing computational demands of Deep Neural Networks (DNNs). Mapping DNN layers spatially onto NVM-based IMC accelerators achieves high degrees of parallelism. However, two challenges that arise in this approach are the highly non-uniform distribution of layer processing times and high area requirements. We propose LRMP, a method to jointly apply layer replication and mixed precision quantization to improve the performance of DNNs when mapped to area-constrained NVM-based IMC accelerators. LRMP uses a combination of reinforcement learning and integer linear programming to search the replication-quantization design space using a model that is closely informed by the target hardware architecture. Across five DNN benchmarks, LRMP achieves 2.8-9$\\times$ latency and 11.8-19$\\times$ throughput improvement at iso-accuracy.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03146"
  },
  "2312.03140": {
    "title": "FlexModel: A Framework for Interpretability of Distributed Large Language Models",
    "authors": [
      "Matthew Choi",
      "Muhammad Adil Asif",
      "John Willes",
      "David Emerson"
    ],
    "abstract": "With the growth of large language models, now incorporating billions of parameters, the hardware prerequisites for their training and deployment have seen a corresponding increase. Although existing tools facilitate model parallelization and distributed training, deeper model interactions, crucial for interpretability and responsible AI techniques, still demand thorough knowledge of distributed computing. This often hinders contributions from researchers with machine learning expertise but limited distributed computing background. Addressing this challenge, we present FlexModel, a software package providing a streamlined interface for engaging with models distributed across multi-GPU and multi-node configurations. The library is compatible with existing model distribution libraries and encapsulates PyTorch models. It exposes user-registerable HookFunctions to facilitate straightforward interaction with distributed model internals, bridging the gap between distributed and single-device model paradigms. Primarily, FlexModel enhances accessibility by democratizing model interactions and promotes more inclusive research in the domain of large-scale neural networks. The package is found at https://github.com/VectorInstitute/flex_model.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03140"
  },
  "2312.03134": {
    "title": "A Hardware Evaluation Framework for Large Language Model Inference",
    "authors": [
      "Hengrui Zhang",
      "August Ning",
      "Rohan Prabhakar",
      "David Wentzlaff"
    ],
    "abstract": "The past year has witnessed the increasing popularity of Large Language Models (LLMs). Their unprecedented scale and associated high hardware cost have impeded their broader adoption, calling for efficient hardware designs. With the large hardware needed to simply run LLM inference, evaluating different hardware designs becomes a new bottleneck.\n  This work introduces LLMCompass, a hardware evaluation framework for LLM inference workloads. LLMCompass is fast, accurate, versatile, and able to describe and evaluate different hardware designs. LLMCompass includes a mapper to automatically find performance-optimal mapping and scheduling. It also incorporates an area-based cost model to help architects reason about their design choices. Compared to real-world hardware, LLMCompass' estimated latency achieves an average 10.4% error rate across various operators with various input sizes and an average 4.1% error rate for LLM inference. With LLMCompass, simulating a 4-NVIDIA A100 GPU node running GPT-3 175B inference can be done within 16 minutes on commodity hardware, including 26,400 rounds of the mapper's parameter search.\n  With the aid of LLMCompass, this work draws architectural implications and explores new cost-effective hardware designs. By reducing the compute capability or replacing High Bandwidth Memory (HBM) with traditional DRAM, these new designs can achieve as much as 3.41x improvement in performance/cost compared to an NVIDIA A100, making them promising choices for democratizing LLMs.\n  LLMCompass is planned to be fully open-source.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03134"
  },
  "2312.03133": {
    "title": "Predicting Bone Degradation Using Vision Transformer and Synthetic Cellular Microstructures Dataset",
    "authors": [
      "Mohammad Saber Hashemi",
      "Azadeh Sheidaei"
    ],
    "abstract": "Bone degradation, especially for astronauts in microgravity conditions, is crucial for space exploration missions since the lower applied external forces accelerate the diminution in bone stiffness and strength substantially. Although existing computational models help us understand this phenomenon and possibly restrict its effect in the future, they are time-consuming to simulate the changes in the bones, not just the bone microstructures, of each individual in detail. In this study, a robust yet fast computational method to predict and visualize bone degradation has been developed. Our deep-learning method, TransVNet, can take in different 3D voxelized images and predict their evolution throughout months utilizing a hybrid 3D-CNN-VisionTransformer autoencoder architecture. Because of limited available experimental data and challenges of obtaining new samples, a digital twin dataset of diverse and initial bone-like microstructures was generated to train our TransVNet on the evolution of the 3D images through a previously developed degradation model for microgravity.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03133"
  },
  "2312.03131": {
    "title": "Heterogeneous radio access with multiple latency targets",
    "authors": [
      "Israel Leyva-Mayorga",
      "Jose Manuel Gimenez-Guzman",
      "Lorenzo Valentini",
      "Petar Popovski"
    ],
    "abstract": "Since the advent of ultra-reliable and low-latency communications (URLLC), the requirements of low-latency applications tend to be completely characterized by a single pre-defined latency-reliability target. That is, operation is optimal whenever the pre-defined latency threshold is met but the system is assumed to be in error when the latency threshold is violated. This vision is severely limited and does not capture the real requirements of most applications, where multiple latency thresholds can be defined, together with incentives or rewards associated with meeting each of them. Such formulation is a generalization of the single-threshold case popularized by URLLC and, in the asymptotic case, approximates to defining a cost for each point in the support of the latency distribution. In this paper, we explore the implications of defining multiple latency targets on the design of access protocols and on the optimization of repetition-based access strategies in orthogonal and non-orthogonal multiple access scenarios with users that present heterogeneous traffic characteristics and requirements. We observe that the access strategies of the users can be effectively adapted to the requirements of the application by carefully defining the latency targets and the associated rewards.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03131"
  },
  "2312.03129": {
    "title": "Leveraging Laryngograph Data for Robust Voicing Detection in Speech",
    "authors": [
      "Yixuan Zhang",
      "Heming Wang",
      "DeLiang Wang"
    ],
    "abstract": "Accurately detecting voiced intervals in speech signals is a critical step in pitch tracking and has numerous applications. While conventional signal processing methods and deep learning algorithms have been proposed for this task, their need to fine-tune threshold parameters for different datasets and limited generalization restrict their utility in real-world applications. To address these challenges, this study proposes a supervised voicing detection model that leverages recorded laryngograph data. The model is based on a densely-connected convolutional recurrent neural network (DC-CRN), and trained on data with reference voicing decisions extracted from laryngograph data sets. Pretraining is also investigated to improve the generalization ability of the model. The proposed model produces robust voicing detection results, outperforming other strong baseline methods, and generalizes well to unseen datasets. The source code of the proposed model with pretraining is provided along with the list of used laryngograph datasets to facilitate further research in this area.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03129"
  },
  "2312.03126": {
    "title": "Learning Curricula in Open-Ended Worlds",
    "authors": [
      "Minqi Jiang"
    ],
    "abstract": "Deep reinforcement learning (RL) provides powerful methods for training optimal sequential decision-making agents. As collecting real-world interactions can entail additional costs and safety risks, the common paradigm of sim2real conducts training in a simulator, followed by real-world deployment. Unfortunately, RL agents easily overfit to the choice of simulated training environments, and worse still, learning ends when the agent masters the specific set of simulated environments. In contrast, the real world is highly open-ended, featuring endlessly evolving environments and challenges, making such RL approaches unsuitable. Simply randomizing over simulated environments is insufficient, as it requires making arbitrary distributional assumptions and can be combinatorially less likely to sample specific environment instances that are useful for learning. An ideal learning process should automatically adapt the training environment to maximize the learning potential of the agent over an open-ended task space that matches or surpasses the complexity of the real world. This thesis develops a class of methods called Unsupervised Environment Design (UED), which aim to produce such open-ended processes. Given an environment design space, UED automatically generates an infinite sequence or curriculum of training environments at the frontier of the learning agent's capabilities. Through extensive empirical studies and theoretical arguments founded on minimax-regret decision theory and game theory, the findings in this thesis show that UED autocurricula can produce RL agents exhibiting significantly improved robustness and generalization to previously unseen environment instances. Such autocurricula are promising paths toward open-ended learning systems that achieve more general intelligence by continually generating and mastering additional challenges of their own design.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.03126"
  },
  "2312.03122": {
    "title": "Assertion Enhanced Few-Shot Learning: Instructive Technique for Large Language Models to Generate Educational Explanations",
    "authors": [
      "Tasmia Shahriar",
      "Kelly Ramos",
      "Noboru Matsuda"
    ],
    "abstract": "Human educators possess an intrinsic ability to anticipate and seek educational explanations from students, which drives them to pose thought-provoking questions when students cannot articulate these explanations independently. We aim to imbue Intelligent Tutoring Systems with this ability using few-shot learning capability of Large Language Models. Our work proposes a novel prompting technique, Assertion Enhanced Few-Shot Learning, to facilitate the generation of accurate, detailed oriented educational explanations. Our central hypothesis is that, in educational domain, few-shot demonstrations are necessary but not a sufficient condition for quality explanation generation. We conducted a study involving 12 in-service teachers, comparing our approach to Traditional Few-Shot Learning. The results show that Assertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and yields higher-quality explanations, as evaluated by teachers. We also conduct a qualitative ablation study to factor the impact of assertions to provide educator-friendly prompting guidelines for generating explanations in their domain of interest.\n        \u25b3 Less",
    "submission_date": "20 January, 2024",
    "eprint_id": "2312.03122"
  },
  "2312.03121": {
    "title": "Evaluating Agents using Social Choice Theory",
    "authors": [
      "Marc Lanctot",
      "Kate Larson",
      "Yoram Bachrach",
      "Luke Marris",
      "Zun Li",
      "Avishkar Bhoopchand",
      "Thomas Anthony",
      "Brian Tanner",
      "Anna Koop"
    ],
    "abstract": "We argue that many general evaluation problems can be viewed through the lens of voting theory. Each task is interpreted as a separate voter, which requires only ordinal rankings or pairwise comparisons of agents to produce an overall evaluation. By viewing the aggregator as a social welfare function, we are able to leverage centuries of research in social choice theory to derive principled evaluation frameworks with axiomatic foundations. These evaluations are interpretable and flexible, while avoiding many of the problems currently facing cross-task evaluation. We apply this Voting-as-Evaluation (VasE) framework across multiple settings, including reinforcement learning, large language models, and humans. In practice, we observe that VasE can be more robust than popular evaluation frameworks (Elo and Nash averaging), discovers properties in the evaluation data not evident from scores alone, and can predict outcomes better than Elo in a complex seven-player game. We identify one particular approach, maximal lotteries, that satisfies important consistency properties relevant to evaluation, is computationally efficient (polynomial in the size of the evaluation data), and identifies game-theoretic cycles.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.03121"
  },
  "2312.03120": {
    "title": "The Landscape of Modern Machine Learning: A Review of Machine, Distributed and Federated Learning",
    "authors": [
      "Omer Subasi",
      "Oceane Bel",
      "Joseph Manzano",
      "Kevin Barker"
    ],
    "abstract": "With the advance of the powerful heterogeneous, parallel and distributed computing systems and ever increasing immense amount of data, machine learning has become an indispensable part of cutting-edge technology, scientific research and consumer products. In this study, we present a review of modern machine and deep learning. We provide a high-level overview for the latest advanced machine learning algorithms, applications, and frameworks. Our discussion encompasses parallel distributed learning, deep learning as well as federated learning. As a result, our work serves as an introductory text to the vast field of modern machine learning.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03120"
  },
  "2312.03119": {
    "title": "AI-SAM: Automatic and Interactive Segment Anything Model",
    "authors": [
      "Yimu Pan",
      "Sitao Zhang",
      "Alison D. Gernand",
      "Jeffery A. Goldstein",
      "James Z. Wang"
    ],
    "abstract": "Semantic segmentation is a core task in computer vision. Existing methods are generally divided into two categories: automatic and interactive. Interactive approaches, exemplified by the Segment Anything Model (SAM), have shown promise as pre-trained models. However, current adaptation strategies for these models tend to lean towards either automatic or interactive approaches. Interactive methods depend on prompts user input to operate, while automatic ones bypass the interactive promptability entirely. Addressing these limitations, we introduce a novel paradigm and its first model: the Automatic and Interactive Segment Anything Model (AI-SAM). In this paradigm, we conduct a comprehensive analysis of prompt quality and introduce the pioneering Automatic and Interactive Prompter (AI-Prompter) that automatically generates initial point prompts while accepting additional user inputs. Our experimental results demonstrate AI-SAM's effectiveness in the automatic setting, achieving state-of-the-art performance. Significantly, it offers the flexibility to incorporate additional user prompts, thereby further enhancing its performance. The project page is available at https://github.com/ymp5078/AI-SAM.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03119"
  },
  "2312.03113": {
    "title": "GPU Graph Processing on CXL-Based Microsecond-Latency External Memory",
    "authors": [
      "Shintaro Sano",
      "Yosuke Bando",
      "Kazuhiro Hiwada",
      "Hirotsugu Kajihara",
      "Tomoya Suzuki",
      "Yu Nakanishi",
      "Daisuke Taki",
      "Akiyuki Kaneko",
      "Tatsuo Shiozawa"
    ],
    "abstract": "In GPU graph analytics, the use of external memory such as the host DRAM and solid-state drives is a cost-effective approach to processing large graphs beyond the capacity of the GPU onboard memory. This paper studies the use of Compute Express Link (CXL) memory as alternative external memory for GPU graph processing in order to see if this emerging memory expansion technology enables graph processing that is as fast as using the host DRAM. Through analysis and evaluation using FPGA prototypes, we show that representative GPU graph traversal algorithms involving fine-grained random access can tolerate an external memory latency of up to a few microseconds introduced by the CXL interface as well as by the underlying memory devices. This insight indicates that microsecond-latency flash memory may be used as CXL memory devices to realize even more cost-effective GPU graph processing while still achieving performance close to using the host DRAM.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03113"
  },
  "2312.03111": {
    "title": "Parallel Proof-of-Work with DAG-Style Voting and Targeted Reward Discounting",
    "authors": [
      "Patrik Keller"
    ],
    "abstract": "We present parallel proof-of-work with DAG-style voting, a novel proof-of-work cryptocurrency protocol that, compared to Bitcoin, provides better consistency guarantees, higher transaction throughput, lower transaction confirmation latency, and higher resilience against incentive attacks. The superior consistency guarantees follow from implementing parallel proof-of-work, a recent consensus scheme that enforces a configurable number of proof-of-work votes per block. Our work is inspired by another recent protocol, Tailstorm, which structures the individual votes as tree and mitigates incentive attacks by discounting the mining rewards proportionally to the depth of the tree. We propose to structure the votes as a directed acyclic graph (DAG) instead of a tree. This allows for a more targeted punishment of offending miners and, as we show through a reinforcement learning based attack search, makes the protocol even more resilient to incentive attacks. An interesting by-product of our analysis is that parallel proof-of-work without reward discounting is less resilient to incentive attacks than Bitcoin in some realistic network scenarios.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03111"
  },
  "2312.03110": {
    "title": "The Automated Bias Triangle Feature Extraction Framework",
    "authors": [
      "Madeleine Kotzagiannidis",
      "Jonas Schuff",
      "Nathan Korda"
    ],
    "abstract": "Bias triangles represent features in stability diagrams of Quantum Dot (QD) devices, whose occurrence and property analysis are crucial indicators for spin physics. Nevertheless, challenges associated with quality and availability of data as well as the subtlety of physical phenomena of interest have hindered an automatic and bespoke analysis framework, often still relying (in part) on human labelling and verification. We introduce a feature extraction framework for bias triangles, built from unsupervised, segmentation-based computer vision methods, which facilitates the direct identification and quantification of physical properties of the former. Thereby, the need for human input or large training datasets to inform supervised learning approaches is circumvented, while additionally enabling the automation of pixelwise shape and feature labeling. In particular, we demonstrate that Pauli Spin Blockade (PSB) detection can be conducted effectively, efficiently and without any training data as a direct result of this approach.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03110"
  },
  "2312.03105": {
    "title": "Improving Automated Algorithm Selection by Advancing Fitness Landscape Analysis",
    "authors": [
      "Raphael Patrick Prager"
    ],
    "abstract": "Optimization is ubiquitous in our daily lives. In the past, (sub-)optimal solutions to any problem have been derived by trial and error, sheer luck, or the expertise of knowledgeable individuals. In our contemporary age, there thankfully exists a plethora of different algorithms that can find solutions more reliably than ever before. Yet, choosing an appropriate algorithm for any given problem is challenging in itself. The field of automated algorithm selection provides various approaches to tackle this latest problem. This is done by delegating the selection of a suitable algorithm for a given problem to a complex computer model. This computer model is generated through the use of Artificial Intelligence. Many of these computer models rely on some sort of information about the problem to make a reasonable selection. Various methods exist to provide this informative input to the computer model in the form of numerical data.\n  In this cumulative dissertation, I propose several improvements to the different variants of informative inputs. This in turn enhances and refines the current state-of-the-art of automated algorithm selection. Specifically, I identify and address current issues with the existing body of work to strengthen the foundation that future work builds upon. Furthermore, the rise of deep learning offers ample opportunities for automated algorithm selection. In several joint works, my colleagues and I developed and evaluated several different methods that replace the existing methods to extract an informative input. Lastly, automated algorithm selection approaches have been restricted to certain types of problems. I propose a method to extend the generation of informative inputs to other problem types and provide an outlook on further promising research directions.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03105"
  },
  "2312.03100": {
    "title": "Flexible polar encoding for information reconciliation in QKD",
    "authors": [
      "Snehasis Addy",
      "Sabyasachi Dutta",
      "Somnath Panja",
      "Kunal Dey",
      "Reihaneh Safavi-Naini",
      "Daniel Oblak"
    ],
    "abstract": "Quantum Key Distribution (QKD) enables two parties to establish a common secret key that is information-theoretically secure by transmitting random bits that are encoded as qubits and sent over a quantum channel, followed by classical information processing steps known as information reconciliation and key extraction. Transmission of information over a quantum channel introduces errors that are generally considered to be due to the adversary's tempering with the quantum channel and needs to be corrected using classical communication over an (authenticated) public channel. Commonly used error-correcting codes in the context of QKD include cascade codes, low-density parity check (LDPC) codes, and more recently polar codes. In this work, we explore the applicability of designing of a polar code encoder based on a channel reliability sequence. We show that the reliability sequence can be derived and used to design an encoder independent of the choice of decoder. We then implement our design and evaluate its performance against previous implementations of polar code encoders for QKD as well as other typical error-correcting codes. A key advantage of our approach is the modular design which decouples the encoder and decoder design and allows independent optimization of each. Our work leads to more versatile polar code-based error reconciliation in QKD systems that would result in deployment in a broader range of scenarios.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.03100"
  },
  "2312.03095": {
    "title": "Understanding Environmental Posts: Sentiment and Emotion Analysis of Social Media Data",
    "authors": [
      "Daniyar Amangeldi",
      "Aida Usmanova",
      "Pakizar Shamoi"
    ],
    "abstract": "Social media is now the predominant source of information due to the availability of immediate public response. As a result, social media data has become a valuable resource for comprehending public sentiments. Studies have shown that it can amplify ideas and influence public sentiments. This study analyzes the public perception of climate change and the environment over a decade from 2014 to 2023. Using the Pointwise Mutual Information (PMI) algorithm, we identify sentiment and explore prevailing emotions expressed within environmental tweets across various social media platforms, namely Twitter, Reddit, and YouTube. Accuracy on a human-annotated dataset was 0.65, higher than Vader score but lower than that of an expert rater (0.90). Our findings suggest that negative environmental tweets are far more common than positive or neutral ones. Climate change, air quality, emissions, plastic, and recycling are the most discussed topics on all social media platforms, highlighting its huge global concern. The most common emotions in environmental tweets are fear, trust, and anticipation, demonstrating public reactions wide and complex nature. By identifying patterns and trends in opinions related to the environment, we hope to provide insights that can help raise awareness regarding environmental issues, inform the development of interventions, and adapt further actions to meet environmental challenges.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03095"
  },
  "2312.03093": {
    "title": "RESIN-EDITOR: A Schema-guided Hierarchical Event Graph Visualizer and Editor",
    "authors": [
      "Khanh Duy Nguyen",
      "Zixuan Zhang",
      "Reece Suchocki",
      "Sha Li",
      "Martha Palmer",
      "Susan Brown",
      "Jiawei Han",
      "Heng Ji"
    ],
    "abstract": "In this paper, we present RESIN-EDITOR, an interactive event graph visualizer and editor designed for analyzing complex events. Our RESIN-EDITOR system allows users to render and freely edit hierarchical event graphs extracted from multimedia and multi-document news clusters with guidance from human-curated event schemas. RESIN-EDITOR's unique features include hierarchical graph visualization, comprehensive source tracing, and interactive user editing, which is more powerful and versatile than existing Information Extraction (IE) visualization tools. In our evaluation of RESIN-EDITOR, we demonstrate ways in which our tool is effective in understanding complex events and enhancing system performance. The source code, a video demonstration, and a live website for RESIN-EDITOR have been made publicly available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03093"
  },
  "2312.03090": {
    "title": "Critiquing Computing Artifacts through Programming Satirical Python Scripts",
    "authors": [
      "Aadarsh Padiyath",
      "Tamara Nelson-Fromm",
      "Barbara Ericson"
    ],
    "abstract": "Computing artifacts tend to exclude marginalized students, so we must create new methods to critique and change them. We studied the potential for \"satirical programming\" to critique artifacts as part of culturally responsive computing (CRC) pedagogy. We conducted a one-hour session for three different BPC programs (N=51). We showed an example of a satirical Python script and taught elements of Python to create a script. Our findings suggest this method is a promising CRC pedagogical approach: 50% of marginalized students worked together to create a satirical script, and 80% enjoyed translating their \"glitches\" into satirical Python scripts.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03090"
  },
  "2312.03088": {
    "title": "LLMs for Multi-Modal Knowledge Extraction and Analysis in Intelligence/Safety-Critical Applications",
    "authors": [
      "Brett Israelsen",
      "Soumalya Sarkar"
    ],
    "abstract": "Large Language Models have seen rapid progress in capability in recent years; this progress has been accelerating and their capabilities, measured by various benchmarks, are beginning to approach those of humans. There is a strong demand to use such models in a wide variety of applications but, due to unresolved vulnerabilities and limitations, great care needs to be used before applying them to intelligence and safety-critical applications. This paper reviews recent literature related to LLM assessment and vulnerabilities to synthesize the current research landscape and to help understand what advances are most critical to enable use of of these technologies in intelligence and safety-critical applications. The vulnerabilities are broken down into ten high-level categories and overlaid onto a high-level life cycle of an LLM. Some general categories of mitigations are reviewed.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03088"
  },
  "2312.03079": {
    "title": "LooseControl: Lifting ControlNet for Generalized Depth Conditioning",
    "authors": [
      "Shariq Farooq Bhat",
      "Niloy J. Mitra",
      "Peter Wonka"
    ],
    "abstract": "We present LooseControl to allow generalized depth conditioning for diffusion-based image generation. ControlNet, the SOTA for depth-conditioned image generation, produces remarkable results but relies on having access to detailed depth maps for guidance. Creating such exact depth maps, in many scenarios, is challenging. This paper introduces a generalized version of depth conditioning that enables many new content-creation workflows. Specifically, we allow (C1) scene boundary control for loosely specifying scenes with only boundary conditions, and (C2) 3D box control for specifying layout locations of the target objects rather than the exact shape and appearance of the objects. Using LooseControl, along with text guidance, users can create complex environments (e.g., rooms, street views, etc.) by specifying only scene boundaries and locations of primary objects. Further, we provide two editing mechanisms to refine the results: (E1) 3D box editing enables the user to refine images by changing, adding, or removing boxes while freezing the style of the image. This yields minimal changes apart from changes induced by the edited boxes. (E2) Attribute editing proposes possible editing directions to change one particular aspect of the scene, such as the overall object density or a particular object. Extensive tests and comparisons with baselines demonstrate the generality of our method. We believe that LooseControl can become an important design tool for easily creating complex environments and be extended to other forms of guidance channels. Code and more information are available at https://shariqfarooq123.github.io/loose-control/ .\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03079"
  },
  "2312.03077": {
    "title": "Clinical Notes Reveal Physician Fatigue",
    "authors": [
      "Chao-Chun Hsu",
      "Ziad Obermeyer",
      "Chenhao Tan"
    ],
    "abstract": "Physicians write notes about patients. In doing so, they reveal much about themselves. Using data from 129,228 emergency room visits, we train a model to identify notes written by fatigued physicians -- those who worked 5 or more of the prior 7 days. In a hold-out set, the model accurately identifies notes written by these high-workload physicians, and also flags notes written in other high-fatigue settings: on overnight shifts, and after high patient volumes. Model predictions also correlate with worse decision-making on at least one important metric: yield of testing for heart attack is 18% lower with each standard deviation increase in model-predicted fatigue. Finally, the model indicates that notes written about Black and Hispanic patients have 12% and 21% higher predicted fatigue than Whites -- larger than overnight vs. daytime differences. These results have an important implication for large language models (LLMs). Our model indicates that fatigued doctors write more predictable notes. Perhaps unsurprisingly, because word prediction is the core of how LLMs work, we find that LLM-written notes have 17% higher predicted fatigue than real physicians' notes. This indicates that LLMs may introduce distortions in generated text that are not yet fully understood.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03077"
  },
  "2312.03057": {
    "title": "Advantage of Quantum Machine Learning from General Computational Advantages",
    "authors": [
      "Hayata Yamasaki",
      "Natsuto Isogai",
      "Mio Murao"
    ],
    "abstract": "An overarching milestone of quantum machine learning (QML) is to demonstrate the advantage of QML over all possible classical learning methods in accelerating a common type of learning task as represented by supervised learning with classical data. However, the provable advantages of QML in supervised learning have been known so far only for the learning tasks designed for using the advantage of specific quantum algorithms, i.e., Shor's algorithms. Here we explicitly construct an unprecedentedly broader family of supervised learning tasks with classical data to offer the provable advantage of QML based on general quantum computational advantages, progressing beyond Shor's algorithms. Our learning task is feasibly achievable by executing a general class of functions that can be computed efficiently in polynomial time for a large fraction of inputs by arbitrary quantum algorithms but not by any classical algorithm. We prove the hardness of achieving this learning task for any possible polynomial-time classical learning method. We also clarify protocols for preparing the classical data to demonstrate this learning task in experiments. These results open routes to exploit a variety of quantum advantages in computing functions for the experimental demonstration of the advantage of QML.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03057"
  },
  "2312.03053": {
    "title": "DiffusionPCR: Diffusion Models for Robust Multi-Step Point Cloud Registration",
    "authors": [
      "Zhi Chen",
      "Yufan Ren",
      "Tong Zhang",
      "Zheng Dang",
      "Wenbing Tao",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "abstract": "Point Cloud Registration (PCR) estimates the relative rigid transformation between two point clouds. We propose formulating PCR as a denoising diffusion probabilistic process, mapping noisy transformations to the ground truth. However, using diffusion models for PCR has nontrivial challenges, such as adapting a generative model to a discriminative task and leveraging the estimated nonlinear transformation from the previous step. Instead of training a diffusion model to directly map pure noise to ground truth, we map the predictions of an off-the-shelf PCR model to ground truth. The predictions of off-the-shelf models are often imperfect, especially in challenging cases where the two points clouds have low overlap, and thus could be seen as noisy versions of the real rigid transformation. In addition, we transform the rotation matrix into a spherical linear space for interpolation between samples in the forward process, and convert rigid transformations into auxiliary information to implicitly exploit last-step estimations in the reverse process. As a result, conditioned on time step, the denoising model adapts to the increasing accuracy across steps and refines registrations. Our extensive experiments showcase the effectiveness of our DiffusionPCR, yielding state-of-the-art registration recall rates (95.3%/81.6%) on 3DMatch and 3DLoMatch. The code will be made public upon publication.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03053"
  },
  "2312.03051": {
    "title": "Generating Interpretable Networks using Hypernetworks",
    "authors": [
      "Isaac Liao",
      "Ziming Liu",
      "Max Tegmark"
    ],
    "abstract": "An essential goal in mechanistic interpretability to decode a network, i.e., to convert a neural network's raw weights to an interpretable algorithm. Given the difficulty of the decoding problem, progress has been made to understand the easier encoding problem, i.e., to convert an interpretable algorithm into network weights. Previous works focus on encoding existing algorithms into networks, which are interpretable by definition. However, focusing on encoding limits the possibility of discovering new algorithms that humans have never stumbled upon, but that are nevertheless interpretable. In this work, we explore the possibility of using hypernetworks to generate interpretable networks whose underlying algorithms are not yet known. The hypernetwork is carefully designed such that it can control network complexity, leading to a diverse family of interpretable algorithms ranked by their complexity. All of them are interpretable in hindsight, although some of them are less intuitive to humans, hence providing new insights regarding how to \"think\" like a neural network. For the task of computing L1 norms, hypernetworks find three algorithms: (a) the double-sided algorithm, (b) the convexity algorithm, (c) the pudding algorithm, although only the first algorithm was expected by the authors before experiments. We automatically classify these algorithms and analyze how these algorithmic phases develop during training, as well as how they are affected by complexity control. Furthermore, we show that a trained hypernetwork can correctly construct models for input dimensions not seen in training, demonstrating systematic generalization.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03051"
  },
  "2312.03049": {
    "title": "Architectural Approaches to Overcome Challenges in the Development of Data-Intensive Systems",
    "authors": [
      "Aleksandar Dimov",
      "Simeon Emanuilov",
      "Boyan Bontchev",
      "Yavor Dankov",
      "Tasos Papapostolu"
    ],
    "abstract": "Orientation of modern software systems towards data-intensive processing raises new difficulties in software engineering on how to build and maintain such systems. Some of the important challenges concern the design of software architecture. In this article, we survey the fundamental challenges when designing data-intensive computing systems and present some of the most popular software architectural styles together with their potential to tackle these challenges.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03049"
  },
  "2312.03047": {
    "title": "MagicStick: Controllable Video Editing via Control Handle Transformations",
    "authors": [
      "Yue Ma",
      "Xiaodong Cun",
      "Yingqing He",
      "Chenyang Qi",
      "Xintao Wang",
      "Ying Shan",
      "Xiu Li",
      "Qifeng Chen"
    ],
    "abstract": "Text-based video editing has recently attracted considerable interest in changing the style or replacing the objects with a similar structure. Beyond this, we demonstrate that properties such as shape, size, location, motion, etc., can also be edited in videos. Our key insight is that the keyframe transformations of the specific internal feature (e.g., edge maps of objects or human pose), can easily propagate to other frames to provide generation guidance. We thus propose MagicStick, a controllable video editing method that edits the video properties by utilizing the transformation on the extracted internal control signals. In detail, to keep the appearance, we inflate both the pretrained image diffusion model and ControlNet to the temporal dimension and train low-rank adaptions (LORA) layers to fit the specific scenes. Then, in editing, we perform an inversion and editing framework. Differently, finetuned ControlNet is introduced in both inversion and generation for attention guidance with the proposed attention remix between the spatial attention maps of inversion and editing. Yet succinct, our method is the first method to show the ability of video property editing from the pre-trained text-to-image model. We present experiments on numerous examples within our unified framework. We also compare with shape-aware text-based editing and handcrafted motion video generation, demonstrating our superior temporal consistency and editing capability than previous works. The code and models will be made publicly available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03047"
  },
  "2312.03046": {
    "title": "Diversified in-domain synthesis with efficient fine-tuning for few-shot classification",
    "authors": [
      "Victor G. Turrisi da Costa",
      "Nicola Dall'Asen",
      "Yiming Wang",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "abstract": "Few-shot image classification aims to learn an image classifier using only a small set of labeled examples per class. A recent research direction for improving few-shot classifiers involves augmenting the labelled samples with synthetic images created by state-of-the-art text-to-image generation models. Following this trend, we propose Diversified In-domain Synthesis with Efficient Fine-tuning (DISEF), a novel approach which addresses the generalization challenge in few-shot learning using synthetic data. DISEF consists of two main components. First, we propose a novel text-to-image augmentation pipeline that, by leveraging the real samples and their rich semantics coming from an advanced captioning model, promotes in-domain sample diversity for better generalization. Second, we emphasize the importance of effective model fine-tuning in few-shot recognition, proposing to use Low-Rank Adaptation (LoRA) for joint adaptation of the text and image encoders in a Vision Language Model. We validate our method in ten different benchmarks, consistently outperforming baselines and establishing a new state-of-the-art for few-shot classification. Code is available at https://github.com/vturrisi/disef.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.03046"
  },
  "2312.03044": {
    "title": "REST: Enhancing Group Robustness in DNNs through Reweighted Sparse Training",
    "authors": [
      "Jiaxu Zhao",
      "Lu Yin",
      "Shiwei Liu",
      "Meng Fang",
      "Mykola Pechenizkiy"
    ],
    "abstract": "The deep neural network (DNN) has been proven effective in various domains. However, they often struggle to perform well on certain minority groups during inference, despite showing strong performance on the majority of data groups. This is because over-parameterized models learned \\textit{bias attributes} from a large number of \\textit{bias-aligned} training samples. These bias attributes are strongly spuriously correlated with the target variable, causing the models to be biased towards spurious correlations (i.e., \\textit{bias-conflicting}). To tackle this issue, we propose a novel \\textbf{re}weighted \\textbf{s}parse \\textbf{t}raining framework, dubbed as \\textit{\\textbf{REST}}, which aims to enhance the performance of biased data while improving computation and memory efficiency. Our proposed REST framework has been experimentally validated on three datasets, demonstrating its effectiveness in exploring unbiased subnetworks. We found that REST reduces the reliance on spuriously correlated features, leading to better performance across a wider range of data groups with fewer training and inference resources. We highlight that the \\textit{REST} framework represents a promising approach for improving the performance of DNNs on biased data, while simultaneously improving computation and memory efficiency. By reducing the reliance on spurious correlations, REST has the potential to enhance the robustness of DNNs and improve their generalization capabilities. Code is released at \\url{https://github.com/zhao1402072392/REST}\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.03044"
  },
  "2312.03043": {
    "title": "Navigating the Synthetic Realm: Harnessing Diffusion-based Models for Laparoscopic Text-to-Image Generation",
    "authors": [
      "Simeon Allmendinger",
      "Patrick Hemmer",
      "Moritz Queisner",
      "Igor Sauer",
      "Leopold M\u00fcller",
      "Johannes Jakubik",
      "Michael V\u00f6ssing",
      "Niklas K\u00fchl"
    ],
    "abstract": "Recent advances in synthetic imaging open up opportunities for obtaining additional data in the field of surgical imaging. This data can provide reliable supplements supporting surgical applications and decision-making through computer vision. Particularly the field of image-guided surgery, such as laparoscopic and robotic-assisted surgery, benefits strongly from synthetic image datasets and virtual surgical training methods. Our study presents an intuitive approach for generating synthetic laparoscopic images from short text prompts using diffusion-based generative models. We demonstrate the usage of state-of-the-art text-to-image architectures in the context of laparoscopic imaging with regard to the surgical removal of the gallbladder as an example. Results on fidelity and diversity demonstrate that diffusion-based models can acquire knowledge about the style and semantics in the field of image-guided surgery. A validation study with a human assessment survey underlines the realistic nature of our synthetic data, as medical personnel detects actual images in a pool with generated images causing a false-positive rate of 66%. In addition, the investigation of a state-of-the-art machine learning model to recognize surgical actions indicates enhanced results when trained with additional generated images of up to 5.20%. Overall, the achieved image quality contributes to the usage of computer-generated images in surgical applications and enhances its path to maturity.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03043"
  },
  "2312.03042": {
    "title": "Inherent limitations of LLMs regarding spatial information",
    "authors": [
      "He Yan",
      "Xinyao Hu",
      "Xiangpeng Wan",
      "Chengyu Huang",
      "Kai Zou",
      "Shiqi Xu"
    ],
    "abstract": "Despite the significant advancements in natural language processing capabilities demonstrated by large language models such as ChatGPT, their proficiency in comprehending and processing spatial information, especially within the domains of 2D and 3D route planning, remains notably underdeveloped. This paper investigates the inherent limitations of ChatGPT and similar models in spatial reasoning and navigation-related tasks, an area critical for applications ranging from autonomous vehicle guidance to assistive technologies for the visually impaired. In this paper, we introduce a novel evaluation framework complemented by a baseline dataset, meticulously crafted for this study. This dataset is structured around three key tasks: plotting spatial points, planning routes in two-dimensional (2D) spaces, and devising pathways in three-dimensional (3D) environments. We specifically developed this dataset to assess the spatial reasoning abilities of ChatGPT. Our evaluation reveals key insights into the model's capabilities and limitations in spatial understanding.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03042"
  },
  "2312.03038": {
    "title": "Sample-based Dynamic Hierarchical Transformer with Layer and Head Flexibility via Contextual Bandit",
    "authors": [
      "Fanfei Meng",
      "Lele Zhang",
      "Yu Chen",
      "Yuxin Wang"
    ],
    "abstract": "Transformer requires a fixed number of layers and heads which makes them inflexible to the complexity of individual samples and expensive in training and inference. To address this, we propose a sample-based Dynamic Hierarchical Transformer (DHT) model whose layers and heads can be dynamically configured with single data samples via solving contextual bandit problems. To determine the number of layers and heads, we use the Uniform Confidence Bound while we deploy combinatorial Thompson Sampling in order to select specific head combinations given their number. Different from previous work that focuses on compressing trained networks for inference only, DHT is not only advantageous for adaptively optimizing the underlying network architecture during training but also has a flexible network for efficient inference. To the best of our knowledge, this is the first comprehensive data-driven dynamic transformer without any additional auxiliary neural networks that implement the dynamic system. According to the experiment results, we achieve up to 74% computational savings for both training and inference with a minimal loss of accuracy.\n        \u25b3 Less",
    "submission_date": "10 January, 2024",
    "eprint_id": "2312.03038"
  },
  "2312.03037": {
    "title": "Analysis and mining of low-carbon and energy-saving tourism data characteristics based on machine learning algorithm",
    "authors": [
      "Lukasz Wierzbinski"
    ],
    "abstract": "In order to study the formation mechanism of residents' low-carbon awareness and provide an important basis for traffic managers to guide urban residents to choose low-carbon travel mode, this paper proposes a low-carbon energy-saving travel data feature analysis and mining based on machine learning algorithm. This paper uses data mining technology to analyze the data of low-carbon travel questionnaire, and regards the 15-dimensional problem under the framework of planned behavior theory as the internal cause variable that characterizes residents' low-carbon travel willingness. The author uses K-means clustering algorithm to classify the intensity of residents' low-carbon travel willingness, and applies the results as the explanatory variables to the random forest model to explore the mechanism of residents' social attribute characteristics, travel characteristics, etc. on their low-carbon travel willingness. The experimental results show that based on the Silhouette index test and t-SNE dimensionality reduction, residents' low-carbon travel willingness can be divided into three categories: strong, neutral, and not strong; Based on the importance index, the four most significant factors are the occupation, residence, family composition and commuting time of residents. Conclusion: This method provides policy recommendations for the development and management of urban traffic low-carbon from multiple perspectives.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03037"
  },
  "2312.03035": {
    "title": "SEVA: Leveraging sketches to evaluate alignment between human and machine visual abstraction",
    "authors": [
      "Kushin Mukherjee",
      "Holly Huey",
      "Xuanchen Lu",
      "Yael Vinker",
      "Rio Aguina-Kang",
      "Ariel Shamir",
      "Judith E. Fan"
    ],
    "abstract": "Sketching is a powerful tool for creating abstract images that are sparse but meaningful. Sketch understanding poses fundamental challenges for general-purpose vision algorithms because it requires robustness to the sparsity of sketches relative to natural visual inputs and because it demands tolerance for semantic ambiguity, as sketches can reliably evoke multiple meanings. While current vision algorithms have achieved high performance on a variety of visual tasks, it remains unclear to what extent they understand sketches in a human-like way. Here we introduce SEVA, a new benchmark dataset containing approximately 90K human-generated sketches of 128 object concepts produced under different time constraints, and thus systematically varying in sparsity. We evaluated a suite of state-of-the-art vision algorithms on their ability to correctly identify the target concept depicted in these sketches and to generate responses that are strongly aligned with human response patterns on the same sketch recognition task. We found that vision algorithms that better predicted human sketch recognition performance also better approximated human uncertainty about sketch meaning, but there remains a sizable gap between model and human response patterns. To explore the potential of models that emulate human visual abstraction in generative tasks, we conducted further evaluations of a recently developed sketch generation algorithm (Vinker et al., 2022) capable of generating sketches that vary in sparsity. We hope that public release of this dataset and evaluation protocol will catalyze progress towards algorithms with enhanced capacities for human-like visual abstraction.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03035"
  },
  "2312.03034": {
    "title": "Distributed Speech Dereverberation Using Weighted Prediction Error",
    "authors": [
      "Ziye Yang",
      "Mengfei Zhang",
      "Jie Chen"
    ],
    "abstract": "Speech dereverberation aims to alleviate the negative impact of late reverberant reflections. The weighted prediction error (WPE) method is a well-established technique known for its superior performance in dereverberation. However, in scenarios where microphone nodes are dispersed, the centralized approach of the WPE method requires aggregating all observations for inverse filtering, resulting in a significant computational burden. This paper introduces a distributed speech dereverberation method that emphasizes low computational complexity at each node. Specifically, we leverage the distributed adaptive node-specific signal estimation (DANSE) algorithm within the multichannel linear prediction (MCLP) process. This approach empowers each node to perform local operations with reduced complexity while achieving the global performance through inter-node cooperation. Experimental results validate the effectiveness of our proposed method, showcasing its ability to achieve efficient speech dereverberation in dispersed microphone node scenarios.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03034"
  },
  "2312.03033": {
    "title": "LiDAR-based Person Re-identification",
    "authors": [
      "Wenxuan Guo",
      "Zhiyu Pan",
      "Yingping Liang",
      "Ziheng Xi",
      "Zhi Chen Zhong",
      "Jianjiang Feng",
      "Jie Zhou"
    ],
    "abstract": "Camera-based person re-identification (ReID) systems have been widely applied in the field of public security. However, cameras often lack the perception of 3D morphological information of human and are susceptible to various limitations, such as inadequate illumination, complex background, and personal privacy. In this paper, we propose a LiDAR-based ReID framework, ReID3D, that utilizes pre-training strategy to retrieve features of 3D body shape and introduces Graph-based Complementary Enhancement Encoder for extracting comprehensive features. Due to the lack of LiDAR datasets, we build LReID, the first LiDAR-based person ReID dataset, which is collected in several outdoor scenes with variations in natural conditions. Additionally, we introduce LReID-sync, a simulated pedestrian dataset designed for pre-training encoders with tasks of point cloud completion and shape parameter learning. Extensive experiments on LReID show that ReID3D achieves exceptional performance with a rank-1 accuracy of 94.0, highlighting the significant potential of LiDAR in addressing person ReID tasks. To the best of our knowledge, we are the first to propose a solution for LiDAR-based ReID. The code and datasets will be released soon.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.03033"
  },
  "2312.03032": {
    "title": "Zero-Shot Point Cloud Registration",
    "authors": [
      "Weijie Wang",
      "Guofeng Mei",
      "Bin Ren",
      "Xiaoshui Huang",
      "Fabio Poiesi",
      "Luc Van Gool",
      "Nicu Sebe",
      "Bruno Lepri"
    ],
    "abstract": "Learning-based point cloud registration approaches have significantly outperformed their traditional counterparts. However, they typically require extensive training on specific datasets. In this paper, we propose , the first zero-shot point cloud registration approach that eliminates the need for training on point cloud datasets. The cornerstone of ZeroReg is the novel transfer of image features from keypoints to the point cloud, enriched by aggregating information from 3D geometric neighborhoods. Specifically, we extract keypoints and features from 2D image pairs using a frozen pretrained 2D backbone. These features are then projected in 3D, and patches are constructed by searching for neighboring points. We integrate the geometric and visual features of each point using our novel parameter-free geometric decoder. Subsequently, the task of determining correspondences between point clouds is formulated as an optimal transport problem. Extensive evaluations of ZeroReg demonstrate its competitive performance against both traditional and learning-based methods. On benchmarks such as 3DMatch, 3DLoMatch, and ScanNet, ZeroReg achieves impressive Recall Ratios (RR) of over 84%, 46%, and 75%, respectively.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.03032"
  },
  "2312.03030": {
    "title": "Generating Visually Realistic Adversarial Patch",
    "authors": [
      "Xiaosen Wang",
      "Kunyu Wang"
    ],
    "abstract": "Deep neural networks (DNNs) are vulnerable to various types of adversarial examples, bringing huge threats to security-critical applications. Among these, adversarial patches have drawn increasing attention due to their good applicability to fool DNNs in the physical world. However, existing works often generate patches with meaningless noise or patterns, making it conspicuous to humans. To address this issue, we explore how to generate visually realistic adversarial patches to fool DNNs. Firstly, we analyze that a high-quality adversarial patch should be realistic, position irrelevant, and printable to be deployed in the physical world. Based on this analysis, we propose an effective attack called VRAP, to generate visually realistic adversarial patches. Specifically, VRAP constrains the patch in the neighborhood of a real image to ensure the visual reality, optimizes the patch at the poorest position for position irrelevance, and adopts Total Variance loss as well as gamma transformation to make the generated patch printable without losing information. Empirical evaluations on the ImageNet dataset demonstrate that the proposed VRAP exhibits outstanding attack performance in the digital world. Moreover, the generated adversarial patches can be disguised as the scrawl or logo in the physical world to fool the deep models without being detected, bringing significant threats to DNNs-enabled applications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03030"
  },
  "2312.03028": {
    "title": "Double Integral Enhanced Zeroing Neural Network Optimized with ALSOA fostered Lung Cancer Classification using CT Images",
    "authors": [
      "V S Priya Sumitha",
      "V. Keerthika",
      "A. Geetha"
    ],
    "abstract": "Lung cancer is one of the deadliest diseases and the leading cause of illness and death. Since lung cancer cannot predicted at premature stage, it able to only be discovered more broadly once it has spread to other lung parts. The risk grows when radiologists and other specialists determine whether lung cancer is current. Owing to significance of determining type of treatment and its depth based on severity of the illness, critical to develop smart and automatic cancer prediction scheme is precise, at which stage of cancer. In this paper, Double Integral Enhanced Zeroing Neural Network Optimized with ALSOA fostered Lung Cancer Classification using CT Images (LCC-DIEZNN-ALSO-CTI) is proposed. Initially, input CT image is amassed from lung cancer dataset. The input CT image is pre-processing via Unscented Trainable Kalman Filtering (UTKF) technique. In pre-processing stage unwanted noise are removed from CT images. Afterwards, grayscale statistic features and Haralick texture features extracted by Adaptive and Concise Empirical Wavelet Transform (ACEWT). The proposed model is implemented on MATLAB. The performance of the proposed method is analyzed through existing techniques. The proposed method attains 18.32%, 27.20%, and 34.32% higher accuracy analyzed with existing method likes Deep Learning Assisted Predict of Lung Cancer on Computed Tomography Images Utilizing AHHMM (LCC-AHHMM-CT), Convolutional neural networks based pulmonary nodule malignancy assessment in pipeline for classifying lung cancer (LCC-ICNN-CT), Automated Decision Support Scheme for Lung Cancer Identification with Categorization (LCC-RFCN-MLRPN-CT) methods respectively.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03028"
  },
  "2312.03026": {
    "title": "Uni3DL: Unified Model for 3D and Language Understanding",
    "authors": [
      "Xiang Li",
      "Jian Ding",
      "Zhaoyang Chen",
      "Mohamed Elhoseiny"
    ],
    "abstract": "In this work, we present Uni3DL, a unified model for 3D and Language understanding. Distinct from existing unified vision-language models in 3D which are limited in task variety and predominantly dependent on projected multi-view images, Uni3DL operates directly on point clouds. This approach significantly expands the range of supported tasks in 3D, encompassing both vision and vision-language tasks in 3D. At the core of Uni3DL, a query transformer is designed to learn task-agnostic semantic and mask outputs by attending to 3D visual features, and a task router is employed to selectively generate task-specific outputs required for diverse tasks. With a unified architecture, our Uni3DL model enjoys seamless task decomposition and substantial parameter sharing across tasks. Uni3DL has been rigorously evaluated across diverse 3D vision-language understanding tasks, including semantic segmentation, object detection, instance segmentation, visual grounding, 3D captioning, and text-3D cross-modal retrieval. It demonstrates performance on par with or surpassing state-of-the-art (SOTA) task-specific models. We hope our benchmark and Uni3DL model will serve as a solid step to ease future research in unified models in the realm of 3D and language understanding. Project page: https://uni3dl.github.io.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03026"
  },
  "2312.03025": {
    "title": "Training on Synthetic Data Beats Real Data in Multimodal Relation Extraction",
    "authors": [
      "Zilin Du",
      "Haoxin Li",
      "Xu Guo",
      "Boyang Li"
    ],
    "abstract": "The task of multimodal relation extraction has attracted significant research attention, but progress is constrained by the scarcity of available training data. One natural thought is to extend existing datasets with cross-modal generative models. In this paper, we consider a novel problem setting, where only unimodal data, either text or image, are available during training. We aim to train a multimodal classifier from synthetic data that perform well on real multimodal test data. However, training with synthetic data suffers from two obstacles: lack of data diversity and label information loss. To alleviate the issues, we propose Mutual Information-aware Multimodal Iterated Relational dAta GEneration (MI2RAGE), which applies Chained Cross-modal Generation (CCG) to promote diversity in the generated data and exploits a teacher network to select valuable training samples with high mutual information with the ground-truth labels. Comparing our method to direct training on synthetic data, we observed a significant improvement of 24.06% F1 with synthetic text and 26.42% F1 with synthetic images. Notably, our best model trained on completely synthetic images outperforms prior state-of-the-art models trained on real multimodal data by a margin of 3.76% in F1. Our codebase will be made available upon acceptance.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03025"
  },
  "2312.03024": {
    "title": "Role of Uncertainty in Anticipatory Trajectory Prediction for a Ping-Pong Playing Robot",
    "authors": [
      "Nima Rahmanian",
      "Michael Gupta",
      "Renzo Soatto",
      "Srisai Nachuri",
      "Michael Psenka",
      "Yi Ma",
      "S. Shankar Sastry"
    ],
    "abstract": "Robotic interaction in fast-paced environments presents a substantial challenge, particularly in tasks requiring the prediction of dynamic, non-stationary objects for timely and accurate responses. An example of such a task is ping-pong, where the physical limitations of a robot may prevent it from reaching its goal in the time it takes the ball to cross the table. The scene of a ping-pong match contains rich visual information of a player's movement that can allow future game state prediction, with varying degrees of uncertainty. To this aim, we present a visual modeling, prediction, and control system to inform a ping-pong playing robot utilizing visual model uncertainty to allow earlier motion of the robot throughout the game. We present demonstrations and metrics in simulation to show the benefit of incorporating model uncertainty, the limitations of current standard model uncertainty estimators, and the need for more verifiable model uncertainty estimation. Our code is publicly available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03024"
  },
  "2312.03022": {
    "title": "Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction",
    "authors": [
      "Hongbin Ye",
      "Honghao Gui",
      "Aijia Zhang",
      "Tong Liu",
      "Wei Hua",
      "Weiqiang Jia"
    ],
    "abstract": "Knowledge graph construction (KGC) is a multifaceted undertaking involving the extraction of entities, relations, and events. Traditionally, large language models (LLMs) have been viewed as solitary task-solving agents in this complex landscape. However, this paper challenges this paradigm by introducing a novel framework, CooperKGC. Departing from the conventional approach, CooperKGC establishes a collaborative processing network, assembling a KGC collaboration team capable of concurrently addressing entity, relation, and event extraction tasks. Our experiments unequivocally demonstrate that fostering collaboration and information interaction among diverse agents within CooperKGC yields superior results compared to individual cognitive processes operating in isolation. Importantly, our findings reveal that the collaboration facilitated by CooperKGC enhances knowledge selection, correction, and aggregation capabilities across multiple rounds of interactions.\n        \u25b3 Less",
    "submission_date": "29 December, 2023",
    "eprint_id": "2312.03022"
  },
  "2312.03020": {
    "title": "Enhanced Breast Cancer Tumor Classification using MobileNetV2: A Detailed Exploration on Image Intensity, Error Mitigation, and Streamlit-driven Real-time Deployment",
    "authors": [
      "Aaditya Surya",
      "Aditya Shah",
      "Jarnell Kabore",
      "Subash Sasikumar"
    ],
    "abstract": "This research introduces a sophisticated transfer learning model based on Google's MobileNetV2 for breast cancer tumor classification into normal, benign, and malignant categories, utilizing a dataset of 1576 ultrasound images (265 normal, 891 benign, 420 malignant). The model achieves an accuracy of 0.82, precision of 0.83, recall of 0.81, ROC-AUC of 0.94, PR-AUC of 0.88, and MCC of 0.74. It examines image intensity distributions and misclassification errors, offering improvements for future applications. Addressing dataset imbalances, the study ensures a generalizable model. This work, using a dataset from Baheya Hospital, Cairo, Egypt, compiled by Walid Al-Dhabyani et al., emphasizes MobileNetV2's potential in medical imaging, aiming to improve diagnostic precision in oncology. Additionally, the paper explores Streamlit-based deployment for real-time tumor classification, demonstrating MobileNetV2's applicability in medical imaging and setting a benchmark for future research in oncology diagnostics.\n        \u25b3 Less",
    "submission_date": "6 January, 2024",
    "eprint_id": "2312.03020"
  },
  "2312.03019": {
    "title": "Towards Optimizations of Quantum Circuit Simulation for Solving Max-Cut Problems with QAOA",
    "authors": [
      "Yu-Cheng Lin",
      "Chuan-Chi Wang",
      "Chia-Heng Tu",
      "Shih-Hao Hung"
    ],
    "abstract": "Quantum approximate optimization algorithm (QAOA) is one of the popular quantum algorithms that are used to solve combinatorial optimization problems via approximations. QAOA is able to be evaluated on both physical and virtual quantum computers simulated by classical computers, with virtual ones being favored for their noise-free feature and availability. Nevertheless, performing QAOA on virtual quantum computers suffers from a slow simulation speed for solving combinatorial optimization problems which require large-scale quantum circuit simulation (QCS). In this paper, we propose techniques to accelerate QCS for QAOA using mathematical optimizations to compress quantum operations, incorporating efficient bitwise operations to further lower the computational complexity, and leveraging different levels of parallelisms from modern multi-core processors, with a study case to show the effectiveness on solving max-cut problems.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.03019"
  },
  "2312.03017": {
    "title": "AI-driven emergence of frequency information non-uniform distribution via THz metasurface spectrum prediction",
    "authors": [
      "Xiaohua Xing",
      "Yuqi Ren",
      "Die Zou",
      "Qiankun Zhang",
      "Bingxuan Mao",
      "Jianquan Yao",
      "Deyi Xiong",
      "Shuang Zhang",
      "Liang Wu"
    ],
    "abstract": "Recently, artificial intelligence has been extensively deployed across various scientific disciplines, optimizing and guiding the progression of experiments through the integration of abundant datasets, whilst continuously probing the vast theoretical space encapsulated within the data. Particularly, deep learning models, due to their end-to-end adaptive learning capabilities, are capable of autonomously learning intrinsic data features, thereby transcending the limitations of traditional experience to a certain extent. Here, we unveil previously unreported information characteristics pertaining to different frequencies emerged during our work on predicting the terahertz spectral modulation effects of metasurfaces based on AI-prediction. Moreover, we have substantiated that our proposed methodology of simply adding supplementary multi-frequency inputs to the existing dataset during the target spectral prediction process can significantly enhance the predictive accuracy of the network. This approach effectively optimizes the utilization of existing datasets and paves the way for interdisciplinary research and applications in artificial intelligence, chemistry, composite material design, biomedicine, and other fields.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03017"
  },
  "2312.03016": {
    "title": "Protein Language Model-Powered 3D Ligand Binding Site Prediction from Protein Sequence",
    "authors": [
      "Shuo Zhang",
      "Lei Xie"
    ],
    "abstract": "Prediction of ligand binding sites of proteins is a fundamental and important task for understanding the function of proteins and screening potential drugs. Most existing methods require experimentally determined protein holo-structures as input. However, such structures can be unavailable on novel or less-studied proteins. To tackle this limitation, we propose LaMPSite, which only takes protein sequences and ligand molecular graphs as input for ligand binding site predictions. The protein sequences are used to retrieve residue-level embeddings and contact maps from the pre-trained ESM-2 protein language model. The ligand molecular graphs are fed into a graph neural network to compute atom-level embeddings. Then we compute and update the protein-ligand interaction embedding based on the protein residue-level embeddings and ligand atom-level embeddings, and the geometric constraints in the inferred protein contact map and ligand distance map. A final pooling on protein-ligand interaction embedding would indicate which residues belong to the binding sites. Without any 3D coordinate information of proteins, our proposed model achieves competitive performance compared to baseline methods that require 3D protein structures when predicting binding sites. Given that less than 50% of proteins have reliable structure information in the current stage, LaMPSite will provide new opportunities for drug discovery.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03016"
  },
  "2312.03015": {
    "title": "PartSLIP++: Enhancing Low-Shot 3D Part Segmentation via Multi-View Instance Segmentation and Maximum Likelihood Estimation",
    "authors": [
      "Yuchen Zhou",
      "Jiayuan Gu",
      "Xuanlin Li",
      "Minghua Liu",
      "Yunhao Fang",
      "Hao Su"
    ],
    "abstract": "Open-world 3D part segmentation is pivotal in diverse applications such as robotics and AR/VR. Traditional supervised methods often grapple with limited 3D data availability and struggle to generalize to unseen object categories. PartSLIP, a recent advancement, has made significant strides in zero- and few-shot 3D part segmentation. This is achieved by harnessing the capabilities of the 2D open-vocabulary detection module, GLIP, and introducing a heuristic method for converting and lifting multi-view 2D bounding box predictions into 3D segmentation masks. In this paper, we introduce PartSLIP++, an enhanced version designed to overcome the limitations of its predecessor. Our approach incorporates two major improvements. First, we utilize a pre-trained 2D segmentation model, SAM, to produce pixel-wise 2D segmentations, yielding more precise and accurate annotations than the 2D bounding boxes used in PartSLIP. Second, PartSLIP++ replaces the heuristic 3D conversion process with an innovative modified Expectation-Maximization algorithm. This algorithm conceptualizes 3D instance segmentation as unobserved latent variables, and then iteratively refines them through an alternating process of 2D-3D matching and optimization with gradient descent. Through extensive evaluations, we show that PartSLIP++ demonstrates better performance over PartSLIP in both low-shot 3D semantic and instance-based object part segmentation tasks. Code released at https://github.com/zyc00/PartSLIP2.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03015"
  },
  "2312.03014": {
    "title": "Foundation Models for Weather and Climate Data Understanding: A Comprehensive Survey",
    "authors": [
      "Shengchao Chen",
      "Guodong Long",
      "Jing Jiang",
      "Dikai Liu",
      "Chengqi Zhang"
    ],
    "abstract": "As artificial intelligence (AI) continues to rapidly evolve, the realm of Earth and atmospheric sciences is increasingly adopting data-driven models, powered by progressive developments in deep learning (DL). Specifically, DL techniques are extensively utilized to decode the chaotic and nonlinear aspects of Earth systems, and to address climate challenges via understanding weather and climate data. Cutting-edge performance on specific tasks within narrower spatio-temporal scales has been achieved recently through DL. The rise of large models, specifically large language models (LLMs), has enabled fine-tuning processes that yield remarkable outcomes across various downstream tasks, thereby propelling the advancement of general AI. However, we are still navigating the initial stages of crafting general AI for weather and climate. In this survey, we offer an exhaustive, timely overview of state-of-the-art AI methodologies specifically engineered for weather and climate data, with a special focus on time series and text data. Our primary coverage encompasses four critical aspects: types of weather and climate data, principal model architectures, model scopes and applications, and datasets for weather and climate. Furthermore, in relation to the creation and application of foundation models for weather and climate data understanding, we delve into the field's prevailing challenges, offer crucial insights, and propose detailed avenues for future research. This comprehensive approach equips practitioners with the requisite knowledge to make substantial progress in this domain. Our survey encapsulates the most recent breakthroughs in research on large, data-driven models for weather and climate data understanding, emphasizing robust foundations, current advancements, practical applications, crucial resources, and prospective research opportunities.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03014"
  },
  "2312.03013": {
    "title": "Breast Ultrasound Report Generation using LangChain",
    "authors": [
      "Jaeyoung Huh",
      "Hyun Jeong Park",
      "Jong Chul Ye"
    ],
    "abstract": "Breast ultrasound (BUS) is a critical diagnostic tool in the field of breast imaging, aiding in the early detection and characterization of breast abnormalities. Interpreting breast ultrasound images commonly involves creating comprehensive medical reports, containing vital information to promptly assess the patient's condition. However, the ultrasound imaging system necessitates capturing multiple images of various parts to compile a single report, presenting a time-consuming challenge. To address this problem, we propose the integration of multiple image analysis tools through a LangChain using Large Language Models (LLM), into the breast reporting process. Through a combination of designated tools and text generation through LangChain, our method can accurately extract relevant features from ultrasound images, interpret them in a clinical context, and produce comprehensive and standardized reports. This approach not only reduces the burden on radiologists and healthcare professionals but also enhances the consistency and quality of reports. The extensive experiments shows that each tools involved in the proposed method can offer qualitatively and quantitatively significant results. Furthermore, clinical evaluation on the generated reports demonstrates that the proposed method can make report in clinically meaningful way.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03013"
  },
  "2312.03012": {
    "title": "A Waddington landscape for prototype learning in generalized Hopfield networks",
    "authors": [
      "Nacer Eddine Boukacem",
      "Allen Leary",
      "Robin Th\u00e9riault",
      "Felix Gottlieb",
      "Madhav Mani",
      "Paul Fran\u00e7ois"
    ],
    "abstract": "Networks in machine learning offer examples of complex high-dimensional dynamical systems reminiscent of biological systems. Here, we study the learning dynamics of Generalized Hopfield networks, which permit a visualization of internal memories. These networks have been shown to proceed through a 'feature-to-prototype' transition, as the strength of network nonlinearity is increased, wherein the learned, or terminal, states of internal memories transition from mixed to pure states. Focusing on the prototype learning dynamics of the internal memories we observe a strong resemblance to the canalized, or low-dimensional, dynamics of cells as they differentiate within a Waddingtonian landscape. Dynamically, we demonstrate that learning in a Generalized Hopfield Network proceeds through sequential 'splits' in memory space. Furthermore, order of splitting is interpretable and reproducible. The dynamics between the splits are canalized in the Waddington sense -- robust to variations in detailed aspects of the system. In attempting to make the analogy a rigorous equivalence, we study smaller subsystems that exhibit similar properties to the full system. We combine analytical calculations with numerical simulations to study the dynamical emergence of the feature-to-prototype transition, and the behaviour of splits in the landscape, saddles points, visited during learning. We exhibit regimes where saddles appear and disappear through saddle-node bifurcations, qualitatively changing the distribution of learned memories as the strength of the nonlinearity is varied -- allowing us to systematically investigate the mechanisms that underlie the emergence of Waddingtonian dynamics. Memories can thus differentiate in a predictive and controlled way, revealing new bridges between experimental biology, dynamical systems theory, and machine learning.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03012"
  },
  "2312.03008": {
    "title": "Deep Reinforcement Learning for Community Battery Scheduling under Uncertainties of Load, PV Generation, and Energy Prices",
    "authors": [
      "Jiarong Fan",
      "Hao Wang"
    ],
    "abstract": "In response to the growing uptake of distributed energy resources (DERs), community batteries have emerged as a promising solution to support renewable energy integration, reduce peak load, and enhance grid reliability. This paper presents a deep reinforcement learning (RL) strategy, centered around the soft actor-critic (SAC) algorithm, to schedule a community battery system in the presence of uncertainties, such as solar photovoltaic (PV) generation, local demand, and real-time energy prices. We position the community battery to play a versatile role, in integrating local PV energy, reducing peak load, and exploiting energy price fluctuations for arbitrage, thereby minimizing the system cost. To improve exploration and convergence during RL training, we utilize the noisy network technique. This paper conducts a comparative study of different RL algorithms, including proximal policy optimization (PPO) and deep deterministic policy gradient (DDPG) algorithms, to evaluate their effectiveness in the community battery scheduling problem. The results demonstrate the potential of RL in addressing community battery scheduling challenges and show that the SAC algorithm achieves the best performance compared to RL and optimization benchmarks.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03008"
  },
  "2312.03006": {
    "title": "Multi-Weight Ranking for Multi-Criteria Decision Making",
    "authors": [
      "Andreas H Hamel",
      "Daniel Kostner"
    ],
    "abstract": "Cone distribution functions from statistics are turned into Multi-Criteria Decision Making tools. It is demonstrated that this procedure can be considered as an upgrade of the weighted sum scalarization insofar as it absorbs a whole collection of weighted sum scalarizations at once instead of fixing a particular one in advance. As examples show, this type of scalarization--in contrast to a pure weighted sum scalarization-is also able to detect ``non-convex\" parts of the Pareto frontier. Situations are characterized in which different types of rank reversal occur, and it is explained why this might even be useful for analyzing the ranking procedure. The ranking functions are then extended to sets providing unary indicators for set preferences which establishes, for the first time, the link between set optimization methods and set-based multi-objective optimization. A potential application in machine learning is outlined.\n        \u25b3 Less",
    "submission_date": "14 January, 2024",
    "eprint_id": "2312.03006"
  },
  "2312.03005": {
    "title": "Few-Shot Anomaly Detection with Adversarial Loss for Robust Feature Representations",
    "authors": [
      "Jae Young Lee",
      "Wonjun Lee",
      "Jaehyun Choi",
      "Yongkwi Lee",
      "Young Seog Yoon"
    ],
    "abstract": "Anomaly detection is a critical and challenging task that aims to identify data points deviating from normal patterns and distributions within a dataset. Various methods have been proposed using a one-class-one-model approach, but these techniques often face practical problems such as memory inefficiency and the requirement of sufficient data for training. In particular, few-shot anomaly detection presents significant challenges in industrial applications, where limited samples are available before mass production. In this paper, we propose a few-shot anomaly detection method that integrates adversarial training loss to obtain more robust and generalized feature representations. We utilize the adversarial loss previously employed in domain adaptation to align feature distributions between source and target domains, to enhance feature robustness and generalization in few-shot anomaly detection tasks. We hypothesize that adversarial loss is effective when applied to features that should have similar characteristics, such as those from the same layer in a Siamese network's parallel branches or input-output pairs of reconstruction-based methods. Experimental results demonstrate that the proposed method generally achieves better performance when utilizing the adversarial loss.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.03005"
  },
  "2312.03002": {
    "title": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task",
    "authors": [
      "Gautam Reddy"
    ],
    "abstract": "Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence. In-context learning contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.03002"
  },
  "2312.03000": {
    "title": "VidereX: A Navigational Application inspired by ants",
    "authors": [
      "Nam Ho Koh",
      "Doran Amos",
      "Paul Graham",
      "Andrew Philippides"
    ],
    "abstract": "Navigation is a crucial element in any person's life, whether for work, education, social living or any other miscellaneous reason; naturally, the importance of it is universally recognised and valued. One of the critical components of navigation is vision, which facilitates movement from one place to another. Navigating unfamiliar settings, especially for the blind or visually impaired, can pose significant challenges, impacting their independence and quality of life. Current assistive travel solutions have shortcomings, including GPS limitations and a demand for an efficient, user-friendly, and portable model. Addressing these concerns, this paper presents VidereX: a smartphone-based solution using an ant-inspired navigation algorithm. Emulating ants' ability to learn a route between nest and feeding grounds after a single traversal, VidereX enables users to rapidly acquire navigational data using a one/few-shot learning strategy. A key component of VidereX is its emphasis on active user engagement. Like ants with a scanning behaviour to actively investigate their environment, users wield the camera, actively exploring the visual landscape. Far from the passive reception of data, this process constitutes a dynamic exploration, echoing nature's navigational mechanisms.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.03000"
  },
  "2312.02999": {
    "title": "Efficient Incremental Potential Contact for Actuated Face Simulation",
    "authors": [
      "Bo Li",
      "Lingchen Yang",
      "Barbara Solenthaler"
    ],
    "abstract": "We present a quasi-static finite element simulator for human face animation. We model the face as an actuated soft body, which can be efficiently simulated using Projective Dynamics (PD). We adopt Incremental Potential Contact (IPC) to handle self-intersection. However, directly integrating IPC into the simulation would impede the high efficiency of the PD solver, since the stiffness matrix in the global step is no longer constant and cannot be pre-factorized. We notice that the actual number of vertices affected by the collision is only a small fraction of the whole model, and by utilizing this fact we effectively decrease the scale of the linear system to be solved. With the proposed optimization method for collision, we achieve high visual fidelity at a relatively low performance overhead.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02999"
  },
  "2312.02998": {
    "title": "Personality of AI",
    "authors": [
      "Byunggu Yu",
      "Junwhan Kim"
    ],
    "abstract": "This research paper delves into the evolving landscape of fine-tuning large language models (LLMs) to align with human users, extending beyond basic alignment to propose \"personality alignment\" for language models in organizational settings. Acknowledging the impact of training methods on the formation of undefined personality traits in AI models, the study draws parallels with human fitting processes using personality tests. Through an original case study, we demonstrate the necessity of personality fine-tuning for AIs and raise intriguing questions about applying human-designed tests to AIs, engineering specialized AI personality tests, and shaping AI personalities to suit organizational roles. The paper serves as a starting point for discussions and developments in the burgeoning field of AI personality alignment, offering a foundational anchor for future exploration in human-machine teaming and co-existence.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02998"
  },
  "2312.02997": {
    "title": "Simulation-Based Inference of Surface Accumulation and Basal Melt Rates of an Antarctic Ice Shelf from Isochronal Layers",
    "authors": [
      "Guy Moss",
      "Vjeran Vi\u0161njevi\u0107",
      "Olaf Eisen",
      "Falk M. Oraschewski",
      "Cornelius Schr\u00f6der",
      "Jakob H. Macke",
      "Reinhard Drews"
    ],
    "abstract": "The ice shelves buttressing the Antarctic ice sheet determine the rate of ice-discharge into the surrounding oceans. The geometry of ice shelves, and hence their buttressing strength, is determined by ice flow as well as by the local surface accumulation and basal melt rates, governed by atmospheric and oceanic conditions. Contemporary methods resolve one of these rates, but typically not both. Moreover, there is little information of how they changed in time. We present a new method to simultaneously infer the surface accumulation and basal melt rates averaged over decadal and centennial timescales. We infer the spatial dependence of these rates along flow line transects using internal stratigraphy observed by radars, using a kinematic forward model of internal stratigraphy. We solve the inverse problem using simulation-based inference (SBI). SBI performs Bayesian inference by training neural networks on simulations of the forward model to approximate the posterior distribution, allowing us to also quantify uncertainties over the inferred parameters. We demonstrate the validity of our method on a synthetic example, and apply it to Ekstr\u00f6m Ice Shelf, Antarctica, for which newly acquired radar measurements are available. We obtain posterior distributions of surface accumulation and basal melt averaging over 42, 84, 146, and 188 years before 2022. Our results suggest stable atmospheric and oceanographic conditions over this period in this catchment of Antarctica. Use of observed internal stratigraphy can separate the effects of surface accumulation and basal melt, allowing them to be interpreted in a historical context of the last centuries and beyond.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02997"
  },
  "2312.02996": {
    "title": "A Relation Algebra for Term Rewriting: A differential approach to sequential reduction (Revised Version)",
    "authors": [
      "Lorenzo Pace"
    ],
    "abstract": "Recently, Gavazzo has developed a relational theory of symbolic manipulation, that allows to study syntax-based rewriting systems without relying on specific notions of syntax. This theory was obtained by extending the algebra of relations with syntax-inspired operators. Within the algebras thus obtained, it is possible to encode notions of parallel and full reduction for first-order rewriting systems, as well as to prove nontrivial properties about them in an algebraic and syntax-independent fashion. Sequential reduction, however, was not explored, but it was conjectured that it could be studied through a differential relational theory of rewriting. This manuscript proves the above conjecture by defining differential algebras of term relations, viz. algebras of term relations extended with novel operators inspired by the theory of functor derivatives. We give a set of axioms and rules for such operators and show that the resulting theory is expressive enough to define notions of parallel, full, and sequential reduction. We prove fundamental results relating all these notions in a purely algebraic and syntax-independent way, and showcase the effectiveness of our theory by proving the soundness of a proof technique for weak confluence akin to the so-called Critical Pair Lemma.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.02996"
  },
  "2312.02995": {
    "title": "Literature Review of Mixed Reality Research",
    "authors": [
      "Aizierjiang Aiersilan"
    ],
    "abstract": "In the global context, while mixed reality has been an emerging concept for years, recent technological and scientific advancements have now made it poised to revolutionize industries and daily life by offering enhanced functionalities and improved services. Besides reviewing the highly cited papers in the last 20 years among over a thousand research papers on mixed reality, this systematic review provides the state-of-the-art applications and utilities of the mixed reality by primarily scrutinizing the associated papers in 2022 and 2023. Focusing on the potentials that this technology have in providing digitally supported simulations and other utilities in the era of large language models, highlighting the potential and limitations of the innovative solutions and also bringing focus to emerging research directions, such as telemedicine, remote control and optimization of direct volume rendering. The paper's associated repository is publicly accessible at https://aizierjiang.github.io/mr.\n        \u25b3 Less",
    "submission_date": "15 December, 2023",
    "eprint_id": "2312.02995"
  },
  "2312.02994": {
    "title": "High Performance Multiple Sequence Alignment Algorithms for Comparison of Microbial Genomes",
    "authors": [
      "Manal Helal",
      "Hossam El-Gindy",
      "Bruno Gaeta",
      "Vitali Sinchenko"
    ],
    "abstract": "Advances in gene sequencing have enabled in silico analyses of microbial genomes and have led to the revision of concepts of microbial taxonomy and evolution. We explore deficiencies in existing multiple sequence global alignment algorithms and introduce a new indexing scheme to partition the dynamic programming algorithm hypercube scoring tensor over processors based on the dependency between partitions to be scored in parallel. The performance of algorithms is compared in the study of rpoB gene sequences of Mycoplasma species.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.02994"
  },
  "2312.02993": {
    "title": "ZTCloudGuard: Zero Trust Context-Aware Access Management Framework to Avoid Misuse Cases in the Era of Generative AI and Cloud-based Health Information Ecosystem",
    "authors": [
      "Khalid Al-hammuri",
      "Fayez Gebali",
      "Awos Kanan"
    ],
    "abstract": "Managing access between large numbers of distributed medical devices has become a crucial aspect of modern healthcare systems, enabling the establishment of smart hospitals and telehealth infrastructure. However, as telehealth technology continues to evolve and Internet of Things (IoT) devices become more widely used, they are also becoming increasingly exposed to various types of vulnerabilities and medical errors. In healthcare information systems, about 90\\% of vulnerabilities emerged from misuse cases and human errors. As a result, there is a need for additional research and development of security tools to prevent such attacks. This article proposes a zero-trust-based context-aware framework for managing access to the main components of the cloud ecosystem, including users, devices and output data. The main goal and benefit of the proposed framework is to build a scoring system to prevent or alleviate misuse cases while using distributed medical devices in cloud-based healthcare information systems. The framework has two main scoring schemas to maintain the chain of trust. First, it proposes a critical trust score based on cloud-native micro-services of authentication, encryption, logging, and authorizations. Second, creating a bond trust scoring to assess the real-time semantic and syntactic analysis of attributes stored in a healthcare information system. The analysis is based on a pre-trained machine learning model to generate the semantic and syntactic scores. The framework also takes into account regulatory compliance and user consent to create a scoring system. The advantage of this method is that it is applicable to any language and adapts to all attributes as it relies on a language model, not just a set of predefined and limited attributes. The results show a high F1 score of 93.5%, which proves that it is valid for detecting misuse cases.\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.02993"
  },
  "2312.02992": {
    "title": "Advancing Web Accessibility -- A guide to transitioning Design Systems from WCAG 2.0 to WCAG 2.1",
    "authors": [
      "Hardik Shah"
    ],
    "abstract": "This research focuses on the critical process of upgrading a Design System from Web Content Accessibility Guidelines (WCAG) 2.0 to WCAG 2.1, which is an essential step in enhancing web accessibility. It emphasizes the importance of staying up to date on increasing accessibility requirements, as well as the critical function of Design Systems in supporting inclusion in digital environments. The article lays out a complete strategy for meeting WCAG 2.1 compliance. Assessment, strategic planning, implementation, and testing are all part of this strategy. The need for collaboration and user involvement is emphasized as critical strategies and best practices for a successful migration journey. In addition, the article digs into migration barriers and discusses significant lessons acquired, offering a realistic view of the intricacies of this transforming road. Finally, it is a practical guide and a necessary resource for organizations committed to accessible and user-centered design. The document provides them with the knowledge and resources they need to navigate the changing world of web accessibility properly.\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.02992"
  },
  "2312.02991": {
    "title": "REFRESH FPGAs: Sustainable FPGA Chiplet Architectures",
    "authors": [
      "Peipei Zhou",
      "Jinming Zhuang",
      "Stephen Cahoon",
      "Yue Tang",
      "Zhuoping Yang",
      "Xingzhen Chen",
      "Yiyu Shi",
      "Jingtong Hu",
      "Alex K. Jones"
    ],
    "abstract": "There is a growing call for greater amounts of increasingly agile computational power for edge and cloud infrastructure to serve the computationally complex needs of ubiquitous computing devices. Thus, an important challenge is addressing the holistic environmental impacts of these next-generation computing systems. To accomplish this, a life-cycle view of sustainability for computing advancements is necessary to reduce environmental impacts such as greenhouse warming gas emissions from these computing choices. Unfortunately, decadal efforts to address operational energy efficiency in computing devices have ignored and in some cases exacerbated embodied impacts from manufacturing these edge and cloud systems, particularly their integrated circuits. During this time FPGA architectures have not changed dramatically except to increase in size. Given this context, we propose REFRESH FPGAs to build new FPGA devices and architectures from recently retired FPGA dies using 2.5D integration. To build REFRESH FPGAs requires creative architectures that leverage existing chiplet pins with an inexpensive to-manufacture interposer coupled with creative design automation. In this paper, we discuss how REFRESH FPGAs can leverage industry trends for renewable energy integration into data centers while providing an overall improvement for sustainability and amortizing their significant embodied cost investment over a much longer ``first'' lifetime.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.02991"
  },
  "2312.02988": {
    "title": "Efficient Subgraph Isomorphism Finding in Large Graphs using Eccentricity and Limiting Recursive Calls",
    "authors": [
      "Zubair Ali Ansari",
      "Muhammad Abulaish",
      "Irfan Rashid Thoker",
      "Jahiruddin"
    ],
    "abstract": "The subgraph isomorphism finding problem is a well-studied problem in the field of computer science and graph theory, and it aims to enumerate all instances of a query graph in the respective data graph. In this paper, we propose an efficient method, SubISO, to find subgraph isomorphisms using an objective function, which exploits some isomorphic invariants and eccentricity of the query graph's vertices. The proposed objective function is used to determine pivot vertex, which minimizes both number and size of the candidate regions in the data graph. SubISO also limits the maximum recursive calls of the generic SubgraphSearch function to deal with straggler queries for which most of the existing algorithms show exponential behaviour. The proposed approach is evaluated over three benchmark datasets. It is also compared with three well known subgraph isomorphism finding algorithms in terms of execution time, number of identified embeddings, and ability to deal with the straggler queries, and it performs significantly better.\n        \u25b3 Less",
    "submission_date": "21 November, 2023",
    "eprint_id": "2312.02988"
  },
  "2312.02985": {
    "title": "FocalPose++: Focal Length and Object Pose Estimation via Render and Compare",
    "authors": [
      "Martin C\u00edfka",
      "Georgy Ponimatkin",
      "Yann Labb\u00e9",
      "Bryan Russell",
      "Mathieu Aubry",
      "Vladimir Petrik",
      "Josef Sivic"
    ],
    "abstract": "We introduce FocalPose++, a neural render-and-compare method for jointly estimating the camera-object 6D pose and camera focal length given a single RGB input image depicting a known object. The contributions of this work are threefold. First, we derive a focal length update rule that extends an existing state-of-the-art render-and-compare 6D pose estimator to address the joint estimation task. Second, we investigate several different loss functions for jointly estimating the object pose and focal length. We find that a combination of direct focal length regression with a reprojection loss disentangling the contribution of translation, rotation, and focal length leads to improved results. Third, we explore the effect of different synthetic training data on the performance of our method. Specifically, we investigate different distributions used for sampling object's 6D pose and camera's focal length when rendering the synthetic images, and show that parametric distribution fitted on real training data works the best. We show results on three challenging benchmark datasets that depict known 3D models in uncontrolled settings. We demonstrate that our focal length and 6D pose estimates have lower error than the existing state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "15 November, 2023",
    "eprint_id": "2312.02985"
  },
  "2312.02984": {
    "title": "Diff-GO: Diffusion Goal-Oriented Communications to Achieve Ultra-High Spectrum Efficiency",
    "authors": [
      "Achintha Wijesinghe",
      "Songyang Zhang",
      "Suchinthaka Wanninayaka",
      "Weiwei Wang",
      "Zhi Ding"
    ],
    "abstract": "The latest advances in artificial intelligence (AI) present many unprecedented opportunities to achieve much improved bandwidth saving in communications. Unlike conventional communication systems focusing on packet transport, rich datasets and AI makes it possible to efficiently transfer only the information most critical to the goals of message recipients. One of the most exciting advances in generative AI known as diffusion model presents a unique opportunity for designing ultra-fast communication systems well beyond language-based messages. This work presents an ultra-efficient communication design by utilizing generative AI-based on diffusion models as a specific example of the general goal-oriented communication framework. To better control the regenerated message at the receiver output, our diffusion system design includes a local regeneration module with finite dimensional noise latent. The critical significance of noise latent control and sharing residing on our Diff-GO is the ability to introduce the concept of \"local generative feedback\" (Local-GF), which enables the transmitter to monitor the quality and gauge the quality or accuracy of the message recovery at the semantic system receiver. To this end, we propose a new low-dimensional noise space for the training of diffusion models, which significantly reduces the communication overhead and achieves satisfactory message recovery performance. Our experimental results demonstrate that the proposed noise space and the diffusion-based generative model achieve ultra-high spectrum efficiency and accurate recovery of transmitted image signals. By trading off computation for bandwidth efficiency (C4BE), this new framework provides an important avenue to achieve exceptional computation-bandwidth tradeoff.\n        \u25b3 Less",
    "submission_date": "13 November, 2023",
    "eprint_id": "2312.02984"
  },
  "2312.02981": {
    "title": "ReconFusion: 3D Reconstruction with Diffusion Priors",
    "authors": [
      "Rundi Wu",
      "Ben Mildenhall",
      "Philipp Henzler",
      "Keunhong Park",
      "Ruiqi Gao",
      "Daniel Watson",
      "Pratul P. Srinivasan",
      "Dor Verbin",
      "Jonathan T. Barron",
      "Ben Poole",
      "Aleksander Holynski"
    ],
    "abstract": "3D reconstruction methods such as Neural Radiance Fields (NeRFs) excel at rendering photorealistic novel views of complex scenes. However, recovering a high-quality NeRF typically requires tens to hundreds of input images, resulting in a time-consuming capture process. We present ReconFusion to reconstruct real-world scenes using only a few photos. Our approach leverages a diffusion prior for novel view synthesis, trained on synthetic and multiview datasets, which regularizes a NeRF-based 3D reconstruction pipeline at novel camera poses beyond those captured by the set of input images. Our method synthesizes realistic geometry and texture in underconstrained regions while preserving the appearance of observed regions. We perform an extensive evaluation across various real-world datasets, including forward-facing and 360-degree scenes, demonstrating significant performance improvements over previous few-view NeRF reconstruction approaches.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02981"
  },
  "2312.02980": {
    "title": "GPT4Point: A Unified Framework for Point-Language Understanding and Generation",
    "authors": [
      "Zhangyang Qi",
      "Ye Fang",
      "Zeyi Sun",
      "Xiaoyang Wu",
      "Tong Wu",
      "Jiaqi Wang",
      "Dahua Lin",
      "Hengshuang Zhao"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have excelled in 2D image-text comprehension and image generation, but their understanding of the 3D world is notably deficient, limiting progress in 3D language understanding and generation. To solve this problem, we introduce GPT4Point, an innovative groundbreaking point-language multimodal model designed specifically for unified 3D object understanding and generation within the MLLM framework. GPT4Point as a powerful 3D MLLM seamlessly can execute a variety of point-text reference tasks such as point-cloud captioning and Q&A. Additionally, GPT4Point is equipped with advanced capabilities for controllable 3D generation, it can get high-quality results through a low-quality point-text feature maintaining the geometric shapes and colors. To support the expansive needs of 3D object-text pairs, we develop Pyramid-XL, a point-language dataset annotation engine. It constructs a large-scale database over 1M objects of varied text granularity levels from the Objaverse-XL dataset, essential for training GPT4Point. A comprehensive benchmark has been proposed to evaluate 3D point-language understanding capabilities. In extensive evaluations, GPT4Point has demonstrated superior performance in understanding and generation.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02980"
  },
  "2312.02975": {
    "title": "Dexterous Functional Grasping",
    "authors": [
      "Ananye Agarwal",
      "Shagun Uppal",
      "Kenneth Shaw",
      "Deepak Pathak"
    ],
    "abstract": "While there have been significant strides in dexterous manipulation, most of it is limited to benchmark tasks like in-hand reorientation which are of limited utility in the real world. The main benefit of dexterous hands over two-fingered ones is their ability to pickup tools and other objects (including thin ones) and grasp them firmly to apply force. However, this task requires both a complex understanding of functional affordances as well as precise low-level control. While prior work obtains affordances from human data this approach doesn't scale to low-level control. Similarly, simulation training cannot give the robot an understanding of real-world semantics. In this paper, we aim to combine the best of both worlds to accomplish functional grasping for in-the-wild objects. We use a modular approach. First, affordances are obtained by matching corresponding regions of different objects and then a low-level policy trained in sim is run to grasp it. We propose a novel application of eigengrasps to reduce the search space of RL using a small amount of human data and find that it leads to more stable and physically realistic motion. We find that eigengrasp action space beats baselines in simulation and outperforms hardcoded grasping in real and matches or outperforms a trained human teleoperator. Results visualizations and videos at https://dexfunc.github.io/\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02975"
  },
  "2312.02973": {
    "title": "GauHuman: Articulated Gaussian Splatting from Monocular Human Videos",
    "authors": [
      "Shoukang Hu",
      "Ziwei Liu"
    ],
    "abstract": "We present, GauHuman, a 3D human model with Gaussian Splatting for both fast training (1 ~ 2 minutes) and real-time rendering (up to 189 FPS), compared with existing NeRF-based implicit representation modelling frameworks demanding hours of training and seconds of rendering per frame. Specifically, GauHuman encodes Gaussian Splatting in the canonical space and transforms 3D Gaussians from canonical space to posed space with linear blend skinning (LBS), in which effective pose and LBS refinement modules are designed to learn fine details of 3D humans under negligible computational cost. Moreover, to enable fast optimization of GauHuman, we initialize and prune 3D Gaussians with 3D human prior, while splitting/cloning via KL divergence guidance, along with a novel merge operation for further speeding up. Extensive experiments on ZJU_Mocap and MonoCap datasets demonstrate that GauHuman achieves state-of-the-art performance quantitatively and qualitatively with fast training and real-time rendering speed. Notably, without sacrificing rendering quality, GauHuman can fast model the 3D human performer with ~13k 3D Gaussians.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02973"
  },
  "2312.02970": {
    "title": "Alchemist: Parametric Control of Material Properties with Diffusion Models",
    "authors": [
      "Prafull Sharma",
      "Varun Jampani",
      "Yuanzhen Li",
      "Xuhui Jia",
      "Dmitry Lagun",
      "Fredo Durand",
      "William T. Freeman",
      "Mark Matthews"
    ],
    "abstract": "We propose a method to control material attributes of objects like roughness, metallic, albedo, and transparency in real images. Our method capitalizes on the generative prior of text-to-image models known for photorealism, employing a scalar value and instructions to alter low-level material properties. Addressing the lack of datasets with controlled material attributes, we generated an object-centric synthetic dataset with physically-based materials. Fine-tuning a modified pre-trained text-to-image model on this synthetic dataset enables us to edit material properties in real-world images while preserving all other attributes. We show the potential application of our model to material edited NeRFs.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02970"
  },
  "2312.02969": {
    "title": "Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models",
    "authors": [
      "Xinyu Zhang",
      "Sebastian Hofst\u00e4tter",
      "Patrick Lewis",
      "Raphael Tang",
      "Jimmy Lin"
    ],
    "abstract": "Listwise rerankers based on large language models (LLM) are the zero-shot state-of-the-art. However, current works in this direction all depend on the GPT models, making it a single point of failure in scientific reproducibility. Moreover, it raises the concern that the current research findings only hold for GPT models but not LLM in general. In this work, we lift this pre-condition and build for the first time effective listwise rerankers without any form of dependency on GPT. Our passage retrieval experiments show that our best list se reranker surpasses the listwise rerankers based on GPT-3.5 by 13% and achieves 97% effectiveness of the ones built on GPT-4. Our results also show that the existing training datasets, which were expressly constructed for pointwise ranking, are insufficient for building such listwise rerankers. Instead, high-quality listwise ranking data is required and crucial, calling for further work on building human-annotated listwise data resources.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02969"
  },
  "2312.02967": {
    "title": "AmbiGen: Generating Ambigrams from Pre-trained Diffusion Model",
    "authors": [
      "Boheng Zhao",
      "Rana Hanocka",
      "Raymond A. Yeh"
    ],
    "abstract": "Ambigrams are calligraphic designs that have different meanings depending on the viewing orientation. Creating ambigrams is a challenging task even for skilled artists, as it requires maintaining the meaning under two different viewpoints at the same time. In this work, we propose to generate ambigrams by distilling a large-scale vision and language diffusion model, namely DeepFloyd IF, to optimize the letters' outline for legibility in the two viewing orientations. Empirically, we demonstrate that our approach outperforms existing ambigram generation methods. On the 500 most common words in English, our method achieves more than an 11.6% increase in word accuracy and at least a 41.9% reduction in edit distance.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02967"
  },
  "2312.02966": {
    "title": "Diffusion-SS3D: Diffusion Model for Semi-supervised 3D Object Detection",
    "authors": [
      "Cheng-Ju Ho",
      "Chen-Hsuan Tai",
      "Yen-Yu Lin",
      "Ming-Hsuan Yang",
      "Yi-Hsuan Tsai"
    ],
    "abstract": "Semi-supervised object detection is crucial for 3D scene understanding, efficiently addressing the limitation of acquiring large-scale 3D bounding box annotations. Existing methods typically employ a teacher-student framework with pseudo-labeling to leverage unlabeled point clouds. However, producing reliable pseudo-labels in a diverse 3D space still remains challenging. In this work, we propose Diffusion-SS3D, a new perspective of enhancing the quality of pseudo-labels via the diffusion model for semi-supervised 3D object detection. Specifically, we include noises to produce corrupted 3D object size and class label distributions, and then utilize the diffusion model as a denoising process to obtain bounding box outputs. Moreover, we integrate the diffusion model into the teacher-student framework, so that the denoised bounding boxes can be used to improve pseudo-label generation, as well as the entire semi-supervised learning process. We conduct experiments on the ScanNet and SUN RGB-D benchmark datasets to demonstrate that our approach achieves state-of-the-art performance against existing methods. We also present extensive analysis to understand how our diffusion model design affects performance in semi-supervised learning.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02966"
  },
  "2312.02963": {
    "title": "MVHumanNet: A Large-scale Dataset of Multi-view Daily Dressing Human Captures",
    "authors": [
      "Zhangyang Xiong",
      "Chenghong Li",
      "Kenkun Liu",
      "Hongjie Liao",
      "Jianqiao Hu",
      "Junyi Zhu",
      "Shuliang Ning",
      "Lingteng Qiu",
      "Chongjie Wang",
      "Shijie Wang",
      "Shuguang Cui",
      "Xiaoguang Han"
    ],
    "abstract": "In this era, the success of large language models and text-to-image models can be attributed to the driving force of large-scale datasets. However, in the realm of 3D vision, while remarkable progress has been made with models trained on large-scale synthetic and real-captured object data like Objaverse and MVImgNet, a similar level of progress has not been observed in the domain of human-centric tasks partially due to the lack of a large-scale human dataset. Existing datasets of high-fidelity 3D human capture continue to be mid-sized due to the significant challenges in acquiring large-scale high-quality 3D human data. To bridge this gap, we present MVHumanNet, a dataset that comprises multi-view human action sequences of 4,500 human identities. The primary focus of our work is on collecting human data that features a large number of diverse identities and everyday clothing using a multi-view human capture system, which facilitates easily scalable data collection. Our dataset contains 9,000 daily outfits, 60,000 motion sequences and 645 million frames with extensive annotations, including human masks, camera parameters, 2D and 3D keypoints, SMPL/SMPLX parameters, and corresponding textual descriptions. To explore the potential of MVHumanNet in various 2D and 3D visual tasks, we conducted pilot studies on view-consistent action recognition, human NeRF reconstruction, text-driven view-unconstrained human image generation, as well as 2D view-unconstrained human image and 3D avatar generation. Extensive experiments demonstrate the performance improvements and effective applications enabled by the scale provided by MVHumanNet. As the current largest-scale 3D human dataset, we hope that the release of MVHumanNet data with annotations will foster further innovations in the domain of 3D human-centric tasks at scale.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02963"
  },
  "2312.02962": {
    "title": "Predicting Horizontal Gene Transfers with Perfect Transfer Networks",
    "authors": [
      "Alitzel L\u00f3pez S\u00e1nchez",
      "Manuel Lafond"
    ],
    "abstract": "Horizontal gene transfer inference approaches are usually based on gene sequences: parametric methods search for patterns that deviate from a particular genomic signature, while phylogenetic methods use sequences to reconstruct the gene and species trees. However, it is well-known that sequences have difficulty identifying ancient transfers since mutations have enough time to erase all evidence of such events. In this work, we ask whether character-based methods can predict gene transfers. Their advantage over sequences is that homologous genes can have low DNA similarity, but still have retained enough important common motifs that allow them to have common character traits, for instance the same functional or expression profile. A phylogeny that has two separate clades that acquired the same character independently might indicate the presence of a transfer even in the absence of sequence similarity. We introduce perfect transfer networks, which are phylogenetic networks that can explain the character diversity of a set of taxa under the assumption that characters have unique births, and that once a character is gained it is rarely lost. Examples of such traits include transposable elements, biochemical markers and emergence of organelles, just to name a few. We study the differences between our model and two similar models: perfect phylogenetic networks and ancestral recombination networks. Our goals are to initiate a study on the structural and algorithmic properties of perfect transfer networks. We then show that in polynomial time, one can decide whether a given network is a valid explanation for a set of taxa, and show how, for a given tree, one can add transfer edges to it so that it explains a set of taxa. We finally provide lower and upper bounds on the number of transfers required to explain a set of taxa, in the worst case.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02962"
  },
  "2312.02956": {
    "title": "Choroidalyzer: An open-source, end-to-end pipeline for choroidal analysis in optical coherence tomography",
    "authors": [
      "Justin Engelmann",
      "Jamie Burke",
      "Charlene Hamid",
      "Megan Reid-Schachter",
      "Dan Pugh",
      "Neeraj Dhaun",
      "Diana Moukaddem",
      "Lyle Gray",
      "Niall Strang",
      "Paul McGraw",
      "Amos Storkey",
      "Paul J. Steptoe",
      "Stuart King",
      "Tom MacGillivray",
      "Miguel O. Bernabeu",
      "Ian J. C. MacCormick"
    ],
    "abstract": "Purpose: To develop Choroidalyzer, an open-source, end-to-end pipeline for segmenting the choroid region, vessels, and fovea, and deriving choroidal thickness, area, and vascular index.\n  Methods: We used 5,600 OCT B-scans (233 subjects, 6 systemic disease cohorts, 3 device types, 2 manufacturers). To generate region and vessel ground-truths, we used state-of-the-art automatic methods following manual correction of inaccurate segmentations, with foveal positions manually annotated. We trained a U-Net deep-learning model to detect the region, vessels, and fovea to calculate choroid thickness, area, and vascular index in a fovea-centred region of interest. We analysed segmentation agreement (AUC, Dice) and choroid metrics agreement (Pearson, Spearman, mean absolute error (MAE)) in internal and external test sets. We compared Choroidalyzer to two manual graders on a small subset of external test images and examined cases of high error.\n  Results: Choroidalyzer took 0.299 seconds per image on a standard laptop and achieved excellent region (Dice: internal 0.9789, external 0.9749), very good vessel segmentation performance (Dice: internal 0.8817, external 0.8703) and excellent fovea location prediction (MAE: internal 3.9 pixels, external 3.4 pixels). For thickness, area, and vascular index, Pearson correlations were 0.9754, 0.9815, and 0.8285 (internal) / 0.9831, 0.9779, 0.7948 (external), respectively (all p<0.0001). Choroidalyzer's agreement with graders was comparable to the inter-grader agreement across all metrics.\n  Conclusions: Choroidalyzer is an open-source, end-to-end pipeline that accurately segments the choroid and reliably extracts thickness, area, and vascular index. Especially choroidal vessel segmentation is a difficult and subjective task, and fully-automatic methods like Choroidalyzer could provide objectivity and standardisation.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02956"
  },
  "2312.02955": {
    "title": "Switch Points of Bi-Persistence Matching Distance",
    "authors": [
      "Robyn Brooks",
      "Celia Hacker",
      "Claudia Landi",
      "Barbara I. Mahler",
      "Elizabeth R. Stephenson"
    ],
    "abstract": "In multi-parameter persistence, the matching distance is defined as the supremum of weighted bottleneck distances on the barcodes given by the restriction of persistence modules to lines with a positive slope. In the case of finitely presented bi-persistence modules, all the available methods to compute the matching distance are based on restricting the computation to lines through pairs from a finite set of points in the plane. Some of these points are determined by the filtration data as they are entrance values of critical simplices. However, these critical values alone are not sufficient for the matching distance computation and it is necessary to add so-called switch points, i.e. points such that on a line through any of them, the bottleneck matching switches the matched pair.\n  This paper is devoted to the algorithmic computation of the set of switch points given a set of critical values. We find conditions under which a candidate switch point is erroneous or superfluous. The obtained conditions are turned into algorithms that have been implemented. With this, we analyze how the size of the set of switch points increases as the number of critical values increases, and how it varies depending on the distribution of critical values. Experiments are carried out on various types of bi-persistence modules.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02955"
  },
  "2312.02949": {
    "title": "LLaVA-Grounding: Grounded Visual Chat with Large Multimodal Models",
    "authors": [
      "Hao Zhang",
      "Hongyang Li",
      "Feng Li",
      "Tianhe Ren",
      "Xueyan Zou",
      "Shilong Liu",
      "Shijia Huang",
      "Jianfeng Gao",
      "Lei Zhang",
      "Chunyuan Li",
      "Jianwei Yang"
    ],
    "abstract": "With the recent significant advancements in large multi-modal models (LMMs), the importance of their grounding capability in visual chat is increasingly recognized. Despite recent efforts to enable LMMs to support grounding, their capabilities for grounding and chat are usually separate, and their chat performance drops dramatically when asked to ground. The problem is the lack of a dataset for grounded visual chat (GVC). Existing grounding datasets only contain short captions. To address this issue, we have created GVC data that allows for the combination of grounding and chat capabilities. To better evaluate the GVC capabilities, we have introduced a benchmark called Grounding-Bench. Additionally, we have proposed a model design that can support GVC and various types of visual prompts by connecting segmentation models with language models. Experimental results demonstrate that our model outperforms other LMMs on Grounding-Bench. Furthermore, our model achieves competitive performance on classic grounding benchmarks like RefCOCO/+/g and Flickr30K Entities. Our code will be released at https://github.com/UX-Decoder/LLaVA-Grounding .\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02949"
  },
  "2312.02944": {
    "title": "An alternating peak-optimization method for optimal trajectory generation of quadrotor drones",
    "authors": [
      "Wytze A. B. de Vries",
      "Ming Li",
      "Qirui Song",
      "Zhiyong Sun"
    ],
    "abstract": "In this paper, we propose an alternating optimization method to address a time-optimal trajectory generation problem. Different from the existing solutions, our approach introduces a new formulation that minimizes the overall trajectory running time while maintaining the polynomial smoothness constraints and incorporating hard limits on motion derivatives to ensure feasibility. To address this problem, an alternating peak-optimization method is developed, which splits the optimization process into two sub-optimizations: the first sub-optimization optimizes polynomial coefficients for smoothness, and the second sub-optimization adjusts the time allocated to each trajectory segment. These are alternated until a feasible minimum-time solution is found. We offer a comprehensive set of simulations and experiments to showcase the superior performance of our approach in comparison to existing methods.\n  A collection of demonstration videos with real drone flying experiments can be accessed at https://www.youtube.com/playlist?list=PLQGtPFK17zUYkwFT-fr0a8E49R8Uq712l .\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02944"
  },
  "2312.02941": {
    "title": "Fast CT anatomic localization algorithm",
    "authors": [
      "Amit Oved"
    ],
    "abstract": "Automatically determining the position of every slice in a CT scan is a basic yet powerful capability allowing fast retrieval of region of interest for visual inspection and automated analysis. Unlike conventional localization approaches which work at the slice level, we directly localize only a fraction of the slices and and then fit a linear model which maps slice index to its estimated axial anatomical position based on those slices. The model is then used to assign axial position to every slices of the scan. This approach proves to be both computationally efficient, with a typical processing time of less than a second per scan (regardless of its size), accurate, with a typical median localization error of 1 cm, and robust to different noise sources, imaging protocols, metal induced artifacts, anatomical deformations etc. Another key element of our approach is the introduction of a mapping confidence score. This score acts as a fail safe mechanism which allows a rejection of unreliable localization results in rare cases of anomalous scans. Our algorithm sets new State Of The Art results in terms of localization accuracy. It also offers a decrease of two orders of magnitude in processing time with respect to all published processing times. It was designed to be invariant to various scan resolutions, scan protocols, patient orientations, strong artifacts and various deformations and abnormalities. Additionally, our algorithm is the first one to the best of our knowledge which supports the entire body from head to feet and is not confined to specific anatomical region. This algorithm was tested on thousands of scans and proves to be very reliable and useful as a preprocessing stage for many applications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02941"
  },
  "2312.02937": {
    "title": "Synergistic Perception and Control Simplex for Verifiable Safe Vertical Landing",
    "authors": [
      "Ayoosh Bansal",
      "Yang Zhao",
      "James Zhu",
      "Sheng Cheng",
      "Yuliang Gu",
      "Hyung-Jin Yoon",
      "Hunmin Kim",
      "Naira Hovakimyan",
      "Lui Sha"
    ],
    "abstract": "Perception, Planning, and Control form the essential components of autonomy in advanced air mobility. This work advances the holistic integration of these components to enhance the performance and robustness of the complete cyber-physical system. We adapt Perception Simplex, a system for verifiable collision avoidance amidst obstacle detection faults, to the vertical landing maneuver for autonomous air mobility vehicles. We improve upon this system by replacing static assumptions of control capabilities with dynamic confirmation, i.e., real-time confirmation of control limitations of the system, ensuring reliable fulfillment of safety maneuvers and overrides, without dependence on overly pessimistic assumptions. Parameters defining control system capabilities and limitations, e.g., maximum deceleration, are continuously tracked within the system and used to make safety-critical decisions. We apply these techniques to propose a verifiable collision avoidance solution for autonomous aerial mobility vehicles operating in cluttered and potentially unsafe environments.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02937"
  },
  "2312.02936": {
    "title": "Drag-A-Video: Non-rigid Video Editing with Point-based Interaction",
    "authors": [
      "Yao Teng",
      "Enze Xie",
      "Yue Wu",
      "Haoyu Han",
      "Zhenguo Li",
      "Xihui Liu"
    ],
    "abstract": "Video editing is a challenging task that requires manipulating videos on both the spatial and temporal dimensions. Existing methods for video editing mainly focus on changing the appearance or style of the objects in the video, while keeping their structures unchanged. However, there is no existing method that allows users to interactively ``drag'' any points of instances on the first frame to precisely reach the target points with other frames consistently deformed. In this paper, we propose a new diffusion-based method for interactive point-based video manipulation, called Drag-A-Video. Our method allows users to click pairs of handle points and target points as well as masks on the first frame of an input video. Then, our method transforms the inputs into point sets and propagates these sets across frames. To precisely modify the contents of the video, we employ a new video-level motion supervision to update the features of the video and introduce the latent offsets to achieve this update at multiple denoising timesteps. We propose a temporal-consistent point tracking module to coordinate the movement of the points in the handle point sets. We demonstrate the effectiveness and flexibility of our method on various videos. The website of our work is available here: https://drag-a-video.github.io/.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02936"
  },
  "2312.02931": {
    "title": "WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words",
    "authors": [
      "Lukas Wolf",
      "Greta Tuckute",
      "Klemen Kotar",
      "Eghbal Hosseini",
      "Tamar Regev",
      "Ethan Wilcox",
      "Alex Warstadt"
    ],
    "abstract": "Training on multiple modalities of input can augment the capabilities of a language model. Here, we ask whether such a training regime can improve the quality and efficiency of these systems as well. We focus on text--audio and introduce Whisbert, which is inspired by the text--image approach of FLAVA (Singh et al., 2022). In accordance with Babylm guidelines (Warstadt et al., 2023), we pretrain Whisbert on a dataset comprising only 100 million words plus their corresponding speech from the word-aligned version of the People's Speech dataset (Galvez et al., 2021). To assess the impact of multimodality, we compare versions of the model that are trained on text only and on both audio and text simultaneously. We find that while Whisbert is able to perform well on multimodal masked modeling and surpasses the Babylm baselines in most benchmark tasks, it struggles to optimize its complex objective and outperform its text-only Whisbert baseline.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02931"
  },
  "2312.02928": {
    "title": "LivePhoto: Real Image Animation with Text-guided Motion Control",
    "authors": [
      "Xi Chen",
      "Zhiheng Liu",
      "Mengting Chen",
      "Yutong Feng",
      "Yu Liu",
      "Yujun Shen",
      "Hengshuang Zhao"
    ],
    "abstract": "Despite the recent progress in text-to-video generation, existing studies usually overlook the issue that only spatial contents but not temporal motions in synthesized videos are under the control of text. Towards such a challenge, this work presents a practical system, named LivePhoto, which allows users to animate an image of their interest with text descriptions. We first establish a strong baseline that helps a well-learned text-to-image generator (i.e., Stable Diffusion) take an image as a further input. We then equip the improved generator with a motion module for temporal modeling and propose a carefully designed training pipeline to better link texts and motions. In particular, considering the facts that (1) text can only describe motions roughly (e.g., regardless of the moving speed) and (2) text may include both content and motion descriptions, we introduce a motion intensity estimation module as well as a text re-weighting module to reduce the ambiguity of text-to-motion mapping. Empirical evidence suggests that our approach is capable of well decoding motion-related textual instructions into videos, such as actions, camera movements, or even conjuring new contents from thin air (e.g., pouring water into an empty glass). Interestingly, thanks to the proposed intensity learning mechanism, our system offers users an additional control signal (i.e., the motion intensity) besides text for video customization.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02928"
  },
  "2312.02921": {
    "title": "Cyber Insurance for Cyber Resilience",
    "authors": [
      "Shutian Liu",
      "Quanyan Zhu"
    ],
    "abstract": "Cyber insurance is a complementary mechanism to further reduce the financial impact on the systems after their effort in defending against cyber attacks and implementing resilience mechanism to maintain the system-level operator even though the attacker is already in the system. This chapter presents a review of the quantitative cyber insurance design framework that takes into account the incentives as well as the perceptual aspects of multiple parties. The design framework builds on the correlation between state-of-the-art attacker vectors and defense mechanisms. In particular, we propose the notion of residual risks to characterize the goal of cyber insurance design. By elaborating the insurer's observations necessary for the modeling of the cyber insurance contract, we make comparison between the design strategies of the insurer under scenarios with different monitoring rules. These distinct but practical scenarios give rise to the concept of the intensity of the moral hazard issue. Using the modern techniques in quantifying the risk preferences of individuals, we link the economic impacts of perception manipulation with moral hazard. With the joint design of cyber insurance design and risk perceptions, cyber resilience can be enhanced under mild assumptions on the monitoring of insurees' actions. Finally, we discuss possible extensions on the cyber insurance design framework to more sophisticated settings and the regulations to strengthen the cyber insurance markets.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02921"
  },
  "2312.02919": {
    "title": "Fine-grained Controllable Video Generation via Object Appearance and Context",
    "authors": [
      "Hsin-Ping Huang",
      "Yu-Chuan Su",
      "Deqing Sun",
      "Lu Jiang",
      "Xuhui Jia",
      "Yukun Zhu",
      "Ming-Hsuan Yang"
    ],
    "abstract": "Text-to-video generation has shown promising results. However, by taking only natural languages as input, users often face difficulties in providing detailed information to precisely control the model's output. In this work, we propose fine-grained controllable video generation (FACTOR) to achieve detailed control. Specifically, FACTOR aims to control objects' appearances and context, including their location and category, in conjunction with the text prompt. To achieve detailed control, we propose a unified framework to jointly inject control signals into the existing text-to-video model. Our model consists of a joint encoder and adaptive cross-attention layers. By optimizing the encoder and the inserted layer, we adapt the model to generate videos that are aligned with both text prompts and fine-grained control. Compared to existing methods relying on dense control signals such as edge maps, we provide a more intuitive and user-friendly interface to allow object-level fine-grained control. Our method achieves controllability of object appearances without finetuning, which reduces the per-subject optimization efforts for the users. Extensive experiments on standard benchmark datasets and user-provided inputs validate that our model obtains a 70% improvement in controllability metrics over competitive baselines.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02919"
  },
  "2312.02916": {
    "title": "MIND: Multi-Task Incremental Network Distillation",
    "authors": [
      "Jacopo Bonato",
      "Francesco Pelosin",
      "Luigi Sabetta",
      "Alessandro Nicolosi"
    ],
    "abstract": "The recent surge of pervasive devices that generate dynamic data streams has underscored the necessity for learning systems to adapt continually to data distributional shifts. To tackle this challenge, the research community has put forth a spectrum of methodologies, including the demanding pursuit of class-incremental learning without replay data. In this study, we present MIND, a parameter isolation method that aims to significantly enhance the performance of replay-free solutions and achieve state-of-the-art results on several widely studied datasets. Our approach introduces two main contributions: two alternative distillation procedures that significantly improve the efficiency of MIND increasing the accumulated knowledge of each sub-network, and the optimization of the BachNorm layers across tasks inside the sub-networks. Overall, MIND outperforms all the state-of-the-art methods for rehearsal-free Class-Incremental learning (with an increment in classification accuracy of approx. +6% on CIFAR-100/10 and +10% on TinyImageNet/10) reaching up to approx. +40% accuracy in Domain-Incremental scenarios. Moreover, we ablated each contribution to demonstrate its impact on performance improvement. Our results showcase the superior performance of MIND indicating its potential for addressing the challenges posed by Class-incremental and Domain-Incremental learning in resource-constrained environments.\n        \u25b3 Less",
    "submission_date": "20 December, 2023",
    "eprint_id": "2312.02916"
  },
  "2312.02913": {
    "title": "Let the LLMs Talk: Simulating Human-to-Human Conversational QA via Zero-Shot LLM-to-LLM Interactions",
    "authors": [
      "Zahra Abbasiantaeb",
      "Yifei Yuan",
      "Evangelos Kanoulas",
      "Mohammad Aliannejadi"
    ],
    "abstract": "Conversational question-answering (CQA) systems aim to create interactive search systems that effectively retrieve information by interacting with users. To replicate human-to-human conversations, existing work uses human annotators to play the roles of the questioner (student) and the answerer (teacher). Despite its effectiveness, challenges exist as human annotation is time-consuming, inconsistent, and not scalable. To address this issue and investigate the applicability of large language models (LLMs) in CQA simulation, we propose a simulation framework that employs zero-shot learner LLMs for simulating teacher-student interactions. Our framework involves two LLMs interacting on a specific topic, with the first LLM acting as a student, generating questions to explore a given search topic. The second LLM plays the role of a teacher by answering questions and is equipped with additional information, including a text on the given topic. We implement both the student and teacher by zero-shot prompting the GPT-4 model. To assess the effectiveness of LLMs in simulating CQA interactions and understand the disparities between LLM- and human-generated conversations, we evaluate the simulated data from various perspectives. We begin by evaluating the teacher's performance through both automatic and human assessment. Next, we evaluate the performance of the student, analyzing and comparing the disparities between questions generated by the LLM and those generated by humans. Furthermore, we conduct extensive analyses to thoroughly examine the LLM performance by benchmarking state-of-the-art reading comprehension models on both datasets. Our results reveal that the teacher LLM generates lengthier answers that tend to be more accurate and complete. The student LLM generates more diverse questions, covering more aspects of a given topic.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02913"
  },
  "2312.02912": {
    "title": "Realistic Scatterer Based Adversarial Attacks on SAR Image Classifiers",
    "authors": [
      "Tian Ye",
      "Rajgopal Kannan",
      "Viktor Prasanna",
      "Carl Busart",
      "Lance Kaplan"
    ],
    "abstract": "Adversarial attacks have highlighted the vulnerability of classifiers based on machine learning for Synthetic Aperture Radar (SAR) Automatic Target Recognition (ATR) tasks. An adversarial attack perturbs SAR images of on-ground targets such that the classifiers are misled into making incorrect predictions. However, many existing attacking techniques rely on arbitrary manipulation of SAR images while overlooking the feasibility of executing the attacks on real-world SAR imagery. Instead, adversarial attacks should be able to be implemented by physical actions, for example, placing additional false objects as scatterers around the on-ground target to perturb the SAR image and fool the SAR ATR.\n  In this paper, we propose the On-Target Scatterer Attack (OTSA), a scatterer-based physical adversarial attack. To ensure the feasibility of its physical execution, we enforce a constraint on the positioning of the scatterers. Specifically, we restrict the scatterers to be placed only on the target instead of in the shadow regions or the background. To achieve this, we introduce a positioning score based on Gaussian kernels and formulate an optimization problem for our OTSA attack. Using a gradient ascent method to solve the optimization problem, the OTSA can generate a vector of parameters describing the positions, shapes, sizes and amplitudes of the scatterers to guide the physical execution of the attack that will mislead SAR image classifiers. The experimental results show that our attack obtains significantly higher success rates under the positioning constraint compared with the existing method.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02912"
  },
  "2312.02910": {
    "title": "Rare Galaxy Classes Identified In Foundation Model Representations",
    "authors": [
      "Mike Walmsley",
      "Anna M. M. Scaife"
    ],
    "abstract": "We identify rare and visually distinctive galaxy populations by searching for structure within the learned representations of pretrained models. We show that these representations arrange galaxies by appearance in patterns beyond those needed to predict the pretraining labels. We design a clustering approach to isolate specific local patterns, revealing groups of galaxies with rare and scientifically-interesting morphologies.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02910"
  },
  "2312.02908": {
    "title": "Deep Learning Segmentation of Spiral Arms and Bars",
    "authors": [
      "Mike Walmsley",
      "Ashley Spindler"
    ],
    "abstract": "We present the first deep learning model for segmenting galactic spiral arms and bars. In a blinded assessment by expert astronomers, our predicted spiral arm masks are preferred over both current automated methods (99% of evaluations) and our original volunteer labels (79% of evaluations). Experts rated our spiral arm masks as `mostly good' to `perfect' in 89% of evaluations. Bar lengths trivially derived from our predicted bar masks are in excellent agreement with a dedicated crowdsourcing project. The pixelwise precision of our masks, previously impossible at scale, will underpin new research into how spiral arms and bars evolve.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02908"
  },
  "2312.02906": {
    "title": "Uncovering Patterns of Participant-Invariant Influence in Networks",
    "authors": [
      "Min Shaojie"
    ],
    "abstract": "In this paper, we explore the nature of influence in a network. The concept of participant-invariant influence is derived from an influence matrix M specifically designed to explore this phenomenon. Through nonnegative matrix factorization approximation, we managed to extract a participant-invariant matrix H representing a shared pattern that all participants must obey. The acquired H is highly field-related and can be further utilized to cluster factual networks. Our discovery of the unveiled participant-independent influence within network dynamics opens up new avenues for further research on network behavior and its implications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02906"
  },
  "2312.02901": {
    "title": "Concept Drift Adaptation in Text Stream Mining Settings: A Comprehensive Review",
    "authors": [
      "Cristiano Mesquita Garcia",
      "Ramon Simoes Abilio",
      "Alessandro Lameiras Koerich",
      "Alceu de Souza Britto Jr.",
      "Jean Paul Barddal"
    ],
    "abstract": "Due to the advent and increase in the popularity of the Internet, people have been producing and disseminating textual data in several ways, such as reviews, social media posts, and news articles. As a result, numerous researchers have been working on discovering patterns in textual data, especially because social media posts function as social sensors, indicating peoples' opinions, interests, etc. However, most tasks regarding natural language processing are addressed using traditional machine learning methods and static datasets. This setting can lead to several problems, such as an outdated dataset, which may not correspond to reality, and an outdated model, which has its performance degrading over time. Concept drift is another aspect that emphasizes these issues, which corresponds to data distribution and pattern changes. In a text stream scenario, it is even more challenging due to its characteristics, such as the high speed and data arriving sequentially. In addition, models for this type of scenario must adhere to the constraints mentioned above while learning from the stream by storing texts for a limited time and consuming low memory. In this study, we performed a systematic literature review regarding concept drift adaptation in text stream scenarios. Considering well-defined criteria, we selected 40 papers to unravel aspects such as text drift categories, types of text drift detection, model update mechanism, the addressed stream mining tasks, types of text representations, and text representation update mechanism. In addition, we discussed drift visualization and simulation and listed real-world datasets used in the selected papers. Therefore, this paper comprehensively reviews the concept drift adaptation in text stream mining scenarios.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02901"
  },
  "2312.02897": {
    "title": "Perspectives from Naive Participants and Experienced Social Science Researchers on Addressing Embodiment in a Virtual Cyberball Task",
    "authors": [
      "Tao Long",
      "Swati Pandita",
      "Andrea Stevenson Won"
    ],
    "abstract": "We describe the design of an immersive virtual Cyberball task that included avatar customization, and user feedback on this design. We first created a prototype of an avatar customization template and added it to a Cyberball prototype built in the Unity3D game engine. Then, we conducted in-depth user testing and feedback sessions with 15 Cyberball stakeholders: five naive participants with no prior knowledge of Cyberball and ten experienced researchers with extensive experience using the Cyberball paradigm. We report the divergent perspectives of the two groups on the following design insights; designing for intuitive use, inclusivity, and realistic experiences versus minimalism. Participant responses shed light on how system design problems may contribute to or perpetuate negative experiences when customizing avatars. They also demonstrate the value of considering multiple stakeholders' feedback in the design process for virtual reality, presenting a more comprehensive view in designing future Cyberball prototypes and interactive systems for social science research.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02897"
  },
  "2312.02896": {
    "title": "BenchLMM: Benchmarking Cross-style Visual Capability of Large Multimodal Models",
    "authors": [
      "Rizhao Cai",
      "Zirui Song",
      "Dayan Guan",
      "Zhenhao Chen",
      "Xing Luo",
      "Chenyu Yi",
      "Alex Kot"
    ],
    "abstract": "Large Multimodal Models (LMMs) such as GPT-4V and LLaVA have shown remarkable capabilities in visual reasoning with common image styles. However, their robustness against diverse style shifts, crucial for practical applications, remains largely unexplored. In this paper, we propose a new benchmark, BenchLMM, to assess the robustness of LMMs against three different styles: artistic image style, imaging sensor style, and application style, where each style has five sub-styles. Utilizing BenchLMM, we comprehensively evaluate state-of-the-art LMMs and reveal: 1) LMMs generally suffer performance degradation when working with other styles; 2) An LMM performs better than another model in common style does not guarantee its superior performance in other styles; 3) LMMs' reasoning capability can be enhanced by prompting LMMs to predict the style first, based on which we propose a versatile and training-free method for improving LMMs; 4) An intelligent LMM is expected to interpret the causes of its errors when facing stylistic variations. We hope that our benchmark and analysis can shed new light on developing more intelligent and versatile LMMs.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02896"
  },
  "2312.02882": {
    "title": "Zero Trust for Cyber Resilience",
    "authors": [
      "Yunfei Ge",
      "Quanyan Zhu"
    ],
    "abstract": "The increased connectivity and potential insider threats make traditional network defense vulnerable. Instead of assuming that everything behind the security perimeter is safe, the zero-trust security model verifies every incoming request before granting access. This chapter draws attention to the cyber resilience within the zero-trust model. We introduce the evolution from traditional perimeter-based security to zero trust and discuss their difference. Two key elements of the zero-trust engine are trust evaluation (TE) and policy engine (PE). We introduce the design of the two components and discuss how their interplay would contribute to cyber resilience. Dynamic game theory and learning are applied as quantitative approaches to achieve automated zero-trust cyber resilience. Several case studies and implementations are introduced to illustrate the benefits of such a security model.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02882"
  },
  "2312.02873": {
    "title": "Toward autocorrection of chemical process flowsheets using large language models",
    "authors": [
      "Lukas Schulze Balhorn",
      "Marc Caballero",
      "Artur M. Schweidtmann"
    ],
    "abstract": "The process engineering domain widely uses Process Flow Diagrams (PFDs) and Process and Instrumentation Diagrams (P&IDs) to represent process flows and equipment configurations. However, the P&IDs and PFDs, hereafter called flowsheets, can contain errors causing safety hazards, inefficient operation, and unnecessary expenses. Correcting and verifying flowsheets is a tedious, manual process. We propose a novel generative AI methodology for automatically identifying errors in flowsheets and suggesting corrections to the user, i.e., autocorrecting flowsheets. Inspired by the breakthrough of Large Language Models (LLMs) for grammatical autocorrection of human language, we investigate LLMs for the autocorrection of flowsheets. The input to the model is a potentially erroneous flowsheet and the output of the model are suggestions for a corrected flowsheet. We train our autocorrection model on a synthetic dataset in a supervised manner. The model achieves a top-1 accuracy of 80% and a top-5 accuracy of 84% on an independent test dataset of synthetically generated flowsheets. The results suggest that the model can learn to autocorrect the synthetic flowsheets. We envision that flowsheet autocorrection will become a useful tool for chemical engineers.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02873"
  },
  "2312.02872": {
    "title": "Experimental Insights Towards Explainable and Interpretable Pedestrian Crossing Prediction",
    "authors": [
      "Angie Nataly Melo",
      "Carlota Salinas",
      "Miguel Angel Sotelo"
    ],
    "abstract": "In the context of autonomous driving, pedestrian crossing prediction is a key component for improving road safety. Presently, the focus of these predictions extends beyond achieving trustworthy results; it is shifting towards the explainability and interpretability of these predictions. This research introduces a novel neuro-symbolic approach that combines deep learning and fuzzy logic for an explainable and interpretable pedestrian crossing prediction. We have developed an explainable predictor (ExPedCross), which utilizes a set of explainable features and employs a fuzzy inference system to predict whether the pedestrian will cross or not. Our approach was evaluated on both the PIE and JAAD datasets. The results offer experimental insights into achieving explainability and interpretability in the pedestrian crossing prediction task. Furthermore, the testing results yield a set of guidelines and recommendations regarding the process of dataset selection, feature selection, and explainability.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02872"
  },
  "2312.02871": {
    "title": "Attention-enhanced neural differential equations for physics-informed deep learning of ion transport",
    "authors": [
      "Danyal Rehman",
      "John H. Lienhard"
    ],
    "abstract": "Species transport models typically combine partial differential equations (PDEs) with relations from hindered transport theory to quantify electromigrative, convective, and diffusive transport through complex nanoporous systems; however, these formulations are frequently substantial simplifications of the governing dynamics, leading to the poor generalization performance of PDE-based models. Given the growing interest in deep learning methods for the physical sciences, we develop a machine learning-based approach to characterize ion transport across nanoporous membranes. Our proposed framework centers around attention-enhanced neural differential equations that incorporate electroneutrality-based inductive biases to improve generalization performance relative to conventional PDE-based methods. In addition, we study the role of the attention mechanism in illuminating physically-meaningful ion-pairing relationships across diverse mixture compositions. Further, we investigate the importance of pre-training on simulated data from PDE-based models, as well as the performance benefits from hard vs. soft inductive biases. Our results indicate that physics-informed deep learning solutions can outperform their classical PDE-based counterparts and provide promising avenues for modelling complex transport phenomena across diverse applications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02871"
  },
  "2312.02869": {
    "title": "Can a Tabula Recta provide security in the XXI century?",
    "authors": [
      "Francisco Ruiz"
    ],
    "abstract": "In the not so unlikely scenario of total compromise of computers accessible to a group of users, they might be tempted to resort to human-computable paper-and-pencil cryptographic methods aided by a classic Tabula Recta, which helps to perform addition and subtraction directly with letters. But do these classic algorithms, or some new ones using the same simple tools, have any chance against computer-aided cryptanalysis? In this paper I discuss how some human-computable algorithms can indeed afford sufficient security in this situation, drawing conclusions from computer-based statistical analysis. Three kinds of algorithms are discussed: those that concentrate entropy from shared text sources, stream ciphers based on arithmetic of non-binary spaces, and hash-like algorithms that may be used to generate a password from a challenge text.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02869"
  },
  "2312.02859": {
    "title": "Lessons from Usable ML Deployments and Application to Wind Turbine Monitoring",
    "authors": [
      "Alexandra Zytek",
      "Wei-En Wang",
      "Sofia Koukoura",
      "Kalyan Veeramachaneni"
    ],
    "abstract": "Through past experiences deploying what we call usable ML (one step beyond explainable ML, including both explanations and other augmenting information) to real-world domains, we have learned three key lessons. First, many organizations are beginning to hire people who we call ``bridges'' because they bridge the gap between ML developers and domain experts, and these people fill a valuable role in developing usable ML applications. Second, a configurable system that enables easily iterating on usable ML interfaces during collaborations with bridges is key. Finally, there is a need for continuous, in-deployment evaluations to quantify the real-world impact of usable ML. Throughout this paper, we apply these lessons to the task of wind turbine monitoring, an essential task in the renewable energy domain. Turbine engineers and data analysts must decide whether to perform costly in-person investigations on turbines to prevent potential cases of brakepad failure, and well-tuned usable ML interfaces can aid with this decision-making process. Through the applications of our lessons to this task, we hope to demonstrate the potential real-world impact of usable ML in the renewable energy domain.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02859"
  },
  "2312.02858": {
    "title": "Towards Causal Representations of Climate Model Data",
    "authors": [
      "Julien Boussard",
      "Chandni Nagda",
      "Julia Kaltenborn",
      "Charlotte Emilie Elektra Lange",
      "Philippe Brouillard",
      "Yaniv Gurwicz",
      "Peer Nowack",
      "David Rolnick"
    ],
    "abstract": "Climate models, such as Earth system models (ESMs), are crucial for simulating future climate change based on projected Shared Socioeconomic Pathways (SSP) greenhouse gas emissions scenarios. While ESMs are sophisticated and invaluable, machine learning-based emulators trained on existing simulation data can project additional climate scenarios much faster and are computationally efficient. However, they often lack generalizability and interpretability. This work delves into the potential of causal representation learning, specifically the \\emph{Causal Discovery with Single-parent Decoding} (CDSD) method, which could render climate model emulation efficient \\textit{and} interpretable. We evaluate CDSD on multiple climate datasets, focusing on emissions, temperature, and precipitation. Our findings shed light on the challenges, limitations, and promise of using CDSD as a stepping stone towards more interpretable and robust climate model emulation.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02858"
  },
  "2312.02855": {
    "title": "Exploring Error Bits for Memory Failure Prediction: An In-Depth Correlative Study",
    "authors": [
      "Qiao Yu",
      "Wengui Zhang",
      "Jorge Cardoso",
      "Odej Kao"
    ],
    "abstract": "In large-scale datacenters, memory failure is a common cause of server crashes, with Uncorrectable Errors (UEs) being a major indicator of Dual Inline Memory Module (DIMM) defects. Existing approaches primarily focus on predicting UEs using Correctable Errors (CEs), without fully considering the information provided by error bits. However, error bit patterns have a strong correlation with the occurrence of UEs. In this paper, we present a comprehensive study on the correlation between CEs and UEs, specifically emphasizing the importance of spatio-temporal error bit information. Our analysis reveals a strong correlation between spatio-temporal error bits and UE occurrence. Through evaluations using real-world datasets, we demonstrate that our approach significantly improves prediction performance by 15% in F1-score compared to the state-of-the-art algorithms. Overall, our approach effectively reduces the number of virtual machine interruptions caused by UEs by approximately 59%.\n        \u25b3 Less",
    "submission_date": "18 December, 2023",
    "eprint_id": "2312.02855"
  },
  "2312.02852": {
    "title": "Expert-guided Bayesian Optimisation for Human-in-the-loop Experimental Design of Known Systems",
    "authors": [
      "Tom Savage",
      "Ehecatl Antonio del Rio Chanona"
    ],
    "abstract": "Domain experts often possess valuable physical insights that are overlooked in fully automated decision-making processes such as Bayesian optimisation. In this article we apply high-throughput (batch) Bayesian optimisation alongside anthropological decision theory to enable domain experts to influence the selection of optimal experiments. Our methodology exploits the hypothesis that humans are better at making discrete choices than continuous ones and enables experts to influence critical early decisions. At each iteration we solve an augmented multi-objective optimisation problem across a number of alternate solutions, maximising both the sum of their utility function values and the determinant of their covariance matrix, equivalent to their total variability. By taking the solution at the knee point of the Pareto front, we return a set of alternate solutions at each iteration that have both high utility values and are reasonably distinct, from which the expert selects one for evaluation. We demonstrate that even in the case of an uninformed practitioner, our algorithm recovers the regret of standard Bayesian optimisation.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02852"
  },
  "2312.02850": {
    "title": "A Kernel-Based Neural Network Test for High-dimensional Sequencing Data Analysis",
    "authors": [
      "Tingting Hou",
      "Chang Jiang",
      "Qing Lu"
    ],
    "abstract": "The recent development of artificial intelligence (AI) technology, especially the advance of deep neural network (DNN) technology, has revolutionized many fields. While DNN plays a central role in modern AI technology, it has been rarely used in sequencing data analysis due to challenges brought by high-dimensional sequencing data (e.g., overfitting). Moreover, due to the complexity of neural networks and their unknown limiting distributions, building association tests on neural networks for genetic association analysis remains a great challenge. To address these challenges and fill the important gap of using AI in high-dimensional sequencing data analysis, we introduce a new kernel-based neural network (KNN) test for complex association analysis of sequencing data. The test is built on our previously developed KNN framework, which uses random effects to model the overall effects of high-dimensional genetic data and adopts kernel-based neural network structures to model complex genotype-phenotype relationships. Based on KNN, a Wald-type test is then introduced to evaluate the joint association of high-dimensional genetic data with a disease phenotype of interest, considering non-linear and non-additive effects (e.g., interaction effects). Through simulations, we demonstrated that our proposed method attained higher power compared to the sequence kernel association test (SKAT), especially in the presence of non-linear and interaction effects. Finally, we apply the methods to the whole genome sequencing (WGS) dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI) study, investigating new genes associated with the hippocampal volume change over time.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02850"
  },
  "2312.02845": {
    "title": "A Review of Password-less User Authentication Schemes",
    "authors": [
      "Tunde Oduguwa",
      "Abdullahi Arabo"
    ],
    "abstract": "Since the demise of the password was predicted in 2004, different attempts in industry and academia have been made to create an alternative for the use of passwords in authentication, without compromising on security and user experience. This review examines password-less authentication schemes that have been proposed since after the death knell was placed on passwords in 2004. We start with a brief discussion of the requirements of authentication systems and then identify various password-less authentication proposals to date. We then evaluate the truly password-less and practical schemes using a framework that examines authentication credentials based on their impact on user experience, overall security, and ease of deployment. The findings of this review observe a difficulty in balancing security with a user experience compared to that of passwords in new password-less schemes, providing the opportunity for new applied research to leverage existing knowledge and combine technologies and techniques in innovative ways that can address this imbalance.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02845"
  },
  "2312.02843": {
    "title": "Are Vision Transformers More Data Hungry Than Newborn Visual Systems?",
    "authors": [
      "Lalit Pandey",
      "Samantha M. W. Wood",
      "Justin N. Wood"
    ],
    "abstract": "Vision transformers (ViTs) are top performing models on many computer vision benchmarks and can accurately predict human behavior on object recognition tasks. However, researchers question the value of using ViTs as models of biological learning because ViTs are thought to be more data hungry than brains, with ViTs requiring more training data to reach similar levels of performance. To test this assumption, we directly compared the learning abilities of ViTs and animals, by performing parallel controlled rearing experiments on ViTs and newborn chicks. We first raised chicks in impoverished visual environments containing a single object, then simulated the training data available in those environments by building virtual animal chambers in a video game engine. We recorded the first-person images acquired by agents moving through the virtual chambers and used those images to train self supervised ViTs that leverage time as a teaching signal, akin to biological visual systems. When ViTs were trained through the eyes of newborn chicks, the ViTs solved the same view invariant object recognition tasks as the chicks. Thus, ViTs were not more data hungry than newborn visual systems: both learned view invariant object representations in impoverished visual environments. The flexible and generic attention based learning mechanism in ViTs combined with the embodied data streams available to newborn animals appears sufficient to drive the development of animal-like object recognition.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02843"
  },
  "2312.02839": {
    "title": "Low-complexity Linear Multicast Beamforming for Cache-aided MIMO Communications",
    "authors": [
      "Mohammad NaseriTehrani",
      "MohammadJavad Salehi",
      "Antti T\u00f6lli"
    ],
    "abstract": "A practical and scalable multicast beamformer design in multi-input multi-output~(MIMO) coded caching~(CC) systems is introduced in this paper. The proposed approach allows multicast transmission to multiple groups with partially overlapping user sets using receiver dimensions to distinguish between different group-specific streams. Additionally, it provides flexibility in accommodating various parameter configurations of the MIMO-CC setup and overcomes practical limitations, such as the requirement to use successive interference cancellation~(SIC) at the receiver, while achieving the same degrees-of-freedom~(DoF). To evaluate the proposed scheme, we define the symmetric rate as the sum rate of the partially overlapping streams received per user, comprising a linear multistream multicast transmission vector and the linear minimum mean square error~(LMMSE) receiver. The resulting non-convex symmetric rate maximization problem is solved using alternative optimization and successive convex approximation~(SCA). Moreover, a fast iterative Lagrangian-based algorithm is developed, significantly reducing the computational overhead compared to previous designs. The effectiveness of our proposed method is demonstrated by extensive simulations.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02839"
  },
  "2312.02831": {
    "title": "Detection of Seismic Infrasonic Elephant Rumbles Using Spectrogram-Based Machine Learning",
    "authors": [
      "A. M. J. V. Costa",
      "C. S. Pallikkonda",
      "H. H. R. Hiroshan",
      "G. R. U. Y. Gamlath",
      "S. R. Munasinghe",
      "C. U. S. Edussooriya"
    ],
    "abstract": "This paper presents an effective method of identifying elephant rumbles in infrasonic seismic signals. The design and implementation of electronic circuitry to amplify, filter, and digitize the seismic signals captured through geophones are presented. A collection of seismic infrasonic elephant rumbles was collected at a free-ranging area of an elephant orphanage in Sri Lanka. The seismic rumbles were converted to spectrograms, and several methods were used for spectral feature extraction. Using LasyPredict, the features extracted using different methods were fed into their corresponding machine-learning algorithms to train them for automatic seismic rumble identification. It was found that the Mel frequency cepstral coefficient (MFCC) together with the Ridge classifier machine learning algorithm produced the best performance in identifying seismic elephant rumbles. A novel method for denoising the spectrum that leads to enhanced accuracy in identifying seismic rumbles is also presented.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02831"
  },
  "2312.02829": {
    "title": "MIMONets: Multiple-Input-Multiple-Output Neural Networks Exploiting Computation in Superposition",
    "authors": [
      "Nicolas Menet",
      "Michael Hersche",
      "Geethan Karunaratne",
      "Luca Benini",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "abstract": "With the advent of deep learning, progressively larger neural networks have been designed to solve complex tasks. We take advantage of these capacity-rich models to lower the cost of inference by exploiting computation in superposition. To reduce the computational burden per input, we propose Multiple-Input-Multiple-Output Neural Networks (MIMONets) capable of handling many inputs at once. MIMONets augment various deep neural network architectures with variable binding mechanisms to represent an arbitrary number of inputs in a compositional data structure via fixed-width distributed representations. Accordingly, MIMONets adapt nonlinear neural transformations to process the data structure holistically, leading to a speedup nearly proportional to the number of superposed input items in the data structure. After processing in superposition, an unbinding mechanism recovers each transformed input of interest. MIMONets also provide a dynamic trade-off between accuracy and throughput by an instantaneous on-demand switching between a set of accuracy-throughput operating points, yet within a single set of fixed parameters. We apply the concept of MIMONets to both CNN and Transformer architectures resulting in MIMOConv and MIMOFormer, respectively. Empirical evaluations show that MIMOConv achieves about 2-4 x speedup at an accuracy delta within [+0.68, -3.18]% compared to WideResNet CNNs on CIFAR10 and CIFAR100. Similarly, MIMOFormer can handle 2-4 inputs at once while maintaining a high average accuracy within a [-1.07, -3.43]% delta on the long range arena benchmark. Finally, we provide mathematical bounds on the interference between superposition channels in MIMOFormer. Our code is available at https://github.com/IBM/multiple-input-multiple-output-nets.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02829"
  },
  "2312.02826": {
    "title": "Calibrated Adaptive Teacher for Domain Adaptive Intelligent Fault Diagnosis",
    "authors": [
      "Florent Forest",
      "Olga Fink"
    ],
    "abstract": "Intelligent Fault Diagnosis (IFD) based on deep learning has proven to be an effective and flexible solution, attracting extensive research. Deep neural networks can learn rich representations from vast amounts of representative labeled data for various applications. In IFD, they achieve high classification performance from signals in an end-to-end manner, without requiring extensive domain knowledge. However, deep learning models usually only perform well on the data distribution they have been trained on. When applied to a different distribution, they may experience performance drops. This is also observed in IFD, where assets are often operated in working conditions different from those in which labeled data have been collected. Unsupervised domain adaptation (UDA) deals with the scenario where labeled data are available in a source domain, and only unlabeled data are available in a target domain, where domains may correspond to operating conditions. Recent methods rely on training with confident pseudo-labels for target samples. However, the confidence-based selection of pseudo-labels is hindered by poorly calibrated confidence estimates in the target domain, primarily due to over-confident predictions, which limits the quality of pseudo-labels and leads to error accumulation. In this paper, we propose a novel UDA method called Calibrated Adaptive Teacher (CAT), where we propose to calibrate the predictions of the teacher network throughout the self-training process, leveraging post-hoc calibration techniques. We evaluate CAT on domain-adaptive IFD and perform extensive experiments on the Paderborn benchmark for bearing fault diagnosis under varying operating conditions. Our proposed method achieves state-of-the-art performance on most transfer tasks.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02826"
  },
  "2312.02821": {
    "title": "RotaTR: Detection Transformer for Dense and Rotated Object",
    "authors": [
      "Zhu Yuke",
      "Ruan Yumeng",
      "Yang Lei",
      "Guo Sheng"
    ],
    "abstract": "Detecting the objects in dense and rotated scenes is a challenging task. Recent works on this topic are mostly based on Faster RCNN or Retinanet. As they are highly dependent on the pre-set dense anchors and the NMS operation, the approach is indirect and suboptimal.The end-to-end DETR-based detectors have achieved great success in horizontal object detection and many other areas like segmentation, tracking, action recognition and etc.However, the DETR-based detectors perform poorly on dense rotated target tasks and perform worse than most modern CNN-based detectors. In this paper, we find the most significant reason for the poor performance is that the original attention can not accurately focus on the oriented targets. Accordingly, we propose Rotated object detection TRansformer (RotaTR) as an extension of DETR to oriented detection. Specifically, we design Rotation Sensitive deformable (RSDeform) attention to enhance the DETR's ability to detect oriented targets. It is used to build the feature alignment module and rotation-sensitive decoder for our model. We test RotaTR on four challenging-oriented benchmarks. It shows a great advantage in detecting dense and oriented objects compared to the original DETR. It also achieves competitive results when compared to the state-of-the-art.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02821"
  },
  "2312.02820": {
    "title": "Clustering Pseudo Language Family in Multilingual Translation Models with Fisher Information Matrix",
    "authors": [
      "Xinyu Ma",
      "Xuebo Liu",
      "Min Zhang"
    ],
    "abstract": "In multilingual translation research, the comprehension and utilization of language families are of paramount importance. Nevertheless, clustering languages based solely on their ancestral families can yield suboptimal results due to variations in the datasets employed during the model's training phase. To mitigate this challenge, we introduce an innovative method that leverages the fisher information matrix (FIM) to cluster language families, anchored on the multilingual translation model's characteristics. We hypothesize that language pairs with similar effects on model parameters exhibit a considerable degree of linguistic congruence and should thus be grouped cohesively. This concept has led us to define pseudo language families. We provide an in-depth discussion regarding the inception and application of these pseudo language families. Empirical evaluations reveal that employing these pseudo language families enhances performance over conventional language families in adapting a multilingual translation model to unfamiliar language pairs. The proposed methodology may also be extended to scenarios requiring language similarity measurements. The source code and associated scripts can be accessed at https://github.com/ecoli-hit/PseudoFamily.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02820"
  },
  "2312.02819": {
    "title": "Deterministic Guidance Diffusion Model for Probabilistic Weather Forecasting",
    "authors": [
      "Donggeun Yoon",
      "Minseok Seo",
      "Doyi Kim",
      "Yeji Choi",
      "Donghyeon Cho"
    ],
    "abstract": "Weather forecasting requires not only accuracy but also the ability to perform probabilistic prediction. However, deterministic weather forecasting methods do not support probabilistic predictions, and conversely, probabilistic models tend to be less accurate. To address these challenges, in this paper, we introduce the \\textbf{\\textit{D}}eterministic \\textbf{\\textit{G}}uidance \\textbf{\\textit{D}}iffusion \\textbf{\\textit{M}}odel (DGDM) for probabilistic weather forecasting, integrating benefits of both deterministic and probabilistic approaches. During the forward process, both the deterministic and probabilistic models are trained end-to-end. In the reverse process, weather forecasting leverages the predicted result from the deterministic model, using as an intermediate starting point for the probabilistic model. By fusing deterministic models with probabilistic models in this manner, DGDM is capable of providing accurate forecasts while also offering probabilistic predictions. To evaluate DGDM, we assess it on the global weather forecasting dataset (WeatherBench) and the common video frame prediction benchmark (Moving MNIST). We also introduce and evaluate the Pacific Northwest Windstorm (PNW)-Typhoon weather satellite dataset to verify the effectiveness of DGDM in high-resolution regional forecasting. As a result of our experiments, DGDM achieves state-of-the-art results not only in global forecasting but also in regional forecasting. The code is available at: \\url{https://github.com/DongGeun-Yoon/DGDM}.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02819"
  },
  "2312.02812": {
    "title": "Simulating Vision Impairment in Virtual Reality -- A Comparison of Visual Task Performance with Real and Simulated Tunnel Vision",
    "authors": [
      "Alexander Neugebauer",
      "Nora Castner",
      "Bj\u00f6rn Severitt",
      "Katarina Stingl",
      "Iliya Ivanov",
      "Siegfried Wahl"
    ],
    "abstract": "Purpose: In this work, we explore the potential and limitations of simulating gaze-contingent tunnel vision conditions using Virtual Reality (VR) with built-in eye tracking technology. This approach promises an easy and accessible way of expanding study populations and test groups for visual training, visual aids, or accessibility evaluations. However, it is crucial to assess the validity and reliability of simulating these types of visual impairments and evaluate the extend to which participants with simulated tunnel vision can represent real patients. Methods: Two age-matched participant groups were acquired: The first group (n=8 aged 20-60, average 49.1, sd 13.2) consisted of patients diagnosed with Retinitis pigmentosa (RP). The second group (n=8, aged 27-59, average 46.5, sd 10.8) consisted of visually healthy participants with simulated tunnel vision. Both groups carried out different visual tasks in a virtual environment for 30 minutes per day over the course of four weeks. Task performances as well as gaze characteristics were evaluated in both groups over the course of the study. Results: Using the \"two one-sided tests for equivalence\" method, the two groups were found to perform similar in all three visual tasks. Significant differences between groups were found in different aspects of their gaze behavior, though most of these aspects seem to converge over time. Conclusion: Our study evaluates the potential and limitations of using Virtual Reality technology to simulate the effects of tunnel vision within controlled virtual environments. We find that the simulation accurately represents performance of RP patients in the context of group averages, but fails to fully replicate effects on gaze behavior.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02812"
  },
  "2312.02810": {
    "title": "Using the SP!CE Framework to Code Influence Campaign Activity on Social Media: Case Study on the 2022 Brazilian Presidential Election",
    "authors": [
      "Alexander Gocso",
      "Claudia Perez Brito",
      "Bryan Ruesca",
      "Allen Mendes",
      "Mark A. Finlayson"
    ],
    "abstract": "We describe a case study in the use of the Structured Process for Information Campaign Enhancement (SP!CE, version 2.1) to evaluate influence campaigns present in the 2nd round of the Brazilian presidential election in 2022 October. SP!CE is a US-military focused framework for describing both friendly and adversary actions in influence campaigns, and is inter-operable with the Disinformation Analysis and Risk Management (DISARM) framework. The purpose of the case study is to demonstrate how SP!CE can be used to describe influence campaign behaviors. We selected the Brazilian election as the target of the case study as it is known that there were significant amounts of mis- and disinformation present on social media during the campaigns. Our goal was to demonstrate how SP!CE could be applied in such a context, showing how social media content could be aligned with information campaign behaviors and how such an alignment can be used to analyze which mis- and disinformation narratives were in play. Additionally, we aim to provide insights on best practices regarding how to apply the framework in further research. We release the coding and screenshots of the relevant social media posts to support future research.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02810"
  },
  "2312.02803": {
    "title": "Leveraging Domain Adaptation and Data Augmentation to Improve Qur'anic IR in English and Arabic",
    "authors": [
      "Vera Pavlova"
    ],
    "abstract": "In this work, we approach the problem of Qur'anic information retrieval (IR) in Arabic and English. Using the latest state-of-the-art methods in neural IR, we research what helps to tackle this task more efficiently. Training retrieval models requires a lot of data, which is difficult to obtain for training in-domain. Therefore, we commence with training on a large amount of general domain data and then continue training on in-domain data. To handle the lack of in-domain data, we employed a data augmentation technique, which considerably improved results in MRR@10 and NDCG@5 metrics, setting the state-of-the-art in Qur'anic IR for both English and Arabic. The absence of an Islamic corpus and domain-specific model for IR task in English motivated us to address this lack of resources and take preliminary steps of the Islamic corpus compilation and domain-specific language model (LM) pre-training, which helped to improve the performance of the retrieval models that use the domain-specific LM as the shared backbone. We examined several language models (LMs) in Arabic to select one that efficiently deals with the Qur'anic IR task. Besides transferring successful experiments from English to Arabic, we conducted additional experiments with retrieval task in Arabic to amortize the scarcity of general domain datasets used to train the retrieval models. Handling Qur'anic IR task combining English and Arabic allowed us to enhance the comparison and share valuable insights across models and languages.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02803"
  },
  "2312.02798": {
    "title": "Weakly Supervised Detection of Hallucinations in LLM Activations",
    "authors": [
      "Miriam Rateike",
      "Celia Cintas",
      "John Wamburu",
      "Tanya Akumu",
      "Skyler Speakman"
    ],
    "abstract": "We propose an auditing method to identify whether a large language model (LLM) encodes patterns such as hallucinations in its internal states, which may propagate to downstream tasks. We introduce a weakly supervised auditing technique using a subset scanning approach to detect anomalous patterns in LLM activations from pre-trained models. Importantly, our method does not need knowledge of the type of patterns a-priori. Instead, it relies on a reference dataset devoid of anomalies during testing. Further, our approach enables the identification of pivotal nodes responsible for encoding these patterns, which may offer crucial insights for fine-tuning specific sub-networks for bias mitigation. We introduce two new scanning methods to handle LLM activations for anomalous sentences that may deviate from the expected distribution in either direction. Our results confirm prior findings of BERT's limited internal capacity for encoding hallucinations, while OPT appears capable of encoding hallucination information internally. Importantly, our scanning approach, without prior exposure to false statements, performs comparably to a fully supervised out-of-distribution classifier.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02798"
  },
  "2312.02796": {
    "title": "Materials Expert-Artificial Intelligence for Materials Discovery",
    "authors": [
      "Yanjun Liu",
      "Milena Jovanovic",
      "Krishnanand Mallayya",
      "Wesley J. Maddox",
      "Andrew Gordon Wilson",
      "Sebastian Klemenz",
      "Leslie M. Schoop",
      "Eun-Ah Kim"
    ],
    "abstract": "The advent of material databases provides an unprecedented opportunity to uncover predictive descriptors for emergent material properties from vast data space. However, common reliance on high-throughput ab initio data necessarily inherits limitations of such data: mismatch with experiments. On the other hand, experimental decisions are often guided by an expert's intuition honed from experiences that are rarely articulated. We propose using machine learning to \"bottle\" such operational intuition into quantifiable descriptors using expertly curated measurement-based data. We introduce \"Materials Expert-Artificial Intelligence\" (ME-AI) to encapsulate and articulate this human intuition. As a first step towards such a program, we focus on the topological semimetal (TSM) among square-net materials as the property inspired by the expert-identified descriptor based on structural information: the tolerance factor. We start by curating a dataset encompassing 12 primary features of 879 square-net materials, using experimental data whenever possible. We then use Dirichlet-based Gaussian process regression using a specialized kernel to reveal composite descriptors for square-net topological semimetals. The ME-AI learned descriptors independently reproduce expert intuition and expand upon it. Specifically, new descriptors point to hypervalency as a critical chemical feature predicting TSM within square-net compounds. Our success with a carefully defined problem points to the \"machine bottling human insight\" approach as promising for machine learning-aided material discovery.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02796"
  },
  "2312.02790": {
    "title": "A Low-cost, High-impact Node Injection Approach for Attacking Social Network Alignment",
    "authors": [
      "Shuyu Jiang",
      "Yunxiang Qiu",
      "Xian Mo",
      "Rui Tang",
      "Wei Wang"
    ],
    "abstract": "Social network alignment (SNA) holds significant importance for various downstream applications, prompting numerous professionals to develop and share SNA tools. Unfortunately, these tools can be exploited by malicious actors to integrate sensitive user information, posing cybersecurity risks. While many researchers have explored attacking SNA (ASNA) through a network modification attack way, practical feasibility remains a challenge. This paper introduces a novel approach, the node injection attack. To overcome the problem of modeling and solving within a limited time and balancing costs and benefits, we propose a low-cost, high-impact node injection attack via dynamic programming (DPNIA) framework. DPNIA models ASNA as a problem of maximizing the number of confirmed incorrect correspondent node pairs who have a greater similarity scores than the pairs between existing nodes, making ASNA solvable. Meanwhile, it employs a cross-network evaluation method to identify node vulnerability, facilitating a progressive attack from easy to difficult. Additionally, it utilizes an optimal injection strategy searching method, based on dynamic programming, to determine which links should be added between injected nodes and existing nodes, thereby achieving a high impact for attack effectiveness at a low cost. Experiments on four real-world datasets consistently demonstrate that DPNIA consistently and significantly outperforms various attack baselines.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02790"
  },
  "2312.02786": {
    "title": "Machine Learning Driven Sensitivity Analysis of E3SM Land Model Parameters for Wetland Methane Emissions",
    "authors": [
      "Sandeep Chinta",
      "Xiang Gao",
      "Qing Zhu"
    ],
    "abstract": "Methane (CH4) is the second most critical greenhouse gas after carbon dioxide, contributing to 16-25% of the observed atmospheric warming. Wetlands are the primary natural source of methane emissions globally. However, wetland methane emission estimates from biogeochemistry models contain considerable uncertainty. One of the main sources of this uncertainty arises from the numerous uncertain model parameters within various physical, biological, and chemical processes that influence methane production, oxidation, and transport. Sensitivity Analysis (SA) can help identify critical parameters for methane emission and achieve reduced biases and uncertainties in future projections. This study performs SA for 19 selected parameters responsible for critical biogeochemical processes in the methane module of the Energy Exascale Earth System Model (E3SM) land model (ELM). The impact of these parameters on various CH4 fluxes is examined at 14 FLUXNET- CH4 sites with diverse vegetation types. Given the extensive number of model simulations needed for global variance-based SA, we employ a machine learning (ML) algorithm to emulate the complex behavior of ELM methane biogeochemistry. ML enables the computational time to be shortened significantly from 6 CPU hours to 0.72 milliseconds, achieving reduced computational costs. We found that parameters linked to CH4 production and diffusion generally present the highest sensitivities despite apparent seasonal variation. Comparing simulated emissions from perturbed parameter sets against FLUXNET-CH4 observations revealed that better performances can be achieved at each site compared to the default parameter values. This presents a scope for further improving simulated emissions using parameter calibration with advanced optimization techniques like Bayesian optimization.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02786"
  },
  "2312.02781": {
    "title": "PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo Multi-modal Features",
    "authors": [
      "Tianshun Han",
      "Shengnan Gui",
      "Yiqing Huang",
      "Baihui Li",
      "Lijian Liu",
      "Benjia Zhou",
      "Ning Jiang",
      "Quan Lu",
      "Ruicong Zhi",
      "Yanyan Liang",
      "Du Zhang",
      "Jun Wan"
    ],
    "abstract": "Speech-driven 3D facial animation has improved a lot recently while most related works only utilize acoustic modality and neglect the influence of visual and textual cues, leading to unsatisfactory results in terms of precision and coherence. We argue that visual and textual cues are not trivial information. Therefore, we present a novel framework, namely PMMTalk, using complementary Pseudo Multi-Modal features for improving the accuracy of facial animation. The framework entails three modules: PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder. Specifically, the PMMTalk encoder employs the off-the-shelf talking head generation architecture and speech recognition technology to extract visual and textual information from speech, respectively. Subsequently, the cross-modal alignment module aligns the audio-image-text features at temporal and semantic levels. Then PMMTalk decoder is employed to predict lip-syncing facial blendshape coefficients. Contrary to prior methods, PMMTalk only requires an additional random reference face image but yields more accurate results. Additionally, it is artist-friendly as it seamlessly integrates into standard animation production workflows by introducing facial blendshape coefficients. Finally, given the scarcity of 3D talking face datasets, we introduce a large-scale 3D Chinese Audio-Visual Facial Animation (3D-CAVFA) dataset. Extensive experiments and user studies show that our approach outperforms the state of the art. We recommend watching the supplementary video.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02781"
  },
  "2312.02780": {
    "title": "Scaling Laws for Adversarial Attacks on Language Model Activations",
    "authors": [
      "Stanislav Fort"
    ],
    "abstract": "We explore a class of adversarial attacks targeting the activations of language models. By manipulating a relatively small subset of model activations, $a$, we demonstrate the ability to control the exact prediction of a significant number (in some cases up to 1000) of subsequent tokens $t$. We empirically verify a scaling law where the maximum number of target tokens $t_\\mathrm{max}$ predicted depends linearly on the number of tokens $a$ whose activations the attacker controls as $t_\\mathrm{max} = \u03baa$. We find that the number of bits of control in the input space needed to control a single bit in the output space (what we call attack resistance $\u03c7$) is remarkably constant between $\\approx 16$ and $\\approx 25$ over 2 orders of magnitude of model sizes for different language models. Compared to attacks on tokens, attacks on activations are predictably much stronger, however, we identify a surprising regularity where one bit of input steered either via activations or via tokens is able to exert control over a similar amount of output bits. This gives support for the hypothesis that adversarial attacks are a consequence of dimensionality mismatch between the input and output spaces. A practical implication of the ease of attacking language model activations instead of tokens is for multi-modal and selected retrieval models, where additional data sources are added as activations directly, sidestepping the tokenized input. This opens up a new, broad attack surface. By using language models as a controllable test-bed to study adversarial attacks, we were able to experiment with input-output dimensions that are inaccessible in computer vision, especially where the output dimension dominates.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02780"
  },
  "2312.02776": {
    "title": "On Age of Information and Energy-Transfer in a STAR-RIS-assisted System",
    "authors": [
      "Mohammad Reza Kavianinia",
      "Mohammad Mehdi Setoode",
      "Mohammad Javad Emadi"
    ],
    "abstract": "Battery-limited devices and time-sensitive applications are considered as key players in the forthcoming wireless sensor network. Therefore, the main goal of the network is two-fold; Charge battery-limited devices, and provide status updates to users where information-freshness matters. In this paper, a multi-antenna base station (BS) in assistance of simultaneously-transmitting-and-reflecting reconfigurable intelligent surface (STAR-RIS) transmits power to energy-harvesting devices while controlling status update performance at information-users by analyzing age of information (AoI) metric. Therefore, we derive a scheduling policy at BS, and analyze joint transmit beamforming and amplitude-phase optimization at BS and STAR-RIS, respectively, to reduce average sum-AoI for the time-sensitive information-users while satisfying minimum required energy at energy-harvesting users. Moreover, two different energy-splitting and mode switching policies at STAR-RIS are studied. Then, by use of an alternating optimization algorithm, the optimization problem is studied and non-convexity of the problem is tackled by using the successive convex approximation technique. Through numerical results, AoI-metric and energy harvesting requirements of the network are analyzed versus different parameters such as number of antennas at BS, size of STAR-RIS, and transmitted power to highlight how we can improve two fold performance of the system by utilizing STAR-RIS compared to the conventional RIS structure.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02776"
  },
  "2312.02773": {
    "title": "Integrating Plug-and-Play Data Priors with Weighted Prediction Error for Speech Dereverberation",
    "authors": [
      "Ziye Yang",
      "Wenxing Yang",
      "Kai Xie",
      "Jie Chen"
    ],
    "abstract": "Speech dereverberation aims to alleviate the detrimental effects of late-reverberant components. While the weighted prediction error (WPE) method has shown superior performance in dereverberation, there is still room for further improvement in terms of performance and robustness in complex and noisy environments. Recent research has highlighted the effectiveness of integrating physics-based and data-driven methods, enhancing the performance of various signal processing tasks while maintaining interpretability. Motivated by these advancements, this paper presents a novel dereverberation frame-work, which incorporates data-driven methods for capturing speech priors within the WPE framework. The plug-and-play strategy (PnP), specifically the regularization by denoising (RED) strategy, is utilized to incorporate speech prior information learnt from data during the optimization problem solving iterations. Experimental results validate the effectiveness of the proposed approach.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02773"
  },
  "2312.02771": {
    "title": "Scaling-up Memristor Monte Carlo with magnetic domain-wall physics",
    "authors": [
      "Thomas Dalgaty",
      "Shogo Yamada",
      "Anca Molnos",
      "Eiji Kawasaki",
      "Thomas Mesquida",
      "Fran\u00e7ois Rummens",
      "Tatsuo Shibata",
      "Yukihiro Urakawa",
      "Yukio Terasaki",
      "Tomoyuki Sasaki",
      "Marc Duranton"
    ],
    "abstract": "By exploiting the intrinsic random nature of nanoscale devices, Memristor Monte Carlo (MMC) is a promising enabler of edge learning systems. However, due to multiple algorithmic and device-level limitations, existing demonstrations have been restricted to very small neural network models and datasets. We discuss these limitations, and describe how they can be overcome, by mapping the stochastic gradient Langevin dynamics (SGLD) algorithm onto the physics of magnetic domain-wall Memristors to scale-up MMC models by five orders of magnitude. We propose the push-pull pulse programming method that realises SGLD in-physics, and use it to train a domain-wall based ResNet18 on the CIFAR-10 dataset. On this task, we observe no performance degradation relative to a floating point model down to an update precision of between 6 and 7-bits, indicating we have made a step towards a large-scale edge learning system leveraging noisy analogue devices.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02771"
  },
  "2312.02770": {
    "title": "Learning \"Look-Ahead\" Nonlocal Traffic Dynamics in a Ring Road",
    "authors": [
      "Chenguang Zhao",
      "Huan Yu"
    ],
    "abstract": "The macroscopic traffic flow model is widely used for traffic control and management. To incorporate drivers' anticipative behaviors and to remove impractical speed discontinuity inherent in the classic Lighthill-Whitham-Richards (LWR) traffic model, nonlocal partial differential equation (PDE) models with ``look-ahead\" dynamics have been proposed, which assume that the speed is a function of weighted downstream traffic density. However, it lacks data validation on two important questions: whether there exist nonlocal dynamics, and how the length and weight of the ``look-ahead\" window affect the spatial temporal propagation of traffic densities. In this paper, we adopt traffic trajectory data from a ring-road experiment and design a physics-informed neural network to learn the fundamental diagram and look-ahead kernel that best fit the data, and reinvent a data-enhanced nonlocal LWR model via minimizing the loss function combining the data discrepancy and the nonlocal model discrepancy. Results show that the learned nonlocal LWR yields a more accurate prediction of traffic wave propagation in three different scenarios: stop-and-go oscillations, congested, and free traffic. We first demonstrate the existence of ``look-ahead\" effect with real traffic data. The optimal nonlocal kernel is found out to take a length of around 35 to 50 meters, and the kernel weight within 5 meters accounts for the majority of the nonlocal effect. Our results also underscore the importance of choosing a priori physics in machine learning models.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02770"
  },
  "2312.02769": {
    "title": "Blockchain Participation Games",
    "authors": [
      "Pyrros Chaidos",
      "Aggelos Kiayias",
      "Evangelos Markakis"
    ],
    "abstract": "We study game-theoretic models for capturing participation in blockchain systems. Permissionless blockchains can be naturally viewed as games, where a set of potentially interested users is faced with the dilemma of whether to engage with the protocol or not. Engagement here implies that the user will be asked to complete certain tasks, whenever they are selected to contribute (typically according to some stochastic process) and be rewarded if they choose to do so. Apart from the basic dilemma of engaging or not, even more strategic considerations arise in settings where users may be able to declare participation and then retract before completing their tasks (but are still able to receive rewards) or are rewarded independently of whether they contribute. Such variations occur naturally in the blockchain setting due to the complexity of tracking ``on-chain'' the behavior of the participants.\n  We capture these participation considerations offering a series of models that enable us to reason about the basic dilemma, the case where retraction effects influence the outcome and the case when payments are given universally irrespective of the stochastic process. In all cases we provide characterization results or necessary conditions on the structure of Nash equilibria. Our findings reveal that appropriate reward mechanisms can be used to stimulate participation and avoid negative effects of free riding, results that are in line but also can inform real world blockchain system deployments.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02769"
  },
  "2312.02756": {
    "title": "GenVectorX: A performance-portable SYCL library for Lorentz Vectors operations",
    "authors": [
      "Monica Dessole",
      "Jolly Chen",
      "Axel Naumann"
    ],
    "abstract": "The Large Hadron Collider (LHC) at CERN will see an upgraded hardware configuration which will bring a new era of physics data taking and related computational challenges. To this end, it is necessary to exploit the ever increasing variety of computational architectures, featuring GPUs from multiple vendors and new accelerators. Performance portable frameworks, like SYCL, allow to offload the computational work on non-CPU resources, while retaining their performance, without the need to maintain different implementations of the same code. The High Energy Physics (HEP) community employs a wide variety of algorithms and tools for accelerators, but it still lacks a streamlined coherent approach that can target many use cases without compromising the usability aspect. In this paper, we present our efforts in creating GenVectorX, a C++ package that provides classes and functionalities to represent and manipulate particle events using the SYCL programming model. The SYCL-based implementation exhibits comparable performance and scalability as the CUDA implementation when targeting NVIDIA GPUs.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02756"
  },
  "2312.02753": {
    "title": "C3: High-performance and low-complexity neural compression from a single image or video",
    "authors": [
      "Hyunjik Kim",
      "Matthias Bauer",
      "Lucas Theis",
      "Jonathan Richard Schwarz",
      "Emilien Dupont"
    ],
    "abstract": "Most neural compression models are trained on large datasets of images or videos in order to generalize to unseen data. Such generalization typically requires large and expressive architectures with a high decoding complexity. Here we introduce C3, a neural compression method with strong rate-distortion (RD) performance that instead overfits a small model to each image or video separately. The resulting decoding complexity of C3 can be an order of magnitude lower than neural baselines with similar RD performance. C3 builds on COOL-CHIC (Ladune et al.) and makes several simple and effective improvements for images. We further develop new methodology to apply C3 to videos. On the CLIC2020 image benchmark, we match the RD performance of VTM, the reference implementation of the H.266 codec, with less than 3k MACs/pixel for decoding. On the UVG video benchmark, we match the RD performance of the Video Compression Transformer (Mentzer et al.), a well-established neural video codec, with less than 5k MACs/pixel for decoding.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02753"
  },
  "2312.02751": {
    "title": "C-NERF: Representing Scene Changes as Directional Consistency Difference-based NeRF",
    "authors": [
      "Rui Huang",
      "Binbin Jiang",
      "Qingyi Zhao",
      "William Wang",
      "Yuxiang Zhang",
      "Qing Guo"
    ],
    "abstract": "In this work, we aim to detect the changes caused by object variations in a scene represented by the neural radiance fields (NeRFs). Given an arbitrary view and two sets of scene images captured at different timestamps, we can predict the scene changes in that view, which has significant potential applications in scene monitoring and measuring. We conducted preliminary studies and found that such an exciting task cannot be easily achieved by utilizing existing NeRFs and 2D change detection methods with many false or missing detections. The main reason is that the 2D change detection is based on the pixel appearance difference between spatial-aligned image pairs and neglects the stereo information in the NeRF. To address the limitations, we propose the C-NERF to represent scene changes as directional consistency difference-based NeRF, which mainly contains three modules. We first perform the spatial alignment of two NeRFs captured before and after changes. Then, we identify the change points based on the direction-consistent constraint; that is, real change points have similar change representations across view directions, but fake change points do not. Finally, we design the change map rendering process based on the built NeRFs and can generate the change map of an arbitrarily specified view direction. To validate the effectiveness, we build a new dataset containing ten scenes covering diverse scenarios with different changing objects. Our approach surpasses state-of-the-art 2D change detection and NeRF-based methods by a significant margin.\n        \u25b3 Less",
    "submission_date": "23 December, 2023",
    "eprint_id": "2312.02751"
  },
  "2312.02748": {
    "title": "Compositional Generalization for Data-to-Text Generation",
    "authors": [
      "Xinnuo Xu",
      "Ivan Titov",
      "Mirella Lapata"
    ],
    "abstract": "Data-to-text generation involves transforming structured data, often represented as predicate-argument tuples, into coherent textual descriptions. Despite recent advances, systems still struggle when confronted with unseen combinations of predicates, producing unfaithful descriptions (e.g. hallucinations or omissions). We refer to this issue as compositional generalisation, and it encouraged us to create a benchmark for assessing the performance of different approaches on this specific problem. Furthermore, we propose a novel model that addresses compositional generalization by clustering predicates into groups. Our model generates text in a sentence-by-sentence manner, relying on one cluster of predicates at a time. This approach significantly outperforms T5~baselines across all evaluation metrics.Notably, it achieved a 31% improvement over T5 in terms of a metric focused on maintaining faithfulness to the input.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02748"
  },
  "2312.02746": {
    "title": "Empowering the 6G Cellular Architecture with Open RAN",
    "authors": [
      "Michele Polese",
      "Mischa Dohler",
      "Falko Dressler",
      "Melike Erol-Kantarci",
      "Rittwik Jana",
      "Raymond Knopp",
      "Tommaso Melodia"
    ],
    "abstract": "Innovation and standardization in 5G have brought advancements to every facet of the cellular architecture. This ranges from the introduction of new frequency bands and signaling technologies for the radio access network (RAN), to a core network underpinned by micro-services and network function virtualization (NFV). However, like any emerging technology, the pace of real-world deployments does not instantly match the pace of innovation. To address this discrepancy, one of the key aspects under continuous development is the RAN with the aim of making it more open, adaptive, functional, and easy to manage. In this paper, we highlight the transformative potential of embracing novel cellular architectures by transitioning from conventional systems to the progressive principles of Open RAN. This promises to make 6G networks more agile, cost-effective, energy-efficient, and resilient. It opens up a plethora of novel use cases, ranging from ubiquitous support for autonomous devices to cost-effective expansions in regions previously underserved. The principles of Open RAN encompass: (i) a disaggregated architecture with modular and standardized interfaces; (ii) cloudification, programmability and orchestration; and (iii) AI-enabled data-centric closed-loop control and automation. We first discuss the transformative role Open RAN principles have played in the 5G era. Then, we adopt a system-level approach and describe how these Open RAN principles will support 6G RAN and architecture innovation. We qualitatively discuss potential performance gains that Open RAN principles yield for specific 6G use cases. For each principle, we outline the steps that research, development and standardization communities ought to take to make Open RAN principles central to next-generation cellular network designs.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02746"
  },
  "2312.02730": {
    "title": "Towards Measuring Representational Similarity of Large Language Models",
    "authors": [
      "Max Klabunde",
      "Mehdi Ben Amor",
      "Michael Granitzer",
      "Florian Lemmerich"
    ],
    "abstract": "Understanding the similarity of the numerous released large language models (LLMs) has many uses, e.g., simplifying model selection, detecting illegal model reuse, and advancing our understanding of what makes LLMs perform well. In this work, we measure the similarity of representations of a set of LLMs with 7B parameters. Our results suggest that some LLMs are substantially different from others. We identify challenges of using representational similarity measures that suggest the need of careful study of similarity scores to avoid false conclusions.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02730"
  },
  "2312.02728": {
    "title": "Overview of RIS-Enabled Secure Transmission in 6G Wireless Networks",
    "authors": [
      "JungSook Bae",
      "Waqas Khalid",
      "Anseok Lee",
      "Heesoo Lee",
      "Song Noh",
      "Heejung Yu"
    ],
    "abstract": "As sixth-generation (6G) wireless communication networks evolve, privacy concerns are expected due to the transmission of vast amounts of security-sensitive private information. In this context, a reconfigurable intelligent surface (RIS) emerges as a promising technology capable of enhancing transmission efficiency and strengthening information security. This study demonstrates how RISs can play a crucial role in making 6G networks more secure against eavesdropping attacks. We discuss the fundamentals, and standardization aspects of RISs, along with an in-depth analysis of physical-layer security (PLS). Our discussion centers on PLS design using RIS, highlighting aspects like beamforming, resource allocation, artificial noise, and cooperative communications. We also identify the research issues, propose potential solutions, and explore future perspectives. Finally, numerical results are provided to support our discussions and demonstrate the enhanced security enabled by RIS.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02728"
  },
  "2312.02724": {
    "title": "RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!",
    "authors": [
      "Ronak Pradeep",
      "Sahel Sharifymoghaddam",
      "Jimmy Lin"
    ],
    "abstract": "In information retrieval, proprietary large language models (LLMs) such as GPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital role in reranking. However, the gap between open-source and closed models persists, with reliance on proprietary, non-transparent models constraining reproducibility. Addressing this gap, we introduce RankZephyr, a state-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr not only bridges the effectiveness gap with GPT-4 but in some cases surpasses the proprietary model. Our comprehensive evaluations across several datasets (TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability. RankZephyr benefits from strategic training choices and is resilient against variations in initial document ordering and the number of documents reranked. Additionally, our model outperforms GPT-4 on the NovelEval test set, comprising queries and passages past its training period, which addresses concerns about data contamination. To foster further research in this rapidly evolving field, we provide all code necessary to reproduce our results at https://github.com/castorini/rank_llm.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02724"
  },
  "2312.02722": {
    "title": "Improved Algorithms for Minimum-Membership Geometric Set Cover",
    "authors": [
      "Sathish Govindarajan",
      "Siddhartha Sarkar"
    ],
    "abstract": "Bandyapadhyay et al. introduced the generalized minimum-membership geometric set cover (GMMGSC) problem [SoCG, 2023], which is defined as follows. We are given two sets $P$ and $P'$ of points in $\\mathbb{R}^{2}$, $n=\\max(|P|, |P'|)$, and a set $\\mathcal{S}$ of $m$ axis-parallel unit squares. The goal is to find a subset $\\mathcal{S}^{*}\\subseteq \\mathcal{S}$ that covers all the points in $P$ while minimizing $\\mathsf{memb}(P', \\mathcal{S}^{*})$, where $\\mathsf{memb}(P', \\mathcal{S}^{*})=\\max_{p\\in P'}|\\{s\\in \\mathcal{S}^{*}: p\\in s\\}|$. We study GMMGSC problem and give a $16$-approximation algorithm that runs in $O(m^2\\log m + m^2n)$ time. Our result is a significant improvement to the $144$-approximation given by Bandyapadhyay et al. that runs in $\\tilde{O}(nm)$ time.\n  GMMGSC problem is a generalization of another well-studied problem called Minimum Ply Geometric Set Cover (MPGSC), in which the goal is to minimize the ply of $\\mathcal{S}^{*}$, where the ply is the maximum cardinality of a subset of the unit squares that have a non-empty intersection. The best-known result for the MPGSC problem is an $8$-approximation algorithm by Durocher et al. that runs in $O(n + m^{8}k^{4}\\log k + m^{8}\\log m\\log k)$ time, where $k$ is the optimal ply value [WALCOM, 2023].\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02722"
  },
  "2312.02720": {
    "title": "Towards the Inferrence of Structural Similarity of Combinatorial Landscapes",
    "authors": [
      "Mingyu Huang",
      "Ke Li"
    ],
    "abstract": "One of the most common problem-solving heuristics is by analogy. For a given problem, a solver can be viewed as a strategic walk on its fitness landscape. Thus if a solver works for one problem instance, we expect it will also be effective for other instances whose fitness landscapes essentially share structural similarities with each other. However, due to the black-box nature of combinatorial optimization, it is far from trivial to infer such similarity in real-world scenarios. To bridge this gap, by using local optima network as a proxy of fitness landscapes, this paper proposed to leverage graph data mining techniques to conduct qualitative and quantitative analyses to explore the latent topological structural information embedded in those landscapes. By conducting large-scale empirical experiments on three classic combinatorial optimization problems, we gain concrete evidence to support the existence of structural similarity between landscapes of the same classes within neighboring dimensions. We also interrogated the relationship between landscapes of different problem classes.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02720"
  },
  "2312.02719": {
    "title": "A Conditional Denoising Diffusion Probabilistic Model for Point Cloud Upsampling",
    "authors": [
      "Wentao Qu",
      "Yuantian Shao",
      "Lingwu Meng",
      "Xiaoshui Huang",
      "Liang Xiao"
    ],
    "abstract": "Point cloud upsampling (PCU) enriches the representation of raw point clouds, significantly improving the performance in downstream tasks such as classification and reconstruction. Most of the existing point cloud upsampling methods focus on sparse point cloud feature extraction and upsampling module design. In a different way, we dive deeper into directly modelling the gradient of data distribution from dense point clouds. In this paper, we proposed a conditional denoising diffusion probability model (DDPM) for point cloud upsampling, called PUDM. Specifically, PUDM treats the sparse point cloud as a condition, and iteratively learns the transformation relationship between the dense point cloud and the noise. Simultaneously, PUDM aligns with a dual mapping paradigm to further improve the discernment of point features. In this context, PUDM enables learning complex geometry details in the ground truth through the dominant features, while avoiding an additional upsampling module design. Furthermore, to generate high-quality arbitrary-scale point clouds during inference, PUDM exploits the prior knowledge of the scale between sparse point clouds and dense point clouds during training by parameterizing a rate factor. Moreover, PUDM exhibits strong noise robustness in experimental results. In the quantitative and qualitative evaluations on PU1K and PUGAN, PUDM significantly outperformed existing methods in terms of Chamfer Distance (CD) and Hausdorff Distance (HD), achieving state of the art (SOTA) performance.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02719"
  },
  "2312.02711": {
    "title": "HARMONIOUS -- Human-like reactive motion control and multimodal perception for humanoid robots",
    "authors": [
      "Jakub Rozlivek",
      "Alessandro Roncone",
      "Ugo Pattacini",
      "Matej Hoffmann"
    ],
    "abstract": "For safe and effective operation of humanoid robots in human-populated environments, the problem of commanding a large number of Degrees of Freedom (DoF) while simultaneously considering dynamic obstacles and human proximity has still not been solved. We present a new reactive motion controller that commands two arms of a humanoid robot and three torso joints (17 DoF in total). We formulate a quadratic program that seeks joint velocity commands respecting multiple constraints while minimizing the magnitude of the velocities. We introduce a new unified treatment of obstacles that dynamically maps visual and proximity (pre-collision) and tactile (post-collision) obstacles as additional constraints to the motion controller, in a distributed fashion over surface of the upper-body of the iCub robot (with 2000 pressure-sensitive receptors). The bio-inspired controller: (i) produces human-like minimum jerk movement profiles; (ii) gives rise to a robot with whole-body visuo-tactile awareness, resembling peripersonal space representations. The controller was extensively experimentally validated, including a physical human-robot interaction scenario.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02711"
  },
  "2312.02710": {
    "title": "User Interaction Data in Apps: Comparing Policy Claims to Implementations",
    "authors": [
      "Feiyang Tang",
      "Bjarte M. \u00d8stvold"
    ],
    "abstract": "As mobile app usage continues to rise, so does the generation of extensive user interaction data, which includes actions such as swiping, zooming, or the time spent on a screen. Apps often collect a large amount of this data and claim to anonymize it, yet concerns arise regarding the adequacy of these measures. In many cases, the so-called anonymized data still has the potential to profile and, in some instances, re-identify individual users. This situation is compounded by a lack of transparency, leading to potential breaches of user trust.\n  Our work investigates the gap between privacy policies and actual app behavior, focusing on the collection and handling of user interaction data. We analyzed the top 100 apps across diverse categories using static analysis methods to evaluate the alignment between policy claims and implemented data collection techniques. Our findings highlight the lack of transparency in data collection and the associated risk of re-identification, raising concerns about user privacy and trust. This study emphasizes the importance of clear communication and enhanced transparency in privacy practices for mobile app development.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02710"
  },
  "2312.02708": {
    "title": "Provable Adversarial Robustness for Group Equivariant Tasks: Graphs, Point Clouds, Molecules, and More",
    "authors": [
      "Jan Schuchardt",
      "Yan Scholten",
      "Stephan G\u00fcnnemann"
    ],
    "abstract": "A machine learning model is traditionally considered robust if its prediction remains (almost) constant under input perturbations with small norm. However, real-world tasks like molecular property prediction or point cloud segmentation have inherent equivariances, such as rotation or permutation equivariance. In such tasks, even perturbations with large norm do not necessarily change an input's semantic content. Furthermore, there are perturbations for which a model's prediction explicitly needs to change. For the first time, we propose a sound notion of adversarial robustness that accounts for task equivariance. We then demonstrate that provable robustness can be achieved by (1) choosing a model that matches the task's equivariances (2) certifying traditional adversarial robustness. Certification methods are, however, unavailable for many models, such as those with continuous equivariances. We close this gap by developing the framework of equivariance-preserving randomized smoothing, which enables architecture-agnostic certification. We additionally derive the first architecture-specific graph edit distance certificates, i.e. sound robustness guarantees for isomorphism equivariant tasks like node classification. Overall, a sound notion of robustness is an important prerequisite for future work at the intersection of robust and geometric machine learning.\n        \u25b3 Less",
    "submission_date": "15 January, 2024",
    "eprint_id": "2312.02708"
  },
  "2312.02705": {
    "title": "Unified learning-based lossy and lossless JPEG recompression",
    "authors": [
      "Jianghui Zhang",
      "Yuanyuan Wang",
      "Lina Guo",
      "Jixiang Luo",
      "Tongda Xu",
      "Yan Wang",
      "Zhi Wang",
      "Hongwei Qin"
    ],
    "abstract": "JPEG is still the most widely used image compression algorithm. Most image compression algorithms only consider uncompressed original image, while ignoring a large number of already existing JPEG images. Recently, JPEG recompression approaches have been proposed to further reduce the size of JPEG files. However, those methods only consider JPEG lossless recompression, which is just a special case of the rate-distortion theorem. In this paper, we propose a unified lossly and lossless JPEG recompression framework, which consists of learned quantization table and Markovian hierarchical variational autoencoders. Experiments show that our method can achieve arbitrarily low distortion when the bitrate is close to the upper bound, namely the bitrate of the lossless compression model. To the best of our knowledge, this is the first learned method that bridges the gap between lossy and lossless recompression of JPEG images.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02705"
  },
  "2312.02703": {
    "title": "MyPortrait: Morphable Prior-Guided Personalized Portrait Generation",
    "authors": [
      "Bo Ding",
      "Zhenfeng Fan",
      "Shuang Yang",
      "Shihong Xia"
    ],
    "abstract": "Generating realistic talking faces is an interesting and long-standing topic in the field of computer vision. Although significant progress has been made, it is still challenging to generate high-quality dynamic faces with personalized details. This is mainly due to the inability of the general model to represent personalized details and the generalization problem to unseen controllable parameters. In this work, we propose Myportrait, a simple, general, and flexible framework for neural portrait generation. We incorporate personalized prior in a monocular video and morphable prior in 3D face morphable space for generating personalized details under novel controllable parameters. Our proposed framework supports both video-driven and audio-driven face animation given a monocular video of a single person. Distinguished by whether the test data is sent to training or not, our method provides a real-time online version and a high-quality offline version. Comprehensive experiments in various metrics demonstrate the superior performance of our method over the state-of-the-art methods. The code will be publicly available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02703"
  },
  "2312.02699": {
    "title": "Enhancing Vehicle Entrance and Parking Management: Deep Learning Solutions for Efficiency and Security",
    "authors": [
      "Muhammad Umer Ramzan",
      "Usman Ali",
      "Syed Haider Abbas Naqvi",
      "Zeeshan Aslam",
      "Tehseen",
      "Husnain Ali",
      "Muhammad Faheem"
    ],
    "abstract": "The auto-management of vehicle entrance and parking in any organization is a complex challenge encompassing record-keeping, efficiency, and security concerns. Manual methods for tracking vehicles and finding parking spaces are slow and a waste of time. To solve the problem of auto management of vehicle entrance and parking, we have utilized state-of-the-art deep learning models and automated the process of vehicle entrance and parking into any organization. To ensure security, our system integrated vehicle detection, license number plate verification, and face detection and recognition models to ensure that the person and vehicle are registered with the organization. We have trained multiple deep-learning models for vehicle detection, license number plate detection, face detection, and recognition, however, the YOLOv8n model outperformed all the other models. Furthermore, License plate recognition is facilitated by Google's Tesseract-OCR Engine. By integrating these technologies, the system offers efficient vehicle detection, precise identification, streamlined record keeping, and optimized parking slot allocation in buildings, thereby enhancing convenience, accuracy, and security. Future research opportunities lie in fine-tuning system performance for a wide range of real-world applications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02699"
  },
  "2312.02697": {
    "title": "Hierarchical Visual Policy Learning for Long-Horizon Robot Manipulation in Densely Cluttered Scenes",
    "authors": [
      "Hecheng Wang",
      "Lizhe Qi",
      "Bin Fang",
      "Yunquan Sun"
    ],
    "abstract": "In this work, we focus on addressing the long-horizon manipulation tasks in densely cluttered scenes. Such tasks require policies to effectively manage severe occlusions among objects and continually produce actions based on visual observations. We propose a vision-based Hierarchical policy for Cluttered-scene Long-horizon Manipulation (HCLM). It employs a high-level policy and three options to select and instantiate three parameterized action primitives: push, pick, and place. We first train the pick and place options by behavior cloning (BC). Subsequently, we use hierarchical reinforcement learning (HRL) to train the high-level policy and push option. During HRL, we propose a Spatially Extended Q-update (SEQ) to augment the updates for the push option and a Two-Stage Update Scheme (TSUS) to alleviate the non-stationary transition problem in updating the high-level policy. We demonstrate that HCLM significantly outperforms baseline methods in terms of success rate and efficiency in diverse tasks. We also highlight our method's ability to generalize to more cluttered environments with more additional blocks.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02697"
  },
  "2312.02694": {
    "title": "UPOCR: Towards Unified Pixel-Level OCR Interface",
    "authors": [
      "Dezhi Peng",
      "Zhenhua Yang",
      "Jiaxin Zhang",
      "Chongyu Liu",
      "Yongxin Shi",
      "Kai Ding",
      "Fengjun Guo",
      "Lianwen Jin"
    ],
    "abstract": "In recent years, the optical character recognition (OCR) field has been proliferating with plentiful cutting-edge approaches for a wide spectrum of tasks. However, these approaches are task-specifically designed with divergent paradigms, architectures, and training strategies, which significantly increases the complexity of research and maintenance and hinders the fast deployment in applications. To this end, we propose UPOCR, a simple-yet-effective generalist model for Unified Pixel-level OCR interface. Specifically, the UPOCR unifies the paradigm of diverse OCR tasks as image-to-image transformation and the architecture as a vision Transformer (ViT)-based encoder-decoder. Learnable task prompts are introduced to push the general feature representations extracted by the encoder toward task-specific spaces, endowing the decoder with task awareness. Moreover, the model training is uniformly aimed at minimizing the discrepancy between the generated and ground-truth images regardless of the inhomogeneity among tasks. Experiments are conducted on three pixel-level OCR tasks including text removal, text segmentation, and tampered text detection. Without bells and whistles, the experimental results showcase that the proposed method can simultaneously achieve state-of-the-art performance on three tasks with a unified single model, which provides valuable strategies and insights for future research on generalist OCR models. Code will be publicly available.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02694"
  },
  "2312.02684": {
    "title": "DeepPointMap: Advancing LiDAR SLAM with Unified Neural Descriptors",
    "authors": [
      "Xiaze Zhang",
      "Ziheng Ding",
      "Qi Jing",
      "Yuejie Zhang",
      "Wenchao Ding",
      "Rui Feng"
    ],
    "abstract": "Point clouds have shown significant potential in various domains, including Simultaneous Localization and Mapping (SLAM). However, existing approaches either rely on dense point clouds to achieve high localization accuracy or use generalized descriptors to reduce map size. Unfortunately, these two aspects seem to conflict with each other. To address this limitation, we propose a unified architecture, DeepPointMap, achieving excellent preference on both aspects. We utilize neural network to extract highly representative and sparse neural descriptors from point clouds, enabling memory-efficient map representation and accurate multi-scale localization tasks (e.g., odometry and loop-closure). Moreover, we showcase the versatility of our framework by extending it to more challenging multi-agent collaborative SLAM. The promising results obtained in these scenarios further emphasize the effectiveness and potential of our approach.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02684"
  },
  "2312.02683": {
    "title": "Diffusion-Based Speech Enhancement in Matched and Mismatched Conditions Using a Heun-Based Sampler",
    "authors": [
      "Philippe Gonzalez",
      "Zheng-Hua Tan",
      "Jan \u00d8stergaard",
      "Jesper Jensen",
      "Tommy Sonne Alstr\u00f8m",
      "Tobias May"
    ],
    "abstract": "Diffusion models are a new class of generative models that have recently been applied to speech enhancement successfully. Previous works have demonstrated their superior performance in mismatched conditions compared to state-of-the art discriminative models. However, this was investigated with a single database for training and another one for testing, which makes the results highly dependent on the particular databases. Moreover, recent developments from the image generation literature remain largely unexplored for speech enhancement. These include several design aspects of diffusion models, such as the noise schedule or the reverse sampler. In this work, we systematically assess the generalization performance of a diffusion-based speech enhancement model by using multiple speech, noise and binaural room impulse response (BRIR) databases to simulate mismatched acoustic conditions. We also experiment with a noise schedule and a sampler that have not been applied to speech enhancement before. We show that the proposed system substantially benefits from using multiple databases for training, and achieves superior performance compared to state-of-the-art discriminative models in both matched and mismatched conditions. We also show that a Heun-based sampler achieves superior performance at a smaller computational cost compared to a sampler commonly used for speech enhancement.\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2312.02683"
  },
  "2312.02682": {
    "title": "H-GAP: Humanoid Control with a Generalist Planner",
    "authors": [
      "Zhengyao Jiang",
      "Yingchen Xu",
      "Nolan Wagener",
      "Yicheng Luo",
      "Michael Janner",
      "Edward Grefenstette",
      "Tim Rockt\u00e4schel",
      "Yuandong Tian"
    ],
    "abstract": "Humanoid control is an important research challenge offering avenues for integration into human-centric infrastructures and enabling physics-driven humanoid animations. The daunting challenges in this field stem from the difficulty of optimizing in high-dimensional action spaces and the instability introduced by the bipedal morphology of humanoids. However, the extensive collection of human motion-captured data and the derived datasets of humanoid trajectories, such as MoCapAct, paves the way to tackle these challenges. In this context, we present Humanoid Generalist Autoencoding Planner (H-GAP), a state-action trajectory generative model trained on humanoid trajectories derived from human motion-captured data, capable of adeptly handling downstream control tasks with Model Predictive Control (MPC). For 56 degrees of freedom humanoid, we empirically demonstrate that H-GAP learns to represent and generate a wide range of motor behaviours. Further, without any learning from online interactions, it can also flexibly transfer these behaviors to solve novel downstream control tasks via planning. Notably, H-GAP excels established MPC baselines that have access to the ground truth dynamics model, and is superior or comparable to offline RL methods trained for individual tasks. Finally, we do a series of empirical studies on the scaling properties of H-GAP, showing the potential for performance gains via additional data but not computing. Code and videos are available at https://ycxuyingchen.github.io/hgap/.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02682"
  },
  "2312.02674": {
    "title": "Amortized Bayesian Decision Making for simulation-based models",
    "authors": [
      "Mila Gorecki",
      "Jakob H. Macke",
      "Michael Deistler"
    ],
    "abstract": "Simulation-based inference (SBI) provides a powerful framework for inferring posterior distributions of stochastic simulators in a wide range of domains. In many settings, however, the posterior distribution is not the end goal itself -- rather, the derived parameter values and their uncertainties are used as a basis for deciding what actions to take. Unfortunately, because posterior distributions provided by SBI are (potentially crude) approximations of the true posterior, the resulting decisions can be suboptimal. Here, we address the question of how to perform Bayesian decision making on stochastic simulators, and how one can circumvent the need to compute an explicit approximation to the posterior. Our method trains a neural network on simulated data and can predict the expected cost given any data and action, and can, thus, be directly used to infer the action with lowest cost. We apply our method to several benchmark problems and demonstrate that it induces similar cost as the true posterior distribution. We then apply the method to infer optimal actions in a real-world simulator in the medical neurosciences, the Bayesian Virtual Epileptic Patient, and demonstrate that it allows to infer actions associated with low cost after few simulations.\n        \u25b3 Less",
    "submission_date": "18 December, 2023",
    "eprint_id": "2312.02674"
  },
  "2312.02673": {
    "title": "Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics",
    "authors": [
      "Xiaoxing Mo",
      "Yechao Zhang",
      "Leo Yu Zhang",
      "Wei Luo",
      "Nan Sun",
      "Shengshan Hu",
      "Shang Gao",
      "Yang Xiang"
    ],
    "abstract": "A backdoor attack in deep learning inserts a hidden backdoor in the model to trigger malicious behavior upon specific input patterns. Existing detection approaches assume a metric space (for either the original inputs or their latent representations) in which normal samples and malicious samples are separable. We show that this assumption has a severe limitation by introducing a novel SSDT (Source-Specific and Dynamic-Triggers) backdoor, which obscures the difference between normal samples and malicious samples.\n  To overcome this limitation, we move beyond looking for a perfect metric space that would work for different deep-learning models, and instead resort to more robust topological constructs. We propose TED (Topological Evolution Dynamics) as a model-agnostic basis for robust backdoor detection. The main idea of TED is to view a deep-learning model as a dynamical system that evolves inputs to outputs. In such a dynamical system, a benign input follows a natural evolution trajectory similar to other benign inputs. In contrast, a malicious sample displays a distinct trajectory, since it starts close to benign samples but eventually shifts towards the neighborhood of attacker-specified target samples to activate the backdoor.\n  Extensive evaluations are conducted on vision and natural language datasets across different network architectures. The results demonstrate that TED not only achieves a high detection rate, but also significantly outperforms existing state-of-the-art detection approaches, particularly in addressing the sophisticated SSDT attack. The code to reproduce the results is made public on GitHub.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02673"
  },
  "2312.02671": {
    "title": "Learning a Sparse Representation of Barron Functions with the Inverse Scale Space Flow",
    "authors": [
      "Tjeerd Jan Heeringa",
      "Tim Roith",
      "Christoph Brune",
      "Martin Burger"
    ],
    "abstract": "This paper presents a method for finding a sparse representation of Barron functions. Specifically, given an $L^2$ function $f$, the inverse scale space flow is used to find a sparse measure $\u03bc$ minimising the $L^2$ loss between the Barron function associated to the measure $\u03bc$ and the function $f$. The convergence properties of this method are analysed in an ideal setting and in the cases of measurement noise and sampling bias. In an ideal setting the objective decreases strictly monotone in time to a minimizer with $\\mathcal{O}(1/t)$, and in the case of measurement noise or sampling bias the optimum is achieved up to a multiplicative or additive constant. This convergence is preserved on discretization of the parameter space, and the minimizers on increasingly fine discretizations converge to the optimum on the full parameter space.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02671"
  },
  "2312.02668": {
    "title": "Approximate Nash Equilibria Algorithms for Shapley Network Design Games",
    "authors": [
      "Hangxin Gan",
      "Xianhao Meng",
      "Chunying Ren",
      "Yongtang Shi"
    ],
    "abstract": "We consider a weighted Shapley network design game, where selfish players choose paths in a network to minimize their cost. The cost function of each edge in the network is affine linear with respect to the sum of weights of the players who choose the edge. We first show the existence of \u03b1-approximate pure Nash equilibrium by constructing a potential function and establish an upper bound O(log2(W)) of \u03b1, where W is the sum of the weight of all players. Furthermore, we assume that the coefficients of the cost function (affine linear function) of the edge all are \u03c6-smooth random variables on [0, 1]. In this case, we show that \u03b5-best response dynamics can compute the (1 + \u03b5)\u03b1-approximate pure Nash equilibrium (\u03b5is a positive constant close to 0) in polynomial time by proving the expected number of iterations is polynomial in 1/\u03b5, \u03c6, the number of players and the number of edges in the network.\n        \u25b3 Less",
    "submission_date": "17 December, 2023",
    "eprint_id": "2312.02668"
  },
  "2312.02665": {
    "title": "Lights out: training RL agents robust to temporary blindness",
    "authors": [
      "N. Ordonez",
      "M. Tromp",
      "P. M. Julbe",
      "W. B\u00f6hmer"
    ],
    "abstract": "Agents trained with DQN rely on an observation at each timestep to decide what action to take next. However, in real world applications observations can change or be missing entirely. Examples of this could be a light bulb breaking down, or the wallpaper in a certain room changing. While these situations change the actual observation, the underlying optimal policy does not change. Because of this we want our agent to continue taking actions until it receives a (recognized) observation again. To achieve this we introduce a combination of a neural network architecture that uses hidden representations of the observations and a novel n-step loss function. Our implementation is able to withstand location based blindness stretches longer than the ones it was trained on, and therefore shows robustness to temporary blindness. For access to our implementation, please email Nathan, Marije, or Pau.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02665"
  },
  "2312.02664": {
    "title": "Domain-Specific Tensor Languages",
    "authors": [
      "Jean-Philippe Bernardy",
      "Patrik Jansson"
    ],
    "abstract": "The tensor notation used in several areas of mathematics is a useful one, but it is not widely available to the functional programming community. In a practical sense, the (embedded) domain-specific languages (DSLs) that are currently in use for tensor algebra are either 1. array-oriented languages that do not enforce or take advantage of tensor properties and algebraic structure or 2. follow the categorical structure of tensors but require the programmer to manipulate tensors in an unwieldy point-free notation. A deeper issue is that for tensor calculus, the dominant pedagogical paradigm assumes an audience which is either comfortable with notational liberties which programmers cannot afford, or focus on the applied mathematics of tensors, largely leaving their linguistic aspects (behaviour of variable binding, syntax and semantics, etc.) for the reader to figure out by themselves. This state of affairs is hardly surprising, because, as we highlight, several properties of standard tensor notation are somewhat exotic from the perspective of lambda calculi. We bridge the gap by defining a DSL, embedded in Haskell, whose syntax closely captures the index notation for tensors in wide use in the literature. The semantics of this EDSL is defined in terms of the algebraic structures which define tensors in their full generality. This way, we believe that our EDSL can be used both as a tool for scientific computing, but also as a vehicle to express and present the theory and applications of tensors.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02664"
  },
  "2312.02663": {
    "title": "FaceStudio: Put Your Face Everywhere in Seconds",
    "authors": [
      "Yuxuan Yan",
      "Chi Zhang",
      "Rui Wang",
      "Yichao Zhou",
      "Gege Zhang",
      "Pei Cheng",
      "Gang Yu",
      "Bin Fu"
    ],
    "abstract": "This study investigates identity-preserving image synthesis, an intriguing task in image generation that seeks to maintain a subject's identity while adding a personalized, stylistic touch. Traditional methods, such as Textual Inversion and DreamBooth, have made strides in custom image creation, but they come with significant drawbacks. These include the need for extensive resources and time for fine-tuning, as well as the requirement for multiple reference images. To overcome these challenges, our research introduces a novel approach to identity-preserving synthesis, with a particular focus on human images. Our model leverages a direct feed-forward mechanism, circumventing the need for intensive fine-tuning, thereby facilitating quick and efficient image generation. Central to our innovation is a hybrid guidance framework, which combines stylized images, facial images, and textual prompts to guide the image generation process. This unique combination enables our model to produce a variety of applications, such as artistic portraits and identity-blended images. Our experimental results, including both qualitative and quantitative evaluations, demonstrate the superiority of our method over existing baseline models and previous works, particularly in its remarkable efficiency and ability to preserve the subject's identity with high fidelity.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02663"
  },
  "2312.02661": {
    "title": "A Self-Commissioning Edge Computing Method for Data-Driven Anomaly Detection in Power Electronic Systems",
    "authors": [
      "Pere Izquierdo Gomez",
      "Miguel E. Lopez Gajardo",
      "Nenad Mijatovic",
      "Tomislav Dragicevic"
    ],
    "abstract": "Ensuring the reliability of power electronic converters is a matter of great importance, and data-driven condition monitoring techniques are cementing themselves as an important tool for this purpose. However, translating methods that work well in controlled lab environments to field applications presents significant challenges, notably because of the limited diversity and accuracy of the lab training data. By enabling the use of field data, online machine learning can be a powerful tool to overcome this problem, but it introduces additional challenges in ensuring the stability and predictability of the training processes. This work presents an edge computing method that mitigates these shortcomings with minimal additional memory usage, by employing an autonomous algorithm that prioritizes the storage of training samples with larger prediction errors. The method is demonstrated on the use case of a self-commissioning condition monitoring system, in the form of a thermal anomaly detection scheme for a variable frequency motor drive, where the algorithm self-learned to distinguish normal and anomalous operation with minimal prior knowledge. The obtained results, based on experimental data, show a significant improvement in prediction accuracy and training speed, when compared to equivalent models trained online without the proposed data selection process.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02661"
  },
  "2312.02652": {
    "title": "What Machine Learning Can Do for Focusing Aerogel Detectors",
    "authors": [
      "Foma Shipilov",
      "Alexander Barnyakov",
      "Vladimir Bobrovnikov",
      "Sergey Kononov",
      "Fedor Ratnikov"
    ],
    "abstract": "Particle identification at the Super Charm-Tau factory experiment will be provided by a Focusing Aerogel Ring Imaging CHerenkov detector (FARICH). The specifics of detector location make proper cooling difficult, therefore a significant number of ambient background hits are captured. They must be mitigated to reduce the data flow and improve particle velocity resolution. In this work we present several approaches to filtering signal hits, inspired by machine learning techniques from computer vision.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02652"
  },
  "2312.02649": {
    "title": "A Q-learning approach to the continuous control problem of robot inverted pendulum balancing",
    "authors": [
      "Mohammad Safeea",
      "Pedro Neto"
    ],
    "abstract": "This study evaluates the application of a discrete action space reinforcement learning method (Q-learning) to the continuous control problem of robot inverted pendulum balancing. To speed up the learning process and to overcome technical difficulties related to the direct learning on the real robotic system, the learning phase is performed in simulation environment. A mathematical model of the system dynamics is implemented, deduced by curve fitting on data acquired from the real system. The proposed approach demonstrated feasible, featuring its application on a real world robot that learned to balance an inverted pendulum. This study also reinforces and demonstrates the importance of an accurate representation of the physical world in simulation to achieve a more efficient implementation of reinforcement learning algorithms in real world, even when using a discrete action space algorithm to control a continuous action.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02649"
  },
  "2312.02641": {
    "title": "Inertial Line-Of-Sight Stabilization Using a 3-DOF Spherical Parallel Manipulator with Coaxial Input Shafts",
    "authors": [
      "Alexandre Le",
      "Guillaume Rance",
      "Fabrice Rouillier",
      "Damien Chablat"
    ],
    "abstract": "This article dives into the use of a 3-RRR Spherical Parallel Manipulator (SPM) for the purpose of inertial Line Of Sight (LOS) stabilization. Such a parallel robot provides three Degrees of Freedom (DOF) in orientation and is studied from the kinematic point of view. In particular, one guarantees that the singular loci (with the resulting numerical instabilities and inappropriate behavior of the mechanism) are far away from the prescribed workspace. Once the kinematics of the device is certified, a control strategy needs to be implemented in order to stabilize the LOS through the upper platform of the mechanism. Such a work is done with MATLAB Simulink using a SimMechanics model of our robot.\n        \u25b3 Less",
    "submission_date": "2 January, 2024",
    "eprint_id": "2312.02641"
  },
  "2312.02635": {
    "title": "Multi-rotor Aerial Vehicles in Physical Interactions: A Survey",
    "authors": [
      "Jiawei Xu"
    ],
    "abstract": "Research on Multi-rotor Aerial Vehicles (MAVs) has experienced remarkable advancements over the past two decades, propelling the field forward at an accelerated pace. Through the implementation of motion control and the integration of specialized mechanisms, researchers have unlocked the potential of MAVs to perform a wide range of tasks in diverse scenarios. Notably, the literature has highlighted the distinctive attributes of MAVs that endow them with a competitive edge in physical interaction when compared to other robotic systems. In this survey, we present a categorization of the various types of physical interactions in which MAVs are involved, supported by comprehensive case studies. We examine the approaches employed by researchers to address different challenges using MAVs and their applications, including the development of different types of controllers to handle uncertainties inherent in these interactions. By conducting a thorough analysis of the strengths and limitations associated with different methodologies, as well as engaging in discussions about potential enhancements, this survey aims to illuminate the path for future research focusing on MAVs with high actuation capabilities.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02635"
  },
  "2312.02632": {
    "title": "How Good Is Open Bicycle Infrastructure Data? A Countrywide Case Study of Denmark",
    "authors": [
      "Ane Rahbek Vier\u00f8",
      "Anastassia Vybornova",
      "Michael Szell"
    ],
    "abstract": "Cycling is a key ingredient for a sustainability shift of Denmark's transportation system. To increase cycling rates, a better nationwide network of bicycle infrastructure is required. Planning such a network requires high-quality infrastructure data, however, the quality of bicycle infrastructure data is severely understudied. Here, we compare Denmark's two largest open data sets on dedicated bicycle infrastructure, OpenStreetMap (OSM) and GeoDanmark, in a countrywide data quality assessment, asking whether data is good enough for network-based analysis of cycling conditions. We find that neither of the data sets is of sufficient quality, and that data set conflation is necessary to obtain a complete dataset. Our analysis of the spatial variation of data quality suggests that rural areas are more likely to suffer from problems with data completeness. We demonstrate that the prevalent method of using infrastructure density as a proxy for data completeness is not suitable for bicycle infrastructure data, and that matching of corresponding features thus is necessary to assess data completeness. Based on our data quality assessment we recommend strategic mapping efforts towards data completeness, consistent standards to support comparability between different data sources, and increased focus on data topology to ensure high-quality bicycle network data.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02632"
  },
  "2312.02622": {
    "title": "On the Initialization of Graph Neural Networks",
    "authors": [
      "Jiahang Li",
      "Yakun Song",
      "Xiang Song",
      "David Paul Wipf"
    ],
    "abstract": "Graph Neural Networks (GNNs) have displayed considerable promise in graph representation learning across various applications. The core learning process requires the initialization of model weight matrices within each GNN layer, which is typically accomplished via classic initialization methods such as Xavier initialization. However, these methods were originally motivated to stabilize the variance of hidden embeddings and gradients across layers of Feedforward Neural Networks (FNNs) and Convolutional Neural Networks (CNNs) to avoid vanishing gradients and maintain steady information flow. In contrast, within the GNN context classical initializations disregard the impact of the input graph structure and message passing on variance. In this paper, we analyze the variance of forward and backward propagation across GNN layers and show that the variance instability of GNN initializations comes from the combined effect of the activation function, hidden dimension, graph structure and message passing. To better account for these influence factors, we propose a new initialization method for Variance Instability Reduction within GNN Optimization (Virgo), which naturally tends to equate forward and backward variances across successive layers. We conduct comprehensive experiments on 15 datasets to show that Virgo can lead to superior model performance and more stable variance at initialization on node classification, link prediction and graph classification tasks. Codes are in https://github.com/LspongebobJH/virgo_icml2023.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02622"
  },
  "2312.02619": {
    "title": "Rethinking and Simplifying Bootstrapped Graph Latents",
    "authors": [
      "Wangbin Sun",
      "Jintang Li",
      "Liang Chen",
      "Bingzhe Wu",
      "Yatao Bian",
      "Zibin Zheng"
    ],
    "abstract": "Graph contrastive learning (GCL) has emerged as a representative paradigm in graph self-supervised learning, where negative samples are commonly regarded as the key to preventing model collapse and producing distinguishable representations. Recent studies have shown that GCL without negative samples can achieve state-of-the-art performance as well as scalability improvement, with bootstrapped graph latent (BGRL) as a prominent step forward. However, BGRL relies on a complex architecture to maintain the ability to scatter representations, and the underlying mechanisms enabling the success remain largely unexplored. In this paper, we introduce an instance-level decorrelation perspective to tackle the aforementioned issue and leverage it as a springboard to reveal the potential unnecessary model complexity within BGRL. Based on our findings, we present SGCL, a simple yet effective GCL framework that utilizes the outputs from two consecutive iterations as positive pairs, eliminating the negative samples. SGCL only requires a single graph augmentation and a single graph encoder without additional parameters. Extensive experiments conducted on various graph benchmarks demonstrate that SGCL can achieve competitive performance with fewer parameters, lower time and space costs, and significant convergence speedup.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02619"
  },
  "2312.02617": {
    "title": "DreaMo: Articulated 3D Reconstruction From A Single Casual Video",
    "authors": [
      "Tao Tu",
      "Ming-Feng Li",
      "Chieh Hubert Lin",
      "Yen-Chi Cheng",
      "Min Sun",
      "Ming-Hsuan Yang"
    ],
    "abstract": "Articulated 3D reconstruction has valuable applications in various domains, yet it remains costly and demands intensive work from domain experts. Recent advancements in template-free learning methods show promising results with monocular videos. Nevertheless, these approaches necessitate a comprehensive coverage of all viewpoints of the subject in the input video, thus limiting their applicability to casually captured videos from online sources. In this work, we study articulated 3D shape reconstruction from a single and casually captured internet video, where the subject's view coverage is incomplete. We propose DreaMo that jointly performs shape reconstruction while solving the challenging low-coverage regions with view-conditioned diffusion prior and several tailored regularizations. In addition, we introduce a skeleton generation strategy to create human-interpretable skeletons from the learned neural bones and skinning weights. We conduct our study on a self-collected internet video collection characterized by incomplete view coverage. DreaMo shows promising quality in novel-view rendering, detailed articulated shape reconstruction, and skeleton generation. Extensive qualitative and quantitative studies validate the efficacy of each proposed component, and show existing methods are unable to solve correct geometry due to the incomplete view coverage.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.02617"
  },
  "2312.02616": {
    "title": "Facilitating the Production of Well-tailored Video Summaries for Sharing on Social Media",
    "authors": [
      "Evlampios Apostolidis",
      "Konstantinos Apostolidis",
      "Vasileios Mezaris"
    ],
    "abstract": "This paper presents a web-based tool that facilitates the production of tailored summaries for online sharing on social media. Through an interactive user interface, it supports a ``one-click'' video summarization process. Based on the integrated AI models for video summarization and aspect ratio transformation, it facilitates the generation of multiple summaries of a full-length video according to the needs of target platforms with regard to the video's length and aspect ratio.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02616"
  },
  "2312.02615": {
    "title": "Projection Regret: Reducing Background Bias for Novelty Detection via Diffusion Models",
    "authors": [
      "Sungik Choi",
      "Hankook Lee",
      "Honglak Lee",
      "Moontae Lee"
    ],
    "abstract": "Novelty detection is a fundamental task of machine learning which aims to detect abnormal ($\\textit{i.e.}$ out-of-distribution (OOD)) samples. Since diffusion models have recently emerged as the de facto standard generative framework with surprising generation results, novelty detection via diffusion models has also gained much attention. Recent methods have mainly utilized the reconstruction property of in-distribution samples. However, they often suffer from detecting OOD samples that share similar background information to the in-distribution data. Based on our observation that diffusion models can \\emph{project} any sample to an in-distribution sample with similar background information, we propose \\emph{Projection Regret (PR)}, an efficient novelty detection method that mitigates the bias of non-semantic information. To be specific, PR computes the perceptual distance between the test image and its diffusion-based projection to detect abnormality. Since the perceptual distance often fails to capture semantic changes when the background information is dominant, we cancel out the background bias by comparing it against recursive projections. Extensive experiments demonstrate that PR outperforms the prior art of generative-model-based novelty detection methods by a significant margin.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02615"
  },
  "2312.02613": {
    "title": "A Unified Simulation Framework for Visual and Behavioral Fidelity in Crowd Analysis",
    "authors": [
      "Niccol\u00f2 Bisagno",
      "Nicola Garau",
      "Antonio Luigi Stefani",
      "Nicola Conci"
    ],
    "abstract": "Simulation is a powerful tool to easily generate annotated data, and a highly desirable feature, especially in those domains where learning models need large training datasets. Machine learning and deep learning solutions, have proven to be extremely data-hungry and sometimes, the available real-world data are not sufficient to effectively model the given task. Despite the initial skepticism of a portion of the scientific community, the potential of simulation has been largely confirmed in many application areas, and the recent developments in terms of rendering and virtualization engines, have shown a good ability also in representing complex scenes. This includes environmental factors, such as weather conditions and surface reflectance, as well as human-related events, like human actions and behaviors. We present a human crowd simulator, called UniCrowd, and its associated validation pipeline. We show how the simulator can generate annotated data, suitable for computer vision tasks, in particular for detection and segmentation, as well as the related applications, as crowd counting, human pose estimation, trajectory analysis and prediction, and anomaly detection.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02613"
  },
  "2312.02611": {
    "title": "Privacy-Aware Data Acquisition under Data Similarity in Regression Markets",
    "authors": [
      "Shashi Raj Pandey",
      "Pierre Pinson",
      "Petar Popovski"
    ],
    "abstract": "Data markets facilitate decentralized data exchange for applications such as prediction, learning, or inference. The design of these markets is challenged by varying privacy preferences as well as data similarity among data owners. Related works have often overlooked how data similarity impacts pricing and data value through statistical information leakage. We demonstrate that data similarity and privacy preferences are integral to market design and propose a query-response protocol using local differential privacy for a two-party data acquisition mechanism. In our regression data market model, we analyze strategic interactions between privacy-aware owners and the learner as a Stackelberg game over the asked price and privacy factor. Finally, we numerically evaluate how data similarity affects market participation and traded data value.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02611"
  },
  "2312.02608": {
    "title": "Panoptica -- instance-wise evaluation of 3D semantic and instance segmentation maps",
    "authors": [
      "Florian Kofler",
      "Hendrik M\u00f6ller",
      "Josef A. Buchner",
      "Ezequiel de la Rosa",
      "Ivan Ezhov",
      "Marcel Rosier",
      "Isra Mekki",
      "Suprosanna Shit",
      "Moritz Negwer",
      "Rami Al-Maskari",
      "Ali Ert\u00fcrk",
      "Shankeeth Vinayahalingam",
      "Fabian Isensee",
      "Sarthak Pati",
      "Daniel Rueckert",
      "Jan S. Kirschke",
      "Stefan K. Ehrlich",
      "Annika Reinke",
      "Bjoern Menze",
      "Benedikt Wiestler",
      "Marie Piraud"
    ],
    "abstract": "This paper introduces panoptica, a versatile and performance-optimized package designed for computing instance-wise segmentation quality metrics from 2D and 3D segmentation maps. panoptica addresses the limitations of existing metrics and provides a modular framework that complements the original intersection over union-based panoptic quality with other metrics, such as the distance metric Average Symmetric Surface Distance. The package is open-source, implemented in Python, and accompanied by comprehensive documentation and tutorials. panoptica employs a three-step metrics computation process to cover diverse use cases. The efficacy of panoptica is demonstrated on various real-world biomedical datasets, where an instance-wise evaluation is instrumental for an accurate representation of the underlying clinical task. Overall, we envision panoptica as a valuable tool facilitating in-depth evaluation of segmentation methods.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02608"
  },
  "2312.02607": {
    "title": "Projective Space Stern Decoding and Application to SDitH",
    "authors": [
      "Kevin Carrier",
      "Val\u00e9rian Hatey",
      "Jean-Pierre Tillich"
    ],
    "abstract": "We show that here standard decoding algorithms for generic linear codes over a finite field can speeded up by a factor which is essentially the size of the finite field by reducing it to a low weight codeword problem and working in the relevant projective space. We apply this technique to SDitH and show that the parameters of both the original submission and the updated version fall short of meeting the security requirements asked by the NIST.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02607"
  },
  "2312.02605": {
    "title": "Accelerating Learnt Video Codecs with Gradient Decay and Layer-wise Distillation",
    "authors": [
      "Tianhao Peng",
      "Ge Gao",
      "Heming Sun",
      "Fan Zhang",
      "David Bull"
    ],
    "abstract": "In recent years, end-to-end learnt video codecs have demonstrated their potential to compete with conventional coding algorithms in term of compression efficiency. However, most learning-based video compression models are associated with high computational complexity and latency, in particular at the decoder side, which limits their deployment in practical applications. In this paper, we present a novel model-agnostic pruning scheme based on gradient decay and adaptive layer-wise distillation. Gradient decay enhances parameter exploration during sparsification whilst preventing runaway sparsity and is superior to the standard Straight-Through Estimation. The adaptive layer-wise distillation regulates the sparse training in various stages based on the distortion of intermediate features. This stage-wise design efficiently updates parameters with minimal computational overhead. The proposed approach has been applied to three popular end-to-end learnt video codecs, FVC, DCVC, and DCVC-HEM. Results confirm that our method yields up to 65% reduction in MACs and 2x speed-up with less than 0.3dB drop in BD-PSNR. Supporting code and supplementary material can be downloaded from: https://jasminepp.github.io/lightweightdvc/\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02605"
  },
  "2312.02603": {
    "title": "Automatic Robot Path Planning for Visual Inspection from Object Shape",
    "authors": [
      "O. Tasneem",
      "R. Pieters"
    ],
    "abstract": "Visual inspection is a crucial yet time-consuming task across various industries. Numerous established methods employ machine learning in inspection tasks, necessitating specific training data that includes predefined inspection poses and training images essential for the training of models. The acquisition of such data and their integration into an inspection framework is challenging due to the variety in objects and scenes involved and due to additional bottlenecks caused by the manual collection of training data by humans, thereby hindering the automation of visual inspection across diverse domains. This work proposes a solution for automatic path planning using a single depth camera mounted on a robot manipulator. Point clouds obtained from the depth images are processed and filtered to extract object profiles and transformed to inspection target paths for the robot end-effector. The approach relies on the geometry of the object and generates an inspection path that follows the shape normal to the surface. Depending on the object size and shape, inspection paths can be defined as single or multi-path plans. Results are demonstrated in both simulated and real-world environments, yielding promising inspection paths for objects with varying sizes and shapes. Code and video are open-source available at: https://github.com/CuriousLad1000/Auto-Path-Planner\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02603"
  },
  "2312.02601": {
    "title": "A Neural Receiver for 5G NR Multi-user MIMO",
    "authors": [
      "Sebastian Cammerer",
      "Fay\u00e7al A\u00eft Aoudia",
      "Jakob Hoydis",
      "Andreas Oeldemann",
      "Andreas Roessler",
      "Timo Mayer",
      "Alexander Keller"
    ],
    "abstract": "We introduce a neural network (NN)-based multiuser multiple-input multiple-output (MU-MIMO) receiver with 5G New Radio (5G NR) physical uplink shared channel (PUSCH) compatibility. The NN architecture is based on convolution layers to exploit the time and frequency correlation of the channel and a graph neural network (GNN) to handle multiple users. The proposed architecture adapts to an arbitrary number of sub-carriers and supports a varying number of multiple-input multiple-output (MIMO) layers and users without the need for any retraining. The receiver operates on an entire 5G NR slot, i.e., processes the entire received orthogonal frequency division multiplexing (OFDM) time-frequency resource grid by jointly performing channel estimation, equalization, and demapping. The proposed architecture operates less than 1 dB away from a baseline using linear minimum mean square error (LMMSE) channel estimation with K-best detection but benefits from a significantly lower computational complexity. We show the importance of a carefully designed training process such that the trained receiver is universal for a wide range of different unseen channel conditions. Finally, we demonstrate the results of a hardware-in-the-loop verification based on 3GPP compliant conformance test scenarios.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02601"
  },
  "2312.02598": {
    "title": "Impact of Tokenization on LLaMa Russian Adaptation",
    "authors": [
      "Mikhail Tikhomirov",
      "Daniil Chernyshev"
    ],
    "abstract": "Latest instruction-tuned large language models (LLM) show great results on various tasks, however, they often face performance degradation for non-English input. There is evidence that the reason lies in inefficient tokenization caused by low language representation in pre-training data which hinders the comprehension of non-English instructions, limiting the potential of target language instruction-tuning. In this work we investigate the possibility of addressing the issue with vocabulary substitution in the context of LLaMa Russian language adaptation. We explore three variants of vocabulary adaptation and test their performance on Saiga instruction-tuning and fine-tuning on Russian Super Glue benchmark. The results of automatic evaluation show that vocabulary substitution not only improves the model's quality in Russian but also accelerates fine-tuning (35%) and inference (up to 60%) while reducing memory consumption. Additional human evaluation of the instruction-tuned models demonstrates that models with Russian-adapted vocabulary generate answers with higher user preference than the original Saiga-LLaMa model.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02598"
  },
  "2312.02595": {
    "title": "Optimal Fairness Scheduling for Coded Caching in Multi-AP Multi-antenna WLAN",
    "authors": [
      "Kagan Akcay",
      "MohammadJavad Salehi",
      "Antti T\u00f6lli",
      "Giuseppe Caire"
    ],
    "abstract": "Coded caching (CC) schemes exploit the cumulative cache memory of network users, outperforming traditional uncoded schemes where cache contents are only used locally. Interestingly, this CC gain can also be combined with the spatial multiplexing gain of multi-antenna transmissions. In this paper, we extend the existing results of CC-aided data delivery in multi-access point (AP) wireless local area networks (WLAN) and video streaming applications by assuming multi-antenna transmitters at AP nodes. We present two distinct methods for using the extra resource that multi-antenna transmitters provide. While the first method tries to reduce the number of interference links in the network graph, the second one aims to remove inter-stream interference so that users with similar cache contents can be served simultaneously. While both methods provide increased throughput, they differ significantly in the underlying concept. Numerical simulations are used to compare the performance of different methods.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02595"
  },
  "2312.02593": {
    "title": "6D Assembly Pose Estimation by Point Cloud Registration for Robot Manipulation",
    "authors": [
      "K. Samarawickrama",
      "G. Sharma",
      "A. Angleraud",
      "R. Pieters"
    ],
    "abstract": "The demands on robotic manipulation skills to perform challenging tasks have drastically increased in recent times. To perform these tasks with dexterity, robots require perception tools to understand the scene and extract useful information that transforms to robot control inputs. To this end, recent research has introduced various object pose estimation and grasp pose detection methods that yield precise results. Assembly pose estimation is a secondary yet highly desirable skill in robotic assembling as it requires more detailed information on object placement as compared to bin picking and pick-and-place tasks. However, it has been often overlooked in research due to the complexity of integration in an agile framework. To address this issue, we propose an assembly pose estimation method with RGB-D input and 3D CAD models of the associated objects. The framework consists of semantic segmentation of the scene and registering point clouds of local surfaces against target point clouds derived from CAD models to estimate 6D poses. We show that our method can deliver sufficient accuracy for assembling object assemblies using evaluation metrics and demonstrations. The source code and dataset for the work can be found at: https://github.com/KulunuOS/6DAPose\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02593"
  },
  "2312.02590": {
    "title": "Text Intimacy Analysis using Ensembles of Multilingual Transformers",
    "authors": [
      "Tanmay Chavan",
      "Ved Patwardhan"
    ],
    "abstract": "Intimacy estimation of a given text has recently gained importance due to the increase in direct interaction of NLP systems with humans. Intimacy is an important aspect of natural language and has a substantial impact on our everyday communication. Thus the level of intimacy can provide us with deeper insights and richer semantics of conversations. In this paper, we present our work on the SemEval shared task 9 on predicting the level of intimacy for the given text. The dataset consists of tweets in ten languages, out of which only six are available in the training dataset. We conduct several experiments and show that an ensemble of multilingual models along with a language-specific monolingual model has the best performance. We also evaluate other data augmentation methods such as translation and present the results. Lastly, we study the results thoroughly and present some noteworthy insights into this problem.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02590"
  },
  "2312.02589": {
    "title": "ESP2CS: Securing Internet of Vehicles through Blockchain-enabled Communications and Payments",
    "authors": [
      "Rateb Jabbar",
      "Mohamed Kharbeche"
    ],
    "abstract": "The burgeoning domain of the Internet of Vehicles (IoV), a subset of the Internet of Things (IoT), promises to revolutionize transportation through enhanced safety, efficiency, and environmental sustainability. By amalgamating technologies like sensors and cloud computing, the IoV paves the way for optimized traffic management, heightened vehicle safety, and the birth of novel business paradigms. However, this growth is shadowed by significant security concerns, especially in the communication and payment sectors. Addressing the pressing need for secure Vehicle to Everything (V2X) communications and payments amidst rising cyber threats, this research introduces the Ethereum based Secure Payment and Communication Solution (ESP2CS). Utilizing Ethereum as a middleware, ESP2CS ensures robust and secure V2X interactions. The solution is complemented by an Android Auto application for vehicles, streamlining inter vehicle communication, parking space detection, and transaction management. Furthermore, dedicated Android applications are developed for parking space renters and the parking IoT system. Preliminary evaluations underscore ESP2CS's superior cost effectiveness, integrity and consistency over contemporary solutions, with Ethereum bolstering both security and efficiency.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02589"
  },
  "2312.02586": {
    "title": "Mapping the Information Journey: Unveiling the Documentation Experience of Software Developers in China",
    "authors": [
      "Zhijun Gao",
      "Jiangying Wang",
      "Meina Wang"
    ],
    "abstract": "This research delves into understanding the behaviors and characteristics of Chinese developers in relation to their use of technical documentation, which is crucial for creating high-quality developer documentation. We conducted interviews with 25 software developers and surveyed 177 participants, using the preliminary interview findings to inform the survey design. Our approach encompassed traditional user research methods, including persona and user journey mapping, to develop typical personas and information journeys based on the qualitative data from the interviews and quantitative results from the survey. Our results revealed distinct characteristics and differences between junior and senior developers in terms of their use of technical documentation, broadly categorized into personality traits, learning habits, and working habits. We observed that the information journey of both groups typically encompasses four stages: Exploration, Understanding, Practice, and Application. Consequently, we created two distinct personas and information journey maps to represent these two developer groups. Our findings highlight that developers prioritize the content, organization, and maintenance aspects of documentation. In conclusion, we recommend organizing documentation content to align with developers' information journeys, tailoring documentation to meet the needs of developers at various levels, and focusing on the content, organization, and maintenance aspects of documentation.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02586"
  },
  "2312.02585": {
    "title": "CVE representation to build attack positions graphs",
    "authors": [
      "Manuel Poisson",
      "Val\u00e9rie Viet Triem Tong",
      "Gilles Guette",
      "Fr\u00e9d\u00e9ric Guih\u00e9ry",
      "Damien Cr\u00e9milleux"
    ],
    "abstract": "In cybersecurity, CVEs (Common Vulnerabilities and Exposures) are publicly disclosed hardware or software vulnerabilities. These vulnerabilities are documented and listed in the NVD database maintained by the NIST. Knowledge of the CVEs impacting an information system provides a measure of its level of security. This article points out that these vulnerabilities should be described in greater detail to understand how they could be chained together in a complete attack scenario. This article presents the first proposal for the CAPG format, which is a method for representing a CVE vulnerability, a corresponding exploit, and associated attack positions.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02585"
  },
  "2312.02581": {
    "title": "Auralization based on multi-perspective ambisonic room impulse responses",
    "authors": [
      "Kaspar M\u00fcller",
      "Franz Zotter"
    ],
    "abstract": "Most often, virtual acoustic rendering employs real-time updated room acoustic simulations to accomplish auralization for a variable listener perspective. As an alternative, we propose and test a technique to interpolate room impulse responses, specifically Ambisonic room impulse responses (ARIRs) available at a grid of spatially distributed receiver perspectives, measured or simulated in a desired acoustic environment. In particular, we extrapolate a triplet of neighboring ARIRs to the variable listener perspective, preceding their linear interpolation. The extrapolation is achieved by decomposing each ARIR into localized sound events and re-assigning their direction, time, and level to what could be observed at the listener perspective, with as much temporal, directional, and perspective context as possible. We propose to undertake this decomposition in two levels: Peaks in the early ARIRs are decomposed into jointly localized sound events, based on time differences of arrival observed in either an ARIR triplet, or all ARIRs observing the direct sound. Sound events that could not be jointly localized are treated as residuals whose less precise localization utilizes direction-of-arrival detection and the estimated time of arrival. For the interpolated rendering, suitable parameter settings are found by evaluating the proposed method in a listening experiment, using both measured and simulated ARIR data sets, under static and time-varying conditions.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02581"
  },
  "2312.02579": {
    "title": "Simple and fast Algorithm for Finding Roots of Error-Locator Polynomials: Modulus Search",
    "authors": [
      "Gennady N. Glushchenko"
    ],
    "abstract": "A novel very simple method for finding roots of polynomials over finite fields has been proposed. The essence of the proposed method is to search the roots via nested cycles over the subgroups of the multiplicative group of the Galois field. The modified Chien search is actually used in the inner cycles, but the internal polynomials are small. The word \"modulus\" was used because the search is doing on subsets like $\u03b1^{a+bi}$, where a,b=const. In addition, modulo division of polynomials is actively used. The algorithm is applicable not for all Galois fields, but for selective ones, starting from GF($2^8$). The algorithm has an advantage for large polynomials. The number of operations is significant for small polynomials, but it grows very slowly with the degree of the polynomial. When the polynomial is large or very large, the proposed method can be 10-100 times faster than Chien search.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02579"
  },
  "2312.02578": {
    "title": "Empathy and Distress Detection using Ensembles of Transformer Models",
    "authors": [
      "Tanmay Chavan",
      "Kshitij Deshpande",
      "Sheetal Sonawane"
    ],
    "abstract": "This paper presents our approach for the WASSA 2023 Empathy, Emotion and Personality Shared Task. Empathy and distress are human feelings that are implicitly expressed in natural discourses. Empathy and distress detection are crucial challenges in Natural Language Processing that can aid our understanding of conversations. The provided dataset consists of several long-text examples in the English language, with each example associated with a numeric score for empathy and distress. We experiment with several BERT-based models as a part of our approach. We also try various ensemble methods. Our final submission has a Pearson's r score of 0.346, placing us third in the empathy and distress detection subtask.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02578"
  },
  "2312.02576": {
    "title": "An Integrated System for Spatio-Temporal Summarization of 360-degrees Videos",
    "authors": [
      "Ioannis Kontostathis",
      "Evlampios Apostolidis",
      "Vasileios Mezaris"
    ],
    "abstract": "In this work, we present an integrated system for spatiotemporal summarization of 360-degrees videos. The video summary production mainly involves the detection of salient events and their synopsis into a concise summary. The analysis relies on state-of-the-art methods for saliency detection in 360-degrees video (ATSal and SST-Sal) and video summarization (CA-SUM). It also contains a mechanism that classifies a 360-degrees video based on the use of static or moving camera during recording and decides which saliency detection method will be used, as well as a 2D video production component that is responsible to create a conventional 2D video containing the salient events in the 360-degrees video. Quantitative evaluations using two datasets for 360-degrees video saliency detection (VR-EyeTracking, Sports-360) show the accuracy and positive impact of the developed decision mechanism, and justify our choice to use two different methods for detecting the salient events. A qualitative analysis using content from these datasets, gives further insights about the functionality of the decision mechanism, shows the pros and cons of each used saliency detection method and demonstrates the advanced performance of the trained summarization method against a more conventional approach.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02576"
  },
  "2312.02573": {
    "title": "UTBoost: A Tree-boosting based System for Uplift Modeling",
    "authors": [
      "Junjie Gao",
      "Xiangyu Zheng",
      "DongDong Wang",
      "Zhixiang Huang",
      "Bangqi Zheng",
      "Kai Yang"
    ],
    "abstract": "Uplift modeling refers to the set of machine learning techniques that a manager may use to estimate customer uplift, that is, the net effect of an action on some customer outcome. By identifying the subset of customers for whom a treatment will have the greatest effect, uplift models assist decision-makers in optimizing resource allocations and maximizing overall returns. Accurately estimating customer uplift poses practical challenges, as it requires assessing the difference between two mutually exclusive outcomes for each individual. In this paper, we propose two innovative adaptations of the well-established Gradient Boosting Decision Trees (GBDT) algorithm, which learn the causal effect in a sequential way and overcome the counter-factual nature. Both approaches innovate existing techniques in terms of ensemble learning method and learning objectives, respectively. Experiments on large-scale datasets demonstrate the usefulness of the proposed methods, which often yielding remarkable improvements over base models. To facilitate the application, we develop the UTBoost, an end-to-end tree boosting system specifically designed for uplift modeling. The package is open source and has been optimized for training speed to meet the needs of real industrial applications.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02573"
  },
  "2312.02568": {
    "title": "Prompt2NeRF-PIL: Fast NeRF Generation via Pretrained Implicit Latent",
    "authors": [
      "Jianmeng Liu",
      "Yuyao Zhang",
      "Zeyuan Meng",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "abstract": "This paper explores promptable NeRF generation (e.g., text prompt or single image prompt) for direct conditioning and fast generation of NeRF parameters for the underlying 3D scenes, thus undoing complex intermediate steps while providing full 3D generation with conditional control. Unlike previous diffusion-CLIP-based pipelines that involve tedious per-prompt optimizations, Prompt2NeRF-PIL is capable of generating a variety of 3D objects with a single forward pass, leveraging a pre-trained implicit latent space of NeRF parameters. Furthermore, in zero-shot tasks, our experiments demonstrate that the NeRFs produced by our method serve as semantically informative initializations, significantly accelerating the inference process of existing prompt-to-NeRF methods. Specifically, we will show that our approach speeds up the text-to-NeRF model DreamFusion and the 3D reconstruction speed of the image-to-NeRF method Zero-1-to-3 by 3 to 5 times.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02568"
  },
  "2312.02566": {
    "title": "Structured World Representations in Maze-Solving Transformers",
    "authors": [
      "Michael Igorevich Ivanitskiy",
      "Alex F. Spies",
      "Tilman R\u00e4uker",
      "Guillaume Corlouer",
      "Chris Mathwin",
      "Lucia Quirke",
      "Can Rager",
      "Rusheb Shah",
      "Dan Valentine",
      "Cecilia Diniz Behn",
      "Katsumi Inoue",
      "Samy Wu Fung"
    ],
    "abstract": "Transformer models underpin many recent advances in practical machine learning applications, yet understanding their internal behavior continues to elude researchers. Given the size and complexity of these models, forming a comprehensive picture of their inner workings remains a significant challenge. To this end, we set out to understand small transformer models in a more tractable setting: that of solving mazes. In this work, we focus on the abstractions formed by these models and find evidence for the consistent emergence of structured internal representations of maze topology and valid paths. We demonstrate this by showing that the residual stream of only a single token can be linearly decoded to faithfully reconstruct the entire maze. We also find that the learned embeddings of individual tokens have spatial structure. Furthermore, we take steps towards deciphering the circuity of path-following by identifying attention heads (dubbed $\\textit{adjacency heads}$), which are implicated in finding valid subsequent tokens.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02566"
  },
  "2312.02561": {
    "title": "DanZero+: Dominating the GuanDan Game through Reinforcement Learning",
    "authors": [
      "Youpeng Zhao",
      "Yudong Lu",
      "Jian Zhao",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "abstract": "The utilization of artificial intelligence (AI) in card games has been a well-explored subject within AI research for an extensive period. Recent advancements have propelled AI programs to showcase expertise in intricate card games such as Mahjong, DouDizhu, and Texas Hold'em. In this work, we aim to develop an AI program for an exceptionally complex and popular card game called GuanDan. This game involves four players engaging in both competitive and cooperative play throughout a long process to upgrade their level, posing great challenges for AI due to its expansive state and action space, long episode length, and complex rules. Employing reinforcement learning techniques, specifically Deep Monte Carlo (DMC), and a distributed training framework, we first put forward an AI program named DanZero for this game. Evaluation against baseline AI programs based on heuristic rules highlights the outstanding performance of our bot. Besides, in order to further enhance the AI's capabilities, we apply policy-based reinforcement learning algorithm to GuanDan. To address the challenges arising from the huge action space, which will significantly impact the performance of policy-based algorithms, we adopt the pre-trained model to facilitate the training process and the achieved AI program manages to achieve a superior performance.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02561"
  },
  "2312.02557": {
    "title": "BOgen: Generating Part-Level 3D Designs Based on User Intention Inference through Bayesian Optimization and Variational Autoencoder",
    "authors": [
      "Seung Won Lee",
      "Jiin Choi",
      "Kyung Hoon Hyun"
    ],
    "abstract": "Advancements in generative artificial intelligence (AI) have introduced various AI models capable of producing impressive visual design outputs. However, when it comes to AI models in the design process, prioritizing outputs that align with designers' needs over mere visual craftsmanship becomes even more crucial. Furthermore, designers often intricately combine parts of various designs to create novel designs. The ability to generate designs that align with the designers' intentions at the part level is pivotal for assisting designers. Hence, we introduced BOgen, which empowers designers to proactively generate and explore part-level designs through Bayesian optimization and variational autoencoders, thereby enhancing their overall user experience. We assessed BOgen's performance using a study involving 30 designers. The results revealed that, compared to the baseline, BOgen fulfilled the designer requirements for part recommendations and design exploration space guidance. BOgen assists designers in navigation and development, offering valuable design suggestions and fosters proactive design exploration and creation.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02557"
  },
  "2312.02550": {
    "title": "An empirical study of next-basket recommendations",
    "authors": [
      "Zhufeng Shao",
      "Shoujin Wang",
      "Qian Zhang",
      "Wenpeng Lu",
      "Zhao Li",
      "Xueping Peng"
    ],
    "abstract": "Next Basket Recommender Systems (NBRs) function to recommend the subsequent shopping baskets for users through the modeling of their preferences derived from purchase history, typically manifested as a sequence of historical baskets. Given their widespread applicability in the E-commerce industry, investigations into NBRs have garnered increased attention in recent years. Despite the proliferation of diverse NBR methodologies, a substantial challenge lies in the absence of a systematic and unified evaluation framework across these methodologies. Various studies frequently appraise NBR approaches using disparate datasets and diverse experimental settings, impeding a fair and effective comparative assessment of methodological performance. To bridge this gap, this study undertakes a systematic empirical inquiry into NBRs, reviewing seminal works within the domain and scrutinizing their respective merits and drawbacks. Subsequently, we implement designated NBR algorithms on uniform datasets, employing consistent experimental configurations, and assess their performances via identical metrics. This methodological rigor establishes a cohesive framework for the impartial evaluation of diverse NBR approaches. It is anticipated that this study will furnish a robust foundation and serve as a pivotal reference for forthcoming research endeavors in this dynamic field.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02550"
  },
  "2312.02549": {
    "title": "DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding",
    "authors": [
      "Thong Nguyen",
      "Xiaobao Wu",
      "Xinshuai Dong",
      "Cong-Duy Nguyen",
      "See-Kiong Ng",
      "Luu Anh Tuan"
    ],
    "abstract": "Temporal Language Grounding seeks to localize video moments that semantically correspond to a natural language query. Recent advances employ the attention mechanism to learn the relations between video moments and the text query. However, naive attention might not be able to appropriately capture such relations, resulting in ineffective distributions where target video moments are difficult to separate from the remaining ones. To resolve the issue, we propose an energy-based model framework to explicitly learn moment-query distributions. Moreover, we propose DemaFormer, a novel Transformer-based architecture that utilizes exponential moving average with a learnable damping factor to effectively encode moment-query inputs. Comprehensive experiments on four public temporal language grounding datasets showcase the superiority of our methods over the state-of-the-art baselines.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02549"
  },
  "2312.02547": {
    "title": "On Optimal Consistency-Robustness Trade-Off for Learning-Augmented Multi-Option Ski Rental",
    "authors": [
      "Yongho Shin",
      "Changyeol Lee",
      "Hyung-Chan An"
    ],
    "abstract": "The learning-augmented multi-option ski rental problem generalizes the classical ski rental problem in two ways: the algorithm is provided with a prediction on the number of days we can ski, and the ski rental options now come with a variety of rental periods and prices to choose from, unlike the classical two-option setting. Subsequent to the initial study of the multi-option ski rental problem (without learning augmentation) due to Zhang, Poon, and Xu, significant progress has been made for this problem recently in particular. The problem is very well understood when we relinquish one of the two generalizations -- for the learning-augmented classical ski rental problem, algorithms giving best-possible trade-off between consistency and robustness exist; for the multi-option ski rental problem without learning augmentation, deterministic/randomized algorithms giving the best-possible competitiveness have been found. However, in presence of both generalizations, there remained a huge gap between the algorithmic and impossibility results. In fact, for randomized algorithms, we did not have any nontrivial lower bounds on the consistency-robustness trade-off before.\n  This paper bridges this gap for both deterministic and randomized algorithms. For deterministic algorithms, we present a best-possible algorithm that completely matches the known lower bound. For randomized algorithms, we show the first nontrivial lower bound on the consistency-robustness trade-off, and also present an improved randomized algorithm. Our algorithm matches our lower bound on robustness within a factor of e/2 when the consistency is at most 1.086.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02547"
  },
  "2312.02542": {
    "title": "Fortress: Securing IoT Peripherals with Trusted Execution Environments",
    "authors": [
      "Peterson Yuhala",
      "J\u00e4mes M\u00e9n\u00e9trey",
      "Pascal Felber",
      "Marcelo Pasin",
      "Valerio Schiavoni"
    ],
    "abstract": "With the increasing popularity of Internet of Things (IoT) devices, securing sensitive user data has emerged as a major challenge. These devices often collect confidential information, such as audio and visual data, through peripheral inputs like microphones and cameras. Such sensitive information is then exposed to potential threats, either from malicious software with high-level access rights or transmitted (sometimes inadvertently) to untrusted cloud services. In this paper, we propose a generic design to enhance the privacy in IoT-based systems by isolating peripheral I/O memory regions in a secure kernel space of a trusted execution environment (TEE). Only a minimal set of peripheral driver code, resident within the secure kernel, can access this protected memory area.\n  This design effectively restricts any unauthorised access by system software, including the operating system and hypervisor. The sensitive peripheral data is then securely transferred to a user-space TEE, where obfuscation mechanisms can be applied before it is relayed to third parties, e.g., the cloud. To validate our architectural approach, we provide a proof-of-concept implementation of our design by securing an audio peripheral based on inter-IC sound (I2S), a serial bus to interconnect audio devices. The experimental results show that our design offers a robust security solution with an acceptable computational overhead.\n        \u25b3 Less",
    "submission_date": "20 December, 2023",
    "eprint_id": "2312.02542"
  },
  "2312.02541": {
    "title": "Explainable Severity ranking via pairwise n-hidden comparison: a case study of glaucoma",
    "authors": [
      "Hong Nguyen",
      "Cuong V. Nguyen",
      "Shrikanth Narayanan",
      "Benjamin Y. Xu",
      "Michael Pazzani"
    ],
    "abstract": "Primary open-angle glaucoma (POAG) is a chronic and progressive optic nerve condition that results in an acquired loss of optic nerve fibers and potential blindness. The gradual onset of glaucoma results in patients progressively losing their vision without being consciously aware of the changes. To diagnose POAG and determine its severity, patients must undergo a comprehensive dilated eye examination. In this work, we build a framework to rank, compare, and interpret the severity of glaucoma using fundus images. We introduce a siamese-based severity ranking using pairwise n-hidden comparisons. We additionally have a novel approach to explaining why a specific image is deemed more severe than others. Our findings indicate that the proposed severity ranking model surpasses traditional ones in terms of diagnostic accuracy and delivers improved saliency explanations.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02541"
  },
  "2312.02538": {
    "title": "A Multi-Granularity-Aware Aspect Learning Model for Multi-Aspect Dense Retrieval",
    "authors": [
      "Xiaojie Sun",
      "Keping Bi",
      "Jiafeng Guo",
      "Sihui Yang",
      "Qishen Zhang",
      "Zhongyi Liu",
      "Guannan Zhang",
      "Xueqi Cheng"
    ],
    "abstract": "Dense retrieval methods have been mostly focused on unstructured text and less attention has been drawn to structured data with various aspects, e.g., products with aspects such as category and brand. Recent work has proposed two approaches to incorporate the aspect information into item representations for effective retrieval by predicting the values associated with the item aspects. Despite their efficacy, they treat the values as isolated classes (e.g., \"Smart Homes\", \"Home, Garden & Tools\", and \"Beauty & Health\") and ignore their fine-grained semantic relation. Furthermore, they either enforce the learning of aspects into the CLS token, which could confuse it from its designated use for representing the entire content semantics, or learn extra aspect embeddings only with the value prediction objective, which could be insufficient especially when there are no annotated values for an item aspect. Aware of these limitations, we propose a MUlti-granulaRity-aware Aspect Learning model (MURAL) for multi-aspect dense retrieval. It leverages aspect information across various granularities to capture both coarse and fine-grained semantic relations between values. Moreover, MURAL incorporates separate aspect embeddings as input to transformer encoders so that the masked language model objective can assist implicit aspect learning even without aspect-value annotations. Extensive experiments on two real-world datasets of products and mini-programs show that MURAL outperforms state-of-the-art baselines significantly.\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2312.02538"
  },
  "2312.02537": {
    "title": "Asymmetric leader-laggard cluster synchronization for collective decision-making with laser network",
    "authors": [
      "Shun Kotoku",
      "Takatomo Mihana",
      "Andr\u00e9 R\u00f6hm",
      "Ryoichi Horisaki",
      "Makoto Naruse"
    ],
    "abstract": "Photonic accelerators have recently attracted soaring interest, harnessing the ultimate nature of light for information processing. Collective decision-making with a laser network, employing the chaotic and synchronous dynamics of optically interconnected lasers to address the competitive multi-armed bandit (CMAB) problem, is a highly compelling approach due to its scalability and experimental feasibility. We investigated essential network structures for collective decision-making through quantitative stability analysis. Moreover, we demonstrated the asymmetric preferences of players in the CMAB problem, extending its functionality to more practical applications. Our study highlights the capability and significance of machine learning built upon chaotic lasers and photonic devices.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02537"
  },
  "2312.02535": {
    "title": "Towards Open-set Gesture Recognition via Feature Activation Enhancement and Orthogonal Prototype Learning",
    "authors": [
      "Chen Liu",
      "Can Han",
      "Chengfeng Zhou",
      "Crystal Cai",
      "Suncheng Xiang",
      "Hualiang Ni",
      "Dahong Qian"
    ],
    "abstract": "Gesture recognition is a foundational task in human-machine interaction (HMI). While there has been significant progress in gesture recognition based on surface electromyography (sEMG), accurate recognition of predefined gestures only within a closed set is still inadequate in practice. It is essential to effectively discern and reject unknown gestures of disinterest in a robust system. Numerous methods based on prototype learning (PL) have been proposed to tackle this open set recognition (OSR) problem. However, they do not fully explore the inherent distinctions between known and unknown classes. In this paper, we propose a more effective PL method leveraging two novel and inherent distinctions, feature activation level and projection inconsistency. Specifically, the Feature Activation Enhancement Mechanism (FAEM) widens the gap in feature activation values between known and unknown classes. Furthermore, we introduce Orthogonal Prototype Learning (OPL) to construct multiple perspectives. OPL acts to project a sample from orthogonal directions to maximize the distinction between its two projections, where unknown samples will be projected near the clusters of different known classes while known samples still maintain intra-class similarity. Our proposed method simultaneously achieves accurate closed-set classification for predefined gestures and effective rejection for unknown gestures. Extensive experiments demonstrate its efficacy and superiority in open-set gesture recognition based on sEMG.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02535"
  },
  "2312.02532": {
    "title": "DRAFT: Dense Retrieval Augmented Few-shot Topic classifier Framework",
    "authors": [
      "Keonwoo Kim",
      "Younggun Lee"
    ],
    "abstract": "With the growing volume of diverse information, the demand for classifying arbitrary topics has become increasingly critical. To address this challenge, we introduce DRAFT, a simple framework designed to train a classifier for few-shot topic classification. DRAFT uses a few examples of a specific topic as queries to construct Customized dataset with a dense retriever model. Multi-query retrieval (MQR) algorithm, which effectively handles multiple queries related to a specific topic, is applied to construct the Customized dataset. Subsequently, we fine-tune a classifier using the Customized dataset to identify the topic. To demonstrate the efficacy of our proposed approach, we conduct evaluations on both widely used classification benchmark datasets and manually constructed datasets with 291 diverse topics, which simulate diverse contents encountered in real-world applications. DRAFT shows competitive or superior performance compared to baselines that use in-context learning, such as GPT-3 175B and InstructGPT 175B, on few-shot topic classification tasks despite having 177 times fewer parameters, demonstrating its effectiveness.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02532"
  },
  "2312.02531": {
    "title": "PolyFit: A Peg-in-hole Assembly Framework for Unseen Polygon Shapes via Sim-to-real Adaptation",
    "authors": [
      "Geonhyup Lee",
      "Joosoon Lee",
      "Sangjun Noh",
      "Minhwan Ko",
      "Kangmin Kim",
      "Kyoobin Lee"
    ],
    "abstract": "The study addresses the foundational and challenging task of peg-in-hole assembly in robotics, where misalignments caused by sensor inaccuracies and mechanical errors often result in insertion failures or jamming. This research introduces PolyFit, representing a paradigm shift by transitioning from a reinforcement learning approach to a supervised learning methodology. PolyFit is a Force/Torque (F/T)-based supervised learning framework designed for 5-DoF peg-in-hole assembly. It utilizes F/T data for accurate extrinsic pose estimation and adjusts the peg pose to rectify misalignments. Extensive training in a simulated environment involves a dataset encompassing a diverse range of peg-hole shapes, extrinsic poses, and their corresponding contact F/T readings. To enhance extrinsic pose estimation, a multi-point contact strategy is integrated into the model input, recognizing that identical F/T readings can indicate different poses. The study proposes a sim-to-real adaptation method for real-world application, using a sim-real paired dataset to enable effective generalization to complex and unseen polygon shapes. PolyFit achieves impressive peg-in-hole success rates of 97.3% and 96.3% for seen and unseen shapes in simulations, respectively. Real-world evaluations further demonstrate substantial success rates of 86.7% and 85.0%, highlighting the robustness and adaptability of the proposed method.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02531"
  },
  "2312.02530": {
    "title": "MEMTO: Memory-guided Transformer for Multivariate Time Series Anomaly Detection",
    "authors": [
      "Junho Song",
      "Keonwoo Kim",
      "Jeonglyul Oh",
      "Sungzoon Cho"
    ],
    "abstract": "Detecting anomalies in real-world multivariate time series data is challenging due to complex temporal dependencies and inter-variable correlations. Recently, reconstruction-based deep models have been widely used to solve the problem. However, these methods still suffer from an over-generalization issue and fail to deliver consistently high performance. To address this issue, we propose the MEMTO, a memory-guided Transformer using a reconstruction-based approach. It is designed to incorporate a novel memory module that can learn the degree to which each memory item should be updated in response to the input data. To stabilize the training procedure, we use a two-phase training paradigm which involves using K-means clustering for initializing memory items. Additionally, we introduce a bi-dimensional deviation-based detection criterion that calculates anomaly scores considering both input space and latent space. We evaluate our proposed method on five real-world datasets from diverse domains, and it achieves an average anomaly detection F1-score of 95.74%, significantly outperforming the previous state-of-the-art methods. We also conduct extensive experiments to empirically validate the effectiveness of our proposed model's key components.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02530"
  },
  "2312.02522": {
    "title": "MASP: Scalable GNN-based Planning for Multi-Agent Navigation",
    "authors": [
      "Xinyi Yang",
      "Xinting Yang",
      "Chao Yu",
      "Jiayu Chen",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "abstract": "We investigate the problem of decentralized multi-agent navigation tasks, where multiple agents need to reach initially unassigned targets in a limited time. Classical planning-based methods suffer from expensive computation overhead at each step and offer limited expressiveness for complex cooperation strategies. In contrast, reinforcement learning (RL) has recently become a popular paradigm for addressing this issue. However, RL struggles with low data efficiency and cooperation when directly exploring (nearly) optimal policies in the large search space, especially with an increased agent number (e.g., 10+ agents) or in complex environments (e.g., 3D simulators). In this paper, we propose Multi-Agent Scalable GNN-based P lanner (MASP), a goal-conditioned hierarchical planner for navigation tasks with a substantial number of agents. MASP adopts a hierarchical framework to divide a large search space into multiple smaller spaces, thereby reducing the space complexity and accelerating training convergence. We also leverage graph neural networks (GNN) to model the interaction between agents and goals, improving goal achievement. Besides, to enhance generalization capabilities in scenarios with unseen team sizes, we divide agents into multiple groups, each with a previously trained number of agents. The results demonstrate that MASP outperforms classical planning-based competitors and RL baselines, achieving a nearly 100% success rate with minimal training data in both multi-agent particle environments (MPE) with 50 agents and a quadrotor 3-dimensional environment (OmniDrones) with 20 agents. Furthermore, the learned policy showcases zero-shot generalization across unseen team sizes.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02522"
  },
  "2312.02519": {
    "title": "Creative Agents: Empowering Agents with Imagination for Creative Tasks",
    "authors": [
      "Chi Zhang",
      "Penglin Cai",
      "Yuhui Fu",
      "Haoqi Yuan",
      "Zongqing Lu"
    ],
    "abstract": "We study building embodied agents for open-ended creative tasks. While existing methods build instruction-following agents that can perform diverse open-ended tasks, none of them demonstrates creativity -- the ability to give novel and diverse task solutions implicit in the language instructions. This limitation comes from their inability to convert abstract language instructions into concrete task goals in the environment and perform long-horizon planning for such complicated goals. Given the observation that humans perform creative tasks with the help of imagination, we propose a class of solutions for creative agents, where the controller is enhanced with an imaginator that generates detailed imaginations of task outcomes conditioned on language instructions. We introduce several approaches to implementing the components of creative agents. We implement the imaginator with either a large language model for textual imagination or a diffusion model for visual imagination. The controller can either be a behavior-cloning policy learned from data or a pre-trained foundation model generating executable codes in the environment. We benchmark creative tasks with the challenging open-world game Minecraft, where the agents are asked to create diverse buildings given free-form language instructions. In addition, we propose novel evaluation metrics for open-ended creative tasks utilizing GPT-4V, which holds many advantages over existing metrics. We perform a detailed experimental analysis of creative agents, showing that creative agents are the first AI agents accomplishing diverse building creation in the survival mode of Minecraft. Our benchmark and models are open-source for future research on creative agents (https://github.com/PKU-RL/Creative-Agents).\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02519"
  },
  "2312.02517": {
    "title": "Simplifying Neural Network Training Under Class Imbalance",
    "authors": [
      "Ravid Shwartz-Ziv",
      "Micah Goldblum",
      "Yucen Lily Li",
      "C. Bayan Bruss",
      "Andrew Gordon Wilson"
    ],
    "abstract": "Real-world datasets are often highly class-imbalanced, which can adversely impact the performance of deep learning models. The majority of research on training neural networks under class imbalance has focused on specialized loss functions, sampling techniques, or two-stage training procedures. Notably, we demonstrate that simply tuning existing components of standard deep learning pipelines, such as the batch size, data augmentation, optimizer, and label smoothing, can achieve state-of-the-art performance without any such specialized class imbalance methods. We also provide key prescriptions and considerations for training under class imbalance, and an understanding of why imbalance methods succeed or fail.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02517"
  },
  "2312.02514": {
    "title": "Skipping Scheme for Gate-hiding Garbled Circuits",
    "authors": [
      "Ke Lin"
    ],
    "abstract": "In classic settings of garbled circuits, each gate type is leaked to improve both space and speed optimization. Zahur et al. have shown in EUROCRYPT 2015 that a typical linear garbling scheme requires at least two $\u03bb$-bit elements per gate with a security parameter of $\u03bb$, which limits their efficiency. In contrast to typical garbled circuits, gate-hiding garbled circuits have the potential to drastically reduce time costs, although they have been underappreciated.\n  We propose the first skipping scheme for gate-hiding garbled circuits to enhance the efficiency of evaluation by observing prime implicants. Our scheme introduces skip gates to eliminate the need to calculate the entire circuit, enabling unnecessary execution paths to be avoided. We also introduce two variants of our scheme that balance security with parallelism. A proof of hybrid security that combines simulation-based and symmetry-based security in semi-honest scenarios is presented to demonstrate its security under gate-hiding conditions. Our scheme will inspire new directions to improve the general garbling scheme and lead to more practical ones.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02514"
  },
  "2312.02510": {
    "title": "Estimation of articulated angle in six-wheeled dump trucks using multiple GNSS receivers for autonomous driving",
    "authors": [
      "Taro Suzuki",
      "Kazunori Ohno",
      "Syotaro Kojima",
      "Naoto Miyamoto",
      "Takahiro Suzuki",
      "Tomohiro Komatsu",
      "Yukinori Shibata",
      "Kimitaka Asano",
      "Keiji Nagatani"
    ],
    "abstract": "Due to the declining birthrate and aging population, the shortage of labor in the construction industry has become a serious problem, and increasing attention has been paid to automation of construction equipment. We focus on the automatic operation of articulated six-wheel dump trucks at construction sites. For the automatic operation of the dump trucks, it is important to estimate the position and the articulated angle of the dump trucks with high accuracy. In this study, we propose a method for estimating the state of a dump truck by using four global navigation satellite systems (GNSSs) installed on an articulated dump truck and a graph optimization method that utilizes the redundancy of multiple GNSSs. By adding real-time kinematic (RTK)-GNSS constraints and geometric constraints between the four antennas, the proposed method can robustly estimate the position and articulation angle even in environments where GNSS satellites are partially blocked. As a result of evaluating the accuracy of the proposed method through field tests, it was confirmed that the articulated angle could be estimated with an accuracy of 0.1$^\\circ$ in an open-sky environment and 0.7$^\\circ$ in a mountainous area simulating an elevation angle of 45$^\\circ$ where GNSS satellites are blocked.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02510"
  },
  "2312.02509": {
    "title": "When PETs misbehave: A Contextual Integrity analysis",
    "authors": [
      "Ero Balsa",
      "Yan Shvartzshnaider"
    ],
    "abstract": "Privacy enhancing technologies, or PETs, have been hailed as a promising means to protect privacy without compromising on the functionality of digital services. At the same time, and partly because they may encode a narrow conceptualization of privacy as confidentiality that is popular among policymakers, engineers and the public, PETs risk being co-opted to promote privacy-invasive practices. In this paper, we resort to the theory of Contextual Integrity to explain how privacy technologies may be misused to erode privacy. To illustrate, we consider three PETs and scenarios: anonymous credentials for age verification, client-side scanning for illegal content detection, and homomorphic encryption for machine learning model training. Using the theory of Contextual Integrity, we reason about the notion of privacy that these PETs encode, and show that CI enables us to identify and reason about the limitations of PETs and their misuse, and which may ultimately lead to privacy violations.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02509"
  },
  "2312.02505": {
    "title": "Evaluating eVTOL Network Performance and Fleet Dynamics through Simulation-Based Analysis",
    "authors": [
      "Emin Burak Onat",
      "Vishwanath Bulusu",
      "Anjan Chakrabarty",
      "Mark Hansen",
      "Raja Sengupta",
      "Banavar Sridar"
    ],
    "abstract": "Urban Air Mobility (UAM) represents a promising solution for future transportation. In this study, we introduce VertiSim, an advanced event-driven simulator developed to evaluate e-VTOL transportation networks. Uniquely, VertiSim simultaneously models passenger, aircraft, and energy flows, reflecting the interrelated complexities of UAM systems. We utilized VertiSim to assess 19 operational scenarios serving a daily demand for 2,834 passengers with varying fleet sizes and vertiport distances. The study aims to support stakeholders in making informed decisions about fleet size, network design, and infrastructure development by understanding tradeoffs in passenger delay time, operational costs, and fleet utilization. Our simulations, guided by a heuristic dispatch and charge policy, indicate that fleet size significantly influences passenger delay and energy consumption within UAM networks. We find that increasing the fleet size can reduce average passenger delays, but this comes at the cost of higher operational expenses due to an increase in the number of repositioning flights. Additionally, our analysis highlights how vertiport distances impact fleet utilization: longer distances result in reduced total idle time and increased cruise and charge times, leading to more efficient fleet utilization but also longer passenger delays. These findings are important for UAM network planning, especially in balancing fleet size with vertiport capacity and operational costs. Simulator demo is available at: https://tinyurl.com/vertisim-vis\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02505"
  },
  "2312.02503": {
    "title": "SAVE: Protagonist Diversification with Structure Agnostic Video Editing",
    "authors": [
      "Yeji Song",
      "Wonsik Shin",
      "Junsoo Lee",
      "Jeesoo Kim",
      "Nojun Kwak"
    ],
    "abstract": "Driven by the upsurge progress in text-to-image (T2I) generation models, text-to-video (T2V) generation has experienced a significant advance as well. Accordingly, tasks such as modifying the object or changing the style in a video have been possible. However, previous works usually work well on trivial and consistent shapes, and easily collapse on a difficult target that has a largely different body shape from the original one. In this paper, we spot the bias problem in the existing video editing method that restricts the range of choices for the new protagonist and attempt to address this issue using the conventional image-level personalization method. We adopt motion personalization that isolates the motion from a single source video and then modifies the protagonist accordingly. To deal with the natural discrepancy between image and video, we propose a motion word with an inflated textual embedding to properly represent the motion in a source video. We also regulate the motion word to attend to proper motion-related areas by introducing a novel pseudo optical flow, efficiently computed from the pre-calculated attention maps. Finally, we decouple the motion from the appearance of the source video with an additional pseudo word. Extensive experiments demonstrate the editing capability of our method, taking a step toward more diverse and extensive video editing.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02503"
  },
  "2312.02501": {
    "title": "Inspecting Model Fairness in Ultrasound Segmentation Tasks",
    "authors": [
      "Zikang Xu",
      "Fenghe Tang",
      "Quan Quan",
      "Jianrui Ding",
      "Chunping Ning",
      "S. Kevin Zhou"
    ],
    "abstract": "With the rapid expansion of machine learning and deep learning (DL), researchers are increasingly employing learning-based algorithms to alleviate diagnostic challenges across diverse medical tasks and applications. While advancements in diagnostic precision are notable, some researchers have identified a concerning trend: their models exhibit biased performance across subgroups characterized by different sensitive attributes. This bias not only infringes upon the rights of patients but also has the potential to lead to life-altering consequences. In this paper, we inspect a series of DL segmentation models using two ultrasound datasets, aiming to assess the presence of model unfairness in these specific tasks. Our findings reveal that even state-of-the-art DL algorithms demonstrate unfair behavior in ultrasound segmentation tasks. These results serve as a crucial warning, underscoring the necessity for careful model evaluation before their deployment in real-world scenarios. Such assessments are imperative to ensure ethical considerations and mitigate the risk of adverse impacts on patient outcomes.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02501"
  },
  "2312.02496": {
    "title": "MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative Models on Medical Conversation Tasks",
    "authors": [
      "Ke Liang",
      "Sifan Wu",
      "Jiayi Gu"
    ],
    "abstract": "Using natural language processing (NLP) technologies to develop medical chatbots makes the diagnosis of the patient more convenient and efficient, which is a typical application in healthcare AI. Because of its importance, lots of research have been come out. Recently, the neural generative models have shown their impressive ability as the core of chatbot, while it cannot scale well when directly applied to medical conversation due to the lack of medical-specific knowledge. To address the limitation, a scalable Medical Knowledge Assisted mechanism, MKA, is proposed in this paper. The mechanism aims to assist general neural generative models to achieve better performance on the medical conversation task. The medical-specific knowledge graph is designed within the mechanism, which contains 6 types of medical-related information, including department, drug, check, symptom, disease, food. Besides, the specific token concatenation policy is defined to effectively inject medical information into the input data. Evaluation of our method is carried out on two typical medical datasets, MedDG and MedDialog-CN. The evaluation results demonstrate that models combined with our mechanism outperform original methods in multiple automatic evaluation metrics. Besides, MKA-Bert-GPT achieves state-of-the-art performance. The open-sourced codes are public: https://github.com/LIANGKE23/Knowledge_Assisted_Medical_Dialogue_Generation_Mechanism\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02496"
  },
  "2312.02494": {
    "title": "ReconU-Net: a direct PET image reconstruction using U-Net architecture with back projection-induced skip connection",
    "authors": [
      "Fumio Hashimoto",
      "Kibo Ote"
    ],
    "abstract": "[Objective] This study aims to introduce a novel back projection-induced U-Net-shaped architecture, called ReconU-Net, for deep learning-based direct positron emission tomography (PET) image reconstruction. Additionally, our objective is to analyze the behavior of direct PET image reconstruction and gain deeper insights by comparing the proposed ReconU-Net architecture with other encoder-decoder architectures without skip connections. [Approach] The proposed ReconU-Net architecture uniquely integrates the physical model of the back projection operation into the skip connection. This distinctive feature facilitates the effective transfer of intrinsic spatial information from the input sinogram to the reconstructed image via an embedded physical model. The proposed ReconU-Net was trained using Monte Carlo simulation data from the Brainweb phantom and tested on both simulated and real Hoffman brain phantom data. [Main results] The proposed ReconU-Net method generated a reconstructed image with a more accurate structure compared to other deep learning-based direct reconstruction methods. Further analysis showed that the proposed ReconU-Net architecture has the ability to transfer features of multiple resolutions, especially non-abstract high-resolution information, through skip connections. Despite limited training on simulated data, the proposed ReconU-Net successfully reconstructed the real Hoffman brain phantom, unlike other deep learning-based direct reconstruction methods, which failed to produce a reconstructed image. [Significance] The proposed ReconU-Net can improve the fidelity of direct PET image reconstruction, even when dealing with small training datasets, by leveraging the synergistic relationship between data-driven modeling and the physics model of the imaging process.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02494"
  },
  "2312.02490": {
    "title": "Constrained Twin Variational Auto-Encoder for Intrusion Detection in IoT Systems",
    "authors": [
      "Phai Vu Dinh",
      "Quang Uy Nguyen",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Son Pham Bao",
      "Eryk Dutkiewicz"
    ],
    "abstract": "Intrusion detection systems (IDSs) play a critical role in protecting billions of IoT devices from malicious attacks. However, the IDSs for IoT devices face inherent challenges of IoT systems, including the heterogeneity of IoT data/devices, the high dimensionality of training data, and the imbalanced data. Moreover, the deployment of IDSs on IoT systems is challenging, and sometimes impossible, due to the limited resources such as memory/storage and computing capability of typical IoT devices. To tackle these challenges, this article proposes a novel deep neural network/architecture called Constrained Twin Variational Auto-Encoder (CTVAE) that can feed classifiers of IDSs with more separable/distinguishable and lower-dimensional representation data. Additionally, in comparison to the state-of-the-art neural networks used in IDSs, CTVAE requires less memory/storage and computing power, hence making it more suitable for IoT IDS systems. Extensive experiments with the 11 most popular IoT botnet datasets show that CTVAE can boost around 1% in terms of accuracy and Fscore in detection attack compared to the state-of-the-art machine learning and representation learning methods, whilst the running time for attack detection is lower than 2E-6 seconds and the model size is lower than 1 MB. We also further investigate various characteristics of CTVAE in the latent space and in the reconstruction representation to demonstrate its efficacy compared with current well-known methods.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02490"
  },
  "2312.02488": {
    "title": "Uncertainty-Aware Shared Autonomy System with Hierarchical Conservative Skill Inference",
    "authors": [
      "Taewoo Kim",
      "Donghyung Kim",
      "Minsu Jang",
      "Jaehong Kim"
    ],
    "abstract": "Shared autonomy imitation learning, in which robots share workspace with humans for learning, enables correct actions in unvisited states and the effective resolution of compounding errors through expert's corrections. However, it demands continuous human attention and supervision to lead the demonstrations, without considering the risks associated with human judgment errors and delayed interventions. This can potentially lead to high levels of fatigue for the demonstrator and the additional errors. In this work, we propose an uncertainty-aware shared autonomy system that enables the robot to infer conservative task skills considering environmental uncertainties and learning from expert demonstrations and corrections. To enhance generalization and scalability, we introduce a hierarchical structure-based skill uncertainty inference framework operating at more abstract levels. We apply this to robot motion to promote a more stable interaction. Although shared autonomy systems have demonstrated high-level results in recent research and play a critical role, specific system design details have remained elusive. This paper provides a detailed design proposal for a shared autonomy system considering various robot configurations. Furthermore, we experimentally demonstrate the system's capability to learn operational skills, even in dynamic environments with interference, through pouring and pick-and-place tasks. Our code will be released soon.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02488"
  },
  "2312.02485": {
    "title": "Robust UAV Position and Attitude Estimation using Multiple GNSS Receivers for Laser-based 3D Mapping",
    "authors": [
      "Taro Suzuki",
      "Daichi Inoue",
      "Yoshiharu Amano"
    ],
    "abstract": "Small-sized unmanned aerial vehicles (UAVs) have been widely investigated for use in a variety of applications such as remote sensing and aerial surveying. Direct three-dimensional (3D) mapping using a small-sized UAV equipped with a laser scanner is required for numerous remote sensing applications. In direct 3D mapping, the precise information about the position and attitude of the UAV is necessary for constructing 3D maps. In this study, we propose a novel and robust technique for estimating the position and attitude of small-sized UAVs by employing multiple low-cost and light-weight global navigation satellite system (GNSS) antennas/receivers. Using the \"redundancy\" of multiple GNSS receivers, we enhance the performance of real-time kinematic (RTK)-GNSS by employing single-frequency GNSS receivers. This method consists of two approaches: hybrid GNSS fix solutions and consistency examination of the GNSS signal strength. The fix rate of RTK-GNSS using single-frequency GNSS receivers can be highly enhanced to combine multiple RTK-GNSS to fix solutions in the multiple antennas. In addition, positioning accuracy and fix rate can be further enhanced to detect multipath signals by using multiple GNSS antennas. In this study, we developed a prototype UAV that is equipped with six GNSS antennas/receivers. From the static test results, we conclude that the proposed technique can enhance the accuracy of the position and attitude estimation in multipath environments. From the flight test, the proposed system could generate a 3D map with an accuracy of 5 cm.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02485"
  },
  "2312.02481": {
    "title": "Learning to Holistically Detect Bridges from Large-Size VHR Remote Sensing Imagery",
    "authors": [
      "Yansheng Li",
      "Junwei Luo",
      "Yongjun Zhang",
      "Yihua Tan",
      "Jin-Gang Yu",
      "Song Bai"
    ],
    "abstract": "Bridge detection in remote sensing images (RSIs) plays a crucial role in various applications, but it poses unique challenges compared to the detection of other objects. In RSIs, bridges exhibit considerable variations in terms of their spatial scales and aspect ratios. Therefore, to ensure the visibility and integrity of bridges, it is essential to perform holistic bridge detection in large-size very-high-resolution (VHR) RSIs. However, the lack of datasets with large-size VHR RSIs limits the deep learning algorithms' performance on bridge detection. Due to the limitation of GPU memory in tackling large-size images, deep learning-based object detection methods commonly adopt the cropping strategy, which inevitably results in label fragmentation and discontinuous prediction. To ameliorate the scarcity of datasets, this paper proposes a large-scale dataset named GLH-Bridge comprising 6,000 VHR RSIs sampled from diverse geographic locations across the globe. These images encompass a wide range of sizes, varying from 2,048*2,048 to 16,38*16,384 pixels, and collectively feature 59,737 bridges. Furthermore, we present an efficient network for holistic bridge detection (HBD-Net) in large-size RSIs. The HBD-Net presents a separate detector-based feature fusion (SDFF) architecture and is optimized via a shape-sensitive sample re-weighting (SSRW) strategy. Based on the proposed GLH-Bridge dataset, we establish a bridge detection benchmark including the OBB and HBB tasks, and validate the effectiveness of the proposed HBD-Net. Additionally, cross-dataset generalization experiments on two publicly available datasets illustrate the strong generalization capability of the GLH-Bridge dataset.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02481"
  },
  "2312.02478": {
    "title": "RL-Based Cargo-UAV Trajectory Planning and Cell Association for Minimum Handoffs, Disconnectivity, and Energy Consumption",
    "authors": [
      "Nesrine Cherif",
      "Wael Jaafar",
      "Halim Yanikomeroglu",
      "Abbas Yongacoglu"
    ],
    "abstract": "Unmanned aerial vehicle (UAV) is a promising technology for last-mile cargo delivery. However, the limited on-board battery capacity, cellular unreliability, and frequent handoffs in the airspace are the main obstacles to unleash its full potential. Given that existing cellular networks were primarily designed to service ground users, re-utilizing the same architecture for highly mobile aerial users, e.g., cargo-UAVs, is deemed challenging. Indeed, to ensure a safe delivery using cargo-UAVs, it is crucial to utilize the available energy efficiently, while guaranteeing reliable connectivity for command-and-control and avoiding frequent handoff. To achieve this goal, we propose a novel approach for joint cargo-UAV trajectory planning and cell association. Specifically, we formulate the cargo-UAV mission as a multi-objective problem aiming to 1) minimize energy consumption, 2) reduce handoff events, and 3) guarantee cellular reliability along the trajectory. We leverage reinforcement learning (RL) to jointly optimize the cargo-UAV's trajectory and cell association. Simulation results demonstrate a performance improvement of our proposed method, in terms of handoffs, disconnectivity, and energy consumption, compared to benchmarks.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02478"
  },
  "2312.02473": {
    "title": "NeutronStream: A Dynamic GNN Training Framework with Sliding Window for Graph Streams",
    "authors": [
      "Chaoyi Chen",
      "Dechao Gao",
      "Yanfeng Zhang",
      "Qiange Wang",
      "Zhenbo Fu",
      "Xuecang Zhang",
      "Junhua Zhu",
      "Yu Gu",
      "Ge Yu"
    ],
    "abstract": "Existing Graph Neural Network (GNN) training frameworks have been designed to help developers easily create performant GNN implementations. However, most existing GNN frameworks assume that the input graphs are static, but ignore that most real-world graphs are constantly evolving. Though many dynamic GNN models have emerged to learn from evolving graphs, the training process of these dynamic GNNs is dramatically different from traditional GNNs in that it captures both the spatial and temporal dependencies of graph updates. This poses new challenges for designing dynamic GNN training frameworks. First, the traditional batched training method fails to capture real-time structural evolution information. Second, the time-dependent nature makes parallel training hard to design. Third, it lacks system supports for users to efficiently implement dynamic GNNs. In this paper, we present NeutronStream, a framework for training dynamic GNN models. NeutronStream abstracts the input dynamic graph into a chronologically updated stream of events and processes the stream with an optimized sliding window to incrementally capture the spatial-temporal dependencies of events. Furthermore, NeutronStream provides a parallel execution engine to tackle the sequential event processing challenge to achieve high performance. NeutronStream also integrates a built-in graph storage structure that supports dynamic updates and provides a set of easy-to-use APIs that allow users to express their dynamic GNNs. Our experimental results demonstrate that, compared to state-of-the-art dynamic GNN implementations, NeutronStream achieves speedups ranging from 1.48X to 5.87X and an average accuracy improvement of 3.97%.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02473"
  },
  "2312.02471": {
    "title": "Congestion-aware Distributed Task Offloading in Wireless Multi-hop Networks Using Graph Neural Networks",
    "authors": [
      "Zhongyuan Zhao",
      "Jake Perazzone",
      "Gunjan Verma",
      "Santiago Segarra"
    ],
    "abstract": "Computational offloading has become an enabling component for edge intelligence in mobile and smart devices. Existing offloading schemes mainly focus on mobile devices and servers, while ignoring the potential network congestion caused by tasks from multiple mobile devices, especially in wireless multi-hop networks. To fill this gap, we propose a low-overhead, congestion-aware distributed task offloading scheme by augmenting a distributed greedy framework with graph-based machine learning. In simulated wireless multi-hop networks with 20-110 nodes and a resource allocation scheme based on shortest path routing and contention-based link scheduling, our approach is demonstrated to be effective in reducing congestion or unstable queues under the context-agnostic baseline, while improving the execution latency over local computing.\n        \u25b3 Less",
    "submission_date": "21 January, 2024",
    "eprint_id": "2312.02471"
  },
  "2312.02470": {
    "title": "Generator Born from Classifier",
    "authors": [
      "Runpeng Yu",
      "Xinchao Wang"
    ],
    "abstract": "In this paper, we make a bold attempt toward an ambitious task: given a pre-trained classifier, we aim to reconstruct an image generator, without relying on any data samples. From a black-box perspective, this challenge seems intractable, since it inevitably involves identifying the inverse function for a classifier, which is, by nature, an information extraction process. As such, we resort to leveraging the knowledge encapsulated within the parameters of the neural network. Grounded on the theory of Maximum-Margin Bias of gradient descent, we propose a novel learning paradigm, in which the generator is trained to ensure that the convergence conditions of the network parameters are satisfied over the generated distribution of the samples. Empirical validation from various image generation tasks substantiates the efficacy of our strategy.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02470"
  },
  "2312.02469": {
    "title": "Learning Energy-based Model via Dual-MCMC Teaching",
    "authors": [
      "Jiali Cui",
      "Tian Han"
    ],
    "abstract": "This paper studies the fundamental learning problem of the energy-based model (EBM). Learning the EBM can be achieved using the maximum likelihood estimation (MLE), which typically involves the Markov Chain Monte Carlo (MCMC) sampling, such as the Langevin dynamics. However, the noise-initialized Langevin dynamics can be challenging in practice and hard to mix. This motivates the exploration of joint training with the generator model where the generator model serves as a complementary model to bypass MCMC sampling. However, such a method can be less accurate than the MCMC and result in biased EBM learning. While the generator can also serve as an initializer model for better MCMC sampling, its learning can be biased since it only matches the EBM and has no access to empirical training examples. Such biased generator learning may limit the potential of learning the EBM. To address this issue, we present a joint learning framework that interweaves the maximum likelihood learning algorithm for both the EBM and the complementary generator model. In particular, the generator model is learned by MLE to match both the EBM and the empirical data distribution, making it a more informative initializer for MCMC sampling of EBM. Learning generator with observed examples typically requires inference of the generator posterior. To ensure accurate and efficient inference, we adopt the MCMC posterior sampling and introduce a complementary inference model to initialize such latent MCMC sampling. We show that three separate models can be seamlessly integrated into our joint framework through two (dual-) MCMC teaching, enabling effective and efficient EBM learning.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02469"
  },
  "2312.02468": {
    "title": "Terrain-Based UAV Deployment: Providing Coverage for Outdoor Users",
    "authors": [
      "Zhengying Lou",
      "Ruibo Wang",
      "Baha Eddine Youcef Belmekki",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "Deploying unmanned aerial vehicle (UAV) networks to provide coverage for outdoor users has attracted great attention during the last decade. However, outdoor coverage is challenging due to the high mobility of crowds and the diverse terrain configurations causing building blockage. Most studies use stochastic channel models to characterize the impact of building blockage on user performance and do not take into account terrain information. On the other hand, real-time search methods use terrain information, but they are only practical when a single UAV serves a single user.In this paper, we put forward two methods to avoid building blockage in a multi-user system by collecting prior terrain information and using real-time search.We proposed four algorithms related to the combinations of the above methods and their performances are evaluated and compared in different scenarios.By adjusting the height of the UAV based on terrain information collected before networking, the performance is significantly enhanced compared to the one when no terrain information is available.The algorithm based on real-time search further improves the coverage performance by avoiding the shadow of buildings. During the execution of the real-time search algorithm, the search distance is reduced using the collected terrain information.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02468"
  },
  "2312.02467": {
    "title": "Object Importance Estimation using Counterfactual Reasoning for Intelligent Driving",
    "authors": [
      "Pranay Gupta",
      "Abhijat Biswas",
      "Henny Admoni",
      "David Held"
    ],
    "abstract": "The ability to identify important objects in a complex and dynamic driving environment is essential for autonomous driving agents to make safe and efficient driving decisions. It also helps assistive driving systems decide when to alert drivers. We tackle object importance estimation in a data-driven fashion and introduce HOIST - Human-annotated Object Importance in Simulated Traffic. HOIST contains driving scenarios with human-annotated importance labels for vehicles and pedestrians. We additionally propose a novel approach that relies on counterfactual reasoning to estimate an object's importance. We generate counterfactual scenarios by modifying the motion of objects and ascribe importance based on how the modifications affect the ego vehicle's driving. Our approach outperforms strong baselines for the task of object importance estimation on HOIST. We also perform ablation studies to justify our design choices and show the significance of the different components of our proposed approach.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02467"
  },
  "2312.02464": {
    "title": "SAM-Assisted Remote Sensing Imagery Semantic Segmentation with Object and Boundary Constraints",
    "authors": [
      "Xianping Ma",
      "Qianqian Wu",
      "Xingyu Zhao",
      "Xiaokang Zhang",
      "Man-On Pun",
      "Bo Huang"
    ],
    "abstract": "Semantic segmentation of remote sensing imagery plays a pivotal role in extracting precise information for diverse down-stream applications. Recent development of the Segment Anything Model (SAM), an advanced general-purpose segmentation model, has revolutionized this field, presenting new avenues for accurate and efficient segmentation. However, SAM is limited to generating segmentation results without class information. Consequently, the utilization of such a powerful general vision model for semantic segmentation in remote sensing images has become a focal point of research. In this paper, we present a streamlined framework aimed at leveraging the raw output of SAM by exploiting two novel concepts called SAM-Generated Object (SGO) and SAM-Generated Boundary (SGB). More specifically, we propose a novel object loss and further introduce a boundary loss as augmentative components to aid in model optimization in a general semantic segmentation framework. Taking into account the content characteristics of SGO, we introduce the concept of object consistency to leverage segmented regions lacking semantic information. By imposing constraints on the consistency of predicted values within objects, the object loss aims to enhance semantic segmentation performance. Furthermore, the boundary loss capitalizes on the distinctive features of SGB by directing the model's attention to the boundary information of the object. Experimental results on two well-known datasets, namely ISPRS Vaihingen and LoveDA Urban, demonstrate the effectiveness of our proposed method. The source code for this work will be accessible at https://github.com/sstary/SSRS.\n        \u25b3 Less",
    "submission_date": "20 December, 2023",
    "eprint_id": "2312.02464"
  },
  "2312.02462": {
    "title": "Dimensionality Reduction and Dynamical Mode Recognition of Circular Arrays of Flame Oscillators Using Deep Neural Network",
    "authors": [
      "Weiming Xu",
      "Tao Yang",
      "Peng Zhang"
    ],
    "abstract": "Oscillatory combustion in aero engines and modern gas turbines often has significant adverse effects on their operation, and accurately recognizing various oscillation modes is the prerequisite for understanding and controlling combustion instability. However, the high-dimensional spatial-temporal data of a complex combustion system typically poses considerable challenges to the dynamical mode recognition. Based on a two-layer bidirectional long short-term memory variational autoencoder (Bi-LSTM-VAE) dimensionality reduction model and a two-dimensional Wasserstein distance-based classifier (WDC), this study proposes a promising method (Bi-LSTM-VAE-WDC) for recognizing dynamical modes in oscillatory combustion systems. Specifically, the Bi-LSTM-VAE dimension reduction model was introduced to reduce the high-dimensional spatial-temporal data of the combustion system to a low-dimensional phase space; Gaussian kernel density estimates (GKDE) were computed based on the distribution of phase points in a grid; two-dimensional WD values were calculated from the GKDE maps to recognize the oscillation modes. The time-series data used in this study were obtained from numerical simulations of circular arrays of laminar flame oscillators. The results show that the novel Bi-LSTM-VAE method can produce a non-overlapping distribution of phase points, indicating an effective unsupervised mode recognition and classification. Furthermore, the present method exhibits a more prominent performance than VAE and PCA (principal component analysis) for distinguishing dynamical modes in complex flame systems, implying its potential in studying turbulent combustion.\n        \u25b3 Less",
    "submission_date": "13 December, 2023",
    "eprint_id": "2312.02462"
  },
  "2312.02456": {
    "title": "Watermarking for Neural Radiation Fields by Invertible Neural Network",
    "authors": [
      "Wenquan Sun",
      "Jia Liu",
      "Weina Dong",
      "Lifeng Chen",
      "Ke Niu"
    ],
    "abstract": "To protect the copyright of the 3D scene represented by the neural radiation field, the embedding and extraction of the neural radiation field watermark are considered as a pair of inverse problems of image transformations. A scheme for protecting the copyright of the neural radiation field is proposed using invertible neural network watermarking, which utilizes watermarking techniques for 2D images to achieve the protection of the 3D scene. The scheme embeds the watermark in the training image of the neural radiation field through the forward process in the invertible network and extracts the watermark from the image rendered by the neural radiation field using the inverse process to realize the copyright protection of both the neural radiation field and the 3D scene. Since the rendering process of the neural radiation field can cause the loss of watermark information, the scheme incorporates an image quality enhancement module, which utilizes a neural network to recover the rendered image and then extracts the watermark. The scheme embeds a watermark in each training image to train the neural radiation field and enables the extraction of watermark information from multiple viewpoints. Simulation experimental results demonstrate the effectiveness of the method.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02456"
  },
  "2312.02450": {
    "title": "GIT-Net: Generalized Integral Transform for Operator Learning",
    "authors": [
      "Chao Wang",
      "Alexandre Hoang Thiery"
    ],
    "abstract": "This article introduces GIT-Net, a deep neural network architecture for approximating Partial Differential Equation (PDE) operators, inspired by integral transform operators. GIT-NET harnesses the fact that differential operators commonly used for defining PDEs can often be represented parsimoniously when expressed in specialized functional bases (e.g., Fourier basis). Unlike rigid integral transforms, GIT-Net parametrizes adaptive generalized integral transforms with deep neural networks. When compared to several recently proposed alternatives, GIT-Net's computational and memory requirements scale gracefully with mesh discretizations, facilitating its application to PDE problems on complex geometries. Numerical experiments demonstrate that GIT-Net is a competitive neural network operator, exhibiting small test errors and low evaluations across a range of PDE problems. This stands in contrast to existing neural network operators, which typically excel in just one of these areas.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02450"
  },
  "2312.02448": {
    "title": "Time-Relative RTK-GNSS: GNSS Loop Closure in Pose Graph Optimization",
    "authors": [
      "Taro Suzuki"
    ],
    "abstract": "A pose-graph-based optimization technique is widely used to estimate robot poses using various sensor measurements from devices such as laser scanners and cameras. The global navigation satellite system (GNSS) has recently been used to estimate the absolute 3D position of outdoor mobile robots. However, since the accuracy of GNSS single-point positioning is only a few meters, the GNSS is not used for the loop closure of a pose graph. The main purpose of this study is to generate a loop closure of a pose graph using a time-relative real-time kinematic GNSS (TR-RTK-GNSS) technique. The proposed TR-RTK-GNSS technique uses time-differential carrier phase positioning, which is based on carrier-phase-based differential GNSS with a single GNSS receiver. Unlike a conventional RTK-GNSS, we can directly compute the robot's relative position using only a stand-alone GNSS receiver. The initial pose graph is generated from the accumulated velocity computed from GNSS Doppler measurements. To reduce the accumulated error of velocity, we use the TR-RTK-GNSS technique for the loop closure in the graph-based optimization framework. The kinematic positioning tests were performed using an unmanned aerial vehicle to confirm the effectiveness of the proposed technique. From the tests, we can estimate the vehicle's trajectory with approximately 3 cm accuracy using only a stand-alone GNSS receiver.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02448"
  },
  "2312.02443": {
    "title": "E4SRec: An Elegant Effective Efficient Extensible Solution of Large Language Models for Sequential Recommendation",
    "authors": [
      "Xinhang Li",
      "Chong Chen",
      "Xiangyu Zhao",
      "Yong Zhang",
      "Chunxiao Xing"
    ],
    "abstract": "The recent advancements in Large Language Models (LLMs) have sparked interest in harnessing their potential within recommender systems. Since LLMs are designed for natural language tasks, existing recommendation approaches have predominantly transformed recommendation tasks into open-domain natural language generation tasks. However, this approach necessitates items to possess rich semantic information, often generates out-of-range results, and suffers from notably low efficiency and limited extensibility. Furthermore, practical ID-based recommendation strategies, reliant on a huge number of unique identities (IDs) to represent users and items, have gained prominence in real-world recommender systems due to their effectiveness and efficiency. Nevertheless, the incapacity of LLMs to model IDs presents a formidable challenge when seeking to leverage LLMs for personalized recommendations. In this paper, we introduce an Elegant Effective Efficient Extensible solution for large language models for Sequential Recommendation (E4SRec), which seamlessly integrates LLMs with traditional recommender systems that exclusively utilize IDs to represent items. Specifically, E4SRec takes ID sequences as inputs, ensuring that the generated outputs fall within the candidate lists. Furthermore, E4SRec possesses the capability to generate the entire ranking list in a single forward process, and demands only a minimal set of pluggable parameters, which are trained for each dataset while keeping the entire LLM frozen. We substantiate the effectiveness, efficiency, and extensibility of our proposed E4SRec through comprehensive experiments conducted on four widely-used real-world datasets. The implementation code is accessible at https://github.com/HestiaSky/E4SRec/.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02443"
  },
  "2312.02441": {
    "title": "MedDM:LLM-executable clinical guidance tree for clinical decision-making",
    "authors": [
      "Binbin Li",
      "Tianxin Meng",
      "Xiaoming Shi",
      "Jie Zhai",
      "Tong Ruan"
    ],
    "abstract": "It is becoming increasingly emphasis on the importance of LLM participating in clinical diagnosis decision-making. However, the low specialization refers to that current medical LLMs can not provide specific medical advice, which are more like a medical Q\\&A. And there is no suitable clinical guidance tree data set that can be used directly with LLM. To address this issue, we first propose LLM-executavle clinical guidance tree(CGT), which can be directly used by large language models, and construct medical diagnostic decision-making dataset (MedDM), from flowcharts in clinical practice guidelines. We propose an approach to screen flowcharts from medical literature, followed by their identification and conversion into standardized diagnostic decision trees. Constructed a knowledge base with 1202 decision trees, which came from 5000 medical literature and covered 12 hospital departments, including internal medicine, surgery, psychiatry, and over 500 diseases.Moreover, we propose a method for reasoning on LLM-executable CGT and a Patient-LLM multi-turn dialogue framework.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02441"
  },
  "2312.02438": {
    "title": "Adaptive Instrument Design for Indirect Experiments",
    "authors": [
      "Yash Chandak",
      "Shiv Shankar",
      "Vasilis Syrgkanis",
      "Emma Brunskill"
    ],
    "abstract": "Indirect experiments provide a valuable framework for estimating treatment effects in situations where conducting randomized control trials (RCTs) is impractical or unethical. Unlike RCTs, indirect experiments estimate treatment effects by leveraging (conditional) instrumental variables, enabling estimation through encouragement and recommendation rather than strict treatment assignment. However, the sample efficiency of such estimators depends not only on the inherent variability in outcomes but also on the varying compliance levels of users with the instrumental variables and the choice of estimator being used, especially when dealing with numerous instrumental variables. While adaptive experiment design has a rich literature for direct experiments, in this paper we take the initial steps towards enhancing sample efficiency for indirect experiments by adaptively designing a data collection policy over instrumental variables. Our main contribution is a practical computational procedure that utilizes influence functions to search for an optimal data collection policy, minimizing the mean-squared error of the desired (non-linear) estimator. Through experiments conducted in various domains inspired by real-world applications, we showcase how our method can significantly improve the sample efficiency of indirect experiments.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02438"
  },
  "2312.02437": {
    "title": "GDN: A Stacking Network Used for Skin Cancer Diagnosis",
    "authors": [
      "Jingmin Wei",
      "Haoyang Shen",
      "Ziyi Wang",
      "Ziqian Zhang"
    ],
    "abstract": "Skin cancer, the primary type of cancer that can be identified by visual recognition, requires an automatic identification system that can accurately classify different types of lesions. This paper presents GoogLe-Dense Network (GDN), which is an image-classification model to identify two types of skin cancer, Basal Cell Carcinoma, and Melanoma. GDN uses stacking of different networks to enhance the model performance. Specifically, GDN consists of two sequential levels in its structure. The first level performs basic classification tasks accomplished by GoogLeNet and DenseNet, which are trained in parallel to enhance efficiency. To avoid low accuracy and long training time, the second level takes the output of the GoogLeNet and DenseNet as the input for a logistic regression model. We compare our method with four baseline networks including ResNet, VGGNet, DenseNet, and GoogLeNet on the dataset, in which GoogLeNet and DenseNet significantly outperform ResNet and VGGNet. In the second level, different stacking methods such as perceptron, logistic regression, SVM, decision trees and K-neighbor are studied in which Logistic Regression shows the best prediction result among all. The results prove that GDN, compared to a single network structure, has higher accuracy in optimizing skin cancer detection.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02437"
  },
  "2312.02434": {
    "title": "FINER: Flexible spectral-bias tuning in Implicit NEural Representation by Variable-periodic Activation Functions",
    "authors": [
      "Zhen Liu",
      "Hao Zhu",
      "Qi Zhang",
      "Jingde Fu",
      "Weibing Deng",
      "Zhan Ma",
      "Yanwen Guo",
      "Xun Cao"
    ],
    "abstract": "Implicit Neural Representation (INR), which utilizes a neural network to map coordinate inputs to corresponding attributes, is causing a revolution in the field of signal processing. However, current INR techniques suffer from a restricted capability to tune their supported frequency set, resulting in imperfect performance when representing complex signals with multiple frequencies. We have identified that this frequency-related problem can be greatly alleviated by introducing variable-periodic activation functions, for which we propose FINER. By initializing the bias of the neural network within different ranges, sub-functions with various frequencies in the variable-periodic function are selected for activation. Consequently, the supported frequency set of FINER can be flexibly tuned, leading to improved performance in signal representation. We demonstrate the capabilities of FINER in the contexts of 2D image fitting, 3D signed distance field representation, and 5D neural radiance fields optimization, and we show that it outperforms existing INRs.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02434"
  },
  "2312.02433": {
    "title": "Lenna: Language Enhanced Reasoning Detection Assistant",
    "authors": [
      "Fei Wei",
      "Xinyu Zhang",
      "Ailing Zhang",
      "Bo Zhang",
      "Xiangxiang Chu"
    ],
    "abstract": "With the fast-paced development of multimodal large language models (MLLMs), we can now converse with AI systems in natural languages to understand images. However, the reasoning power and world knowledge embedded in the large language models have been much less investigated and exploited for image perception tasks. In this paper, we propose Lenna, a language-enhanced reasoning detection assistant, which utilizes the robust multimodal feature representation of MLLMs, while preserving location information for detection. This is achieved by incorporating an additional <DET> token in the MLLM vocabulary that is free of explicit semantic context but serves as a prompt for the detector to identify the corresponding position. To evaluate the reasoning capability of Lenna, we construct a ReasonDet dataset to measure its performance on reasoning-based detection. Remarkably, Lenna demonstrates outstanding performance on ReasonDet and comes with significantly low training costs. It also incurs minimal transferring overhead when extended to other tasks. Our code and model will be available at https://git.io/Lenna.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02433"
  },
  "2312.02431": {
    "title": "Visually Grounded Language Learning: a review of language games, datasets, tasks, and models",
    "authors": [
      "Alessandro Suglia",
      "Ioannis Konstas",
      "Oliver Lemon"
    ],
    "abstract": "In recent years, several machine learning models have been proposed. They are trained with a language modelling objective on large-scale text-only data. With such pretraining, they can achieve impressive results on many Natural Language Understanding and Generation tasks. However, many facets of meaning cannot be learned by ``listening to the radio\" only. In the literature, many Vision+Language (V+L) tasks have been defined with the aim of creating models that can ground symbols in the visual modality. In this work, we provide a systematic literature review of several tasks and models proposed in the V+L field. We rely on Wittgenstein's idea of `language games' to categorise such tasks into 3 different families: 1) discriminative games, 2) generative games, and 3) interactive games. Our analysis of the literature provides evidence that future work should be focusing on interactive games where communication in Natural Language is important to resolve ambiguities about object referents and action plans and that physical embodiment is essential to understand the semantics of situations and events. Overall, these represent key requirements for developing grounded meanings in neural models.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02431"
  },
  "2312.02430": {
    "title": "Almost-Sure Safety Guarantees of Stochastic Zero-Control Barrier Functions Do Not Hold",
    "authors": [
      "Oswin So",
      "Andrew Clark",
      "Chuchu Fan"
    ],
    "abstract": "The 2021 paper \"Control barrier functions for stochastic systems\" provides theorems that give almost sure safety guarantees given stochastic zero control barrier function (ZCBF). Unfortunately, both the theorem and its proof is invalid. In this letter, we illustrate on a toy example that the almost sure safety guarantees for stochastic ZCBF do not hold and explain why the proof is flawed. Although stochastic reciprocal barrier functions (RCBF) also uses the same proof technique, we provide a different proof technique that verifies that stochastic RCBFs are indeed safe with probability one. Using the RCBF, we derive a modified ZCBF condition that guarantees safety with probability one. Finally, we provide some discussion on the role of unbounded controls in the almost-sure safety guarantees of RCBFs, and show that the rate of divergence of the ratio of the drift and diffusion is the key for whether a system has almost sure safety guarantees.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02430"
  },
  "2312.02429": {
    "title": "PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval Models",
    "authors": [
      "Wei-Cheng Chang",
      "Jyun-Yu Jiang",
      "Jiong Zhang",
      "Mutasem Al-Darabsah",
      "Choon Hui Teo",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu",
      "S. V. N. Vishwanathan"
    ],
    "abstract": "Embedding-based Retrieval Models (ERMs) have emerged as a promising framework for large-scale text retrieval problems due to powerful large language models. Nevertheless, fine-tuning ERMs to reach state-of-the-art results can be expensive due to the extreme scale of data as well as the complexity of multi-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this work, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast tuning of ERMs without any backward pass in the optimization. At index building stage, PEFA equips the ERM with a non-parametric k-nearest neighbor (kNN) component. At inference stage, PEFA performs a convex combination of two scoring functions, one from the ERM and the other from the kNN. Based on the neighborhood definition, PEFA framework induces two realizations, namely PEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra small) using a single ANN index. Empirically, PEFA achieves significant improvement on two retrieval applications. For document retrieval, regarding Recall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an average of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%, respectively. For product search, PEFA improves the Recall@100 of the fine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL, respectively. Our code is available at https://github.com/amzn/pecos/tree/mainline/examples/pefa-wsdm24.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02429"
  },
  "2312.02428": {
    "title": "FreestyleRet: Retrieving Images from Style-Diversified Queries",
    "authors": [
      "Hao Li",
      "Curise Jia",
      "Peng Jin",
      "Zesen Cheng",
      "Kehan Li",
      "Jialu Sui",
      "Chang Liu",
      "Li Yuan"
    ],
    "abstract": "Image Retrieval aims to retrieve corresponding images based on a given query. In application scenarios, users intend to express their retrieval intent through various query styles. However, current retrieval tasks predominantly focus on text-query retrieval exploration, leading to limited retrieval query options and potential ambiguity or bias in user intention. In this paper, we propose the Style-Diversified Query-Based Image Retrieval task, which enables retrieval based on various query styles. To facilitate the novel setting, we propose the first Diverse-Style Retrieval dataset, encompassing diverse query styles including text, sketch, low-resolution, and art. We also propose a light-weighted style-diversified retrieval framework. For various query style inputs, we apply the Gram Matrix to extract the query's textural features and cluster them into a style space with style-specific bases. Then we employ the style-init prompt tuning module to enable the visual encoder to comprehend the texture and style information of the query. Experiments demonstrate that our model, employing the style-init prompt tuning strategy, outperforms existing retrieval models on the style-diversified retrieval task. Moreover, style-diversified queries~(sketch+text, art+text, etc) can be simultaneously retrieved in our model. The auxiliary information from other queries enhances the retrieval performance within the respective query.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.02428"
  },
  "2312.02424": {
    "title": "GNSS Odometry: Precise Trajectory Estimation Based on Carrier Phase Cycle Slip Estimation",
    "authors": [
      "Taro Suzuki"
    ],
    "abstract": "This paper proposes a highly accurate trajectory estimation method for outdoor mobile robots using global navigation satellite system (GNSS) time differences of carrier phase (TDCP) measurements. By using GNSS TDCP, the relative 3D position can be estimated with millimeter precision. However, when a phenomenon called cycle slip occurs, wherein the carrier phase measurement jumps and becomes discontinuous, it is impossible to accurately estimate the relative position using TDCP. Although previous studies have eliminated the effect of cycle slip using a robust optimization technique, it was difficult to completely eliminate the effect of outliers. In this paper, we propose a method to detect GNSS carrier phase cycle slip, estimate the amount of cycle slip, and modify the observed TDCP to calculate the relative position using the factor graph optimization framework. The estimated relative position acts as a loop closure in graph optimization and contributes to the reduction in the integration error of the relative position. Experiments with an unmanned aerial vehicle showed that by modifying the cycle slip using the proposed method, the vehicle trajectory could be estimated with an accuracy of 5 to 30 cm using only a single GNSS receiver, without using any other external data or sensors.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02424"
  },
  "2312.02420": {
    "title": "Towards Granularity-adjusted Pixel-level Semantic Annotation",
    "authors": [
      "Rohit Kundu",
      "Sudipta Paul",
      "Rohit Lal",
      "Amit K. Roy-Chowdhury"
    ],
    "abstract": "Recent advancements in computer vision predominantly rely on learning-based systems, leveraging annotations as the driving force to develop specialized models. However, annotating pixel-level information, particularly in semantic segmentation, presents a challenging and labor-intensive task, prompting the need for autonomous processes. In this work, we propose GranSAM which distinguishes itself by providing semantic segmentation at the user-defined granularity level on unlabeled data without the need for any manual supervision, offering a unique contribution in the realm of semantic mask annotation method. Specifically, we propose an approach to enable the Segment Anything Model (SAM) with semantic recognition capability to generate pixel-level annotations for images without any manual supervision. For this, we accumulate semantic information from synthetic images generated by the Stable Diffusion model or web crawled images and employ this data to learn a mapping function between SAM mask embeddings and object class labels. As a result, SAM, enabled with granularity-adjusted mask recognition, can be used for pixel-level semantic annotation purposes. We conducted experiments on the PASCAL VOC 2012 and COCO-80 datasets and observed a +17.95% and +5.17% increase in mIoU, respectively, compared to existing state-of-the-art methods when evaluated under our problem setting.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02420"
  },
  "2312.02418": {
    "title": "Decoding Data Quality via Synthetic Corruptions: Embedding-guided Pruning of Code Data",
    "authors": [
      "Yu Yang",
      "Aaditya K. Singh",
      "Mostafa Elhoushi",
      "Anas Mahmoud",
      "Kushal Tirumala",
      "Fabian Gloeckle",
      "Baptiste Rozi\u00e8re",
      "Carole-Jean Wu",
      "Ari S. Morcos",
      "Newsha Ardalani"
    ],
    "abstract": "Code datasets, often collected from diverse and uncontrolled sources such as GitHub, potentially suffer from quality issues, thereby affecting the performance and training efficiency of Large Language Models (LLMs) optimized for code generation. Previous studies demonstrated the benefit of using embedding spaces for data pruning, but they mainly focused on duplicate removal or increasing variety, and in other modalities, such as images. Our work focuses on using embeddings to identify and remove \"low-quality\" code data. First, we explore features of \"low-quality\" code in embedding space, through the use of synthetic corruptions. Armed with this knowledge, we devise novel pruning metrics that operate in embedding space to identify and remove low-quality entries in the Stack dataset. We demonstrate the benefits of this synthetic corruption informed pruning (SCIP) approach on the well-established HumanEval and MBPP benchmarks, outperforming existing embedding-based methods. Importantly, we achieve up to a 3% performance improvement over no pruning, thereby showing the promise of insights from synthetic corruptions for data pruning.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02418"
  },
  "2312.02417": {
    "title": "Near-Optimal Mean Estimation with Unknown, Heteroskedastic Variances",
    "authors": [
      "Spencer Compton",
      "Gregory Valiant"
    ],
    "abstract": "Given data drawn from a collection of Gaussian variables with a common mean but different and unknown variances, what is the best algorithm for estimating their common mean? We present an intuitive and efficient algorithm for this task. As different closed-form guarantees can be hard to compare, the Subset-of-Signals model serves as a benchmark for heteroskedastic mean estimation: given $n$ Gaussian variables with an unknown subset of $m$ variables having variance bounded by 1, what is the optimal estimation error as a function of $n$ and $m$? Our algorithm resolves this open question up to logarithmic factors, improving upon the previous best known estimation error by polynomial factors when $m = n^c$ for all $0<c<1$. Of particular note, we obtain error $o(1)$ with $m = \\tilde{O}(n^{1/4})$ variance-bounded samples, whereas previous work required $m = \\tilde\u03a9(n^{1/2})$. Finally, we show that in the multi-dimensional setting, even for $d=2$, our techniques enable rates comparable to knowing the variance of each sample.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02417"
  },
  "2312.02416": {
    "title": "Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor",
    "authors": [
      "Jinqian Chen",
      "Jihua Zhu",
      "Qinghai Zheng"
    ],
    "abstract": "Federated learning encounters a critical challenge of data heterogeneity, adversely affecting the performance and convergence of the federated model. Various approaches have been proposed to address this issue, yet their effectiveness is still limited. Recent studies have revealed that the federated model suffers severe forgetting in local training, leading to global forgetting and performance degradation. Although the analysis provides valuable insights, a comprehensive understanding of the vulnerable classes and their impact factors is yet to be established. In this paper, we aim to bridge this gap by systematically analyzing the forgetting degree of each class during local training across different communication rounds. Our observations are: (1) Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance. (2) When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold, indicating that the local model struggles to leverage a few samples of a specific class effectively to prevent forgetting. Motivated by these findings, we propose a novel and straightforward algorithm called Federated Knowledge Anchor (FedKA). Assuming that all clients have a single shared sample for each class, the knowledge anchor is constructed before each local training stage by extracting shared samples for missing classes and randomly selecting one sample per class for non-dominant classes. The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes. Extensive experimental results demonstrate that our proposed FedKA achieves fast and stable convergence, significantly improving accuracy on popular benchmarks.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02416"
  },
  "2312.02412": {
    "title": "A Turing Incomputable Coloring Function",
    "authors": [
      "Michael Stephen Fiske"
    ],
    "abstract": "This paper describes a sequence of natural numbers that grows faster than any Turing computable function. This sequence is generated from a version of the tiling problem, called a coloring system. In our proof that generates the sequence, we use the notions of a chain and an unbounded sequence property, which resemble the methods of point set topology. From this sequence, we define a Turing incomputable coloring function.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02412"
  },
  "2312.02407": {
    "title": "Robust Clustering using Hyperdimensional Computing",
    "authors": [
      "Lulu Ge",
      "Keshab K. Parhi"
    ],
    "abstract": "This paper addresses the clustering of data in the hyperdimensional computing (HDC) domain. In prior work, an HDC-based clustering framework, referred to as HDCluster, has been proposed. However, the performance of the existing HDCluster is not robust. The performance of HDCluster is degraded as the hypervectors for the clusters are chosen at random during the initialization step. To overcome this bottleneck, we assign the initial cluster hypervectors by exploring the similarity of the encoded data, referred to as \\textit{query} hypervectors. Intra-cluster hypervectors have a higher similarity than inter-cluster hypervectors. Harnessing the similarity results among query hypervectors, this paper proposes four HDC-based clustering algorithms: similarity-based k-means, equal bin-width histogram, equal bin-height histogram, and similarity-based affinity propagation. Experimental results illustrate that: (i) Compared to the existing HDCluster, our proposed HDC-based clustering algorithms can achieve better accuracy, more robust performance, fewer iterations, and less execution time. Similarity-based affinity propagation outperforms the other three HDC-based clustering algorithms on eight datasets by 2~38% in clustering accuracy. (ii) Even for one-pass clustering, i.e., without any iterative update of the cluster hypervectors, our proposed algorithms can provide more robust clustering accuracy than HDCluster. (iii) Over eight datasets, five out of eight can achieve higher or comparable accuracy when projected onto the hyperdimensional space. Traditional clustering is more desirable than HDC when the number of clusters, $k$, is large.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02407"
  },
  "2312.02406": {
    "title": "Efficient Online Data Mixing For Language Model Pre-Training",
    "authors": [
      "Alon Albalak",
      "Liangming Pan",
      "Colin Raffel",
      "William Yang Wang"
    ],
    "abstract": "The data used to pretrain large language models has a decisive impact on a model's downstream performance, which has led to a large body of work on data selection methods that aim to automatically determine the most suitable data to use for pretraining. Existing data selection methods suffer from slow and computationally expensive processes, a problem amplified by the increasing size of models and of pretraining datasets. Data mixing, on the other hand, reduces the complexity of data selection by grouping data points together and determining sampling probabilities across entire groups. However, data mixing proportions are typically fixed before training and therefore cannot adapt to changing training dynamics. To address these limitations, we develop an efficient algorithm for Online Data Mixing (ODM) that combines elements from both data selection and data mixing. Based on multi-armed bandit algorithms, our online approach optimizes the data mixing proportions during training. Remarkably, our method trains a model that reaches the final perplexity of the next best method with 19\\% fewer training iterations, and improves performance on the 5-shot MMLU benchmark by 1.9% relative accuracy, while adding negligible wall-clock time during pretraining.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.02406"
  },
  "2312.02405": {
    "title": "BEDD: The MineRL BASALT Evaluation and Demonstrations Dataset for Training and Benchmarking Agents that Solve Fuzzy Tasks",
    "authors": [
      "Stephanie Milani",
      "Anssi Kanervisto",
      "Karolis Ramanauskas",
      "Sander Schulhoff",
      "Brandon Houghton",
      "Rohin Shah"
    ],
    "abstract": "The MineRL BASALT competition has served to catalyze advances in learning from human feedback through four hard-to-specify tasks in Minecraft, such as create and photograph a waterfall. Given the completion of two years of BASALT competitions, we offer to the community a formalized benchmark through the BASALT Evaluation and Demonstrations Dataset (BEDD), which serves as a resource for algorithm development and performance assessment. BEDD consists of a collection of 26 million image-action pairs from nearly 14,000 videos of human players completing the BASALT tasks in Minecraft. It also includes over 3,000 dense pairwise human evaluations of human and algorithmic agents. These comparisons serve as a fixed, preliminary leaderboard for evaluating newly-developed algorithms. To enable this comparison, we present a streamlined codebase for benchmarking new algorithms against the leaderboard. In addition to presenting these datasets, we conduct a detailed analysis of the data from both datasets to guide algorithm development and evaluation. The released code and data are available at https://github.com/minerllabs/basalt-benchmark .\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02405"
  },
  "2312.02403": {
    "title": "Deep Neural Operator Enabled Concurrent Multitask Design for Multifunctional Metamaterials under Heterogeneous Fields",
    "authors": [
      "Doksoo Lee",
      "Lu Zhang",
      "Yue Yu",
      "Wei Chen"
    ],
    "abstract": "Multifunctional metamaterials (MMM) bear promise as next-generation material platforms supporting miniaturization and customization. Despite many proof-of-concept demonstrations and the proliferation of deep learning assisted design, grand challenges of inverse design for MMM, especially those involving heterogeneous fields possibly subject to either mutual meta-atom coupling or long-range interactions, remain largely under-explored. To this end, we present a data-driven design framework, which streamlines the inverse design of MMMs involving heterogeneous fields. A core enabler is implicit Fourier neural operator (IFNO), which predicts heterogeneous fields distributed across a metamaterial array, thus in general at odds with homogenization assumptions, in a parameter-/sample-efficient fashion. Additionally, we propose a standard formulation of inverse problem covering a broad class of MMMs, and gradient-based multitask concurrent optimization identifying a set of Pareto-optimal architecture-stimulus (A-S) pairs. Fourier multiclass blending is proposed to synthesize inter-class meta-atoms anchored on a set of geometric motifs, while enjoying training-free dimension reduction and built-it reconstruction. Interlocking the three pillars, the framework is validated for light-bylight programmable plasmonic nanoantenna, whose design involves vast space jointly spanned by quasi-freeform supercells, maneuverable incident phase distributions, and conflicting figure-of-merits involving on-demand localization patterns. Accommodating all the challenges without a-priori simplifications, our framework could propel future advancements of MMM.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02403"
  },
  "2312.02401": {
    "title": "Harmonizing Global Voices: Culturally-Aware Models for Enhanced Content Moderation",
    "authors": [
      "Alex J. Chan",
      "Jos\u00e9 Luis Redondo Garc\u00eda",
      "Fabrizio Silvestri",
      "Colm O'Donnel",
      "Konstantina Palla"
    ],
    "abstract": "Content moderation at scale faces the challenge of considering local cultural distinctions when assessing content. While global policies aim to maintain decision-making consistency and prevent arbitrary rule enforcement, they often overlook regional variations in interpreting natural language as expressed in content. In this study, we are looking into how moderation systems can tackle this issue by adapting to local comprehension nuances. We train large language models on extensive datasets of media news and articles to create culturally attuned models. The latter aim to capture the nuances of communication across geographies with the goal of recognizing cultural and societal variations in what is considered offensive content. We further explore the capability of these models to generate explanations for instances of content violation, aiming to shed light on how policy guidelines are perceived when cultural and societal contexts change. We find that training on extensive media datasets successfully induced cultural awareness and resulted in improvements in handling content violations on a regional basis. Additionally, these advancements include the ability to provide explanations that align with the specific local norms and nuances as evidenced by the annotators' preference in our conducted study. This multifaceted success reinforces the critical role of an adaptable content moderation approach in keeping pace with the ever-evolving nature of the content it oversees.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02401"
  },
  "2312.02400": {
    "title": "Auto DP-SGD: Dual Improvements of Privacy and Accuracy via Automatic Clipping Threshold and Noise Multiplier Estimation",
    "authors": [
      "Sai Venkatesh Chilukoti",
      "Md Imran Hossen",
      "Liqun Shan",
      "Vijay Srinivas Tida",
      "Xiai Hei"
    ],
    "abstract": "DP-SGD has emerged as a popular method to protect personally identifiable information in deep learning applications. Unfortunately, DP-SGD's per-sample gradient clipping and uniform noise addition during training can significantly degrade model utility. To enhance the model's utility, researchers proposed various adaptive DP-SGD methods. However, we examine and discover that these techniques result in greater privacy leakage or lower accuracy than the traditional DP-SGD method, or a lack of evaluation on a complex data set such as CIFAR100. To address these limitations, we propose an Auto DP-SGD. Our method automates clipping threshold estimation based on the DL model's gradient norm and scales the gradients of each training sample without losing gradient information. This helps to improve the algorithm's utility while using a less privacy budget. To further improve accuracy, we introduce automatic noise multiplier decay mechanisms to decrease the noise multiplier after every epoch. Finally, we develop closed-form mathematical expressions using tCDP accountant for automatic noise multiplier and automatic clipping threshold estimation. Through extensive experimentation, we demonstrate that Auto DP-SGD outperforms existing SOTA DP-SGD methods in privacy and accuracy on various benchmark datasets. We also show that privacy can be improved by lowering the scale factor and using learning rate schedulers without significantly reducing accuracy. Specifically, Auto DP-SGD, when used with a step noise multiplier, improves accuracy by 3.20, 1.57, 6.73, and 1.42 for the MNIST, CIFAR10, CIFAR100, and AG News Corpus datasets, respectively. Furthermore, it obtains a substantial reduction in the privacy budget of 94.9, 79.16, 67.36, and 53.37 for the corresponding data sets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02400"
  },
  "2312.02392": {
    "title": "Instance Space Analysis of Search-Based Software Testing",
    "authors": [
      "Neelofar Neelofar",
      "Kate Smith-Miles",
      "Mario Andres Munoz",
      "Aldeida Aleti"
    ],
    "abstract": "Search-based software testing (SBST) is now a mature area, with numerous techniques developed to tackle the challenging task of software testing. SBST techniques have shown promising results and have been successfully applied in the industry to automatically generate test cases for large and complex software systems. Their effectiveness, however, is problem-dependent. In this paper, we revisit the problem of objective performance evaluation of SBST techniques considering recent methodological advances -- in the form of Instance Space Analysis (ISA) -- enabling the strengths and weaknesses of SBST techniques to be visualized and assessed across the broadest possible space of problem instances (software classes) from common benchmark datasets. We identify features of SBST problems that explain why a particular instance is hard for an SBST technique, reveal areas of hard and easy problems in the instance space of existing benchmark datasets, and identify the strengths and weaknesses of state-of-the-art SBST techniques. In addition, we examine the diversity and quality of common benchmark datasets used in experimental evaluations.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02392"
  },
  "2312.02390": {
    "title": "The Impact of Robots' Facial Emotional Expressions on Light Physical Exercises",
    "authors": [
      "Nourhan Abdulazeem",
      "Yue Hu"
    ],
    "abstract": "To address the global challenge of population aging, our goal is to enhance successful aging through the introduction of robots capable of assisting in daily physical activities and promoting light exercises, which would enhance the cognitive and physical well-being of older adults. Previous studies have shown that facial expressions can increase engagement when interacting with robots. This study aims to investigate how older adults perceive and interact with a robot capable of displaying facial emotions while performing a physical exercise task together. We employed a collaborative robotic arm with a flat panel screen to encourage physical exercise across three different facial emotion conditions. We ran the experiment with older adults aged between 66 and 88. Our findings suggest that individuals perceive robots exhibiting facial expressions as less competent than those without such expressions. Additionally, the presence of facial expressions does not appear to significantly impact participants' levels of engagement, unlike other state-of-the-art studies. This observation is likely linked to our study's emphasis on collaborative physical human-robot interaction (pHRI) applications, as opposed to socially oriented pHRI applications. Additionally, we foresee a requirement for more suitable non-verbal social behavior to effectively enhance participants' engagement levels.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02390"
  },
  "2312.02387": {
    "title": "Dissecting Medical Referral Mechanisms in Health Services: Role of Physician Professional Networks",
    "authors": [
      "Regina de Brito Duarte",
      "Qiwei Han",
      "Claudia Soares"
    ],
    "abstract": "Medical referrals between primary care physicians (PC) and specialist care (SC) physicians profoundly impact patient care regarding quality, satisfaction, and cost. This paper investigates the influence of professional networks among medical doctors on referring patients from PC to SC. Using five-year consultation data from a Portuguese private health provider, we conducted exploratory data analysis and constructed both professional and referral networks among physicians. We then apply Graph Neural Network (GNN) models to learn latent representations of the referral network. Our analysis supports the hypothesis that doctors' professional social connections can predict medical referrals, potentially enhancing collaboration within organizations and improving healthcare services. This research contributes to dissecting the underlying mechanisms in primary-specialty referrals, thereby providing valuable insights for enhancing patient care and effective healthcare management.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02387"
  },
  "2312.02382": {
    "title": "New Evaluation Metrics Capture Quality Degradation due to LLM Watermarking",
    "authors": [
      "Karanpartap Singh",
      "James Zou"
    ],
    "abstract": "With the increasing use of large-language models (LLMs) like ChatGPT, watermarking has emerged as a promising approach for tracing machine-generated content. However, research on LLM watermarking often relies on simple perplexity or diversity-based measures to assess the quality of watermarked text, which can mask important limitations in watermarking. Here we introduce two new easy-to-use methods for evaluating watermarking algorithms for LLMs: 1) evaluation by LLM-judger with specific guidelines; and 2) binary classification on text embeddings to distinguish between watermarked and unwatermarked text. We apply these methods to characterize the effectiveness of current watermarking techniques. Our experiments, conducted across various datasets, reveal that current watermarking methods are detectable by even simple classifiers, challenging the notion of watermarking subtlety. We also found, through the LLM judger, that watermarking impacts text quality, especially in degrading the coherence and depth of the response. Our findings underscore the trade-off between watermark robustness and text quality and highlight the importance of having more informative metrics to assess watermarking quality.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02382"
  },
  "2312.02375": {
    "title": "CityTFT: Temporal Fusion Transformer for Urban Building Energy Modeling",
    "authors": [
      "Ting-Yu Dai",
      "Dev Niyogi",
      "Zoltan Nagy"
    ],
    "abstract": "Urban Building Energy Modeling (UBEM) is an emerging method to investigate urban design and energy systems against the increasing energy demand at urban and neighborhood levels. However, current UBEM methods are mostly physic-based and time-consuming in multiple climate change scenarios. This work proposes CityTFT, a data-driven UBEM framework, to accurately model the energy demands in urban environments. With the empowerment of the underlying TFT framework and an augmented loss function, CityTFT could predict heating and cooling triggers in unseen climate dynamics with an F1 score of 99.98 \\% while RMSE of loads of 13.57 kWh.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02375"
  },
  "2312.02372": {
    "title": "On the Trade-Off between Stability and Representational Capacity in Graph Neural Networks",
    "authors": [
      "Zhan Gao",
      "Amanda Prorok",
      "Elvin Isufi"
    ],
    "abstract": "Analyzing the stability of graph neural networks (GNNs) under topological perturbations is key to understanding their transferability and the role of each architecture component. However, stability has been investigated only for particular architectures, questioning whether it holds for a broader spectrum of GNNs or only for a few instances. To answer this question, we study the stability of EdgeNet: a general GNN framework that unifies more than twenty solutions including the convolutional and attention-based classes, as well as graph isomorphism networks and hybrid architectures. We prove that all GNNs within the EdgeNet framework are stable to topological perturbations. By studying the effect of different EdgeNet categories on the stability, we show that GNNs with fewer degrees of freedom in their parameter space, linked to a lower representational capacity, are more stable. The key factor yielding this trade-off is the eigenvector misalignment between the EdgeNet parameter matrices and the graph shift operator. For example, graph convolutional neural networks that assign a single scalar per signal shift (hence, with a perfect alignment) are more stable than the more involved node or edge-varying counterparts. Extensive numerical results corroborate our theoretical findings and highlight the role of different architecture components in the trade-off.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02372"
  },
  "2312.02368": {
    "title": "RINAS: Training with Dataset Shuffling Can Be General and Fast",
    "authors": [
      "Tianle Zhong",
      "Jiechen Zhao",
      "Xindi Guo",
      "Qiang Su",
      "Geoffrey Fox"
    ],
    "abstract": "Deep learning datasets are expanding at an unprecedented pace, creating new challenges for data processing in model training pipelines. A crucial aspect of these pipelines is dataset shuffling, which significantly improves unbiased learning and convergence accuracy by adhering to the principles of random sampling. However, loading shuffled data for large datasets incurs significant overhead in the deep learning pipeline and severely impacts the end-to-end training throughput. To mitigate this, current deep learning systems often resort to partial dataset shuffling, sacrificing global randomness to maintain acceptable training throughput on large datasets, still leaving global shuffling efficiency issues not fully explored.\n  In this work, we present RINAS, a data loading framework that systematically addresses the performance bottleneck of loading global shuffled datasets. Our key contribution is to offer an intra-batch unordered data fetching approach, which unleashes unexplored parallelism of data loading. We implement RINAS under the PyTorch framework for common dataset libraries HuggingFace and TorchVision. Our experimental results show that RINAS improves the throughput of general language model training and vision model training by up to 59% and 89%, respectively.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02368"
  },
  "2312.02367": {
    "title": "States as goal-directed concepts: an epistemic approach to state-representation learning",
    "authors": [
      "Nadav Amir",
      "Yael Niv",
      "Angela Langdon"
    ],
    "abstract": "Our goals fundamentally shape how we experience the world. For example, when we are hungry, we tend to view objects in our environment according to whether or not they are edible (or tasty). Alternatively, when we are cold, we may view the very same objects according to their ability to produce heat. Computational theories of learning in cognitive systems, such as reinforcement learning, use the notion of \"state-representation\" to describe how agents decide which features of their environment are behaviorally-relevant and which can be ignored. However, these approaches typically assume \"ground-truth\" state representations that are known by the agent, and reward functions that need to be learned. Here we suggest an alternative approach in which state-representations are not assumed veridical, or even pre-defined, but rather emerge from the agent's goals through interaction with its environment. We illustrate this novel perspective by inferring the goals driving rat behavior in an odor-guided choice task and discuss its implications for developing, from first principles, an information-theoretic account of goal-directed state representation learning and behavior.\n        \u25b3 Less",
    "submission_date": "3 January, 2024",
    "eprint_id": "2312.02367"
  },
  "2312.02358": {
    "title": "Peer attention enhances student learning",
    "authors": [
      "Songlin Xu",
      "Dongyin Hu",
      "Ru Wang",
      "Xinyu Zhang"
    ],
    "abstract": "Human visual attention is susceptible to social influences. In education, peer effects impact student learning, but their precise role in modulating attention remains unclear. Our experiment (N=311) demonstrates that displaying peer visual attention regions when students watch online course videos enhances their focus and engagement. However, students retain adaptability in following peer attention cues. Overall, guided peer attention improves learning experiences and outcomes. These findings elucidate how peer visual attention shapes students' gaze patterns, deepening understanding of peer influence on learning. They also offer insights into designing adaptive online learning interventions leveraging peer attention modelling to optimize student attentiveness and success.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02358"
  },
  "2312.02355": {
    "title": "When is Offline Policy Selection Sample Efficient for Reinforcement Learning?",
    "authors": [
      "Vincent Liu",
      "Prabhat Nagarajan",
      "Andrew Patterson",
      "Martha White"
    ],
    "abstract": "Offline reinforcement learning algorithms often require careful hyperparameter tuning. Consequently, before deployment, we need to select amongst a set of candidate policies. As yet, however, there is little understanding about the fundamental limits of this offline policy selection (OPS) problem. In this work we aim to provide clarity on when sample efficient OPS is possible, primarily by connecting OPS to off-policy policy evaluation (OPE) and Bellman error (BE) estimation. We first show a hardness result, that in the worst case, OPS is just as hard as OPE, by proving a reduction of OPE to OPS. As a result, no OPS method can be more sample efficient than OPE in the worst case. We then propose a BE method for OPS, called Identifiable BE Selection (IBES), that has a straightforward method for selecting its own hyperparameters. We highlight that using IBES for OPS generally has more requirements than OPE methods, but if satisfied, can be more sample efficient. We conclude with an empirical study comparing OPE and IBES, and by showing the difficulty of OPS on an offline Atari benchmark dataset.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02355"
  },
  "2312.02353": {
    "title": "Efficient 2D Graph SLAM for Sparse Sensing",
    "authors": [
      "Hanzhi Zhou",
      "Zichao Hu",
      "Sihang Liu",
      "Samira Khan"
    ],
    "abstract": "Simultaneous localization and mapping (SLAM) plays a vital role in mapping unknown spaces and aiding autonomous navigation. Virtually all state-of-the-art solutions today for 2D SLAM are designed for dense and accurate sensors such as laser range-finders (LiDARs). However, these sensors are not suitable for resource-limited nano robots, which become increasingly capable and ubiquitous nowadays, and these robots tend to mount economical and low-power sensors that can only provide sparse and noisy measurements. This introduces a challenging problem called SLAM with sparse sensing. This work addresses the problem by adopting the form of the state-of-the-art graph-based SLAM pipeline with a novel frontend and an improvement for loop closing in the backend, both of which are designed to work with sparse and uncertain range data. Experiments show that the maps constructed by our algorithm have superior quality compared to prior works on sparse sensing. Furthermore, our method is capable of running in real-time on a modern PC with an average processing time of 1/100th the input interval time.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02353"
  },
  "2312.02345": {
    "title": "CLIPDrawX: Primitive-based Explanations for Text Guided Sketch Synthesis",
    "authors": [
      "Nityanand Mathur",
      "Shyam Marjit",
      "Abhra Chaudhuri",
      "Anjan Dutta"
    ],
    "abstract": "With the goal of understanding the visual concepts that CLIP associates with text prompts, we show that the latent space of CLIP can be visualized solely in terms of linear transformations on simple geometric primitives like circles and straight lines. Although existing approaches achieve this by sketch-synthesis-through-optimization, they do so on the space of B\u00e9zier curves, which exhibit a wastefully large set of structures that they can evolve into, as most of them are non-essential for generating meaningful sketches. We present CLIPDrawX, an algorithm that provides significantly better visualizations for CLIP text embeddings, using only simple primitive shapes like straight lines and circles. This constrains the set of possible outputs to linear transformations on these primitives, thereby exhibiting an inherently simpler mathematical form. The synthesis process of CLIPDrawX can be tracked end-to-end, with each visual concept being explained exclusively in terms of primitives. Implementation will be released upon acceptance. Project Page: $\\href{https://clipdrawx.github.io/}{\\text{https://clipdrawx.github.io/}}$.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02345"
  },
  "2312.02344": {
    "title": "STEREOFOG -- Computational DeFogging via Image-to-Image Translation on a real-world Dataset",
    "authors": [
      "Anton Pollak",
      "Rajesh Menon"
    ],
    "abstract": "Image-to-Image translation (I2I) is a subtype of Machine Learning (ML) that has tremendous potential in applications where two domains of images and the need for translation between the two exist, such as the removal of fog. For example, this could be useful for autonomous vehicles, which currently struggle with adverse weather conditions like fog. However, datasets for I2I tasks are not abundant and typically hard to acquire. Here, we introduce STEREOFOG, a dataset comprised of $10,067$ paired fogged and clear images, captured using a custom-built device, with the purpose of exploring I2I's potential in this domain. It is the only real-world dataset of this kind to the best of our knowledge. Furthermore, we apply and optimize the pix2pix I2I ML framework to this dataset. With the final model achieving an average Complex Wavelet-Structural Similarity (CW-SSIM) score of $0.76$, we prove the technique's suitability for the problem.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02344"
  },
  "2312.02341": {
    "title": "Incentive Systems for Fleets of New Mobility Services",
    "authors": [
      "Ali Ghafelebashi",
      "Meisam Razaviyayn",
      "Maged Dessouky"
    ],
    "abstract": "Traffic congestion has become an inevitable challenge in large cities due to population increases and expansion of urban areas. Various approaches are introduced to mitigate traffic issues, encompassing from expanding the road infrastructure to employing demand management. Congestion pricing and incentive schemes are extensively studied for traffic control in traditional networks where each driver is a network \"player\". In this setup, drivers' \"selfish\" behavior hinders the network from reaching a socially optimal state. In future mobility services, on the other hand, a large portion of drivers/vehicles may be controlled by a small number of companies/organizations. In such a system, offering incentives to organizations can potentially be much more effective in reducing traffic congestion rather than offering incentives directly to drivers. This paper studies the problem of offering incentives to organizations to change the behavior of their individual drivers (or individuals relying on the organization's services). We developed a model where incentives are offered to each organization based on the aggregated travel time loss across all drivers in that organization. Such an incentive offering mechanism requires solving a large-scale optimization problem to minimize the system-level travel time. We propose an efficient algorithm for solving this optimization problem. Numerous experiments on Los Angeles County traffic data reveal the ability of our method to reduce system-level travel time by up to 6.9%. Moreover, our experiments demonstrate that incentivizing organizations can be up to 8 times more efficient than incentivizing individual drivers in terms of incentivization monetary cost.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02341"
  },
  "2312.02339": {
    "title": "Expressive Sign Equivariant Networks for Spectral Geometric Learning",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Stefanie Jegelka",
      "Haggai Maron"
    ],
    "abstract": "Recent work has shown the utility of developing machine learning models that respect the structure and symmetries of eigenvectors. These works promote sign invariance, since for any eigenvector v the negation -v is also an eigenvector. However, we show that sign invariance is theoretically limited for tasks such as building orthogonally equivariant models and learning node positional encodings for link prediction in graphs. In this work, we demonstrate the benefits of sign equivariance for these tasks. To obtain these benefits, we develop novel sign equivariant neural network architectures. Our models are based on a new analytic characterization of sign equivariant polynomials and thus inherit provable expressiveness properties. Controlled synthetic experiments show that our networks can achieve the theoretically predicted benefits of sign equivariant models. Code is available at https://github.com/cptq/Sign-Equivariant-Nets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02339"
  },
  "2312.02338": {
    "title": "A Contrastive Compositional Benchmark for Text-to-Image Synthesis: A Study with Unified Text-to-Image Fidelity Metrics",
    "authors": [
      "Xiangru Zhu",
      "Penglei Sun",
      "Chengyu Wang",
      "Jingping Liu",
      "Zhixu Li",
      "Yanghua Xiao",
      "Jun Huang"
    ],
    "abstract": "Text-to-image (T2I) synthesis has recently achieved significant advancements. However, challenges remain in the model's compositionality, which is the ability to create new combinations from known components. We introduce Winoground-T2I, a benchmark designed to evaluate the compositionality of T2I models. This benchmark includes 11K complex, high-quality contrastive sentence pairs spanning 20 categories. These contrastive sentence pairs with subtle differences enable fine-grained evaluations of T2I synthesis models. Additionally, to address the inconsistency across different metrics, we propose a strategy that evaluates the reliability of various metrics by using comparative sentence pairs. We use Winoground-T2I with a dual objective: to evaluate the performance of T2I models and the metrics used for their evaluation. Finally, we provide insights into the strengths and weaknesses of these metrics and the capabilities of current T2I models in tackling challenges across a range of complex compositional categories. Our benchmark is publicly available at https://github.com/zhuxiangru/Winoground-T2I .\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.02338"
  },
  "2312.02337": {
    "title": "Measuring Distributional Shifts in Text: The Advantage of Language Model-Based Embeddings",
    "authors": [
      "Gyandev Gupta",
      "Bashir Rastegarpanah",
      "Amalendu Iyer",
      "Joshua Rubin",
      "Krishnaram Kenthapadi"
    ],
    "abstract": "An essential part of monitoring machine learning models in production is measuring input and output data drift. In this paper, we present a system for measuring distributional shifts in natural language data and highlight and investigate the potential advantage of using large language models (LLMs) for this problem. Recent advancements in LLMs and their successful adoption in different domains indicate their effectiveness in capturing semantic relationships for solving various natural language processing problems. The power of LLMs comes largely from the encodings (embeddings) generated in the hidden layers of the corresponding neural network. First we propose a clustering-based algorithm for measuring distributional shifts in text data by exploiting such embeddings. Then we study the effectiveness of our approach when applied to text embeddings generated by both LLMs and classical embedding algorithms. Our experiments show that general-purpose LLM-based embeddings provide a high sensitivity to data drift compared to other embedding methods. We propose drift sensitivity as an important evaluation metric to consider when comparing language models. Finally, we present insights and lessons learned from deploying our framework as part of the Fiddler ML Monitoring platform over a period of 18 months.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02337"
  },
  "2312.02334": {
    "title": "An Evaluation Framework for Mapping News Headlines to Event Classes in a Knowledge Graph",
    "authors": [
      "Steve Fonin Mbouadeu",
      "Martin Lorenzo",
      "Ken Barker",
      "Oktie Hassanzadeh"
    ],
    "abstract": "Mapping ongoing news headlines to event-related classes in a rich knowledge base can be an important component in a knowledge-based event analysis and forecasting solution. In this paper, we present a methodology for creating a benchmark dataset of news headlines mapped to event classes in Wikidata, and resources for the evaluation of methods that perform the mapping. We use the dataset to study two classes of unsupervised methods for this task: 1) adaptations of classic entity linking methods, and 2) methods that treat the problem as a zero-shot text classification problem. For the first approach, we evaluate off-the-shelf entity linking systems. For the second approach, we explore a) pre-trained natural language inference (NLI) models, and b) pre-trained large generative language models. We present the results of our evaluation, lessons learned, and directions for future work. The dataset and scripts for evaluation are made publicly available.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02334"
  },
  "2312.02331": {
    "title": "Revisiting Topic-Guided Language Models",
    "authors": [
      "Carolina Zheng",
      "Keyon Vafa",
      "David M. Blei"
    ],
    "abstract": "A recent line of work in natural language processing has aimed to combine language models and topic models. These topic-guided language models augment neural language models with topic models, unsupervised learning methods that can discover document-level patterns of word use. This paper compares the effectiveness of these methods in a standardized setting. We study four topic-guided language models and two baselines, evaluating the held-out predictive performance of each model on four corpora. Surprisingly, we find that none of these methods outperform a standard LSTM language model baseline, and most fail to learn good topics. Further, we train a probe of the neural language model that shows that the baseline's hidden states already encode topic information. We make public all code used for this study.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02331"
  },
  "2312.02320": {
    "title": "Cable Slack Detection for Arresting Gear Application using Machine Vision",
    "authors": [
      "Ari Goodman",
      "Glenn Shevach",
      "Sean Zabriskie",
      "Chris Thajudeen"
    ],
    "abstract": "The cable-based arrestment systems are integral to the launch and recovery of aircraft onboard carriers and on expeditionary land-based installations. These modern arrestment systems rely on various mechanisms to absorb energy from an aircraft during an arrestment cycle to bring the aircraft to a full stop. One of the primary components of this system is the cable interface to the engine. The formation of slack in the cable at this interface can result in reduced efficiency and drives maintenance efforts to remove the slack prior to continued operations. In this paper, a machine vision based slack detection system is presented. A situational awareness camera is utilized to collect video data of the cable interface region, machine vision algorithms are applied to reduce noise, remove background clutter, focus on regions of interest, and detect changes in the image representative of slack formations. Some algorithms employed in this system include bilateral image filters, least squares polynomial fit, Canny Edge Detection, K-Means clustering, Gaussian Mixture-based Background/Foreground Segmentation for background subtraction, Hough Circle Transforms, and Hough line Transforms. The resulting detections are filtered and highlighted to create an indication to the shipboard operator of the presence of slack and a need for a maintenance action. A user interface was designed to provide operators with an easy method to redefine regions of interest and adjust the methods to specific locations. The algorithms were validated on shipboard footage and were able to accurately identify slack with minimal false positives.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02320"
  },
  "2312.02317": {
    "title": "GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs",
    "authors": [
      "Ruijie Wang",
      "Luca Rossetto",
      "Michael Cochez",
      "Abraham Bernstein"
    ],
    "abstract": "Most current methods for multi-hop question answering (QA) over knowledge graphs (KGs) only provide final conclusive answers without explanations, such as a set of KG entities that is difficult for normal users to review and comprehend. This issue severely limits the application of KG-based QA in real-world scenarios. However, it is non-trivial to solve due to two challenges: First, annotations of reasoning chains of multi-hop questions, which could serve as supervision for explanation generation, are usually lacking. Second, it is difficult to maintain high efficiency when explicit KG triples need to be retrieved to generate explanations. In this paper, we propose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to solve this issue. GNN2R can provide both final answers and reasoning subgraphs as a rationale behind final answers efficiently with only weak supervision that is available through question-final answer pairs. We extensively evaluated GNN2R with detailed analyses in experiments. The results demonstrate that, in terms of effectiveness, efficiency, and quality of generated explanations, GNN2R outperforms existing state-of-the-art methods that are applicable to this task. Our code and pre-trained models are available at https://github.com/ruijie-wang-uzh/GNN2R.\n        \u25b3 Less",
    "submission_date": "20 January, 2024",
    "eprint_id": "2312.02317"
  },
  "2312.02314": {
    "title": "Fine-tuning pre-trained extractive QA models for clinical document parsing",
    "authors": [
      "Ashwyn Sharma",
      "David I. Feldman",
      "Aneesh Jain"
    ],
    "abstract": "Electronic health records (EHRs) contain a vast amount of high-dimensional multi-modal data that can accurately represent a patient's medical history. Unfortunately, most of this data is either unstructured or semi-structured, rendering it unsuitable for real-time and retrospective analyses. A remote patient monitoring (RPM) program for Heart Failure (HF) patients needs to have access to clinical markers like EF (Ejection Fraction) or LVEF (Left Ventricular Ejection Fraction) in order to ascertain eligibility and appropriateness for the program. This paper explains a system that can parse echocardiogram reports and verify EF values. This system helps identify eligible HF patients who can be enrolled in such a program. At the heart of this system is a pre-trained extractive QA transformer model that is fine-tuned on custom-labeled data. The methods used to prepare such a model for deployment are illustrated by running experiments on a public clinical dataset like MIMIC-IV-Note. The pipeline can be used to generalize solutions to similar problems in a low-resource setting. We found that the system saved over 1500 hours for our clinicians over 12 months by automating the task at scale.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02314"
  },
  "2312.02312": {
    "title": "Visual Encoders for Data-Efficient Imitation Learning in Modern Video Games",
    "authors": [
      "Lukas Sch\u00e4fer",
      "Logan Jones",
      "Anssi Kanervisto",
      "Yuhan Cao",
      "Tabish Rashid",
      "Raluca Georgescu",
      "Dave Bignell",
      "Siddhartha Sen",
      "Andrea Trevi\u00f1o Gavito",
      "Sam Devlin"
    ],
    "abstract": "Video games have served as useful benchmarks for the decision making community, but going beyond Atari games towards training agents in modern games has been prohibitively expensive for the vast majority of the research community. Recent progress in the research, development and open release of large vision models has the potential to amortize some of these costs across the community. However, it is currently unclear which of these models have learnt representations that retain information critical for sequential decision making. Towards enabling wider participation in the research of gameplaying agents in modern games, we present a systematic study of imitation learning with publicly available visual encoders compared to the typical, task-specific, end-to-end training approach in Minecraft, Minecraft Dungeons and Counter-Strike: Global Offensive.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02312"
  },
  "2312.02310": {
    "title": "VaQuitA: Enhancing Alignment in LLM-Assisted Video Understanding",
    "authors": [
      "Yizhou Wang",
      "Ruiyi Zhang",
      "Haoliang Wang",
      "Uttaran Bhattacharya",
      "Yun Fu",
      "Gang Wu"
    ],
    "abstract": "Recent advancements in language-model-based video understanding have been progressing at a remarkable pace, spurred by the introduction of Large Language Models (LLMs). However, the focus of prior research has been predominantly on devising a projection layer that maps video features to tokens, an approach that is both rudimentary and inefficient. In our study, we introduce a cutting-edge framework, VaQuitA, designed to refine the synergy between video and textual information. At the data level, instead of sampling frames uniformly, we implement a sampling method guided by CLIP-score rankings, which enables a more aligned selection of frames with the given question. At the feature level, we integrate a trainable Video Perceiver alongside a Visual-Query Transformer (abbreviated as VQ-Former), which bolsters the interplay between the input question and the video features. We also discover that incorporating a simple prompt, \"Please be critical\", into the LLM input can substantially enhance its video comprehension capabilities. Our experimental results indicate that VaQuitA consistently sets a new benchmark for zero-shot video question-answering tasks and is adept at producing high-quality, multi-turn video dialogues with users.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02310"
  },
  "2312.02309": {
    "title": "Training Reinforcement Learning Agents and Humans With Difficulty-Conditioned Generators",
    "authors": [
      "Sidney Tio",
      "Jimmy Ho",
      "Pradeep Varakantham"
    ],
    "abstract": "We adapt Parameterized Environment Response Model (PERM), a method for training both Reinforcement Learning (RL) Agents and human learners in parameterized environments by directly modeling difficulty and ability. Inspired by Item Response Theory (IRT), PERM aligns environment difficulty with individual ability, creating a Zone of Proximal Development-based curriculum. Remarkably, PERM operates without real-time RL updates and allows for offline training, ensuring its adaptability across diverse students. We present a two-stage training process that capitalizes on PERM's adaptability, and demonstrate its effectiveness in training RL agents and humans in an empirical study.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02309"
  },
  "2312.02308": {
    "title": "AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse Catalysts Design",
    "authors": [
      "Romain Lacombe",
      "Lucas Hendren",
      "Khalid El-Awady"
    ],
    "abstract": "A central challenge of the clean energy transition is the development of catalysts for low-emissions technologies. Recent advances in Machine Learning for quantum chemistry drastically accelerate the computation of catalytic activity descriptors such as adsorption energies. Here we introduce AdsorbRL, a Deep Reinforcement Learning agent aiming to identify potential catalysts given a multi-objective binding energy target, trained using offline learning on the Open Catalyst 2020 and Materials Project data sets. We experiment with Deep Q-Network agents to traverse the space of all ~160,000 possible unary, binary and ternary compounds of 55 chemical elements, with very sparse rewards based on adsorption energy known for only between 2,000 and 3,000 catalysts per adsorbate. To constrain the actions space, we introduce Random Edge Traversal and train a single-objective DQN agent on the known states subgraph, which we find strengthens target binding energy by an average of 4.1 eV. We extend this approach to multi-objective, goal-conditioned learning, and train a DQN agent to identify materials with the highest (respectively lowest) adsorption energies for multiple simultaneous target adsorbates. We experiment with Objective Sub-Sampling, a novel training scheme aimed at encouraging exploration in the multi-objective setup, and demonstrate simultaneous adsorption energy improvement across all target adsorbates, by an average of 0.8 eV. Overall, our results suggest strong potential for Deep Reinforcement Learning applied to the inverse catalysts design problem.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02308"
  },
  "2312.02300": {
    "title": "Reconsideration on evaluation of machine learning models in continuous monitoring using wearables",
    "authors": [
      "Cheng Ding",
      "Zhicheng Guo",
      "Cynthia Rudin",
      "Ran Xiao",
      "Fadi B Nahab",
      "Xiao Hu"
    ],
    "abstract": "This paper explores the challenges in evaluating machine learning (ML) models for continuous health monitoring using wearable devices beyond conventional metrics. We state the complexities posed by real-world variability, disease dynamics, user-specific characteristics, and the prevalence of false notifications, necessitating novel evaluation strategies. Drawing insights from large-scale heart studies, the paper offers a comprehensive guideline for robust ML model evaluation on continuous health monitoring.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02300"
  },
  "2312.02299": {
    "title": "Cotton Yield Prediction Using Random Forest",
    "authors": [
      "Alakananda Mitra",
      "Sahila Beegum",
      "David Fleisher",
      "Vangimalla R. Reddy",
      "Wenguang Sun",
      "Chittaranjan Ray",
      "Dennis Timlin",
      "Arindam Malakar"
    ],
    "abstract": "The cotton industry in the United States is committed to sustainable production practices that minimize water, land, and energy use while improving soil health and cotton output. Climate-smart agricultural technologies are being developed to boost yields while decreasing operating expenses. Crop yield prediction, on the other hand, is difficult because of the complex and nonlinear impacts of cultivar, soil type, management, pest and disease, climate, and weather patterns on crops. To solve this issue, we employ machine learning (ML) to forecast production while considering climate change, soil diversity, cultivar, and inorganic nitrogen levels. From the 1980s to the 1990s, field data were gathered across the southern cotton belt of the United States. To capture the most current effects of climate change over the previous six years, a second data source was produced using the process-based crop model, GOSSYM. We concentrated our efforts on three distinct areas inside each of the three southern states: Texas, Mississippi, and Georgia. To simplify the amount of computations, accumulated heat units (AHU) for each set of experimental data were employed as an analogy to use time-series weather data. The Random Forest Regressor yielded a 97.75% accuracy rate, with a root mean square error of 55.05 kg/ha and an R2 of around 0.98. These findings demonstrate how an ML technique may be developed and applied as a reliable and easy-to-use model to support the cotton climate-smart initiative.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02299"
  },
  "2312.02298": {
    "title": "MoE-AMC: Enhancing Automatic Modulation Classification Performance Using Mixture-of-Experts",
    "authors": [
      "Jiaxin Gao",
      "Qinglong Cao",
      "Yuntian Chen"
    ],
    "abstract": "Automatic Modulation Classification (AMC) plays a vital role in time series analysis, such as signal classification and identification within wireless communications. Deep learning-based AMC models have demonstrated significant potential in this domain. However, current AMC models inadequately consider the disparities in handling signals under conditions of low and high Signal-to-Noise Ratio (SNR), resulting in an unevenness in their performance. In this study, we propose MoE-AMC, a novel Mixture-of-Experts (MoE) based model specifically crafted to address AMC in a well-balanced manner across varying SNR conditions. Utilizing the MoE framework, MoE-AMC seamlessly combines the strengths of LSRM (a Transformer-based model) for handling low SNR signals and HSRM (a ResNet-based model) for high SNR signals. This integration empowers MoE-AMC to achieve leading performance in modulation classification, showcasing its efficacy in capturing distinctive signal features under diverse SNR scenarios. We conducted experiments using the RML2018.01a dataset, where MoE-AMC achieved an average classification accuracy of 71.76% across different SNR levels, surpassing the performance of previous SOTA models by nearly 10%. This study represents a pioneering application of MoE techniques in the realm of AMC, offering a promising avenue for elevating signal classification accuracy within wireless communication systems.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02298"
  },
  "2312.02296": {
    "title": "LLMs Accelerate Annotation for Medical Information Extraction",
    "authors": [
      "Akshay Goel",
      "Almog Gueta",
      "Omry Gilon",
      "Chang Liu",
      "Sofia Erell",
      "Lan Huong Nguyen",
      "Xiaohong Hao",
      "Bolous Jaber",
      "Shashir Reddy",
      "Rupesh Kartha",
      "Jean Steiner",
      "Itay Laish",
      "Amir Feder"
    ],
    "abstract": "The unstructured nature of clinical notes within electronic health records often conceals vital patient-related information, making it challenging to access or interpret. To uncover this hidden information, specialized Natural Language Processing (NLP) models are required. However, training these models necessitates large amounts of labeled data, a process that is both time-consuming and costly when relying solely on human experts for annotation. In this paper, we propose an approach that combines Large Language Models (LLMs) with human expertise to create an efficient method for generating ground truth labels for medical text annotation. By utilizing LLMs in conjunction with human annotators, we significantly reduce the human annotation burden, enabling the rapid creation of labeled datasets. We rigorously evaluate our method on a medical information extraction task, demonstrating that our approach not only substantially cuts down on human intervention but also maintains high accuracy. The results highlight the potential of using LLMs to improve the utilization of unstructured clinical data, allowing for the swift deployment of tailored NLP solutions in healthcare.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02296"
  },
  "2312.02290": {
    "title": "You Can Run but not Hide: Improving Gait Recognition with Intrinsic Occlusion Type Awareness",
    "authors": [
      "Ayush Gupta",
      "Rama Chellappa"
    ],
    "abstract": "While gait recognition has seen many advances in recent years, the occlusion problem has largely been ignored. This problem is especially important for gait recognition from uncontrolled outdoor sequences at range - since any small obstruction can affect the recognition system. Most current methods assume the availability of complete body information while extracting the gait features. When parts of the body are occluded, these methods may hallucinate and output a corrupted gait signature as they try to look for body parts which are not present in the input at all. To address this, we exploit the learned occlusion type while extracting identity features from videos. Thus, in this work, we propose an occlusion aware gait recognition method which can be used to model intrinsic occlusion awareness into potentially any state-of-the-art gait recognition method. Our experiments on the challenging GREW and BRIAR datasets show that networks enhanced with this occlusion awareness perform better at recognition tasks than their counterparts trained on similar occlusions.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02290"
  },
  "2312.02284": {
    "title": "PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation",
    "authors": [
      "Zhenyu Li",
      "Shariq Farooq Bhat",
      "Peter Wonka"
    ],
    "abstract": "Single image depth estimation is a foundational task in computer vision and generative modeling. However, prevailing depth estimation models grapple with accommodating the increasing resolutions commonplace in today's consumer cameras and devices. Existing high-resolution strategies show promise, but they often face limitations, ranging from error propagation to the loss of high-frequency details. We present PatchFusion, a novel tile-based framework with three key components to improve the current state of the art: (1) A patch-wise fusion network that fuses a globally-consistent coarse prediction with finer, inconsistent tiled predictions via high-level feature guidance, (2) A Global-to-Local (G2L) module that adds vital context to the fusion network, discarding the need for patch selection heuristics, and (3) A Consistency-Aware Training (CAT) and Inference (CAI) approach, emphasizing patch overlap consistency and thereby eradicating the necessity for post-processing. Experiments on UnrealStereo4K, MVS-Synth, and Middleburry 2014 demonstrate that our framework can generate high-resolution depth maps with intricate details. PatchFusion is independent of the base model for depth estimation. Notably, our framework built on top of SOTA ZoeDepth brings improvements for a total of 17.3% and 29.4% in terms of the root mean squared error (RMSE) on UnrealStereo4K and MVS-Synth, respectively.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02284"
  },
  "2312.02264": {
    "title": "Scaling Laws in Jet Classification",
    "authors": [
      "Joshua Batson",
      "Yonatan Kahn"
    ],
    "abstract": "We demonstrate the emergence of scaling laws in the benchmark top versus QCD jet classification problem in collider physics. Six distinct physically-motivated classifiers exhibit power-law scaling of the binary cross-entropy test loss as a function of training set size, with distinct power law indices. This result highlights the importance of comparing classifiers as a function of dataset size rather than for a fixed training set, as the optimal classifier may change considerably as the dataset is scaled up. We speculate on the interpretation of our results in terms of previous models of scaling laws observed in natural language and image datasets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02264"
  },
  "2312.02253": {
    "title": "Diversify, Don't Fine-Tune: Scaling Up Visual Recognition Training with Synthetic Images",
    "authors": [
      "Zhuoran Yu",
      "Chenchen Zhu",
      "Sean Culatana",
      "Raghuraman Krishnamoorthi",
      "Fanyi Xiao",
      "Yong Jae Lee"
    ],
    "abstract": "Recent advances in generative deep learning have enabled the creation of high-quality synthetic images in text-to-image generation. Prior work shows that fine-tuning a pretrained diffusion model on ImageNet and generating synthetic training images from the finetuned model can enhance an ImageNet classifier's performance. However, performance degrades as synthetic images outnumber real ones. In this paper, we explore whether generative fine-tuning is essential for this improvement and whether it is possible to further scale up training using more synthetic data. We present a new framework leveraging off-the-shelf generative models to generate synthetic training images, addressing multiple challenges: class name ambiguity, lack of diversity in naive prompts, and domain shifts. Specifically, we leverage large language models (LLMs) and CLIP to resolve class name ambiguity. To diversify images, we propose contextualized diversification (CD) and stylized diversification (SD) methods, also prompted by LLMs. Finally, to mitigate domain shifts, we leverage domain adaptation techniques with auxiliary batch normalization for synthetic images. Our framework consistently enhances recognition model performance with more synthetic data, up to 6x of original ImageNet size showcasing the potential of synthetic data for improved recognition models and strong out-of-domain generalization.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02253"
  },
  "2312.02252": {
    "title": "StoryGPT-V: Large Language Models as Consistent Story Visualizers",
    "authors": [
      "Xiaoqian Shen",
      "Mohamed Elhoseiny"
    ],
    "abstract": "Recent generative models have demonstrated impressive capabilities in generating realistic and visually pleasing images grounded on textual prompts. Nevertheless, a significant challenge remains in applying these models for the more intricate task of story visualization. Since it requires resolving pronouns (he, she, they) in the frame descriptions, i.e., anaphora resolution, and ensuring consistent characters and background synthesis across frames. Yet, the emerging Large Language Model (LLM) showcases robust reasoning abilities to navigate through ambiguous references and process extensive sequences. Therefore, we introduce \\textbf{StoryGPT-V}, which leverages the merits of the latent diffusion (LDM) and LLM to produce images with consistent and high-quality characters grounded on given story descriptions. First, we train a character-aware LDM, which takes character-augmented semantic embedding as input and includes the supervision of the cross-attention map using character segmentation masks, aiming to enhance character generation accuracy and faithfulness. In the second stage, we enable an alignment between the output of LLM and the character-augmented embedding residing in the input space of the first-stage model. This harnesses the reasoning ability of LLM to address ambiguous references and the comprehension capability to memorize the context. We conduct comprehensive experiments on two visual story visualization benchmarks. Our model reports superior quantitative results and consistently generates accurate characters of remarkable quality with low memory consumption. Our code will be made publicly available.\n        \u25b3 Less",
    "submission_date": "13 December, 2023",
    "eprint_id": "2312.02252"
  },
  "2312.02251": {
    "title": "Fine-Tuning Language Models for Context-Specific SQL Query Generation",
    "authors": [
      "Amine Rebei"
    ],
    "abstract": "The ability to generate SQL queries from natural language has significant implications for making data accessible to non-specialists. This paper presents a novel approach to fine-tuning open-source large language models (LLMs) for the task of transforming natural language into SQL queries within the retail domain. We introduce models specialized in generating SQL queries, trained on synthetic datasets tailored to the Snowflake SQL and GoogleSQL dialects. Our methodology involves generating a context-specific dataset using GPT-4, then fine-tuning three open-source LLMs(Starcoder Plus, Code-Llama, and Mistral) employing the LoRa technique to optimize for resource constraints. The fine-tuned models demonstrate superior performance in zero-shot settings compared to the baseline GPT-4, with Code-Llama achieving the highest accuracy rates, at 81.58% for Snowflake SQL and 82.66% for GoogleSQL. These results underscore the effectiveness of fine-tuning LLMs on domain-specific tasks and suggest a promising direction for enhancing the accessibility of relational databases through natural language interfaces.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02251"
  },
  "2312.02248": {
    "title": "Towards early diagnosis of Alzheimer's disease: Advances in immune-related blood biomarkers and computational modeling approaches",
    "authors": [
      "Sophia Krix",
      "Ella Wilczynski",
      "Neus Falg\u00e0s",
      "Raquel S\u00e1nchez-Valle",
      "Eti Yoles",
      "Uri Nevo",
      "Kuti Baruch",
      "Holger Fr\u00f6hlich"
    ],
    "abstract": "Alzheimer's disease has an increasing prevalence in the population world-wide, yet current diagnostic methods based on recommended biomarkers are only available in specialized clinics. Due to these circumstances, Alzheimer's disease is usually diagnosed late, which contrasts with the currently available treatment options that are only effective for patients at an early stage. Blood-based biomarkers could fill in the gap of easily accessible and low-cost methods for early diagnosis of the disease. In particular, immune-based blood-biomarkers might be a promising option, given the recently discovered cross-talk of immune cells of the central nervous system with those in the peripheral immune system. With the help of machine learning algorithms and mechanistic modeling approaches, such as agent-based modeling, an in-depth analysis of the simulation of cell dynamics is possible as well as of high-dimensional omics resources indicative of pathway signaling changes. Here, we give a background on advances in research on brain-immune system cross-talk in Alzheimer's disease and review recent machine learning and mechanistic modeling approaches which leverage modern omics technologies for blood-based immune system-related biomarker discovery.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02248"
  },
  "2312.02247": {
    "title": "Federated Active Learning for Target Domain Generalisation",
    "authors": [
      "Razvan Caramalau",
      "Binod Bhattarai",
      "Danail Stoyanov"
    ],
    "abstract": "In this paper, we introduce Active Learning framework in Federated Learning for Target Domain Generalisation, harnessing the strength from both learning paradigms. Our framework, FEDALV, composed of Active Learning (AL) and Federated Domain Generalisation (FDG), enables generalisation of an image classification model trained from limited source domain client's data without sharing images to an unseen target domain. To this end, our FDG, FEDA, consists of two optimisation updates during training, one at the client and another at the server level. For the client, the introduced losses aim to reduce feature complexity and condition alignment, while in the server, the regularisation limits free energy biases between source and target obtained by the global model. The remaining component of FEDAL is AL with variable budgets, which queries the server to retrieve and sample the most informative local data for the targeted client. We performed multiple experiments on FDG w/ and w/o AL and compared with both conventional FDG baselines and Federated Active Learning baselines. Our extensive quantitative experiments demonstrate the superiority of our method in accuracy and efficiency compared to the multiple contemporary methods. FEDALV manages to obtain the performance of the full training target accuracy while sampling as little as 5% of the source client's data.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02247"
  },
  "2312.02243": {
    "title": "FlowHON: Representing Flow Fields Using Higher-Order Networks",
    "authors": [
      "Nan Chen",
      "Zhihong Li",
      "Jun Tao"
    ],
    "abstract": "Flow fields are often partitioned into data blocks for massively parallel computation and analysis based on blockwise relationships. However, most of the previous techniques only consider the first-order dependencies among blocks, which is insufficient in describing complex flow patterns. In this work, we present FlowHON, an approach to construct higher-order networks (HONs) from flow fields. FlowHON captures the inherent higher-order dependencies in flow fields as nodes and estimates the transitions among them as edges. We formulate the HON construction as an optimization problem with three linear transformations. The first two layers correspond to the node generation and the third one corresponds to edge estimation. Our formulation allows the node generation and edge estimation to be solved in a unified framework. With FlowHON, the rich set of traditional graph algorithms can be applied without any modification to analyze flow fields, while leveraging the higher-order information to understand the inherent structure and manage flow data for efficiency. We demonstrate the effectiveness of FlowHON using a series of downstream tasks, including estimating the density of particles during tracing, partitioning flow fields for data management, and understanding flow fields using the node-link diagram representation of networks.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02243"
  },
  "2312.02241": {
    "title": "A Mapping of Triangular Block Interleavers to DRAM for Optical Satellite Communication",
    "authors": [
      "Lukas Steiner",
      "Timo Lehnigk-Emden",
      "Markus Fehrenz",
      "Norbert Wehn"
    ],
    "abstract": "Communication in optical downlinks of low earth orbit (LEO) satellites requires interleaving to enable reliable data transmission. These interleavers are orders of magnitude larger than conventional interleavers utilized for example in wireless communication. Hence, the capacity of on-chip memories (SRAMs) is insufficient to store all symbols and external memories (DRAMs) must be used. Due to the overall requirement for very high data rates beyond 100 Gbit/s, DRAM bandwidth then quickly becomes a critical bottleneck of the communication system. In this paper, we investigate triangular block interleavers for the aforementioned application and show that the standard mapping of symbols used for SRAMs results in low bandwidth utilization for DRAMs, in some cases below 50 %. As a solution, we present a novel mapping approach that combines different optimizations and achieves over 90 % bandwidth utilization in all tested configurations. Further, the mapping can be applied to any JEDEC-compliant DRAM device.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02241"
  },
  "2312.02240": {
    "title": "Contrastive Learning-Based Spectral Knowledge Distillation for Multi-Modality and Missing Modality Scenarios in Semantic Segmentation",
    "authors": [
      "Aniruddh Sikdar",
      "Jayant Teotia",
      "Suresh Sundaram"
    ],
    "abstract": "Improving the performance of semantic segmentation models using multispectral information is crucial, especially for environments with low-light and adverse conditions. Multi-modal fusion techniques pursue either the learning of cross-modality features to generate a fused image or engage in knowledge distillation but address multimodal and missing modality scenarios as distinct issues, which is not an optimal approach for multi-sensor models. To address this, a novel multi-modal fusion approach called CSK-Net is proposed, which uses a contrastive learning-based spectral knowledge distillation technique along with an automatic mixed feature exchange mechanism for semantic segmentation in optical (EO) and infrared (IR) images. The distillation scheme extracts detailed textures from the optical images and distills them into the optical branch of CSK-Net. The model encoder consists of shared convolution weights with separate batch norm (BN) layers for both modalities, to capture the multi-spectral information from different modalities of the same objects. A Novel Gated Spectral Unit (GSU) and mixed feature exchange strategy are proposed to increase the correlation of modality-shared information and decrease the modality-specific information during the distillation process. Comprehensive experiments show that CSK-Net surpasses state-of-the-art models in multi-modal tasks and for missing modalities when exclusively utilizing IR data for inference across three public benchmarking datasets. For missing modality scenarios, the performance increase is achieved without additional computational costs compared to the baseline segmentation models.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02240"
  },
  "2312.02239": {
    "title": "Model-based Deep Learning for Beam Prediction based on a Channel Chart",
    "authors": [
      "Taha Yassine",
      "Baptiste Chatelier",
      "Vincent Corlay",
      "Matthieu Crussi\u00e8re",
      "Stephane Paquelet",
      "Olav Tirkkonen",
      "Luc Le Magoarou"
    ],
    "abstract": "Channel charting builds a map of the radio environment in an unsupervised way. The obtained chart locations can be seen as low-dimensional compressed versions of channel state information that can be used for a wide variety of applications, including beam prediction. In non-standalone or cell-free systems, chart locations computed at a given base station can be transmitted to several other base stations (possibly operating at different frequency bands) for them to predict which beams to use. This potentially yields a dramatic reduction of the overhead due to channel estimation or beam management, since only the base station performing charting requires channel state information, the others directly predicting the beam from the chart location. In this paper, advanced model-based neural network architectures are proposed for both channel charting and beam prediction. The proposed methods are assessed on realistic synthetic channels, yielding promising results.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02239"
  },
  "2312.02237": {
    "title": "Singular Regularization with Information Bottleneck Improves Model's Adversarial Robustness",
    "authors": [
      "Guanlin Li",
      "Naishan Zheng",
      "Man Zhou",
      "Jie Zhang",
      "Tianwei Zhang"
    ],
    "abstract": "Adversarial examples are one of the most severe threats to deep learning models. Numerous works have been proposed to study and defend adversarial examples. However, these works lack analysis of adversarial information or perturbation, which cannot reveal the mystery of adversarial examples and lose proper interpretation. In this paper, we aim to fill this gap by studying adversarial information as unstructured noise, which does not have a clear pattern. Specifically, we provide some empirical studies with singular value decomposition, by decomposing images into several matrices, to analyze adversarial information for different attacks. Based on the analysis, we propose a new module to regularize adversarial information and combine information bottleneck theory, which is proposed to theoretically restrict intermediate representations. Therefore, our method is interpretable. Moreover, the fashion of our design is a novel principle that is general and unified. Equipped with our new module, we evaluate two popular model structures on two mainstream datasets with various adversarial attacks. The results indicate that the improvement in robust accuracy is significant. On the other hand, we prove that our method is efficient with only a few additional parameters and able to be explained under regional faithfulness analysis.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02237"
  },
  "2312.02236": {
    "title": "Rethinking Adversarial Training with Neural Tangent Kernel",
    "authors": [
      "Guanlin Li",
      "Han Qiu",
      "Shangwei Guo",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "abstract": "Adversarial training (AT) is an important and attractive topic in deep learning security, exhibiting mysteries and odd properties. Recent studies of neural network training dynamics based on Neural Tangent Kernel (NTK) make it possible to reacquaint AT and deeply analyze its properties. In this paper, we perform an in-depth investigation of AT process and properties with NTK, such as NTK evolution. We uncover three new findings that are missed in previous works. First, we disclose the impact of data normalization on AT and the importance of unbiased estimators in batch normalization layers. Second, we experimentally explore the kernel dynamics and propose more time-saving AT methods. Third, we study the spectrum feature inside the kernel to address the catastrophic overfitting problem. To the best of our knowledge, it is the first work leveraging the observations of kernel dynamics to improve existing AT methods.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02236"
  },
  "2312.02231": {
    "title": "Quality Diversity in the Amorphous Fortress (QD-AF): Evolving for Complexity in 0-Player Games",
    "authors": [
      "Sam Earle",
      "M Charity",
      "Dipika Rajesh",
      "Mayu Wilson",
      "Julian Togelius"
    ],
    "abstract": "We explore the generation of diverse environments using the Amorphous Fortress (AF) simulation framework. AF defines a set of Finite State Machine (FSM) nodes and edges that can be recombined to control the behavior of agents in the `fortress' grid-world. The behaviors and conditions of the agents within the framework are designed to capture the common building blocks of multi-agent artificial life and reinforcement learning environments. Using quality diversity evolutionary search, we generate diverse sets of environments. These environments exhibit certain types of complexity according to measures of agents' FSM architectures and activations, and collective behaviors. Our approach, Quality Diversity in Amorphous Fortress (QD-AF) generates families of 0-player games akin to simplistic ecological models, and we identify the emergence of both competitive and co-operative multi-agent and multi-species survival dynamics. We argue that these generated worlds can collectively serve as training and testing grounds for learning algorithms.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02231"
  },
  "2312.02229": {
    "title": "Synthetic Data Generation Techniques for Developing AI-based Speech Assessments for Parkinson's Disease (A Comparative Study)",
    "authors": [
      "Mahboobeh Parsapoor"
    ],
    "abstract": "Changes in speech and language are among the first signs of Parkinson's disease (PD). Thus, clinicians have tried to identify individuals with PD from their voices for years. Doctors can leverage AI-based speech assessments to spot PD thanks to advancements in artificial intelligence (AI). Such AI systems can be developed using machine learning classifiers that have been trained using individuals' voices. Although several studies have shown reasonable results in developing such AI systems, these systems would need more data samples to achieve promising performance. This paper explores using deep learning-based data generation techniques on the accuracy of machine learning classifiers that are the core of such systems.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02229"
  },
  "2312.02227": {
    "title": "Improving Multimodal Sentiment Analysis: Supervised Angular Margin-based Contrastive Learning for Enhanced Fusion Representation",
    "authors": [
      "Cong-Duy Nguyen",
      "Thong Nguyen",
      "Duc Anh Vu",
      "Luu Anh Tuan"
    ],
    "abstract": "The effectiveness of a model is heavily reliant on the quality of the fusion representation of multiple modalities in multimodal sentiment analysis. Moreover, each modality is extracted from raw input and integrated with the rest to construct a multimodal representation. Although previous methods have proposed multimodal representations and achieved promising results, most of them focus on forming positive and negative pairs, neglecting the variation in sentiment scores within the same class. Additionally, they fail to capture the significance of unimodal representations in the fusion vector. To address these limitations, we introduce a framework called Supervised Angular-based Contrastive Learning for Multimodal Sentiment Analysis. This framework aims to enhance discrimination and generalizability of the multimodal representation and overcome biases in the fusion vector's modality. Our experimental results, along with visualizations on two widely used datasets, demonstrate the effectiveness of our approach.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02227"
  },
  "2312.02226": {
    "title": "Generating Action-conditioned Prompts for Open-vocabulary Video Action Recognition",
    "authors": [
      "Chengyou Jia",
      "Minnan Luo",
      "Xiaojun Chang",
      "Zhuohang Dang",
      "Mingfei Han",
      "Mengmeng Wang",
      "Guang Dai",
      "Sizhe Dang",
      "Jingdong Wang"
    ],
    "abstract": "Exploring open-vocabulary video action recognition is a promising venture, which aims to recognize previously unseen actions within any arbitrary set of categories. Existing methods typically adapt pretrained image-text models to the video domain, capitalizing on their inherent strengths in generalization. A common thread among such methods is the augmentation of visual embeddings with temporal information to improve the recognition of seen actions. Yet, they compromise with standard less-informative action descriptions, thus faltering when confronted with novel actions. Drawing inspiration from human cognitive processes, we argue that augmenting text embeddings with human prior knowledge is pivotal for open-vocabulary video action recognition. To realize this, we innovatively blend video models with Large Language Models (LLMs) to devise Action-conditioned Prompts. Specifically, we harness the knowledge in LLMs to produce a set of descriptive sentences that contain distinctive features for identifying given actions. Building upon this foundation, we further introduce a multi-modal action knowledge alignment mechanism to align concepts in video and textual knowledge encapsulated within the prompts. Extensive experiments on various video benchmarks, including zero-shot, few-shot, and base-to-novel generalization settings, demonstrate that our method not only sets new SOTA performance but also possesses excellent interpretability.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02226"
  },
  "2312.02225": {
    "title": "Digital Histopathology with Graph Neural Networks: Concepts and Explanations for Clinicians",
    "authors": [
      "Alessandro Farace di Villaforesta",
      "Lucie Charlotte Magister",
      "Pietro Barbiero",
      "Pietro Li\u00f2"
    ],
    "abstract": "To address the challenge of the ``black-box\" nature of deep learning in medical settings, we combine GCExplainer - an automated concept discovery solution - along with Logic Explained Networks to provide global explanations for Graph Neural Networks. We demonstrate this using a generally applicable graph construction and classification pipeline, involving panoptic segmentation with HoVer-Net and cancer prediction with Graph Convolution Networks. By training on H&E slides of breast cancer, we show promising results in offering explainable and trustworthy AI tools for clinicians.\n        \u25b3 Less",
    "submission_date": "28 December, 2023",
    "eprint_id": "2312.02225"
  },
  "2312.02221": {
    "title": "Slice3D: Multi-Slice, Occlusion-Revealing, Single View 3D Reconstruction",
    "authors": [
      "Yizhi Wang",
      "Wallace Lira",
      "Wenqi Wang",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "abstract": "We introduce multi-slice reasoning, a new notion for single-view 3D reconstruction which challenges the current and prevailing belief that multi-view synthesis is the most natural conduit between single-view and 3D. Our key observation is that object slicing is more advantageous than altering views to reveal occluded structures. Specifically, slicing is more occlusion-revealing since it can peel through any occluders without obstruction. In the limit, i.e., with infinitely many slices, it is guaranteed to unveil all hidden object parts. We realize our idea by developing Slice3D, a novel method for single-view 3D reconstruction which first predicts multi-slice images from a single RGB image and then integrates the slices into a 3D model using a coordinate-based transformer network for signed distance prediction. The slice images can be regressed or generated, both through a U-Net based network. For the former, we inject a learnable slice indicator code to designate each decoded image into a spatial slice location, while the slice generator is a denoising diffusion model operating on the entirety of slice images stacked on the input channels. We conduct extensive evaluation against state-of-the-art alternatives to demonstrate superiority of our method, especially in recovering complex and severely occluded shape structures, amid ambiguities. All Slice3D results were produced by networks trained on a single Nvidia A40 GPU, with an inference time less than 20 seconds.\n        \u25b3 Less",
    "submission_date": "10 December, 2023",
    "eprint_id": "2312.02221"
  },
  "2312.02220": {
    "title": "QuantAttack: Exploiting Dynamic Quantization to Attack Vision Transformers",
    "authors": [
      "Amit Baras",
      "Alon Zolfi",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "In recent years, there has been a significant trend in deep neural networks (DNNs), particularly transformer-based models, of developing ever-larger and more capable models. While they demonstrate state-of-the-art performance, their growing scale requires increased computational resources (e.g., GPUs with greater memory capacity). To address this problem, quantization techniques (i.e., low-bit-precision representation and matrix multiplication) have been proposed. Most quantization techniques employ a static strategy in which the model parameters are quantized, either during training or inference, without considering the test-time sample. In contrast, dynamic quantization techniques, which have become increasingly popular, adapt during inference based on the input provided, while maintaining full-precision performance. However, their dynamic behavior and average-case performance assumption makes them vulnerable to a novel threat vector -- adversarial attacks that target the model's efficiency and availability. In this paper, we present QuantAttack, a novel attack that targets the availability of quantized models, slowing down the inference, and increasing memory usage and energy consumption. We show that carefully crafted adversarial examples, which are designed to exhaust the resources of the operating system, can trigger worst-case performance. In our experiments, we demonstrate the effectiveness of our attack on vision transformers on a wide range of tasks, both uni-modal and multi-modal. We also examine the effect of different attack variants (e.g., a universal perturbation) and the transferability between different models.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02220"
  },
  "2312.02213": {
    "title": "JarviX: A LLM No code Platform for Tabular Data Analysis and Optimization",
    "authors": [
      "Shang-Ching Liu",
      "ShengKun Wang",
      "Wenqi Lin",
      "Chung-Wei Hsiung",
      "Yi-Chen Hsieh",
      "Yu-Ping Cheng",
      "Sian-Hong Luo",
      "Tsungyao Chang",
      "Jianwei Zhang"
    ],
    "abstract": "In this study, we introduce JarviX, a sophisticated data analytics framework. JarviX is designed to employ Large Language Models (LLMs) to facilitate an automated guide and execute high-precision data analyzes on tabular datasets. This framework emphasizes the significance of varying column types, capitalizing on state-of-the-art LLMs to generate concise data insight summaries, propose relevant analysis inquiries, visualize data effectively, and provide comprehensive explanations for results drawn from an extensive data analysis pipeline. Moreover, JarviX incorporates an automated machine learning (AutoML) pipeline for predictive modeling. This integration forms a comprehensive and automated optimization cycle, which proves particularly advantageous for optimizing machine configuration. The efficacy and adaptability of JarviX are substantiated through a series of practical use case studies.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02213"
  },
  "2312.02212": {
    "title": "Portrait Diffusion: Training-free Face Stylization with Chain-of-Painting",
    "authors": [
      "Jin Liu",
      "Huaibo Huang",
      "Chao Jin",
      "Ran He"
    ],
    "abstract": "Face stylization refers to the transformation of a face into a specific portrait style. However, current methods require the use of example-based adaptation approaches to fine-tune pre-trained generative models so that they demand lots of time and storage space and fail to achieve detailed style transformation. This paper proposes a training-free face stylization framework, named Portrait Diffusion. This framework leverages off-the-shelf text-to-image diffusion models, eliminating the need for fine-tuning specific examples. Specifically, the content and style images are first inverted into latent codes. Then, during image reconstruction using the corresponding latent code, the content and style features in the attention space are delicately blended through a modified self-attention operation called Style Attention Control. Additionally, a Chain-of-Painting method is proposed for the gradual redrawing of unsatisfactory areas from rough adjustments to fine-tuning. Extensive experiments validate the effectiveness of our Portrait Diffusion method and demonstrate the superiority of Chain-of-Painting in achieving precise face stylization. Code will be released at \\url{https://github.com/liujin112/PortraitDiffusion}.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.02212"
  },
  "2312.02211": {
    "title": "Cycle-consistent Generative Adversarial Network Synthetic CT for MR-only Adaptive Radiation Therapy on MR-Linac",
    "authors": [
      "Gabriel L. Asher",
      "Bassem I. Zaki",
      "Gregory A. Russo",
      "Gobind S. Gill",
      "Charles R. Thomas",
      "Temiloluwa O. Prioleau",
      "Rongxiao Zhang",
      "Brady Hunt"
    ],
    "abstract": "Purpose: This study assesses the effectiveness of Deep Learning (DL) for creating synthetic CT (sCT) images in MR-guided adaptive radiation therapy (MRgART).\n  Methods: A Cycle-GAN model was trained with MRI and CT scan slices from MR-LINAC treatments, generating sCT volumes. The analysis involved retrospective treatment plan data from patients with various tumors. sCT images were compared with standard CT scans using mean absolute error in Hounsfield Units (HU) and image similarity metrics (SSIM, PSNR, NCC). sCT volumes were integrated into a clinical treatment system for dosimetric re-evaluation.\n  Results: The model, trained on 8405 frames from 57 patients and tested on 357 sCT frames from 17 patients, showed sCTs comparable to dCTs in electron density and structural similarity with MRI scans. The MAE between sCT and dCT was 49.2 +/- 13.2 HU, with sCT NCC exceeding dCT by 0.06, and SSIM and PSNR at 0.97 +/- 0.01 and 19.9 +/- 1.6 respectively. Dosimetric evaluations indicated minimal differences between sCTs and dCTs, with sCTs showing better air-bubble reconstruction.\n  Conclusions: DL-based sCT generation on MR-Linacs is accurate for dose calculation and optimization in MRgART. This could facilitate MR-only treatment planning, enhancing simulation and adaptive planning efficiency on MR-Linacs.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02211"
  },
  "2312.02210": {
    "title": "Low-Precision Mixed-Computation Models for Inference on Edge",
    "authors": [
      "Seyedarmin Azizi",
      "Mahdi Nazemi",
      "Mehdi Kamal",
      "Massoud Pedram"
    ],
    "abstract": "This paper presents a mixed-computation neural network processing approach for edge applications that incorporates low-precision (low-width) Posit and low-precision fixed point (FixP) number systems. This mixed-computation approach employs 4-bit Posit (Posit4), which has higher precision around zero, for representing weights with high sensitivity, while it uses 4-bit FixP (FixP4) for representing other weights. A heuristic for analyzing the importance and the quantization error of the weights is presented to assign the proper number system to different weights. Additionally, a gradient approximation for Posit representation is introduced to improve the quality of weight updates in the backpropagation process. Due to the high energy consumption of the fully Posit-based computations, neural network operations are carried out in FixP or Posit/FixP. An efficient hardware implementation of a MAC operation with a first Posit operand and FixP for a second operand and accumulator is presented. The efficacy of the proposed low-precision mixed-computation approach is extensively assessed on vision and language models. The results show that, on average, the accuracy of the mixed-computation is about 1.5% higher than that of FixP with a cost of 0.19% energy overhead.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02210"
  },
  "2312.02208": {
    "title": "A Data-efficient Framework for Robotics Large-scale LiDAR Scene Parsing",
    "authors": [
      "Kangcheng Liu"
    ],
    "abstract": "Existing state-of-the-art 3D point clouds understanding methods only perform well in a fully supervised manner. To the best of our knowledge, there exists no unified framework which simultaneously solves the downstream high-level understanding tasks, especially when labels are extremely limited. This work presents a general and simple framework to tackle point clouds understanding when labels are limited. We propose a novel unsupervised region expansion based clustering method for generating clusters. More importantly, we innovatively propose to learn to merge the over-divided clusters based on the local low-level geometric property similarities and the learned high-level feature similarities supervised by weak labels. Hence, the true weak labels guide pseudo labels merging taking both geometric and semantic feature correlations into consideration. Finally, the self-supervised reconstruction and data augmentation optimization modules are proposed to guide the propagation of labels among semantically similar points within a scene. Experimental Results demonstrate that our framework has the best performance among the three most important weakly supervised point clouds understanding tasks including semantic segmentation, instance segmentation, and object detection even when limited points are labeled, under the data-efficient settings for the large-scale 3D semantic scene parsing. The developed techniques have postentials to be applied to downstream tasks for better representations in robotic manipulation and robotic autonomous navigation. Codes and models are publicly available at: https://github.com/KangchengLiu.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02208"
  },
  "2312.02207": {
    "title": "TranSegPGD: Improving Transferability of Adversarial Examples on Semantic Segmentation",
    "authors": [
      "Xiaojun Jia",
      "Jindong Gu",
      "Yihao Huang",
      "Simeng Qin",
      "Qing Guo",
      "Yang Liu",
      "Xiaochun Cao"
    ],
    "abstract": "Transferability of adversarial examples on image classification has been systematically explored, which generates adversarial examples in black-box mode. However, the transferability of adversarial examples on semantic segmentation has been largely overlooked. In this paper, we propose an effective two-stage adversarial attack strategy to improve the transferability of adversarial examples on semantic segmentation, dubbed TranSegPGD. Specifically, at the first stage, every pixel in an input image is divided into different branches based on its adversarial property. Different branches are assigned different weights for optimization to improve the adversarial performance of all pixels.We assign high weights to the loss of the hard-to-attack pixels to misclassify all pixels. At the second stage, the pixels are divided into different branches based on their transferable property which is dependent on Kullback-Leibler divergence. Different branches are assigned different weights for optimization to improve the transferability of the adversarial examples. We assign high weights to the loss of the high-transferability pixels to improve the transferability of adversarial examples. Extensive experiments with various segmentation models are conducted on PASCAL VOC 2012 and Cityscapes datasets to demonstrate the effectiveness of the proposed method. The proposed adversarial attack method can achieve state-of-the-art performance.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02207"
  },
  "2312.02206": {
    "title": "Axiomatic Preference Modeling for Longform Question Answering",
    "authors": [
      "Corby Rosset",
      "Guoqing Zheng",
      "Victor Dibia",
      "Ahmed Awadallah",
      "Paul Bennett"
    ],
    "abstract": "The remarkable abilities of large language models (LLMs) like GPT-4 partially stem from post-training processes like Reinforcement Learning from Human Feedback (RLHF) involving human preferences encoded in a reward model. However, these reward models (RMs) often lack direct knowledge of why, or under what principles, the preferences annotations were made. In this study, we identify principles that guide RMs to better align with human preferences, and then develop an axiomatic framework to generate a rich variety of preference signals to uphold them. We use these axiomatic signals to train a model for scoring answers to longform questions. Our approach yields a Preference Model with only about 220M parameters that agrees with gold human-annotated preference labels more often than GPT-4. The contributions of this work include: training a standalone preference model that can score human- and LLM-generated answers on the same scale; developing an axiomatic framework for generating training data pairs tailored to certain principles; and showing that a small amount of axiomatic signals can help small models outperform GPT-4 in preference scoring. We release our model on huggingface: https://huggingface.co/corbyrosset/axiomatic_preference_model\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02206"
  },
  "2312.02205": {
    "title": "Disentangling the Effects of Data Augmentation and Format Transform in Self-Supervised Learning of Image Representations",
    "authors": [
      "Neha Kalibhat",
      "Warren Morningstar",
      "Alex Bijamov",
      "Luyang Liu",
      "Karan Singhal",
      "Philip Mansfield"
    ],
    "abstract": "Self-Supervised Learning (SSL) enables training performant models using limited labeled data. One of the pillars underlying vision SSL is the use of data augmentations/perturbations of the input which do not significantly alter its semantic content. For audio and other temporal signals, augmentations are commonly used alongside format transforms such as Fourier transforms or wavelet transforms. Unlike augmentations, format transforms do not change the information contained in the data; rather, they express the same information in different coordinates. In this paper, we study the effects of format transforms and augmentations both separately and together on vision SSL. We define augmentations in frequency space called Fourier Domain Augmentations (FDA) and show that training SSL models on a combination of these and image augmentations can improve the downstream classification accuracy by up to 1.3% on ImageNet-1K. We also show improvements against SSL baselines in few-shot and transfer learning setups using FDA. Surprisingly, we also observe that format transforms can improve the quality of learned representations even without augmentations; however, the combination of the two techniques yields better quality.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02205"
  },
  "2312.02204": {
    "title": "Can We Learn Communication-Efficient Optimizers?",
    "authors": [
      "Charles-\u00c9tienne Joseph",
      "Benjamin Th\u00e9rien",
      "Abhinav Moudgil",
      "Boris Knyazev",
      "Eugene Belilovsky"
    ],
    "abstract": "Communication-efficient variants of SGD, specifically local SGD, have received a great deal of interest in recent years. These approaches compute multiple gradient steps locally, that is on each worker, before averaging model parameters, helping relieve the critical communication bottleneck in distributed deep learning training. Although many variants of these approaches have been proposed, they can sometimes lag behind state-of-the-art adaptive optimizers for deep learning. In this work, we investigate if the recent progress in the emerging area of learned optimizers can potentially close this gap while remaining communication-efficient. Specifically, we meta-learn how to perform global updates given an update from local SGD iterations. Our results demonstrate that learned optimizers can substantially outperform local SGD and its sophisticated variants while maintaining their communication efficiency. Learned optimizers can even generalize to unseen and much larger datasets and architectures, including ImageNet and ViTs, and to unseen modalities such as language modeling. We therefore demonstrate the potential of learned optimizers for improving communication-efficient distributed learning.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02204"
  },
  "2312.02201": {
    "title": "ImageDream: Image-Prompt Multi-view Diffusion for 3D Generation",
    "authors": [
      "Peng Wang",
      "Yichun Shi"
    ],
    "abstract": "We introduce \"ImageDream,\" an innovative image-prompt, multi-view diffusion model for 3D object generation. ImageDream stands out for its ability to produce 3D models of higher quality compared to existing state-of-the-art, image-conditioned methods. Our approach utilizes a canonical camera coordination for the objects in images, improving visual geometry accuracy. The model is designed with various levels of control at each block inside the diffusion model based on the input image, where global control shapes the overall object layout and local control fine-tunes the image details. The effectiveness of ImageDream is demonstrated through extensive evaluations using a standard prompt list. For more information, visit our project page at https://Image-Dream.github.io.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02201"
  },
  "2312.02200": {
    "title": "An Empirical Study of Automated Mislabel Detection in Real World Vision Datasets",
    "authors": [
      "Maya Srikanth",
      "Jeremy Irvin",
      "Brian Wesley Hill",
      "Felipe Godoy",
      "Ishan Sabane",
      "Andrew Y. Ng"
    ],
    "abstract": "Major advancements in computer vision can primarily be attributed to the use of labeled datasets. However, acquiring labels for datasets often results in errors which can harm model performance. Recent works have proposed methods to automatically identify mislabeled images, but developing strategies to effectively implement them in real world datasets has been sparsely explored. Towards improved data-centric methods for cleaning real world vision datasets, we first conduct more than 200 experiments carefully benchmarking recently developed automated mislabel detection methods on multiple datasets under a variety of synthetic and real noise settings with varying noise levels. We compare these methods to a Simple and Efficient Mislabel Detector (SEMD) that we craft, and find that SEMD performs similarly to or outperforms prior mislabel detection approaches. We then apply SEMD to multiple real world computer vision datasets and test how dataset size, mislabel removal strategy, and mislabel removal amount further affect model performance after retraining on the cleaned data. With careful design of the approach, we find that mislabel removal leads per-class performance improvements of up to 8% of a retrained classifier in smaller data regimes.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02200"
  },
  "2312.02199": {
    "title": "USat: A Unified Self-Supervised Encoder for Multi-Sensor Satellite Imagery",
    "authors": [
      "Jeremy Irvin",
      "Lucas Tao",
      "Joanne Zhou",
      "Yuntao Ma",
      "Langston Nashold",
      "Benjamin Liu",
      "Andrew Y. Ng"
    ],
    "abstract": "Large, self-supervised vision models have led to substantial advancements for automatically interpreting natural images. Recent works have begun tailoring these methods to remote sensing data which has rich structure with multi-sensor, multi-spectral, and temporal information providing massive amounts of self-labeled data that can be used for self-supervised pre-training. In this work, we develop a new encoder architecture called USat that can input multi-spectral data from multiple sensors for self-supervised pre-training. USat is a vision transformer with modified patch projection layers and positional encodings to model spectral bands with varying spatial scales from multiple sensors. We integrate USat into a Masked Autoencoder (MAE) self-supervised pre-training procedure and find that a pre-trained USat outperforms state-of-the-art self-supervised MAE models trained on remote sensing data on multiple remote sensing benchmark datasets (up to 8%) and leads to improvements in low data regimes (up to 7%). Code and pre-trained weights are available at https://github.com/stanfordmlgroup/USat .\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02199"
  },
  "2312.02195": {
    "title": "Cancer Subtype Identification through Integrating Inter and Intra Dataset Relationships in Multi-Omics Data",
    "authors": [
      "Mark Peelen",
      "Leila Bagheriye",
      "Johan Kwisthout"
    ],
    "abstract": "The integration of multi-omics data has emerged as a promising approach for gaining comprehensive insights into complex diseases such as cancer. This paper proposes a novel approach to identify cancer subtypes through the integration of multi-omics data for clustering. The proposed method, named LIDAF utilises affinity matrices based on linear relationships between and within different omics datasets (Linear Inter and Intra Dataset Affinity Fusion (LIDAF)). Canonical Correlation Analysis is in this paper employed to create distance matrices based on Euclidean distances between canonical variates. The distance matrices are converted to affinity matrices and those are fused in a three-step process. The proposed LIDAF addresses the limitations of the existing method resulting in improvement of clustering performance as measured by the Adjusted Rand Index and the Normalized Mutual Information score. Moreover, our proposed LIDAF approach demonstrates a notable enhancement in 50% of the log10 rank p-values obtained from Cox survival analysis, surpassing the performance of the best reported method, highlighting its potential of identifying distinct cancer subtypes.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02195"
  },
  "2312.02194": {
    "title": "Local Masking Meets Progressive Freezing: Crafting Efficient Vision Transformers for Self-Supervised Learning",
    "authors": [
      "Utku Mert Topcuoglu",
      "Erdem Akag\u00fcnd\u00fcz"
    ],
    "abstract": "In this paper, we present an innovative approach to self-supervised learning for Vision Transformers (ViTs), integrating local masked image modeling with progressive layer freezing. This method focuses on enhancing the efficiency and speed of initial layer training in ViTs. By systematically freezing specific layers at strategic points during training, we reduce computational demands while maintaining or improving learning capabilities. Our approach employs a novel multi-scale reconstruction process that fosters efficient learning in initial layers and enhances semantic comprehension across scales. The results demonstrate a substantial reduction in training time (~12.5\\%) with a minimal impact on model accuracy (decrease in top-1 accuracy by 0.6\\%). Our method achieves top-1 and top-5 accuracies of 82.6\\% and 96.2\\%, respectively, underscoring its potential in scenarios where computational resources and time are critical. This work marks an advancement in the field of self-supervised learning for computer vision. The implementation of our approach is available at our project's GitHub repository: github.com/utkutpcgl/ViTFreeze.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02194"
  },
  "2312.02191": {
    "title": "Prompt Tuning for Zero-shot Compositional Learning",
    "authors": [
      "Lingyu Zhang",
      "Ting Hua",
      "Yilin Shen",
      "Hongxia Jin"
    ],
    "abstract": "Open World Compositional Zero-Shot Learning (OW-CZSL) is known to be an extremely challenging task, which aims to recognize unseen compositions formed from seen attributes and objects without any prior assumption of the output space. In order to achieve this goal, a model has to be \"smart\" and \"knowledgeable\". To be smart, a model should be good at reasoning the interactions between attributes and objects from the seen compositions. While \"knowledgeable\" means the model owns \"common sense\" to the open world that can \"foresee\" some features of the unseen compositions. Most previous work focuses on the \"smart\" part, while few of them provided an effective solution to achieve the \"knowledgeable\" goal. In this paper, we proposed a framework named Multi-Modal Prompt Tuning (MMPT) to inherit the \"knowledgeable\" property from the large pre-trained vision-language model. Extensive experiments show that our proposed MMPT obtains new state-of-the-art results in OW-CZSL task. On the UT-Zappos dataset, MMPT pushes the AUC score to $29.8$, while the previous best score is $26.5$. On the more challenging MIT-States dataset, the AUC score of MMPT is 1.5 times better than the current state-of-the-art.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.02191"
  },
  "2312.02190": {
    "title": "Diffusion Handles: Enabling 3D Edits for Diffusion Models by Lifting Activations to 3D",
    "authors": [
      "Karran Pandey",
      "Paul Guerrero",
      "Matheus Gadelha",
      "Yannick Hold-Geoffroy",
      "Karan Singh",
      "Niloy Mitra"
    ],
    "abstract": "Diffusion Handles is a novel approach to enabling 3D object edits on diffusion images. We accomplish these edits using existing pre-trained diffusion models, and 2D image depth estimation, without any fine-tuning or 3D object retrieval. The edited results remain plausible, photo-real, and preserve object identity. Diffusion Handles address a critically missing facet of generative image based creative design, and significantly advance the state-of-the-art in generative image editing. Our key insight is to lift diffusion activations for an object to 3D using a proxy depth, 3D-transform the depth and associated activations, and project them back to image space. The diffusion process applied to the manipulated activations with identity control, produces plausible edited images showing complex 3D occlusion and lighting effects. We evaluate Diffusion Handles: quantitatively, on a large synthetic data benchmark; and qualitatively by a user study, showing our output to be more plausible, and better than prior art at both, 3D editing and identity control. Project Webpage: https://diffusionhandles.github.io/\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02190"
  },
  "2312.02189": {
    "title": "StableDreamer: Taming Noisy Score Distillation Sampling for Text-to-3D",
    "authors": [
      "Pengsheng Guo",
      "Hans Hao",
      "Adam Caccavale",
      "Zhongzheng Ren",
      "Edward Zhang",
      "Qi Shan",
      "Aditya Sankar",
      "Alexander G. Schwing",
      "Alex Colburn",
      "Fangchang Ma"
    ],
    "abstract": "In the realm of text-to-3D generation, utilizing 2D diffusion models through score distillation sampling (SDS) frequently leads to issues such as blurred appearances and multi-faced geometry, primarily due to the intrinsically noisy nature of the SDS loss. Our analysis identifies the core of these challenges as the interaction among noise levels in the 2D diffusion process, the architecture of the diffusion network, and the 3D model representation. To overcome these limitations, we present StableDreamer, a methodology incorporating three advances. First, inspired by InstructNeRF2NeRF, we formalize the equivalence of the SDS generative prior and a simple supervised L2 reconstruction loss. This finding provides a novel tool to debug SDS, which we use to show the impact of time-annealing noise levels on reducing multi-faced geometries. Second, our analysis shows that while image-space diffusion contributes to geometric precision, latent-space diffusion is crucial for vivid color rendition. Based on this observation, StableDreamer introduces a two-stage training strategy that effectively combines these aspects, resulting in high-fidelity 3D models. Third, we adopt an anisotropic 3D Gaussians representation, replacing Neural Radiance Fields (NeRFs), to enhance the overall quality, reduce memory usage during training, and accelerate rendering speeds, and better capture semi-transparent objects. StableDreamer reduces multi-face geometries, generates fine details, and converges stably.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.02189"
  },
  "2312.02188": {
    "title": "Video Summarization: Towards Entity-Aware Captions",
    "authors": [
      "Hammad A. Ayyubi",
      "Tianqi Liu",
      "Arsha Nagrani",
      "Xudong Lin",
      "Mingda Zhang",
      "Anurag Arnab",
      "Feng Han",
      "Yukun Zhu",
      "Jialu Liu",
      "Shih-Fu Chang"
    ],
    "abstract": "Existing popular video captioning benchmarks and models deal with generic captions devoid of specific person, place or organization named entities. In contrast, news videos present a challenging setting where the caption requires such named entities for meaningful summarization. As such, we propose the task of summarizing news video directly to entity-aware captions. We also release a large-scale dataset, VIEWS (VIdeo NEWS), to support research on this task. Further, we propose a method that augments visual information from videos with context retrieved from external world knowledge to generate entity-aware captions. We demonstrate the effectiveness of our approach on three video captioning models. We also show that our approach generalizes to existing news image captions dataset. With all the extensive experiments and insights, we believe we establish a solid basis for future research on this challenging task.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.02188"
  },
  "2312.02185": {
    "title": "Virtual Fusion with Contrastive Learning for Single Sensor-based Activity Recognition",
    "authors": [
      "Duc-Anh Nguyen",
      "Cuong Pham",
      "Nhien-An Le-Khac"
    ],
    "abstract": "Various types of sensors can be used for Human Activity Recognition (HAR), and each of them has different strengths and weaknesses. Sometimes a single sensor cannot fully observe the user's motions from its perspective, which causes wrong predictions. While sensor fusion provides more information for HAR, it comes with many inherent drawbacks like user privacy and acceptance, costly set-up, operation, and maintenance. To deal with this problem, we propose Virtual Fusion - a new method that takes advantage of unlabeled data from multiple time-synchronized sensors during training, but only needs one sensor for inference. Contrastive learning is adopted to exploit the correlation among sensors. Virtual Fusion gives significantly better accuracy than training with the same single sensor, and in some cases, it even surpasses actual fusion using multiple sensors at test time. We also extend this method to a more general version called Actual Fusion within Virtual Fusion (AFVF), which uses a subset of training sensors during inference. Our method achieves state-of-the-art accuracy and F1-score on UCI-HAR and PAMAP2 benchmark datasets. Implementation is available upon request.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.02185"
  },
  "2312.02182": {
    "title": "Adam-like Algorithm with Smooth Clipping Attains Global Minima: Analysis Based on Ergodicity of Functional SDEs",
    "authors": [
      "Keisuke Suzuki"
    ],
    "abstract": "In this paper, we prove that an Adam-type algorithm with smooth clipping approaches the global minimizer of the regularized non-convex loss function. Adding smooth clipping and taking the state space as the set of all trajectories, we can apply the ergodic theory of Markov semigroups for this algorithm and investigate its asymptotic behavior. The ergodic theory we establish in this paper reduces the problem of evaluating the convergence, generalization error and discretization error of this algorithm to the problem of evaluating the difference between two functional stochastic differential equations (SDEs) with different drift coefficients. As a result of our analysis, we have shown that this algorithm minimizes the the regularized non-convex loss function with errors of the form $n^{-1/2}$, $\u03b7^{1/4}$, $\u03b2^{-1} \\log (\u03b2+ 1)$ and $e^{- c t}$. Here, $c$ is a constant and $n$, $\u03b7$, $\u03b2$ and $t$ denote the size of the training dataset, learning rate, inverse temperature and time, respectively.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.02182"
  },
  "2312.02181": {
    "title": "How Generative-AI can be Effectively used in Government Chatbots",
    "authors": [
      "Zeteng Lin"
    ],
    "abstract": "With the rapid development of artificial intelligence and breakthroughs in machine learning and natural language processing, intelligent question-answering robots have become widely used in government affairs. This paper conducts a horizontal comparison between Guangdong Province's government chatbots, ChatGPT, and Wenxin Ernie, two large language models, to analyze the strengths and weaknesses of existing government chatbots and AIGC technology. The study finds significant differences between government chatbots and large language models. China's government chatbots are still in an exploratory stage and have a gap to close to achieve \"intelligence.\" To explore the future direction of government chatbots more deeply, this research proposes targeted optimization paths to help generative AI be effectively applied in government chatbot conversations.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.02181"
  },
  "2312.02179": {
    "title": "Training Chain-of-Thought via Latent-Variable Inference",
    "authors": [
      "Du Phan",
      "Matthew D. Hoffman",
      "David Dohan",
      "Sholto Douglas",
      "Tuan Anh Le",
      "Aaron Parisi",
      "Pavel Sountsov",
      "Charles Sutton",
      "Sharad Vikram",
      "Rif A. Saurous"
    ],
    "abstract": "Large language models (LLMs) solve problems more accurately and interpretably when instructed to work out the answer step by step using a ``chain-of-thought'' (CoT) prompt. One can also improve LLMs' performance on a specific task by supervised fine-tuning, i.e., by using gradient ascent on some tunable parameters to maximize the average log-likelihood of correct answers from a labeled training set. Naively combining CoT with supervised tuning requires supervision not just of the correct answers, but also of detailed rationales that lead to those answers; these rationales are expensive to produce by hand. Instead, we propose a fine-tuning strategy that tries to maximize the \\emph{marginal} log-likelihood of generating a correct answer using CoT prompting, approximately averaging over all possible rationales. The core challenge is sampling from the posterior over rationales conditioned on the correct answer; we address it using a simple Markov-chain Monte Carlo (MCMC) expectation-maximization (EM) algorithm inspired by the self-taught reasoner (STaR), memoized wake-sleep, Markovian score climbing, and persistent contrastive divergence. This algorithm also admits a novel control-variate technique that drives the variance of our gradient estimates to zero as the model improves. Applying our technique to GSM8K and the tasks in BIG-Bench Hard, we find that this MCMC-EM fine-tuning technique typically improves the model's accuracy on held-out examples more than STaR or prompt-tuning with or without CoT.\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.02179"
  },
  "2312.02178": {
    "title": "Hierarchical ML Codebook Design for Extreme MIMO Beam Management",
    "authors": [
      "Ryan M. Dreifuerst",
      "Robert W. Heath Jr"
    ],
    "abstract": "Beam management is a strategy to unify beamforming and channel state information (CSI) acquisition with large antenna arrays in 5G. Codebooks serve multiple uses in beam management including beamforming reference signals, CSI reporting, and analog beam training. In this paper, we propose and evaluate a machine learning-refined codebook design process for extremely large multiple-input multiple-output (X-MIMO) systems. We propose a neural network and beam selection strategy to design the initial access and refinement codebooks using end-to-end learning from beamspace representations. The algorithm, called Extreme-Beam Management (X-BM), can significantly improve the performance of extremely large arrays as envisioned for 6G and capture realistic wireless and physical layer aspects. Our results show an 8dB improvement in initial access and overall effective spectral efficiency improvements compared to traditional codebook methods.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2312.02178"
  },
  "2312.02177": {
    "title": "Entropy generating function for past lifetime and its properties",
    "authors": [
      "Smitha S.",
      "Sudheesh K Kattumannil"
    ],
    "abstract": "The past entropy is considered as an uncertainty measure for the past lifetime distribution. Generating function approach to entropy become popular in recent time as it generate several well-known entropy measures. In this paper, we introduce the past entropy-generating function. We study certain properties of this measure. It is shown that the past entropy-generating function uniquely determines the distribution. Further, we present characterizations for some lifetime models using the relationship between reliability concepts and the past entropy-generating function.\n        \u25b3 Less",
    "submission_date": "19 November, 2023",
    "eprint_id": "2312.02177"
  },
  "2312.02176": {
    "title": "Channel Scheduling for IoT Access with Spatial Correlation",
    "authors": [
      "Prasoon Raghuwanshi",
      "Onel Luis Alcaraz L\u00f3pez",
      "Petar Popovski",
      "Matti Latva-aho"
    ],
    "abstract": "Spatially correlated device activation is a typical feature of the Internet of Things (IoT). This motivates the development of channel scheduling (CS) methods that mitigate device collisions efficiently in such scenarios, which constitutes the scope of this work. Specifically, we present a quadratic program (QP) formulation for the CS problem considering the joint activation probabilities among devices. This formulation allows the devices to stochastically select the transmit channels, thus, leading to a soft-clustering approach. We prove that the optimal QP solution can only be attained when it is transformed into a hard-clustering problem, leading to a pure integer QP, which we transform into a pure integer linear program (PILP). We leverage the branch-and-cut (B&C) algorithm to solve PILP optimally. Due to the high computational cost of B&C, we resort to some sub-optimal clustering methods with low computational costs to tackle the clustering problem in CS. Our findings demonstrate that the CS strategy, sourced from B&C, significantly outperforms those derived from sub-optimal clustering methods, even amidst increased device correlation.\n        \u25b3 Less",
    "submission_date": "17 November, 2023",
    "eprint_id": "2312.02176"
  },
  "2312.02173": {
    "title": "TailorMe: Self-Supervised Learning of an Anatomically Constrained Volumetric Human Shape Model",
    "authors": [
      "Stephan Wenninger",
      "Fabian Kemper",
      "Ulrich Schwanecke",
      "Mario Botsch"
    ],
    "abstract": "Human shape spaces have been extensively studied, as they are a core element of human shape and pose inference tasks. Classic methods for creating a human shape model register a surface template mesh to a database of 3D scans and use dimensionality reduction techniques, such as Principal Component Analysis, to learn a compact representation. While these shape models enable global shape modifications by correlating anthropometric measurements with the learned subspace, they only provide limited localized shape control. We instead register a volumetric anatomical template, consisting of skeleton bones and soft tissue, to the surface scans of the CAESAR database. We further enlarge our training data to the full Cartesian product of all skeletons and all soft tissues using physically plausible volumetric deformation transfer. This data is then used to learn an anatomically constrained volumetric human shape model in a self-supervised fashion. The resulting TailorMe model enables shape sampling, localized shape manipulation, and fast inference from given surface scans.\n        \u25b3 Less",
    "submission_date": "3 November, 2023",
    "eprint_id": "2312.02173"
  },
  "2312.02172": {
    "title": "Mercury: A modeling, simulation, and optimization framework for data stream-oriented IoT applications",
    "authors": [
      "Rom\u00e1n C\u00e1rdenas",
      "Patricia Arroba",
      "Roberto Blanco",
      "Pedro Malag\u00f3n",
      "Jos\u00e9 L. Risco-Mart\u00edn",
      "Jos\u00e9 M. Moya"
    ],
    "abstract": "The Internet of Things is transforming our society by monitoring users and infrastructures' behavior to enable new services that will improve life quality and resource management. These applications require a vast amount of localized information to be processed in real-time so, the deployment of new fog computing infrastructures that bring computing closer to the data sources is a major concern. In this context, we present Mercury, a Modeling, Simulation, and Optimization (M&S&O) framework to analyze the dimensioning and the dynamic operation of real-time fog computing scenarios. Our research proposes a location-aware solution that supports data stream analytics applications including FaaS-based computation offloading. Mercury implements a detailed structural and behavioral simulation model, providing fine-grained simulation outputs, and is described using the Discrete Event System Specification (DEVS) mathematical formalism, helping to validate the model's implementation. Finally, we present a case study using real traces from a driver assistance scenario, offering a detailed comparison with other state-of-the-art simulators.\n        \u25b3 Less",
    "submission_date": "2 November, 2023",
    "eprint_id": "2312.02172"
  },
  "2312.02171": {
    "title": "LpiCT: A logic security analysis framework for protocols",
    "authors": [
      "Fusheng Wu",
      "Jinhui Liu",
      "Yanbing Li",
      "Mingtao Ni"
    ],
    "abstract": "The pi calculus is a basic theory of mobile communication based on the notion of interaction, which, aimed at analyzing and modelling the behaviors of communication process in communicating and mobile systems, is widely applied to the security analysis of cryptographic protocol's design and implementation. But the pi calculus does not provide perfect logic security analysis, so the logic flaws in the design and the implementation of a cryptographic protocol can not be discovered in time. The aim is to analyze whether there are logic flaws in the design and the implementation of a cryptographic protocol, so as to ensure the security of the cryptographic protocol when it is encoded into a software and implemented. This paper introduces logic rules and proofs, binary tree and the KMP algorithm, and proposes a new extension the pi calculus theory, a logic security analysis framework and an algorithm. This paper presents the logic security proof and analysis of TLS1.3 protocol's interactional implementation process. Empirical results show that the new extension theory, the logic security analysis framework and the algorithm can effectively analyze whether there are logic flaws in the design and the implementation of a cryptographic protocol. The security of cryptographic protocols depends not only on cryptographic primitives, but also on the coding of cryptographic protocols and the environment in which they are implemented. The security analysis framework of cryptographic protocol implementation proposed in this paper can ensure the security of protocol implementation.\n        \u25b3 Less",
    "submission_date": "1 November, 2023",
    "eprint_id": "2312.02171"
  },
  "2312.02168": {
    "title": "The SVHN Dataset Is Deceptive for Probabilistic Generative Models Due to a Distribution Mismatch",
    "authors": [
      "Tim Z. Xiao",
      "Johannes Zenn",
      "Robert Bamler"
    ],
    "abstract": "The Street View House Numbers (SVHN) dataset is a popular benchmark dataset in deep learning. Originally designed for digit classification tasks, the SVHN dataset has been widely used as a benchmark for various other tasks including generative modeling. However, with this work, we aim to warn the community about an issue of the SVHN dataset as a benchmark for generative modeling tasks: we discover that the official split into training set and test set of the SVHN dataset are not drawn from the same distribution. We empirically show that this distribution mismatch has little impact on the classification task (which may explain why this issue has not been detected before), but it severely affects the evaluation of probabilistic generative models, such as Variational Autoencoders and diffusion models. As a workaround, we propose to mix and re-split the official training and test set when SVHN is used for tasks other than classification. We publish a new split and the indices we used to create it at https://jzenn.github.io/svhn-remix/ .\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02168"
  },
  "2312.02167": {
    "title": "Uncertainty Quantification in Machine Learning Based Segmentation: A Post-Hoc Approach for Left Ventricle Volume Estimation in MRI",
    "authors": [
      "F. Terhag",
      "P. Knechtges",
      "A. Basermann",
      "R. Tempone"
    ],
    "abstract": "Recent studies have confirmed cardiovascular diseases remain responsible for highest death toll amongst non-communicable diseases. Accurate left ventricular (LV) volume estimation is critical for valid diagnosis and management of various cardiovascular conditions, but poses significant challenge due to inherent uncertainties associated with segmentation algorithms in magnetic resonance imaging (MRI). Recent machine learning advancements, particularly U-Net-like convolutional networks, have facilitated automated segmentation for medical images, but struggles under certain pathologies and/or different scanner vendors and imaging protocols. This study proposes a novel methodology for post-hoc uncertainty estimation in LV volume prediction using It\u00f4 stochastic differential equations (SDEs) to model path-wise behavior for the prediction error. The model describes the area of the left ventricle along the heart's long axis. The method is agnostic to the underlying segmentation algorithm, facilitating its use with various existing and future segmentation technologies. The proposed approach provides a mechanism for quantifying uncertainty, enabling medical professionals to intervene for unreliable predictions. This is of utmost importance in critical applications such as medical diagnosis, where prediction accuracy and reliability can directly impact patient outcomes. The method is also robust to dataset changes, enabling application for medical centers with limited access to labeled data. Our findings highlight the proposed uncertainty estimation methodology's potential to enhance automated segmentation robustness and generalizability, paving the way for more reliable and accurate LV volume estimation in clinical settings as well as opening new avenues for uncertainty quantification in biomedical image segmentation, providing promising directions for future research.\n        \u25b3 Less",
    "submission_date": "30 October, 2023",
    "eprint_id": "2312.02167"
  },
  "2312.02164": {
    "title": "Driver Safety Reward with Cooperative Platooning using Blockchain",
    "authors": [
      "Sruthi Rachamalla",
      "Henry Hexmoor"
    ],
    "abstract": "Cooperative driving (or Platooning) focuses on improving the safety and efficiency by connecting two or more vehicles on a road by vehicular communication protocols. The leader is crucial as it manages the platoon, establishes communication between cars, and perform platoon maneuvers. In this paper, we proposed a driver incentive model which encourages platooning on roads leading to driver safety. As, the leader of platoon have multiple responsibilities than followers, our model rewards more incentives to leader than followers. These incentives will be rewarded as crypto tokens. This digital monetization method for both leaders and followers of a platoon is accomplished by secure transactions using blockchain.\n        \u25b3 Less",
    "submission_date": "24 October, 2023",
    "eprint_id": "2312.02164"
  },
  "2312.02163": {
    "title": "Cooperation Based Joint Active and Passive Sensing with Asynchronous Transceivers for Perceptive Mobile Networks",
    "authors": [
      "Wangjun Jiang",
      "Zhiqing Wei",
      "Shaoshi Yang",
      "Zhiyong Feng",
      "Ping Zhang"
    ],
    "abstract": "Perceptive mobile network (PMN) is an emerging concept for next-generation wireless networks capable of conducting integrated sensing and communication (ISAC). A major challenge for realizing high performance sensing in PMNs is how to deal with spatially separated asynchronous transceivers. Asynchronicity results in timing offsets (TOs) and carrier frequency offsets (CFOs), which further cause ambiguity in ranging and velocity sensing. Most existing algorithms mitigate TOs and CFOs based on the line-of-sight (LOS) propagation path between sensing transceivers. However, LOS paths may not exist in realistic scenarios. In this paper, we propose a cooperation based joint active and passive sensing scheme for the non-LOS (NLOS) scenarios having asynchronous transceivers. This scheme relies on the cross-correlation cooperative sensing (CCCS) algorithm, which regards active sensing as a reference and mitigates TOs and CFOs by correlating active and passive sensing information. Another major challenge for realizing high performance sensing in PMNs is how to realize high accuracy angle-of-arrival (AoA) estimation with low complexity. Correspondingly, we propose a low complexity AoA algorithm based on cooperative sensing, which comprises coarse AoA estimation and fine AoA estimation. Analytical and numerical simulation results verify the performance advantages of the proposed CCCS algorithm and the low complexity AoA estimation algorithm.\n        \u25b3 Less",
    "submission_date": "12 October, 2023",
    "eprint_id": "2312.02163"
  },
  "2312.02161": {
    "title": "Efficient LDPC Decoding using Physical Computation",
    "authors": [
      "Uday Kumar Reddy Vengalam",
      "Andrew Hahn",
      "Yongchao Liu",
      "Anshujit Sharma",
      "Hui Wu",
      "Michael Huang"
    ],
    "abstract": "Due to 5G deployment, there is significant interest in LDPC decoding. While much research is devoted on efficient hardwiring of algorithms based on Belief Propagation (BP), it has been shown that LDPC decoding can be formulated as a combinatorial optimization problem, which could benefit from significant acceleration of physical computation mechanisms such as Ising machines. This approach has so far resulted in poor performance. This paper shows that the reason is not fundamental but suboptimal hardware and formulation. A co-designed Ising machine-based system can improve speed by 3 orders of magnitude. As a result, a physical computation approach can outperform hardwiring state-of-the-art algorithms. In this paper, we show such an augmented Ising machine that is 4.4$\\times$ more energy efficient than the state of the art in the literature.\n        \u25b3 Less",
    "submission_date": "20 September, 2023",
    "eprint_id": "2312.02161"
  },
  "2312.02160": {
    "title": "Coding for the unsourced A-channel with erasures: the linked loop code",
    "authors": [
      "William W. Zheng",
      "Jamison R. Ebert",
      "Stefano Rini",
      "Jean-Francois Chamberland"
    ],
    "abstract": "The A-channel is a noiseless multiple access channel in which users simultaneously transmit Q-ary symbols and the receiver observes the set of transmitted symbols, but not their multiplicities. An A-channel is said to be unsourced if, additionally, users transmissions are encoded across time using a common codebook and decoding of the transmitted messages is done without regard to the identities of the active users. An interesting variant of the unsourced A-channel is the unsourced A-channel with erasures (UACE), in which transmitted symbols are erased with a given independent and identically distributed probability. In this paper, we focus on designing a code that enables a list of transmitted codewords to be recovered despite the erasures of some of the transmitted symbols. To this end, we propose the linked-loop code (LLC), which uses parity bits to link each symbol to the previous M symbols in a tail-biting manner, i.e., the first symbols of the transmission are linked to the last ones. The decoding process occurs in two phases: the first phase decodes the codewords that do not suffer from any erasures, and the second phase attempts to recover the erased symbols using the available parities. We compare the performance of the LLC over the UACE with other codes in the literature and argue for the effectiveness of the construction. Our motivation for studying the UACE comes from its relevance in machine-type communication and coded compressed sensing.\n        \u25b3 Less",
    "submission_date": "19 September, 2023",
    "eprint_id": "2312.02160"
  },
  "2312.02159": {
    "title": "Spectral Temporal Graph Neural Network for massive MIMO CSI Prediction",
    "authors": [
      "Sharan Mourya",
      "Pavan Reddy",
      "SaiDhiraj Amuru",
      "Kiran Kumar Kuchi"
    ],
    "abstract": "In the realm of 5G communication systems, the accuracy of Channel State Information (CSI) prediction is vital for optimizing performance. This letter introduces a pioneering approach: the Spectral-Temporal Graph Neural Network (STEM GNN), which fuses spatial relationships and temporal dynamics of the wireless channel using the Graph Fourier Transform. We compare the STEM GNN approach with conventional Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) models for CSI prediction. Our findings reveal a significant enhancement in overall communication system performance through STEM GNNs. For instance, in one scenario, STEM GNN achieves a sum rate of 5.009 bps/Hz which is $11.9\\%$ higher than that of LSTM and $35\\%$ higher than that of RNN. The spectral-temporal analysis capabilities of STEM GNNs capture intricate patterns often overlooked by traditional models, offering improvements in beamforming, interference mitigation, and ultra-reliable low-latency communication (URLLC).\n        \u25b3 Less",
    "submission_date": "10 September, 2023",
    "eprint_id": "2312.02159"
  },
  "2312.02157": {
    "title": "Mesh-Guided Neural Implicit Field Editing",
    "authors": [
      "Can Wang",
      "Mingming He",
      "Menglei Chai",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "abstract": "Neural implicit fields have emerged as a powerful 3D representation for reconstructing and rendering photo-realistic views, yet they possess limited editability. Conversely, explicit 3D representations, such as polygonal meshes, offer ease of editing but may not be as suitable for rendering high-quality novel views. To harness the strengths of both representations, we propose a new approach that employs a mesh as a guiding mechanism in editing the neural radiance field. We first introduce a differentiable method using marching tetrahedra for polygonal mesh extraction from the neural implicit field and then design a differentiable color extractor to assign colors obtained from the volume renderings to this extracted mesh. This differentiable colored mesh allows gradient back-propagation from the explicit mesh to the implicit fields, empowering users to easily manipulate the geometry and color of neural implicit fields. To enhance user control from coarse-grained to fine-grained levels, we introduce an octree-based structure into its optimization. This structure prioritizes the edited regions and the surface part, making our method achieve fine-grained edits to the neural implicit field and accommodate various user modifications, including object additions, component removals, specific area deformations, and adjustments to local and global colors. Through extensive experiments involving diverse scenes and editing operations, we have demonstrated the capabilities and effectiveness of our method. Our project page is: \\url{https://cassiepython.github.io/MNeuEdit/}\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02157"
  },
  "2312.02156": {
    "title": "Latent Feature-Guided Diffusion Models for Shadow Removal",
    "authors": [
      "Kangfu Mei",
      "Luis Figueroa",
      "Zhe Lin",
      "Zhihong Ding",
      "Scott Cohen",
      "Vishal M. Patel"
    ],
    "abstract": "Recovering textures under shadows has remained a challenging problem due to the difficulty of inferring shadow-free scenes from shadow images. In this paper, we propose the use of diffusion models as they offer a promising approach to gradually refine the details of shadow regions during the diffusion process. Our method improves this process by conditioning on a learned latent feature space that inherits the characteristics of shadow-free images, thus avoiding the limitation of conventional methods that condition on degraded images only. Additionally, we propose to alleviate potential local optima during training by fusing noise features with the diffusion network. We demonstrate the effectiveness of our approach which outperforms the previous best method by 13% in terms of RMSE on the AISTD dataset. Further, we explore instance-level shadow removal, where our model outperforms the previous best method by 82% in terms of RMSE on the DESOBA dataset.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02156"
  },
  "2312.02153": {
    "title": "Aligning and Prompting Everything All at Once for Universal Visual Perception",
    "authors": [
      "Yunhang Shen",
      "Chaoyou Fu",
      "Peixian Chen",
      "Mengdan Zhang",
      "Ke Li",
      "Xing Sun",
      "Yunsheng Wu",
      "Shaohui Lin",
      "Rongrong Ji"
    ],
    "abstract": "Vision foundation models have been explored recently to build general-purpose vision systems. However, predominant paradigms, driven by casting instance-level tasks as an object-word alignment, bring heavy cross-modality interaction, which is not effective in prompting object detection and visual grounding. Another line of work that focuses on pixel-level tasks often encounters a large annotation gap of things and stuff, and suffers from mutual interference between foreground-object and background-class segmentation. In stark contrast to the prevailing methods, we present APE, a universal visual perception model for aligning and prompting everything all at once in an image to perform diverse tasks, i.e., detection, segmentation, and grounding, as an instance-level sentence-object matching paradigm. Specifically, APE advances the convergence of detection and grounding by reformulating language-guided grounding as open-vocabulary detection, which efficiently scales up model prompting to thousands of category vocabularies and region descriptions while maintaining the effectiveness of cross-modality fusion. To bridge the granularity gap of different pixel-level tasks, APE equalizes semantic and panoptic segmentation to proxy instance learning by considering any isolated regions as individual instances. APE aligns vision and language representation on broad data with natural and challenging characteristics all at once without task-specific fine-tuning. The extensive experiments on over 160 datasets demonstrate that, with only one-suit of weights, APE outperforms (or is on par with) the state-of-the-art models, proving that an effective yet universal perception for anything aligning and prompting is indeed feasible. Codes and trained models are released at https://github.com/shenyunhang/APE.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02153"
  },
  "2312.02151": {
    "title": "Guarding Barlow Twins Against Overfitting with Mixed Samples",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Celso M. De Melo",
      "Vishal M. Patel"
    ],
    "abstract": "Self-supervised Learning (SSL) aims to learn transferable feature representations for downstream applications without relying on labeled data. The Barlow Twins algorithm, renowned for its widespread adoption and straightforward implementation compared to its counterparts like contrastive learning methods, minimizes feature redundancy while maximizing invariance to common corruptions. Optimizing for the above objective forces the network to learn useful representations, while avoiding noisy or constant features, resulting in improved downstream task performance with limited adaptation. Despite Barlow Twins' proven effectiveness in pre-training, the underlying SSL objective can inadvertently cause feature overfitting due to the lack of strong interaction between the samples unlike the contrastive learning approaches. From our experiments, we observe that optimizing for the Barlow Twins objective doesn't necessarily guarantee sustained improvements in representation quality beyond a certain pre-training phase, and can potentially degrade downstream performance on some datasets. To address this challenge, we introduce Mixed Barlow Twins, which aims to improve sample interaction during Barlow Twins training via linearly interpolated samples. This results in an additional regularization term to the original Barlow Twins objective, assuming linear interpolation in the input space translates to linearly interpolated features in the feature space. Pre-training with this regularization effectively mitigates feature overfitting and further enhances the downstream performance on CIFAR-10, CIFAR-100, TinyImageNet, STL-10, and ImageNet datasets. The code and checkpoints are available at: https://github.com/wgcban/mix-bt.git\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02151"
  },
  "2312.02146": {
    "title": "Learning Polynomial Problems with $SL(2,\\mathbb{R})$ Equivariance",
    "authors": [
      "Hannah Lawrence",
      "Mitchell Tong Harris"
    ],
    "abstract": "Optimizing and certifying the positivity of polynomials are fundamental primitives across mathematics and engineering applications, from dynamical systems to operations research. However, solving these problems in practice requires large semidefinite programs, with poor scaling in dimension and degree. In this work, we demonstrate for the first time that neural networks can effectively solve such problems in a data-driven fashion, achieving tenfold speedups while retaining high accuracy. Moreover, we observe that these polynomial learning problems are equivariant to the non-compact group $SL(2,\\mathbb{R})$, which consists of area-preserving linear transformations. We therefore adapt our learning pipelines to accommodate this structure, including data augmentation, a new $SL(2,\\mathbb{R})$-equivariant architecture, and an architecture equivariant with respect to its maximal compact subgroup, $SO(2, \\mathbb{R})$. Surprisingly, the most successful approaches in practice do not enforce equivariance to the entire group, which we prove arises from an unusual lack of architecture universality for $SL(2,\\mathbb{R})$ in particular. A consequence of this result, which is of independent interest, is that there exists an equivariant function for which there is no sequence of equivariant polynomials multiplied by arbitrary invariants that approximates the original function. This is a rare example of a symmetric problem where data augmentation outperforms a fully equivariant architecture, and provides interesting lessons in both theory and practice for other problems with non-compact symmetries.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02146"
  },
  "2312.02144": {
    "title": "Optimizing Camera Configurations for Multi-View Pedestrian Detection",
    "authors": [
      "Yunzhong Hou",
      "Xingjian Leng",
      "Tom Gedeon",
      "Liang Zheng"
    ],
    "abstract": "Jointly considering multiple camera views (multi-view) is very effective for pedestrian detection under occlusion. For such multi-view systems, it is critical to have well-designed camera configurations, including camera locations, directions, and fields-of-view (FoVs). Usually, these configurations are crafted based on human experience or heuristics. In this work, we present a novel solution that features a transformer-based camera configuration generator. Using reinforcement learning, this generator autonomously explores vast combinations within the action space and searches for configurations that give the highest detection accuracy according to the training dataset. The generator learns advanced techniques like maximizing coverage, minimizing occlusion, and promoting collaboration. Across multiple simulation scenarios, the configurations generated by our transformer-based model consistently outperform random search, heuristic-based methods, and configurations designed by human experts, shedding light on future camera layout optimization.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02144"
  },
  "2312.02136": {
    "title": "BerfScene: Bev-conditioned Equivariant Radiance Fields for Infinite 3D Scene Generation",
    "authors": [
      "Qihang Zhang",
      "Yinghao Xu",
      "Yujun Shen",
      "Bo Dai",
      "Bolei Zhou",
      "Ceyuan Yang"
    ],
    "abstract": "Generating large-scale 3D scenes cannot simply apply existing 3D object synthesis technique since 3D scenes usually hold complex spatial configurations and consist of a number of objects at varying scales. We thus propose a practical and efficient 3D representation that incorporates an equivariant radiance field with the guidance of a bird's-eye view (BEV) map. Concretely, objects of synthesized 3D scenes could be easily manipulated through steering the corresponding BEV maps. Moreover, by adequately incorporating positional encoding and low-pass filters into the generator, the representation becomes equivariant to the given BEV map. Such equivariance allows us to produce large-scale, even infinite-scale, 3D scenes via synthesizing local scenes and then stitching them with smooth consistency. Extensive experiments on 3D scene datasets demonstrate the effectiveness of our approach. Our project website is at https://zqh0253.github.io/BerfScene/.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02136"
  },
  "2312.02133": {
    "title": "Style Aligned Image Generation via Shared Attention",
    "authors": [
      "Amir Hertz",
      "Andrey Voynov",
      "Shlomi Fruchter",
      "Daniel Cohen-Or"
    ],
    "abstract": "Large-scale Text-to-Image (T2I) models have rapidly gained prominence across creative fields, generating visually compelling outputs from textual prompts. However, controlling these models to ensure consistent style remains challenging, with existing methods necessitating fine-tuning and manual intervention to disentangle content and style. In this paper, we introduce StyleAligned, a novel technique designed to establish style alignment among a series of generated images. By employing minimal `attention sharing' during the diffusion process, our method maintains style consistency across images within T2I models. This approach allows for the creation of style-consistent images using a reference style through a straightforward inversion operation. Our method's evaluation across diverse styles and text prompts demonstrates high-quality synthesis and fidelity, underscoring its efficacy in achieving consistent style across various inputs.\n        \u25b3 Less",
    "submission_date": "11 January, 2024",
    "eprint_id": "2312.02133"
  },
  "2312.02128": {
    "title": "Can we truly transfer an actor's genuine happiness to avatars? An investigation into virtual, real, posed and spontaneous faces",
    "authors": [
      "Vitor Miguel Xavier Peres",
      "Greice Pinho Dal Molin",
      "Soraia Raupp Musse"
    ],
    "abstract": "A look is worth a thousand words is a popular phrase. And why is a simple look enough to portray our feelings about something or someone? Behind this question are the theoretical foundations of the field of psychology regarding social cognition and the studies of psychologist Paul Ekman. Facial expressions, as a form of non-verbal communication, are the primary way to transmit emotions between human beings. The set of movements and expressions of facial muscles that convey some emotional state of the individual to their observers are targets of studies in many areas. Our research aims to evaluate Ekman's action units in datasets of real human faces, posed and spontaneous, and virtual human faces resulting from transferring real faces into Computer Graphics faces. In addition, we also conducted a case study with specific movie characters, such as SheHulk and Genius. We intend to find differences and similarities in facial expressions between real and CG datasets, posed and spontaneous faces, and also to consider the actors' genders in the videos. This investigation can help several areas of knowledge, whether using real or virtual human beings, in education, health, entertainment, games, security, and even legal matters. Our results indicate that AU intensities are greater for posed than spontaneous datasets, regardless of gender. Furthermore, there is a smoothing of intensity up to 80 percent for AU6 and 45 percent for AU12 when a real face is transformed into CG.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02128"
  },
  "2312.02125": {
    "title": "TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and Advanced Decoding Techniques",
    "authors": [
      "Amir Panahandeh",
      "Hanie Asemi",
      "Esmaeil Nourani"
    ],
    "abstract": "Recent advances in language models (LMs), have demonstrated significant efficacy in tasks related to the arts and humanities. While LMs have exhibited exceptional performance across a wide range of natural language processing tasks, there are notable challenges associated with their utilization on small datasets and their ability to replicate more creative human capacities. In this study, we aim to address these challenges by training a Persian classical poetry generation model using a transformer architecture on a specialized dataset with no pretraining. Additionally, we propose a novel decoding method to enhance coherence and meaningfulness in the generated poetry, effectively managing the tradeoff between diversity and quality. Furthermore, the results of our training approach and the proposed decoding method are evaluated through comprehensive set of automatic and human evaluations and showed its superior capability to generate coherent and meaningful poetry in compare to other decoding methods and an existing Persian large language model (LLM).\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.02125"
  },
  "2312.02124": {
    "title": "VerA: Versatile Anonymization Fit for Clinical Facial Images",
    "authors": [
      "Majed El Helou",
      "Doruk Cetin",
      "Petar Stamenkovic",
      "Fabio Zund"
    ],
    "abstract": "The escalating legislative demand for data privacy in facial image dissemination has underscored the significance of image anonymization. Recent advancements in the field surpass traditional pixelation or blur methods, yet they predominantly address regular single images. This leaves clinical image anonymization -- a necessity for illustrating medical interventions -- largely unaddressed. We present VerA, a versatile facial image anonymization that is fit for clinical facial images where: (1) certain semantic areas must be preserved to show medical intervention results, and (2) anonymizing image pairs is crucial for showing before-and-after results. VerA outperforms or is on par with state-of-the-art methods in de-identification and photorealism for regular images. In addition, we validate our results on paired anonymization, and on the anonymization of both single and paired clinical images with extensive quantitative and qualitative evaluation.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02124"
  },
  "2312.02121": {
    "title": "Mathematical Supplement for the $\\texttt{gsplat}$ Library",
    "authors": [
      "Vickie Ye",
      "Angjoo Kanazawa"
    ],
    "abstract": "This report provides the mathematical details of the gsplat library, a modular toolbox for efficient differentiable Gaussian splatting, as proposed by Kerbl et al. It provides a self-contained reference for the computations involved in the forward and backward passes of differentiable Gaussian splatting. To facilitate practical usage and development, we provide a user friendly Python API that exposes each component of the forward and backward passes in rasterization at github.com/nerfstudio-project/gsplat .\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02121"
  },
  "2312.02118": {
    "title": "When it Rains, it Pours: Modeling Media Storms and the News Ecosystem",
    "authors": [
      "Benjamin Litterer",
      "David Jurgens",
      "Dallas Card"
    ],
    "abstract": "Most events in the world receive at most brief coverage by the news media. Occasionally, however, an event will trigger a media storm, with voluminous and widespread coverage lasting for weeks instead of days. In this work, we develop and apply a pairwise article similarity model, allowing us to identify story clusters in corpora covering local and national online news, and thereby create a comprehensive corpus of media storms over a nearly two year period. Using this corpus, we investigate media storms at a new level of granularity, allowing us to validate claims about storm evolution and topical distribution, and provide empirical support for previously hypothesized patterns of influence of storms on media coverage and intermedia agenda setting.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02118"
  },
  "2312.02114": {
    "title": "Transitions of Solutions and Their Efficiency",
    "authors": [
      "Gleb Polevoy"
    ],
    "abstract": "We broaden the basis of non-cooperative game theory by considering miscoordination on a solution concept. For any solution concept, we extend the solution set of a strategic-form game to a transition set. This set contains profiles where various agents simultaneously follow different solutions, e.g.~different Nash equilibria. This models the fact that in practice, complicated agents are rarely perfectly coordinated on the same equilibrium. We define two efficiency measures, called the price of transition anarchy and stability, and bound them. We also refine the notion of transition to the notion of limited transition, where only a limited number of solutions is simultaneously played, and to stable transitions, which allow for only minor lack of coordination. We compare the above mentioned efficiency measures and bound the efficiency of transitions in important cases, including the important cases of constant-sum and potential games, which span the set of finite games with the same number of strategies for each agent. We also prove tight efficiency bounds for routing games and coordination games on graphs. Finally, we study algorithms to find the transition degree required to make a given profile a transition, or to render all the profiles transitions. We conclude that for the sake of efficiency, it is crucial to avoid uncoordinated transitions, besides certain cases, such as constant-sum games, identical utility games, some types of routing games, limited transitions in potential games, and stable transitions in coordination games.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02114"
  },
  "2312.02112": {
    "title": "Distributed Optimization with Feasible Set Privacy",
    "authors": [
      "Shreya Meel",
      "Sennur Ulukus"
    ],
    "abstract": "We consider the setup of a constrained optimization problem with two agents $E_1$ and $E_2$ who jointly wish to learn the optimal solution set while keeping their feasible sets $\\mathcal{P}_1$ and $\\mathcal{P}_2$ private from each other. The objective function $f$ is globally known and each feasible set is a collection of points from a global alphabet. We adopt a sequential symmetric private information retrieval (SPIR) framework where one of the agents (say $E_1$) privately checks in $\\mathcal{P}_2$, the presence of candidate solutions of the problem constrained to $\\mathcal{P}_1$ only, while learning no further information on $\\mathcal{P}_2$ than the solution alone. Further, we extract an information theoretically private threshold PSI (ThPSI) protocol from our scheme and characterize its download cost. We show that, compared to privately acquiring the feasible set $\\mathcal{P}_1\\cap \\mathcal{P}_2$ using an SPIR-based private set intersection (PSI) protocol, and finding the optimum, our scheme is better as it incurs less information leakage and less download cost than the former. Over all possible uniform mappings of $f$ to a fixed range of values, our scheme outperforms the former with a high probability.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02112"
  },
  "2312.02105": {
    "title": "Authoring Worked Examples for Java Programming with Human-AI Collaboration",
    "authors": [
      "Mohammad Hassany",
      "Peter Brusilovsky",
      "Jiaze Ke",
      "Kamil Akhuseyinoglu",
      "Arun Balajiee Lekshmi Narayanan"
    ],
    "abstract": "Worked examples (solutions to typical programming problems presented as a source code in a certain language and are used to explain the topics from a programming class) are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary. We also present a study that assesses the quality of explanations created with this approach.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02105"
  },
  "2312.02103": {
    "title": "Learning Pseudo-Labeler beyond Noun Concepts for Open-Vocabulary Object Detection",
    "authors": [
      "Sunghun Kang",
      "Junbum Cha",
      "Jonghwan Mun",
      "Byungseok Roh",
      "Chang D. Yoo"
    ],
    "abstract": "Open-vocabulary object detection (OVOD) has recently gained significant attention as a crucial step toward achieving human-like visual intelligence. Existing OVOD methods extend target vocabulary from pre-defined categories to open-world by transferring knowledge of arbitrary concepts from vision-language pre-training models to the detectors. While previous methods have shown remarkable successes, they suffer from indirect supervision or limited transferable concepts. In this paper, we propose a simple yet effective method to directly learn region-text alignment for arbitrary concepts. Specifically, the proposed method aims to learn arbitrary image-to-text mapping for pseudo-labeling of arbitrary concepts, named Pseudo-Labeling for Arbitrary Concepts (PLAC). The proposed method shows competitive performance on the standard OVOD benchmark for noun concepts and a large improvement on referring expression comprehension benchmark for arbitrary concepts.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02103"
  },
  "2312.02102": {
    "title": "Mitigating Data Injection Attacks on Federated Learning",
    "authors": [
      "Or Shalom",
      "Amir Leshem",
      "Waheed U. Bajwa"
    ],
    "abstract": "Federated learning is a technique that allows multiple entities to collaboratively train models using their data without compromising data privacy. However, despite its advantages, federated learning can be susceptible to false data injection attacks. In these scenarios, a malicious entity with control over specific agents in the network can manipulate the learning process, leading to a suboptimal model. Consequently, addressing these data injection attacks presents a significant research challenge in federated learning systems. In this paper, we propose a novel technique to detect and mitigate data injection attacks on federated learning systems. Our mitigation method is a local scheme, performed during a single instance of training by the coordinating node, allowing the mitigation during the convergence of the algorithm. Whenever an agent is suspected to be an attacker, its data will be ignored for a certain period, this decision will often be re-evaluated. We prove that with probability 1, after a finite time, all attackers will be ignored while the probability of ignoring a trustful agent becomes 0, provided that there is a majority of truthful agents. Simulations show that when the coordinating node detects and isolates all the attackers, the model recovers and converges to the truthful model.\n        \u25b3 Less",
    "submission_date": "14 January, 2024",
    "eprint_id": "2312.02102"
  },
  "2312.02087": {
    "title": "VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence",
    "authors": [
      "Yuchao Gu",
      "Yipin Zhou",
      "Bichen Wu",
      "Licheng Yu",
      "Jia-Wei Liu",
      "Rui Zhao",
      "Jay Zhangjie Wu",
      "David Junhao Zhang",
      "Mike Zheng Shou",
      "Kevin Tang"
    ],
    "abstract": "Current diffusion-based video editing primarily focuses on structure-preserved editing by utilizing various dense correspondences to ensure temporal consistency and motion alignment. However, these approaches are often ineffective when the target edit involves a shape change. To embark on video editing with shape change, we explore customized video subject swapping in this work, where we aim to replace the main subject in a source video with a target subject having a distinct identity and potentially different shape. In contrast to previous methods that rely on dense correspondences, we introduce the VideoSwap framework that exploits semantic point correspondences, inspired by our observation that only a small number of semantic points are necessary to align the subject's motion trajectory and modify its shape. We also introduce various user-point interactions (\\eg, removing points and dragging points) to address various semantic point correspondence. Extensive experiments demonstrate state-of-the-art video subject swapping results across a variety of real-world videos.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02087"
  },
  "2312.02079": {
    "title": "Deep Set Neural Networks for forecasting asynchronous bioprocess timeseries",
    "authors": [
      "Maxim Borisyak",
      "Stefan Born",
      "Peter Neubauer",
      "Mariano Nicolas Cruz-Bournazou"
    ],
    "abstract": "Cultivation experiments often produce sparse and irregular time series. Classical approaches based on mechanistic models, like Maximum Likelihood fitting or Monte-Carlo Markov chain sampling, can easily account for sparsity and time-grid irregularities, but most statistical and Machine Learning tools are not designed for handling sparse data out-of-the-box. Among popular approaches there are various schemes for filling missing values (imputation) and interpolation into a regular grid (alignment). However, such methods transfer the biases of the interpolation or imputation models to the target model. We show that Deep Set Neural Networks equipped with triplet encoding of the input data can successfully handle bio-process data without any need for imputation or alignment procedures. The method is agnostic to the particular nature of the time series and can be adapted for any task, for example, online monitoring, predictive control, design of experiments, etc. In this work, we focus on forecasting. We argue that such an approach is especially suitable for typical cultivation processes, demonstrate the performance of the method on several forecasting tasks using data generated from macrokinetic growth models under realistic conditions, and compare the method to a conventional fitting procedure and methods based on imputation and alignment.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.02079"
  },
  "2312.02074": {
    "title": "Federated Learning is Better with Non-Homomorphic Encryption",
    "authors": [
      "Konstantin Burlachenko",
      "Abdulmajeed Alrowithi",
      "Fahad Ali Albalawi",
      "Peter Richtarik"
    ],
    "abstract": "Traditional AI methodologies necessitate centralized data collection, which becomes impractical when facing problems with network communication, data privacy, or storage capacity. Federated Learning (FL) offers a paradigm that empowers distributed AI model training without collecting raw data. There are different choices for providing privacy during FL training. One of the popular methodologies is employing Homomorphic Encryption (HE) - a breakthrough in privacy-preserving computation from Cryptography. However, these methods have a price in the form of extra computation and memory footprint. To resolve these issues, we propose an innovative framework that synergizes permutation-based compressors with Classical Cryptography, even though employing Classical Cryptography was assumed to be impossible in the past in the context of FL. Our framework offers a way to replace HE with cheaper Classical Cryptography primitives which provides security for the training process. It fosters asynchronous communication and provides flexible deployment options in various communication topologies.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02074"
  },
  "2312.02071": {
    "title": "Evaluating the Claims of \"SAT Requires Exhaustive Search\"",
    "authors": [
      "Michael C. Chavrimootoo",
      "Yumeng He",
      "Matan Kotler-Berkowitz",
      "Harry Liuson",
      "Zeyu Nie"
    ],
    "abstract": "In this paper, we take a closer look at the claims made by Xu and Zhou in their paper \"SAT Requires Exhaustive Search\" [XZ23], which claims to provide a lower bound on the complexity of the so-called Model RB. Xu and Zhou conclude that their result implies a separation between P and NP, since the lower bound purportedly proves that the Strong Exponential Time Hypothesis (SETH) is true. In examining Xu and Zhou's arguments, we find a flaw in their main theorems. The authors assume that an algorithm for Model RB must have a certain structure that can leverage downward self-reducibility, and argue that such an algorithm cannot run in polynomial time. We argue that this structure is not guaranteed to exist and thus their paper neither proves SETH to be true nor proves P $\\neq$ NP.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02071"
  },
  "2312.02065": {
    "title": "Know Your Audience: Do LLMs Adapt to Different Age and Education Levels?",
    "authors": [
      "Donya Rooein",
      "Amanda Cercas Curry",
      "Dirk Hovy"
    ],
    "abstract": "Large language models (LLMs) offer a range of new possibilities, including adapting the text to different audiences and their reading needs. But how well do they adapt? We evaluate the readability of answers generated by four state-of-the-art LLMs (commercial and open-source) to science questions when prompted to target different age groups and education levels. To assess the adaptability of LLMs to diverse audiences, we compare the readability scores of the generated responses against the recommended comprehension level of each age and education group. We find large variations in the readability of the answers by different LLMs. Our results suggest LLM answers need to be better adapted to the intended audience demographics to be more comprehensible. They underline the importance of enhancing the adaptability of LLMs in education settings to cater to diverse age and education levels. Overall, current LLMs have set readability ranges and do not adapt well to different audiences, even when prompted. That limits their potential for educational purposes.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02065"
  },
  "2312.02063": {
    "title": "The GPU Phase Folding and Deep Learning Method for Detecting Exoplanet Transits",
    "authors": [
      "Kaitlyn Wang",
      "Jian Ge",
      "Kevin Willis",
      "Kevin Wang",
      "Yinan Zhao"
    ],
    "abstract": "This paper presents GPFC, a novel Graphics Processing Unit (GPU) Phase Folding and Convolutional Neural Network (CNN) system to detect exoplanets using the transit method. We devise a fast folding algorithm parallelized on a GPU to amplify low signal-to-noise ratio transit signals, allowing a search at high precision and speed. A CNN trained on two million synthetic light curves reports a score indicating the likelihood of a planetary signal at each period. While the GPFC method has broad applicability across period ranges, this research specifically focuses on detecting ultra-short-period planets with orbital periods less than one day. GPFC improves on speed by three orders of magnitude over the predominant Box-fitting Least Squares (BLS) method. Our simulation results show GPFC achieves $97%$ training accuracy, higher true positive rate at the same false positive rate of detection, and higher precision at the same recall rate when compared to BLS. GPFC recovers $100\\%$ of known ultra-short-period planets in $\\textit{Kepler}$ light curves from a blind search. These results highlight the promise of GPFC as an alternative approach to the traditional BLS algorithm for finding new transiting exoplanets in data taken with $\\textit{Kepler}$ and other space transit missions such as K2, TESS and future PLATO and Earth 2.0.\n        \u25b3 Less",
    "submission_date": "21 January, 2024",
    "eprint_id": "2312.02063"
  },
  "2312.02060": {
    "title": "Right-sizing compute resource allocations for bioinformatics tools with Total Perspective Vortex",
    "authors": [
      "Nuwan Goonasekera",
      "Catherine Bromhead",
      "Simon Gladman",
      "Nate Coraor",
      "Bjorn Gruning",
      "Enis Afgan"
    ],
    "abstract": "In biomedical research, computational methods have become indispensable and their use is increasing, making the efficient allocation of computing resources paramount. Practitioners routinely allocate resources far in excess of what is required for batch processing jobs, leading to not just inflated wait times and costs, but also unnecessary carbon emissions. This is not without reason however, as accurately determining resource needs is complex, affected by the nature of tools, data size, and analysis parameters, especially on popular servers that handle numerous jobs. The Galaxy platform, a web-based hub for biomedical analysis used globally by scientists, exemplifies this challenge. Serving nearly half a million registered users and managing around 2 million monthly jobs, Galaxy's growth outpaces the resources at its disposal. This is necessitating smarter resource utilization. To address this, we have developed a tool named Total Perspective Vortex (TPV) - a software package that right-sizes resource allocations for each job. TPV is able to dynamically set resource requirements for individual jobs and perform meta-scheduling across heterogeneous resources. It also includes a first-ever community-curated database of default resource requirements for nearly 1,000 popular bioinformatics tools. Deployments in Galaxy Australia and Europe demonstrate its effectiveness with meta-scheduling user jobs and an improved experience for systems administrators managing Galaxy servers.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02060"
  },
  "2312.02057": {
    "title": "An improved bound on sums of square roots via the subspace theorem",
    "authors": [
      "Friedrich Eisenbrand",
      "Matthieu Haeberle",
      "Neta Singer"
    ],
    "abstract": "The sum of square roots is as follows: Given $x_1,\\dots,x_n \\in \\mathbb{Z}$ and $a_1,\\dots,a_n \\in \\mathbb{N}$ decide whether $ E=\\sum_{i=1}^n x_i \\sqrt{a_i} \\geq 0$. It is a prominent open problem (Problem 33 of the Open Problems Project), whether this can be decided in polynomial time. The state-of-the-art methods rely on separation bounds, which are lower bounds on the minimum nonzero absolute value of $E$. The current best bound shows that $|E| \\geq \\left(n \\cdot \\max_i (|x_i| \\cdot \\sqrt{a_i})\\right)^{-2^n} $, which is doubly exponentially small.\n  We provide a new bound of the form $|E| \\geq \u03b3\\cdot (n \\cdot \\max_i|x_i|)^{-2n}$ where $\u03b3$ is a constant depending on $a_1,\\dots,a_n$. This is singly exponential in $n$ for fixed $a_1,\\dots,a_n$. The constant $\u03b3$ is not explicit and stems from the subspace theorem, a deep result in the geometry of numbers.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02057"
  },
  "2312.02055": {
    "title": "Transaction Ordering Auctions",
    "authors": [
      "Jan Christoph Schlegel"
    ],
    "abstract": "We study equilibrium investment into bidding and latency reduction for different sequencing policies. For a batch auction design, we observe that bidders shade bids according to the likelihood that competing bidders land in the current batch. Moreover, in equilibrium, in the ex-ante investment stage before the auction, bidders invest into latency until they make zero profit in expectation.\n  We compare the batch auction design to continuous time bidding policies (time boost) and observe that (depending on the choice of parameters) they obtain similar revenue and welfare guarantees.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02055"
  },
  "2312.02054": {
    "title": "From High to Low: Simulating Nondeterminism and State with State",
    "authors": [
      "Wenhao Tang",
      "Tom Schrijvers"
    ],
    "abstract": "Some effects are considered to be higher-level than others. High-level effects provide expressive and succinct abstraction of programming concepts, while low-level effects allow more fine-grained control over program execution and resources. Yet, often it is desirable to write programs using the convenient abstraction offered by high-level effects, and meanwhile still benefit from the optimisations enabled by low-level effects. One solution is to translate high-level effects to low-level ones.\n  This paper studies how algebraic effects and handlers allow us to simulate high-level effects in terms of low-level effects. In particular, we focus on the interaction between state and nondeterminism known as the local state, as provided by Prolog. We map this high-level semantics in successive steps onto a low-level composite state effect, similar to that managed by Prolog's Warren Abstract Machine. We first give a translation from the high-level local-state semantics to the low-level global-state semantics, by explicitly restoring state updates on backtracking. Next, we eliminate nondeterminsm altogether in favor of a lower-level state containing a choicepoint stack. Then we avoid copying the state by restricting ourselves to incremental, reversible state updates. We show how these updates can be stored on a trail stack with another state effect. We prove the correctness of all our steps using program calculation where the fusion laws of effect handlers play a central role.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02054"
  },
  "2312.02037": {
    "title": "GFS: Graph-based Feature Synthesis for Prediction over Relational Databases",
    "authors": [
      "Han Zhang",
      "Quan Gan",
      "David Wipf",
      "Weinan Zhang"
    ],
    "abstract": "Relational databases are extensively utilized in a variety of modern information system applications, and they always carry valuable data patterns. There are a huge number of data mining or machine learning tasks conducted on relational databases. However, it is worth noting that there are limited machine learning models specifically designed for relational databases, as most models are primarily tailored for single table settings. Consequently, the prevalent approach for training machine learning models on data stored in relational databases involves performing feature engineering to merge the data from multiple tables into a single table and subsequently applying single table models. This approach not only requires significant effort in feature engineering but also destroys the inherent relational structure present in the data. To address these challenges, we propose a novel framework called Graph-based Feature Synthesis (GFS). GFS formulates the relational database as a heterogeneous graph, thereby preserving the relational structure within the data. By leveraging the inductive bias from single table models, GFS effectively captures the intricate relationships inherent in each table. Additionally, the whole framework eliminates the need for manual feature engineering. In the extensive experiment over four real-world multi-table relational databases, GFS outperforms previous methods designed for relational databases, demonstrating its superior performance.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02037"
  },
  "2312.02034": {
    "title": "Trust, distrust, and appropriate reliance in (X)AI: a survey of empirical evaluation of user trust",
    "authors": [
      "Roel Visser",
      "Tobias M. Peters",
      "Ingrid Scharlau",
      "Barbara Hammer"
    ],
    "abstract": "A current concern in the field of Artificial Intelligence (AI) is to ensure the trustworthiness of AI systems. The development of explainability methods is one prominent way to address this, which has often resulted in the assumption that the use of explainability will lead to an increase in the trust of users and wider society. However, the dynamics between explainability and trust are not well established and empirical investigations of their relation remain mixed or inconclusive. In this paper we provide a detailed description of the concepts of user trust and distrust in AI and their relation to appropriate reliance. For that we draw from the fields of machine learning, human-computer interaction, and the social sciences. Furthermore, we have created a survey of existing empirical studies that investigate the effects of AI systems and XAI methods on user (dis)trust. With clarifying the concepts and summarizing the empirical investigations, we aim to provide researchers, who examine user trust in AI, with an improved starting point for developing user studies to measure and evaluate the user's attitude towards and reliance on AI systems.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02034"
  },
  "2312.02031": {
    "title": "Virtual Quantum Markov Chains",
    "authors": [
      "Yu-Ao Chen",
      "Chengkai Zhu",
      "Keming He",
      "Mingrui Jing",
      "Xin Wang"
    ],
    "abstract": "Quantum Markov chains generalize classical Markov chains for random variables to the quantum realm and exhibit unique inherent properties, making them an important feature in quantum information theory. In this work, we propose the concept of virtual quantum Markov chains (VQMCs), focusing on scenarios where subsystems retain classical information about global systems from measurement statistics. As a generalization of quantum Markov chains, VQMCs characterize states where arbitrary global shadow information can be recovered from subsystems through local quantum operations and measurements. We present an algebraic characterization for virtual quantum Markov chains and show that the virtual quantum recovery is fully determined by the block matrices of a quantum state on its subsystems. Notably, we find a distinction between two classes of tripartite entanglement by showing that the W state is a VQMC while the GHZ state is not. Furthermore, we establish semidefinite programs to determine the optimal sampling overhead and the robustness of virtual quantum Markov chains. We demonstrate the optimal sampling overhead is additive, indicating no free lunch to further reduce the sampling cost of recovery from parallel calls of the VQMC states. Our findings elucidate distinctions between quantum Markov chains and virtual quantum Markov chains, extending our understanding of quantum recovery to scenarios prioritizing classical information from measurement statistics.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02031"
  },
  "2312.02029": {
    "title": "Implicit Learning of Scene Geometry from Poses for Global Localization",
    "authors": [
      "Mohammad Altillawi",
      "Shile Li",
      "Sai Manoj Prakhya",
      "Ziyuan Liu",
      "Joan Serrat"
    ],
    "abstract": "Global visual localization estimates the absolute pose of a camera using a single image, in a previously mapped area. Obtaining the pose from a single image enables many robotics and augmented/virtual reality applications. Inspired by latest advances in deep learning, many existing approaches directly learn and regress 6 DoF pose from an input image. However, these methods do not fully utilize the underlying scene geometry for pose regression. The challenge in monocular relocalization is the minimal availability of supervised training data, which is just the corresponding 6 DoF poses of the images. In this paper, we propose to utilize these minimal available labels (.i.e, poses) to learn the underlying 3D geometry of the scene and use the geometry to estimate the 6 DoF camera pose. We present a learning method that uses these pose labels and rigid alignment to learn two 3D geometric representations (\\textit{X, Y, Z coordinates}) of the scene, one in camera coordinate frame and the other in global coordinate frame. Given a single image, it estimates these two 3D scene representations, which are then aligned to estimate a pose that matches the pose label. This formulation allows for the active inclusion of additional learning constraints to minimize 3D alignment errors between the two 3D scene representations, and 2D re-projection errors between the 3D global scene representation and 2D image pixels, resulting in improved localization accuracy. During inference, our model estimates the 3D scene geometry in camera and global frames and aligns them rigidly to obtain pose in real-time. We evaluate our work on three common visual localization datasets, conduct ablation studies, and show that our method exceeds state-of-the-art regression methods' pose accuracy on all datasets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02029"
  },
  "2312.02023": {
    "title": "Consistency of Relations over Monoids",
    "authors": [
      "Albert Atserias",
      "Phokion G. Kolaitis"
    ],
    "abstract": "The interplay between local consistency and global consistency has been the object of study in several different areas, including probability theory, relational databases, and quantum information. For relational databases, Beeri, Fagin, Maier, and Yannakakis showed that a database schema is acyclic if and only if it has the local-to-global consistency property for relations, which means that every collection of pairwise consistent relations over the schema is globally consistent. More recently, the same result has been shown under bag semantics. In this paper, we carry out a systematic study of local vs.\\ global consistency for relations over positive commutative monoids, which is a common generalization of ordinary relations and bags. Let $\\mathbb K$ be an arbitrary positive commutative monoid. We begin by showing that acyclicity of the schema is a necessary condition for the local-to-global consistency property for $\\mathbb K$-relations to hold. Unlike the case of ordinary relations and bags, however, we show that acyclicity is not always sufficient. After this, we characterize the positive commutative monoids for which acyclicity is both necessary and sufficient for the local-to-global consistency property to hold; this characterization involves a combinatorial property of monoids, which we call the \\emph{transportation property}. We then identify several different classes of monoids that possess the transportation property. As our final contribution, we introduce a modified notion of local consistency of $\\mathbb{K}$-relations, which we call \\emph{pairwise consistency up to the free cover}. We prove that, for all positive commutative monoids $\\mathbb{K}$, even those without the transportation property, acyclicity is both necessary and sufficient for every family of $\\mathbb{K}$-relations that is pairwise consistent up to the free cover to be globally consistent.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02023"
  },
  "2312.02021": {
    "title": "VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation",
    "authors": [
      "Christoph H\u00fcmmer",
      "Manuel Schwonberg",
      "Liangwei Zhou",
      "Hu Cao",
      "Alois Knoll",
      "Hanno Gottschalk"
    ],
    "abstract": "Domain generalization (DG) remains a significant challenge for perception based on deep neural networks (DNN), where domain shifts occur due to lighting, weather, or geolocation changes. In this work, we propose VLTSeg to enhance domain generalization in semantic segmentation, where the network is solely trained on the source domain and evaluated on unseen target domains. Our method leverages the inherent semantic robustness of vision-language models. First, by substituting traditional vision-only backbones with pre-trained encoders from CLIP and EVA-CLIP as transfer learning setting we find that in the field of DG, vision-language pre-training significantly outperforms supervised and self-supervised vision pre-training. We thus propose a new vision-language approach for domain generalized segmentation, which improves the domain generalization SOTA by 7.6% mIoU when training on the synthetic GTA5 dataset. We further show the superior generalization capabilities of vision-language segmentation models by reaching 76.48% mIoU on the popular Cityscapes-to-ACDC benchmark, outperforming the previous SOTA approach by 6.9% mIoU on the test set at the time of writing. Additionally, our approach shows strong in-domain generalization capabilities indicated by 86.1% mIoU on the Cityscapes test set, resulting in a shared first place with the previous SOTA on the current leaderboard at the time of submission.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.02021"
  },
  "2312.02019": {
    "title": "Action Inference by Maximising Evidence: Zero-Shot Imitation from Observation with World Models",
    "authors": [
      "Xingyuan Zhang",
      "Philip Becker-Ehmck",
      "Patrick van der Smagt",
      "Maximilian Karl"
    ],
    "abstract": "Unlike most reinforcement learning agents which require an unrealistic amount of environment interactions to learn a new behaviour, humans excel at learning quickly by merely observing and imitating others. This ability highly depends on the fact that humans have a model of their own embodiment that allows them to infer the most likely actions that led to the observed behaviour. In this paper, we propose Action Inference by Maximising Evidence (AIME) to replicate this behaviour using world models. AIME consists of two distinct phases. In the first phase, the agent learns a world model from its past experience to understand its own body by maximising the ELBO. While in the second phase, the agent is given some observation-only demonstrations of an expert performing a novel task and tries to imitate the expert's behaviour. AIME achieves this by defining a policy as an inference model and maximising the evidence of the demonstration under the policy and world model. Our method is \"zero-shot\" in the sense that it does not require further training for the world model or online interactions with the environment after given the demonstration. We empirically validate the zero-shot imitation performance of our method on the Walker and Cheetah embodiment of the DeepMind Control Suite and find it outperforms the state-of-the-art baselines. Code is available at: https://github.com/argmax-ai/aime.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02019"
  },
  "2312.02017": {
    "title": "A multi-channel cycleGAN for CBCT to CT synthesis",
    "authors": [
      "Chelsea A. H. Sargeant",
      "Edward G. A. Henderson",
      "D\u00f3nal M. McSweeney",
      "Aaron G. Rankin",
      "Denis Page"
    ],
    "abstract": "Image synthesis is used to generate synthetic CTs (sCTs) from on-treatment cone-beam CTs (CBCTs) with a view to improving image quality and enabling accurate dose computation to facilitate a CBCT-based adaptive radiotherapy workflow. As this area of research gains momentum, developments in sCT generation methods are difficult to compare due to the lack of large public datasets and sizeable variation in training procedures. To compare and assess the latest advancements in sCT generation, the SynthRAD2023 challenge provides a public dataset and evaluation framework for both MR and CBCT to sCT synthesis. Our contribution focuses on the second task, CBCT-to-sCT synthesis. By leveraging a multi-channel input to emphasize specific image features, our approach effectively addresses some of the challenges inherent in CBCT imaging, whilst restoring the contrast necessary for accurate visualisation of patients' anatomy. Additionally, we introduce an auxiliary fusion network to further enhance the fidelity of generated sCT images.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02017"
  },
  "2312.02012": {
    "title": "Optimal Data Generation in Multi-Dimensional Parameter Spaces, using Bayesian Optimization",
    "authors": [
      "M. R. Mahani",
      "Igor A. Nechepurenko",
      "Yasmin Rahimof",
      "Andreas Wicht"
    ],
    "abstract": "Acquiring a substantial number of data points for training accurate machine learning (ML) models is a big challenge in scientific fields where data collection is resource-intensive. Here, we propose a novel approach for constructing a minimal yet highly informative database for training ML models in complex multi-dimensional parameter spaces. To achieve this, we mimic the underlying relation between the output and input parameters using Gaussian process regression (GPR). Using a set of known data, GPR provides predictive means and standard deviation for the unknown data. Given the predicted standard deviation by GPR, we select data points using Bayesian optimization to obtain an efficient database for training ML models. We compare the performance of ML models trained on databases obtained through this method, with databases obtained using traditional approaches. Our results demonstrate that the ML models trained on the database obtained using Bayesian optimization approach consistently outperform the other two databases, achieving high accuracy with a significantly smaller number of data points. Our work contributes to the resource-efficient collection of data in high-dimensional complex parameter spaces, to achieve high precision machine learning predictions.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02012"
  },
  "2312.02011": {
    "title": "What is the disinformation problem? Reviewing the dominant paradigm and motivating an alternative sociopolitical view",
    "authors": [
      "Nicholas Rabb"
    ],
    "abstract": "Disinformation research has proliferated in reaction to widespread false, problematic beliefs purported to explain major social phenomena. Yet while the effects of disinformation are well-known, there is less consensus about its causes; the research spans several disciplines, each focusing on different pieces. This article contributes to this growing field by reviewing prevalent U.S. disinformation discourse (academic writing, media, and corporate and government narrative) and outlining the dominant understanding, or paradigm, of the disinformation problem by analyzing cross-disciplinary discourse about the content, individual, group, and institutional layers of the problem. The result is an individualistic explanation largely blaming social media, malicious individuals or nations, and irrational people. Yet this understanding has shortcomings: notably, that its limited, individualistic views of truth and rationality obscures the influence of oppressive ideologies and media or domestic actors in creating flawed worldviews and spreading disinformation. The article then concludes by putting forth an alternative, sociopolitical paradigm that allows subjective models of the world to govern rationality and information processing -- largely informed by social and group identity -- which are being formed and catered to by institutional actors (corporations, media, political parties, and the government) to maintain or gain legitimacy for their actions.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.02011"
  },
  "2312.01999": {
    "title": "SRTransGAN: Image Super-Resolution using Transformer based Generative Adversarial Network",
    "authors": [
      "Neeraj Baghel",
      "Shiv Ram Dubey",
      "Satish Kumar Singh"
    ],
    "abstract": "Image super-resolution aims to synthesize high-resolution image from a low-resolution image. It is an active area to overcome the resolution limitations in several applications like low-resolution object-recognition, medical image enhancement, etc. The generative adversarial network (GAN) based methods have been the state-of-the-art for image super-resolution by utilizing the convolutional neural networks (CNNs) based generator and discriminator networks. However, the CNNs are not able to exploit the global information very effectively in contrast to the transformers, which are the recent breakthrough in deep learning by exploiting the self-attention mechanism. Motivated from the success of transformers in language and vision applications, we propose a SRTransGAN for image super-resolution using transformer based GAN. Specifically, we propose a novel transformer-based encoder-decoder network as a generator to generate 2x images and 4x images. We design the discriminator network using vision transformer which uses the image as sequence of patches and hence useful for binary classification between synthesized and real high-resolution images. The proposed SRTransGAN outperforms the existing methods by 4.38 % on an average of PSNR and SSIM scores. We also analyze the saliency map to understand the learning ability of the proposed method.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01999"
  },
  "2312.01994": {
    "title": "A Generative Self-Supervised Framework using Functional Connectivity in fMRI Data",
    "authors": [
      "Jungwon Choi",
      "Seongho Keum",
      "EungGu Yun",
      "Byung-Hoon Kim",
      "Juho Lee"
    ],
    "abstract": "Deep neural networks trained on Functional Connectivity (FC) networks extracted from functional Magnetic Resonance Imaging (fMRI) data have gained popularity due to the increasing availability of data and advances in model architectures, including Graph Neural Network (GNN). Recent research on the application of GNN to FC suggests that exploiting the time-varying properties of the FC could significantly improve the accuracy and interpretability of the model prediction. However, the high cost of acquiring high-quality fMRI data and corresponding phenotypic labels poses a hurdle to their application in real-world settings, such that a model na\u00efvely trained in a supervised fashion can suffer from insufficient performance or a lack of generalization on a small number of data. In addition, most Self-Supervised Learning (SSL) approaches for GNNs to date adopt a contrastive strategy, which tends to lose appropriate semantic information when the graph structure is perturbed or does not leverage both spatial and temporal information simultaneously. In light of these challenges, we propose a generative SSL approach that is tailored to effectively harness spatio-temporal information within dynamic FC. Our empirical results, experimented with large-scale (>50,000) fMRI datasets, demonstrate that our approach learns valuable representations and enables the construction of accurate and robust models when fine-tuned for downstream tasks.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01994"
  },
  "2312.01990": {
    "title": "SARA-RT: Scaling up Robotics Transformers with Self-Adaptive Robust Attention",
    "authors": [
      "Isabel Leal",
      "Krzysztof Choromanski",
      "Deepali Jain",
      "Avinava Dubey",
      "Jake Varley",
      "Michael Ryoo",
      "Yao Lu",
      "Frederick Liu",
      "Vikas Sindhwani",
      "Quan Vuong",
      "Tamas Sarlos",
      "Ken Oslund",
      "Karol Hausman",
      "Kanishka Rao"
    ],
    "abstract": "We present Self-Adaptive Robust Attention for Robotics Transformers (SARA-RT): a new paradigm for addressing the emerging challenge of scaling up Robotics Transformers (RT) for on-robot deployment. SARA-RT relies on the new method of fine-tuning proposed by us, called up-training. It converts pre-trained or already fine-tuned Transformer-based robotic policies of quadratic time complexity (including massive billion-parameter vision-language-action models or VLAs), into their efficient linear-attention counterparts maintaining high quality. We demonstrate the effectiveness of SARA-RT by speeding up: (a) the class of recently introduced RT-2 models, the first VLA robotic policies pre-trained on internet-scale data, as well as (b) Point Cloud Transformer (PCT) robotic policies operating on large point clouds. We complement our results with the rigorous mathematical analysis providing deeper insight into the phenomenon of SARA.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01990"
  },
  "2312.01988": {
    "title": "Geranos: a Novel Tilted-Rotors Aerial Robot for the Transportation of Poles",
    "authors": [
      "Nicolas Gorlo",
      "Samuel Bamert",
      "Rafael Cathomen",
      "Gabriel K\u00e4ppeli",
      "Mario M\u00fcller",
      "Tim Reinhart",
      "Henriette Stadler",
      "Hua Shen",
      "Eugenio Cuniato",
      "Marco Tognon",
      "Roland Siegwart"
    ],
    "abstract": "In challenging terrains, constructing structures such as antennas and cable-car masts often requires the use of helicopters to transport loads via ropes. The swinging of the load, exacerbated by wind, impairs positioning accuracy, therefore necessitating precise manual placement by ground crews. This increases costs and risk of injuries. Challenging this paradigm, we present Geranos: a specialized multirotor Unmanned Aerial Vehicle (UAV) designed to enhance aerial transportation and assembly. Geranos demonstrates exceptional prowess in accurately positioning vertical poles, achieving this through an innovative integration of load transport and precision. Its unique ring design mitigates the impact of high pole inertia, while a lightweight two-part grasping mechanism ensures secure load attachment without active force. With four primary propellers countering gravity and four auxiliary ones enhancing lateral precision, Geranos achieves comprehensive position and attitude control around hovering. Our experimental demonstration mimicking antenna/cable-car mast installations showcases Geranos ability in stacking poles (3 kg, 2 m long) with remarkable sub-5 cm placement accuracy, without the need of human manual intervention.\n        \u25b3 Less",
    "submission_date": "11 January, 2024",
    "eprint_id": "2312.01988"
  },
  "2312.01985": {
    "title": "UniGS: Unified Representation for Image Generation and Segmentation",
    "authors": [
      "Lu Qi",
      "Lehan Yang",
      "Weidong Guo",
      "Yu Xu",
      "Bo Du",
      "Varun Jampani",
      "Ming-Hsuan Yang"
    ],
    "abstract": "This paper introduces a novel unified representation of diffusion models for image generation and segmentation. Specifically, we use a colormap to represent entity-level masks, addressing the challenge of varying entity numbers while aligning the representation closely with the image RGB domain. Two novel modules, including the location-aware color palette and progressive dichotomy module, are proposed to support our mask representation. On the one hand, a location-aware palette guarantees the colors' consistency to entities' locations. On the other hand, the progressive dichotomy module can efficiently decode the synthesized colormap to high-quality entity-level masks in a depth-first binary search without knowing the cluster numbers. To tackle the issue of lacking large-scale segmentation training data, we employ an inpainting pipeline and then improve the flexibility of diffusion models across various tasks, including inpainting, image synthesis, referring segmentation, and entity segmentation. Comprehensive experiments validate the efficiency of our approach, demonstrating comparable segmentation mask quality to state-of-the-art and adaptability to multiple tasks. The code will be released at \\href{https://github.com/qqlu/Entity}{https://github.com/qqlu/Entity}.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01985"
  },
  "2312.01973": {
    "title": "Computing Repairs Under Functional and Inclusion Dependencies via Argumentation",
    "authors": [
      "Yasir Mahmood",
      "Jonni Virtema",
      "Timon Barlag",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "abstract": "We discover a connection between finding subset-maximal repairs for sets of functional and inclusion dependencies, and computing extensions within argumentation frameworks (AFs). We study the complexity of the existence of a repair and deciding whether a given tuple belongs to some (or every) repair, by simulating the instances of these problems via AFs. We prove that subset-maximal repairs under functional dependencies correspond to the naive extensions, which also coincide with the preferred and stable extensions in the resulting AFs. For inclusion dependencies, one needs a pre-processing step on the resulting AFs in order for the extensions to coincide. Allowing both types of dependencies breaks this relationship between extensions, and only preferred semantics captures the repairs. Finally, we establish that the complexities of the above decision problems are NP-complete and Pi_2^P-complete, when both functional and inclusion dependencies are allowed.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01973"
  },
  "2312.01970": {
    "title": "CaRL: Cascade Reinforcement Learning with State Space Splitting for O-RAN based Traffic Steering",
    "authors": [
      "Chuanneng Sun",
      "Yu Zhou",
      "Gueyoung Jung",
      "Tuyen Xuan Tran",
      "Dario Pompili"
    ],
    "abstract": "The Open Radio Access Network (O-RAN) architecture empowers intelligent and automated optimization of the RAN through applications deployed on the RAN Intelligent Controller (RIC) platform, enabling capabilities beyond what is achievable with traditional RAN solutions. Within this paradigm, Traffic Steering (TS) emerges as a pivotal RIC application that focuses on optimizing cell-level mobility settings in near-real-time, aiming to significantly improve network spectral efficiency. In this paper, we design a novel TS algorithm based on a Cascade Reinforcement Learning (CaRL) framework. We propose state space factorization and policy decomposition to reduce the need for large models and well-labeled datasets. For each sub-state space, an RL sub-policy will be trained to learn an optimized mapping onto the action space. To apply CaRL on new network regions, we propose a knowledge transfer approach to initialize a new sub-policy based on knowledge learned by the trained policies. To evaluate CaRL, we build a data-driven and scalable RIC digital twin (DT) that is modeled using important real-world data, including network configuration, user geo-distribution, and traffic demand, among others, from a tier-1 mobile operator in the US. We evaluate CaRL on two DT scenarios representing two network clusters in two different cities and compare its performance with the business-as-usual (BAU) policy and other competing optimization approaches using heuristic and Q-table algorithms. Benchmarking results show that CaRL performs the best and improves the average cluster-aggregated downlink throughput over the BAU policy by 24% and 18% in these two scenarios, respectively.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01970"
  },
  "2312.01968": {
    "title": "Augmenting Channel Charting with Classical Wireless Source Localization Techniques",
    "authors": [
      "Florian Euchner",
      "Phillip Stephan",
      "Stephan ten Brink"
    ],
    "abstract": "Channel Charting aims to construct a map of the radio environment by leveraging similarity relationships found in high-dimensional channel state information. Although resulting channel charts usually accurately represent local neighborhood relationships, even under conditions with strong multipath propagation, they often fall short in capturing global geometric features. On the other hand, classical model-based localization methods, such as triangulation and multilateration, can easily localize signal sources in the global coordinate frame. However, these methods rely heavily on the assumption of line-of-sight channels and distributed antenna deployments. Based on measured data, we compare classical source localization techniques to channel charts with respect to localization performance. We suggest and evaluate methods to enhance Channel Charting with model-based localization approaches: One approach involves using information derived from classical localization methods to map channel chart locations to physical positions after conventional training of the forward charting function. Foremost, though, we suggest to incorporate information from model-based approaches during the training of the forward charting function in what we call \"augmented Channel Charting\". We demonstrate that Channel Charting can outperform classical localization methods on the considered dataset.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01968"
  },
  "2312.01959": {
    "title": "Learning-Based Approaches to Predictive Monitoring with Conformal Statistical Guarantees",
    "authors": [
      "Francesca Cairoli",
      "Luca Bortolussi",
      "Nicola Paoletti"
    ],
    "abstract": "This tutorial focuses on efficient methods to predictive monitoring (PM), the problem of detecting at runtime future violations of a given requirement from the current state of a system. While performing model checking at runtime would offer a precise solution to the PM problem, it is generally computationally expensive. To address this scalability issue, several lightweight approaches based on machine learning have recently been proposed. These approaches work by learning an approximate yet efficient surrogate (deep learning) model of the expensive model checker. A key challenge remains to ensure reliable predictions, especially in safety-critical applications. We review our recent work on predictive monitoring, one of the first to propose learning-based approximations for CPS verification of temporal logic specifications and the first in this context to apply conformal prediction (CP) for rigorous uncertainty quantification. These CP-based uncertainty estimators offer statistical guarantees regarding the generalization error of the learning model, and they can be used to determine unreliable predictions that should be rejected. In this tutorial, we present a general and comprehensive framework summarizing our approach to the predictive monitoring of CPSs, examining in detail several variants determined by three main dimensions: system dynamics (deterministic, non-deterministic, stochastic), state observability, and semantics of requirements' satisfaction (Boolean or quantitative).\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01959"
  },
  "2312.01958": {
    "title": "Mechanical Comparison of Arrangement Strategies for Topological Interlocking Assemblies",
    "authors": [
      "Tom Goertzen",
      "Domen Macek",
      "Lukas Schnelle",
      "Meike Wei\u00df",
      "Stefanie Reese",
      "Hagen Holthusen",
      "Alice C. Niemeyer"
    ],
    "abstract": "Topological Interlocking assemblies are arrangements of blocks kinematically constrained by a fixed frame, such that all rigid body motions of each block are constrained only by its permanent contact with other blocks and the frame. In the literature several blocks are introduced that can be arranged into different interlocking assemblies. In this study we investigate the influence of arrangement on the overall structural behaviour of the resulting interlocking assemblies. This is performed using the Versatile Block, as it can be arranged in three different doubly periodic ways given by wallpaper symmetries. Our focus lies on the load transfer mechanisms from the assembly onto the frame. For fast a priori evaluation of the assemblies we introduce a combinatorial model called Interlocking Flows. To investigate our assemblies from a mechanical point of view we conduct several finite element studies. These reveal a strong influence of arrangement on the structural behaviour, for instance, an impact on both the point and amount of maximum deflection. The results of the finite element analysis are in very good agreement with the predictions of the Interlocking Flow model. Our source code, data and examples are available under https://doi.org/10.5281/zenodo.10246034.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01958"
  },
  "2312.01954": {
    "title": "Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large Language Models",
    "authors": [
      "Andrea Papaluca",
      "Daniel Krefl",
      "Sergio Mendez Rodriguez",
      "Artem Lensky",
      "Hanna Suominen"
    ],
    "abstract": "In this work, we tested the Triplet Extraction (TE) capabilities of a variety of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots settings. In detail, we proposed a pipeline that dynamically gathers contextual information from a Knowledge Base (KB), both in the form of context triplets and of (sentence, triplets) pairs as examples, and provides it to the LLM through a prompt. The additional context allowed the LLMs to be competitive with all the older fully trained baselines based on the Bidirectional Long Short-Term Memory (BiLSTM) Network architecture. We further conducted a detailed analysis of the quality of the gathered KB context, finding it to be strongly correlated with the final TE performance of the model. In contrast, the size of the model appeared to only logarithmically improve the TE capabilities of the LLMs.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01954"
  },
  "2312.01951": {
    "title": "DFTWS for blockchain: Deterministic, Fair and Transparent Winner Selection",
    "authors": [
      "Felix Hoffmann",
      "Udo Kebschull"
    ],
    "abstract": "This publication describes the block winner selection process that will be used in a novel Proof-of-Useful-Work blockchain for High Energy Physics that the authors are currently working on. Instead of spamming hashing operations to mine blocks, miners will be running Monte Carlo simulations to support a real-world HEP experiment with useful data. The block problems will be defined by a Root Authority which is represented by a HEP experiment like CBM. The focus in this publication is a mechanism that allows the Root Authority to select a winner from a list of nodes that solved a block problem. The mechanism is designed so that winner selection is deterministic, fair and transparent. This mechanism allows every node to verify the fairness of the winner selection process without giving the nodes a tool to be able to improve their own winning chances.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01951"
  },
  "2312.01947": {
    "title": "Maximising Quantum-Computing Expressive Power through Randomised Circuits",
    "authors": [
      "Yingli Yang",
      "Zongkang Zhang",
      "Anbang Wang",
      "Xiaosi Xu",
      "Xiaoting Wang",
      "Ying Li"
    ],
    "abstract": "In the noisy intermediate-scale quantum era, variational quantum algorithms (VQAs) have emerged as a promising avenue to obtain quantum advantage. However, the success of VQAs depends on the expressive power of parameterised quantum circuits, which is constrained by the limited gate number and the presence of barren plateaus. In this work, we propose and numerically demonstrate a novel approach for VQAs, utilizing randomised quantum circuits to generate the variational wavefunction. We parameterize the distribution function of these random circuits using artificial neural networks and optimize it to find the solution. This random-circuit approach presents a trade-off between the expressive power of the variational wavefunction and time cost, in terms of the sampling cost of quantum circuits. Given a fixed gate number, we can systematically increase the expressive power by extending the quantum-computing time. With a sufficiently large permissible time cost, the variational wavefunction can approximate any quantum state with arbitrary accuracy. Furthermore, we establish explicit relationships between expressive power, time cost, and gate number for variational quantum eigensolvers. These results highlight the promising potential of the random-circuit approach in achieving a high expressive power in quantum computing.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01947"
  },
  "2312.01943": {
    "title": "Instance-guided Cartoon Editing with a Large-scale Dataset",
    "authors": [
      "Jian Lin",
      "Chengze Li",
      "Xueting Liu",
      "Zhongping Ge"
    ],
    "abstract": "Cartoon editing, appreciated by both professional illustrators and hobbyists, allows extensive creative freedom and the development of original narratives within the cartoon domain. However, the existing literature on cartoon editing is complex and leans heavily on manual operations, owing to the challenge of automatic identification of individual character instances. Therefore, an automated segmentation of these elements becomes imperative to facilitate a variety of cartoon editing applications such as visual style editing, motion decomposition and transfer, and the computation of stereoscopic depths for an enriched visual experience. Unfortunately, most current segmentation methods are designed for natural photographs, failing to recognize from the intricate aesthetics of cartoon subjects, thus lowering segmentation quality. The major challenge stems from two key shortcomings: the rarity of high-quality cartoon dedicated datasets and the absence of competent models for high-resolution instance extraction on cartoons. To address this, we introduce a high-quality dataset of over 100k paired high-resolution cartoon images and their instance labeling masks. We also present an instance-aware image segmentation model that can generate accurate, high-resolution segmentation masks for characters in cartoon images. We present that the proposed approach enables a range of segmentation-dependent cartoon editing applications like 3D Ken Burns parallax effects, text-guided cartoon style editing, and puppet animation from illustrations and manga.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01943"
  },
  "2312.01941": {
    "title": "Intrusion Detection System with Machine Learning and Multiple Datasets",
    "authors": [
      "Haiyan Xuan",
      "Mohith Manohar"
    ],
    "abstract": "As Artificial Intelligence (AI) technologies continue to gain traction in the modern-day world, they ultimately pose an immediate threat to current cybersecurity systems via exploitative methods. Prompt engineering is a relatively new field that explores various prompt designs that can hijack large language models (LLMs). If used by an unethical attacker, it can enable an AI system to offer malicious insights and code to them. In this paper, an enhanced intrusion detection system (IDS) that utilizes machine learning (ML) and hyperparameter tuning is explored, which can improve a model's performance in terms of accuracy and efficacy. Ultimately, this improved system can be used to combat the attacks made by unethical hackers. A standard IDS is solely configured with pre-configured rules and patterns; however, with the utilization of machine learning, implicit and different patterns can be generated through the models' hyperparameter settings and parameters. In addition, the IDS will be equipped with multiple datasets so that the accuracy of the models improves. We evaluate the performance of multiple ML models and their respective hyperparameter settings through various metrics to compare their results to other models and past research work. The results of the proposed multi-dataset integration method yielded an accuracy score of 99.9% when equipped with the XGBoost and random forest classifiers and RandomizedSearchCV hyperparameter technique.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01941"
  },
  "2312.01939": {
    "title": "Foundations for Transfer in Reinforcement Learning: A Taxonomy of Knowledge Modalities",
    "authors": [
      "Markus Wulfmeier",
      "Arunkumar Byravan",
      "Sarah Bechtle",
      "Karol Hausman",
      "Nicolas Heess"
    ],
    "abstract": "Contemporary artificial intelligence systems exhibit rapidly growing abilities accompanied by the growth of required resources, expansive datasets and corresponding investments into computing infrastructure. Although earlier successes predominantly focus on constrained settings, recent strides in fundamental research and applications aspire to create increasingly general systems. This evolving landscape presents a dual panorama of opportunities and challenges in refining the generalisation and transfer of knowledge - the extraction from existing sources and adaptation as a comprehensive foundation for tackling new problems. Within the domain of reinforcement learning (RL), the representation of knowledge manifests through various modalities, including dynamics and reward models, value functions, policies, and the original data. This taxonomy systematically targets these modalities and frames its discussion based on their inherent properties and alignment with different objectives and mechanisms for transfer. Where possible, we aim to provide coarse guidance delineating approaches which address requirements such as limiting environment interactions, maximising computational efficiency, and enhancing generalisation across varying axes of change. Finally, we analyse reasons contributing to the prevalence or scarcity of specific forms of transfer, the inherent potential behind pushing these frontiers, and underscore the significance of transitioning from designed to learned transfer.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01939"
  },
  "2312.01938": {
    "title": "DSText V2: A Comprehensive Video Text Spotting Dataset for Dense and Small Text",
    "authors": [
      "Weijia Wu",
      "Yiming Zhang",
      "Yefei He",
      "Luoming Zhang",
      "Zhenyu Lou",
      "Hong Zhou",
      "Xiang Bai"
    ],
    "abstract": "Recently, video text detection, tracking, and recognition in natural scenes are becoming very popular in the computer vision community. However, most existing algorithms and benchmarks focus on common text cases (e.g., normal size, density) and single scenario, while ignoring extreme video text challenges, i.e., dense and small text in various scenarios. In this paper, we establish a video text reading benchmark, named DSText V2, which focuses on Dense and Small text reading challenges in the video with various scenarios. Compared with the previous datasets, the proposed dataset mainly include three new challenges: 1) Dense video texts, a new challenge for video text spotters to track and read. 2) High-proportioned small texts, coupled with the blurriness and distortion in the video, will bring further challenges. 3) Various new scenarios, e.g., Game, Sports, etc. The proposed DSText V2 includes 140 video clips from 7 open scenarios, supporting three tasks, i.e., video text detection (Task 1), video text tracking (Task 2), and end-to-end video text spotting (Task 3). In this article, we describe detailed statistical information of the dataset, tasks, evaluation protocols, and the results summaries. Most importantly, a thorough investigation and analysis targeting three unique challenges derived from our dataset are provided, aiming to provide new insights. Moreover, we hope the benchmark will promise video text research in the community. DSText v2 is built upon DSText v1, which was previously introduced to organize the ICDAR 2023 competition for dense and small video text.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.01938"
  },
  "2312.01935": {
    "title": "A Note on the 2-Colored Rectilinear Crossing Number of Random Point Sets in the Unit Square",
    "authors": [
      "Sergio Cabello",
      "\u00c9va Czabarka",
      "Ruy Fabila-Monroy",
      "Yuya Higashikawa",
      "Raimund Seidel",
      "L\u00e1szl\u00f3 Sz\u00e9kely",
      "Josef Tkadlec",
      "Alexandra Wesolek"
    ],
    "abstract": "Let $S$ be a set of four points chosen independently, uniformly at random from a square. Join every pair of points of $S$ with a straight line segment. Color these edges red if they have positive slope and blue, otherwise. We show that the probability that $S$ defines a pair of crossing edges of the same color is equal to $1/4$. This is connected to a recent result of Aichholzer et al. [GD 2019] who showed that by 2-colouring the edges of a geometric graph and counting monochromatic crossings instead of crossings, the number of crossings can be more than halfed. Our result shows that for the described random drawings, there is a coloring of the edges such that the number of monochromatic crossings is in expectation $\\frac{1}{2}-\\frac{7}{50}$ of the total number of crossings.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01935"
  },
  "2312.01916": {
    "title": "PEACE: Prototype lEarning Augmented transferable framework for Cross-domain rEcommendation",
    "authors": [
      "Chunjing Gan",
      "Bo Huang",
      "Binbin Hu",
      "Jian Ma",
      "Ziqi Liu",
      "Zhiqiang Zhang",
      "Jun Zhou",
      "Guannan Zhang",
      "Wenliang Zhong"
    ],
    "abstract": "To help merchants/customers to provide/access a variety of services through miniapps, online service platforms have occupied a critical position in the effective content delivery, in which how to recommend items in the new domain launched by the service provider for customers has become more urgent. However, the non-negligible gap between the source and diversified target domains poses a considerable challenge to cross-domain recommendation systems, which often leads to performance bottlenecks in industrial settings. While entity graphs have the potential to serve as a bridge between domains, rudimentary utilization still fail to distill useful knowledge and even induce the negative transfer issue. To this end, we propose PEACE, a Prototype lEarning Augmented transferable framework for Cross-domain rEcommendation. For domain gap bridging, PEACE is built upon a multi-interest and entity-oriented pre-training architecture which could not only benefit the learning of generalized knowledge in a multi-granularity manner, but also help leverage more structural information in the entity graph. Then, we bring the prototype learning into the pre-training over source domains, so that representations of users and items are greatly improved by the contrastive prototype learning module and the prototype enhanced attention mechanism for adaptive knowledge utilization. To ease the pressure of online serving, PEACE is carefully deployed in a lightweight manner, and significant performance improvements are observed in both online and offline environments.\n        \u25b3 Less",
    "submission_date": "17 December, 2023",
    "eprint_id": "2312.01916"
  },
  "2312.01915": {
    "title": "A Reliable Representation with Bidirectional Transition Model for Visual Reinforcement Learning Generalization",
    "authors": [
      "Xiaobo Hu",
      "Youfang Lin",
      "Yue Liu",
      "Jinwen Wang",
      "Shuo Wang",
      "Hehe Fan",
      "Kai Lv"
    ],
    "abstract": "Visual reinforcement learning has proven effective in solving control tasks with high-dimensional observations. However, extracting reliable and generalizable representations from vision-based observations remains a central challenge. Inspired by the human thought process, when the representation extracted from the observation can predict the future and trace history, the representation is reliable and accurate in comprehending the environment. Based on this concept, we introduce a Bidirectional Transition (BiT) model, which leverages the ability to bidirectionally predict environmental transitions both forward and backward to extract reliable representations. Our model demonstrates competitive generalization performance and sample efficiency on two settings of the DeepMind Control suite. Additionally, we utilize robotic manipulation and CARLA simulators to demonstrate the wide applicability of our method.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01915"
  },
  "2312.01912": {
    "title": "Resource Leak Checker (RLC#) for C# Code using CodeQL",
    "authors": [
      "Pritam Gharat",
      "Narges Shadab",
      "Shrey Tiwari",
      "Shuvendu Lahiri",
      "Akash Lal"
    ],
    "abstract": "Resource leaks occur when a program fails to release a finite resource after it is no longer needed. These leaks are a significant cause of real-world crashes and performance issues. Given their critical impact on software performance and security, detecting and preventing resource leaks is a crucial problem.\n  Recent research has proposed a specify-and-check approach to prevent resource leaks. In this approach, programmers write resource management specifications that guide how resources are stored, passed around, and released within an application. We have developed a tool called RLC#, for detecting resource leaks in C# code. Inspired by the Resource Leak Checker (RLC) from the Checker Framework, RLC# employs CodeQL for intraprocedural data flow analysis. The tool operates in a modular fashion and relies on resource management specifications integrated at method boundaries for interprocedural analysis.\n  In practice, RLC# has successfully identified 24 resource leaks in open-source projects and internal proprietary Azure microservices. Its implementation is declarative, and it scales well. While it incurs a reasonable false positive rate, the burden on developers is minimal, involving the addition of specifications to the source code.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01912"
  },
  "2312.01907": {
    "title": "Model Predictive Control Approach to Autonomous Formation Flight",
    "authors": [
      "Harun Celik",
      "Dilara Kilinc"
    ],
    "abstract": "Formation flight is when multiple objects fly together in a coordination. Various automatic control methods have been used for the autonomous execution of formation flight of aerial vehicles. In this paper, the capacity of the model predictive control (MPC) approach in the autonomous execution of formation flight is examined. The MPC is a controller that capable of performing formation flight, maintaining tracking desired trajectory while avoiding collisions between aerial vehicles, and obstacles faced. Through this approach, aerial vehicle models with six degrees of freedom in a three-dimensional environment are performed formation flight autonomously, mostly in a triangle order. Not only the trajectory for the formation flight can be tracked through the MPC architecture, also the collision avoidance strategies of the aerial vehicles can be performed by this architecture. Simulation studies show that MPC has sufficient capability in both cases. Therefore, it is concluded that this method can deal with constraints, avoid obstacles as well as collisions between aerial vehicles. However, implementation of MPC to aerial vehicles in real time holds challenges.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01907"
  },
  "2312.01904": {
    "title": "Unsupervised Anomaly Detection using Aggregated Normative Diffusion",
    "authors": [
      "Alexander Frotscher",
      "Jaivardhan Kapoor",
      "Thomas Wolfers",
      "Christian F. Baumgartner"
    ],
    "abstract": "Early detection of anomalies in medical images such as brain MRI is highly relevant for diagnosis and treatment of many conditions. Supervised machine learning methods are limited to a small number of pathologies where there is good availability of labeled data. In contrast, unsupervised anomaly detection (UAD) has the potential to identify a broader spectrum of anomalies by spotting deviations from normal patterns. Our research demonstrates that existing state-of-the-art UAD approaches do not generalise well to diverse types of anomalies in realistic multi-modal MR data. To overcome this, we introduce a new UAD method named Aggregated Normative Diffusion (ANDi). ANDi operates by aggregating differences between predicted denoising steps and ground truth backwards transitions in Denoising Diffusion Probabilistic Models (DDPMs) that have been trained on pyramidal Gaussian noise. We validate ANDi against three recent UAD baselines, and across three diverse brain MRI datasets. We show that ANDi, in some cases, substantially surpasses these baselines and shows increased robustness to varying types of anomalies. Particularly in detecting multiple sclerosis (MS) lesions, ANDi achieves improvements of up to 178% in terms of AUPRC.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01904"
  },
  "2312.01898": {
    "title": "Unlocking optimal batch size schedules using continuous-time control and perturbation theory",
    "authors": [
      "Stefan Perko"
    ],
    "abstract": "Stochastic Gradient Descent (SGD) and its variants are almost universally used to train neural networks and to fit a variety of other parametric models. An important hyperparameter in this context is the batch size, which determines how many samples are processed before an update of the parameters occurs. Previous studies have demonstrated the benefits of using variable batch sizes. In this work, we will theoretically derive optimal batch size schedules for SGD and similar algorithms, up to an error that is quadratic in the learning rate. To achieve this, we approximate the discrete process of parameter updates using a family of stochastic differential equations indexed by the learning rate. To better handle the state-dependent diffusion coefficient, we further expand the solution of this family into a series with respect to the learning rate. Using this setup, we derive a continuous-time optimal batch size schedule for a large family of diffusion coefficients and then apply the results in the setting of linear regression.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01898"
  },
  "2312.01896": {
    "title": "A Linear-time Simulation of Deterministic $d$-Limited Automata",
    "authors": [
      "Alexander Rubtsov"
    ],
    "abstract": "A $d$-limited automaton is a Turing machine that uses only the cells with the input word (and end-markers) and rewrites symbols only in the first $d$ visits. This model was introduced by T. Hibbard in 1967 and he showed that $d$-limited automata recognize context-free languages for each $d \\geq 2$. He also proved that languages recognizable by deterministic $d$-limited automata form a hierarchy and it was shown later by Pighizzini and Pisoni that it begins with deterministic context-free languages (DCFLs) (for $d=2$).\n  As well-known, DCFLs are widely used in practice, especially in compilers since they are linear-time recognizable and have the corresponding CF-grammars subclass (LR$(1)$-grammars). In this paper we present a linear time recognition algorithm for deterministic $d$-limited automata (in the RAM model) which opens an opportunity for their possible practical applications. We also generalize this algorithm to deterministic $d(n)$-limited automata: the extension of deterministic $d$-limited automata, where $d$ is not a constant, but a function depending on the input length $n$.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01896"
  },
  "2312.01895": {
    "title": "An In-Depth Survey on Virtualization Technologies in 6G Integrated Terrestrial and Non-Terrestrial Networks",
    "authors": [
      "Sahar Ammar",
      "Chun Pong Lau",
      "Basem Shihada"
    ],
    "abstract": "6G networks are envisioned to deliver a large diversity of applications and meet stringent quality of service (QoS) requirements. Hence, integrated terrestrial and non-terrestrial networks (TN-NTNs) are anticipated to be key enabling technologies. However, the TN-NTNs integration faces a number of challenges that could be addressed through network virtualization technologies such as Software-Defined Networking (SDN), Network Function Virtualization (NFV) and network slicing. In this survey, we provide a comprehensive review on the adaptation of these networking paradigms in 6G networks. We begin with a brief overview on NTNs and virtualization techniques. Then, we highlight the integral role of Artificial Intelligence in improving network virtualization by summarizing major research areas where AI models are applied. Building on this foundation, the survey identifies the main issues arising from the adaptation of SDN, NFV, and network slicing in integrated TN-NTNs, and proposes a taxonomy of integrated TN-NTNs virtualization offering a thorough review of relevant contributions. The taxonomy is built on a four-level classification indicating for each study the level of TN-NTNs integration, the used virtualization technology, the addressed problem, the type of the study and the proposed solution, which can be based on conventional or AI-enabled methods. Moreover, we present a summary on the simulation tools commonly used in the testing and validation of such networks. Finally, we discuss open issues and give insights on future research directions for the advancement of integrated TN-NTNs virtualization in the 6G era.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01895"
  },
  "2312.01887": {
    "title": "Non-Intrusive Load Monitoring for Feeder-Level EV Charging Detection: Sliding Window-based Approaches to Offline and Online Detection",
    "authors": [
      "Cameron Martin",
      "Fucai Ke",
      "Hao Wang"
    ],
    "abstract": "Understanding electric vehicle (EV) charging on the distribution network is key to effective EV charging management and aiding decarbonization across the energy and transport sectors. Advanced metering infrastructure has allowed distribution system operators and utility companies to collect high-resolution load data from their networks. These advancements enable the non-intrusive load monitoring (NILM) technique to detect EV charging using load measurement data. While existing studies primarily focused on NILM for EV charging detection in individual households, there is a research gap on EV charging detection at the feeder level, presenting unique challenges due to the combined load measurement from multiple households. In this paper, we develop a novel and effective approach for EV detection at the feeder level, involving sliding-window feature extraction and classical machine learning techniques, specifically models like XGBoost and Random Forest. Our developed method offers a lightweight and efficient solution, capable of quick training. Moreover, our developed method is versatile, supporting both offline and online EV charging detection. Our experimental results demonstrate high-accuracy EV charging detection at the feeder level, achieving an F-Score of 98.88% in offline detection and 93.01% in online detection.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01887"
  },
  "2312.01884": {
    "title": "Correlation and Unintended Biases on Univariate and Multivariate Decision Trees",
    "authors": [
      "Mattia Setzu",
      "Salvatore Ruggieri"
    ],
    "abstract": "Decision Trees are accessible, interpretable, and well-performing classification models. A plethora of variants with increasing expressiveness has been proposed in the last forty years. We contrast the two families of univariate DTs, whose split functions partition data through axis-parallel hyperplanes, and multivariate DTs, whose splits instead partition data through oblique hyperplanes. The latter include the former, hence multivariate DTs are in principle more powerful. Surprisingly enough, however, univariate DTs consistently show comparable performances in the literature. We analyze the reasons behind this, both with synthetic and real-world benchmark datasets. Our research questions test whether the pre-processing phase of removing correlation among features in datasets has an impact on the relative performances of univariate vs multivariate DTs. We find that existing benchmark datasets are likely biased towards favoring univariate DTs.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01884"
  },
  "2312.01882": {
    "title": "Unleashing the Potential of Large Language Model: Zero-shot VQA for Flood Disaster Scenario",
    "authors": [
      "Yimin Sun",
      "Chao Wang",
      "Yan Peng"
    ],
    "abstract": "Visual question answering (VQA) is a fundamental and essential AI task, and VQA-based disaster scenario understanding is a hot research topic. For instance, we can ask questions about a disaster image by the VQA model and the answer can help identify whether anyone or anything is affected by the disaster. However, previous VQA models for disaster damage assessment have some shortcomings, such as limited candidate answer space, monotonous question types, and limited answering capability of existing models. In this paper, we propose a zero-shot VQA model named Zero-shot VQA for Flood Disaster Damage Assessment (ZFDDA). It is a VQA model for damage assessment without pre-training. Also, with flood disaster as the main research object, we build a Freestyle Flood Disaster Image Question Answering dataset (FFD-IQA) to evaluate our VQA model. This new dataset expands the question types to include free-form, multiple-choice, and yes-no questions. At the same time, we expand the size of the previous dataset to contain a total of 2,058 images and 22,422 question-meta ground truth pairs. Most importantly, our model uses well-designed chain of thought (CoT) demonstrations to unlock the potential of the large language model, allowing zero-shot VQA to show better performance in disaster scenarios. The experimental results show that the accuracy in answering complex questions is greatly improved with CoT prompts. Our study provides a research basis for subsequent research of VQA for other disaster scenarios.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01882"
  },
  "2312.01880": {
    "title": "Testing popularity in linear time via maximum matching",
    "authors": [
      "Erika B\u00e9rczi-Kov\u00e1cs",
      "Kata Kosztol\u00e1nyi"
    ],
    "abstract": "Popularity is an approach in mechanism design to find fair structures in a graph, based on the votes of the nodes. Popular matchings are the relaxation of stable matchings: given a graph G=(V,E) with strict preferences on the neighbors of the nodes, a matching M is popular if there is no other matching M' such that the number of nodes preferring M' is more than those preferring M. This paper considers the popularity testing problem, when the task is to decide whether a given matching is popular or not. Previous algorithms applied reductions to maximum weight matchings. We give a new algorithm for testing popularity by reducing the problem to maximum matching testing, thus attaining a linear running time O(|E|).\n  Linear programming-based characterization of popularity is often applied for proving the popularity of a certain matching. As a consequence of our algorithm we derive a more structured dual witness than previous ones. Based on this result we give a combinatorial characterization of fractional popular matchings, which are a special class of popular matchings.\n        \u25b3 Less",
    "submission_date": "28 December, 2023",
    "eprint_id": "2312.01880"
  },
  "2312.01874": {
    "title": "Fair Division via Quantile Shares",
    "authors": [
      "Yakov Babichenko",
      "Michal Feldman",
      "Ron Holzman",
      "Vishnu V. Narayan"
    ],
    "abstract": "We consider the problem of fair division, where a set of indivisible goods should be distributed fairly among a set of agents with combinatorial valuations. To capture fairness, we adopt the notion of shares, where each agent is entitled to a fair share, based on some fairness criterion, and an allocation is considered fair if the value of every agent (weakly) exceeds her fair share. A share-based notion is considered universally feasible if it admits a fair allocation for every profile of monotone valuations. A major question arises: is there a non-trivial share-based notion that is universally feasible? The most well-known share-based notions, namely proportionality and maximin share, are not universally feasible, nor are any constant approximations of them.\n  We propose a novel share notion, where an agent assesses the fairness of a bundle by comparing it to her valuation in a random allocation. In this framework, a bundle is considered $q$-quantile fair, for $q\\in[0,1]$, if it is at least as good as a bundle obtained in a uniformly random allocation with probability at least $q$. Our main question is whether there exists a constant value of $q$ for which the $q$-quantile share is universally feasible.\n  Our main result establishes a strong connection between the feasibility of quantile shares and the classical Erd\u0151s Matching Conjecture. Specifically, we show that if a version of this conjecture is true, then the $\\frac{1}{2e}$-quantile share is universally feasible. Furthermore, we provide unconditional feasibility results for additive, unit-demand and matroid-rank valuations for constant values of $q$. Finally, we discuss the implications of our results for other share notions.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01874"
  },
  "2312.01872": {
    "title": "The CURE To Vulnerabilities in RPKI Validation",
    "authors": [
      "Donika Mirdita",
      "Haya Schulmann",
      "Niklas Vogel",
      "Michael Waidner"
    ],
    "abstract": "Over recent years, the Resource Public Key Infrastructure (RPKI) has seen increasing adoption, with now 37.8% of the major networks filtering bogus BGP routes. Systems interact with the RPKI over Relying Party (RP) implementations that fetch RPKI objects and feed BGP routers with the validated prefix-ownership data. Consequently, any vulnerabilities or flaws within the RP software can substantially threaten the stability and security of Internet routing. We uncover severe flaws in all popular RP implementations, making them susceptible to path traversal attacks, remotely triggered crashes, and inherent inconsistencies, violating RPKI standards. We report a total of 18 vulnerabilities that canbe exploited to downgrade RPKI validation in border routers or, worse, enable poisoning of the validation process, resulting in malicious prefixes being wrongfully validated and legitimate RPKI-covered prefixes failing validation. Furthermore, our research discloses inconsistencies in the validation process, with two popular implementations leaving 8149 prefixes unprotected from hijacks, 6405 of which belong to Amazon. While these findings are significant in their own right, our principal contribution lies in developing CURE, the first-of-its-kind system to systematically detect bugs, vulnerabilities, and RFC compliance issues in RP implementations via automated test generation. CURE is a powerful RPKI publication point emulator that enables easy and efficient fuzzing of complex RP validation pipelines. It is designed with a set of novel techniques, utilizing differential and stateful fuzzing. We generated over 600 million test cases and tested all popular RPs on them. Following our disclosure, the vendors already assigned CVEs to the vulnerabilities we found.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01872"
  },
  "2312.01871": {
    "title": "FeaInfNet: Diagnosis in Medical Image with Feature-Driven Inference and Visual Explanations",
    "authors": [
      "Yitao Peng",
      "Lianghua He",
      "Die Hu",
      "Yihang Liu",
      "Longzhen Yang",
      "Shaohua Shang"
    ],
    "abstract": "Interpretable deep learning models have received widespread attention in the field of image recognition. Due to the unique multi-instance learning of medical images and the difficulty in identifying decision-making regions, many interpretability models that have been proposed still have problems of insufficient accuracy and interpretability in medical image disease diagnosis. To solve these problems, we propose feature-driven inference network (FeaInfNet). Our first key innovation involves proposing a feature-based network reasoning structure, which is applied to FeaInfNet. The network of this structure compares the similarity of each sub-region image patch with the disease templates and normal templates that may appear in the region, and finally combines the comparison of each sub-region to make the final diagnosis. It simulates the diagnosis process of doctors to make the model interpretable in the reasoning process, while avoiding the misleading caused by the participation of normal areas in reasoning. Secondly, we propose local feature masks (LFM) to extract feature vectors in order to provide global information for these vectors, thus enhancing the expressive ability of the FeaInfNet. Finally, we propose adaptive dynamic masks (Adaptive-DM) to interpret feature vectors and prototypes into human-understandable image patches to provide accurate visual interpretation. We conducted qualitative and quantitative experiments on multiple publicly available medical datasets, including RSNA, iChallenge-PM, Covid-19, ChinaCXRSet, and MontgomerySet. The results of our experiments validate that our method achieves state-of-the-art performance in terms of classification accuracy and interpretability compared to baseline methods in medical image diagnosis. Additional ablation studies verify the effectiveness of each of our proposed components.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01871"
  },
  "2312.01869": {
    "title": "TCP Slice: A semi-distributed TCP algorithm for Delay-constrained Applications",
    "authors": [
      "Dibbendu Roy",
      "Goutam Das"
    ],
    "abstract": "The TCP congestion control protocol serves as the cornerstone of reliable internet communication. However, as new applications require more specific guarantees regarding data rate and delay, network management must adapt. Thus, service providers are shifting from decentralized to centralized control of the network using a software-defined network controller (SDN). The SDN classifies applications and allocates logically separate resources called slices, over the physical network. We propose TCP Slice, a congestion control algorithm that meets specific delay and bandwidth guarantees. Obtaining closed-form delay bounds for a client is challenging due to dependencies on other clients and their traffic stochasticity. We use network calculus to derive the client's delay bound and incorporate it as a constraint in the Network Utility Maximization problem. We solve the resulting optimization using dual decomposition and obtain a semi-distributed TCP protocol that can be implemented with the help of SDN controller and the use of an Explicit Congestion Notification (ECN) bit. Additionally, we also propose a proactive approach for congestion control using digital twin. TCP Slice represents a significant step towards accommodating evolving internet traffic patterns and the need for better network management in the face of increasing application diversity.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01869"
  },
  "2312.01860": {
    "title": "Unveiling Objects with SOLA: An Annotation-Free Image Search on the Object Level for Automotive Data Sets",
    "authors": [
      "Philipp Rigoll",
      "Jacob Langner",
      "Eric Sax"
    ],
    "abstract": "Huge image data sets are the fundament for the development of the perception of automated driving systems. A large number of images is necessary to train robust neural networks that can cope with diverse situations. A sufficiently large data set contains challenging situations and objects. For testing the resulting functions, it is necessary that these situations and objects can be found and extracted from the data set. While it is relatively easy to record a large amount of unlabeled data, it is far more difficult to find demanding situations and objects. However, during the development of perception systems, it must be possible to access challenging data without having to perform lengthy and time-consuming annotations. A developer must therefore be able to search dynamically for specific situations and objects in a data set. Thus, we designed a method which is based on state-of-the-art neural networks to search for objects with certain properties within an image. For the ease of use, the query of this search is described using natural language. To determine the time savings and performance gains, we evaluated our method qualitatively and quantitatively on automotive data sets.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.01860"
  },
  "2312.01858": {
    "title": "Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness",
    "authors": [
      "Zichao Li",
      "Ines Arous",
      "Siva Reddy",
      "Jackie C. K. Cheung"
    ],
    "abstract": "The potential of using a large language model (LLM) as a knowledge base (KB) has sparked significant interest. To manage the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge. Existing work on editing LLMs has partially addressed the issue of dependency, when the editing of a fact should apply to its lexical variations without disrupting irrelevant ones. However, they neglect the dependency between a fact and its logical implications. We propose an evaluation protocol with an accompanying question-answering dataset, DepEdit, that provides a comprehensive assessment of the editing process considering the above notions of dependency. Our protocol involves setting up a controlled environment in which we edit facts and monitor their impact on LLMs, along with their implications based on If-Then rules. Extensive experiments on DepEdit show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01858"
  },
  "2312.01857": {
    "title": "The Intractability of the Picker Routing Problem",
    "authors": [
      "Thibault Prunet",
      "Nabil Absi",
      "Diego Cattaruzza"
    ],
    "abstract": "The Picker Routing Problem (PRP), which consists in finding a minimum-length tour between a set of storage locations in a warehouse, is one of the most important problems in the warehousing logistics literature. Despite its popularity, the tractability of the PRP in conventional multi-block warehouses remains an open question. This technical note aims to fill this research gap by establishing that the PRP is strongly NP-hard.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01857"
  },
  "2312.01850": {
    "title": "Generalization by Adaptation: Diffusion-Based Domain Extension for Domain-Generalized Semantic Segmentation",
    "authors": [
      "Joshua Niemeijer",
      "Manuel Schwonberg",
      "Jan-Aike Term\u00f6hlen",
      "Nico M. Schmidt",
      "Tim Fingscheidt"
    ],
    "abstract": "When models, e.g., for semantic segmentation, are applied to images that are vastly different from training data, the performance will drop significantly. Domain adaptation methods try to overcome this issue, but need samples from the target domain. However, this might not always be feasible for various reasons and therefore domain generalization methods are useful as they do not require any target data. We present a new diffusion-based domain extension (DIDEX) method and employ a diffusion model to generate a pseudo-target domain with diverse text prompts. In contrast to existing methods, this allows to control the style and content of the generated images and to introduce a high diversity. In a second step, we train a generalizing model by adapting towards this pseudo-target domain. We outperform previous approaches by a large margin across various datasets and architectures without using any real data. For the generalization from GTA5, we improve state-of-the-art mIoU performance by 3.8% absolute on average and for SYNTHIA by 11.8% absolute, marking a big step for the generalization performance on these benchmarks. Code is available at https://github.com/JNiemeijer/DIDEX\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01850"
  },
  "2312.01842": {
    "title": "Exploring the Viability of Synthetic Audio Data for Audio-Based Dialogue State Tracking",
    "authors": [
      "Jihyun Lee",
      "Yejin Jeon",
      "Wonjun Lee",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "Dialogue state tracking plays a crucial role in extracting information in task-oriented dialogue systems. However, preceding research are limited to textual modalities, primarily due to the shortage of authentic human audio datasets. We address this by investigating synthetic audio data for audio-based DST. To this end, we develop cascading and end-to-end models, train them with our synthetic audio dataset, and test them on actual human speech data. To facilitate evaluation tailored to audio modalities, we introduce a novel PhonemeF1 to capture pronunciation similarity. Experimental results showed that models trained solely on synthetic datasets can generalize their performance to human voice data. By eliminating the dependency on human speech data collection, these insights pave the way for significant practical advancements in audio-based DST. Data and code are available at https://github.com/JihyunLee1/E2E-DST.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01842"
  },
  "2312.01841": {
    "title": "VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior",
    "authors": [
      "Xusen Sun",
      "Longhao Zhang",
      "Hao Zhu",
      "Peng Zhang",
      "Bang Zhang",
      "Xinya Ji",
      "Kangneng Zhou",
      "Daiheng Gao",
      "Liefeng Bo",
      "Xun Cao"
    ],
    "abstract": "Audio-driven talking head generation has drawn much attention in recent years, and many efforts have been made in lip-sync, expressive facial expressions, natural head pose generation, and high video quality. However, no model has yet led or tied on all these metrics due to the one-to-many mapping between audio and motion. In this paper, we propose VividTalk, a two-stage generic framework that supports generating high-visual quality talking head videos with all the above properties. Specifically, in the first stage, we map the audio to mesh by learning two motions, including non-rigid expression motion and rigid head motion. For expression motion, both blendshape and vertex are adopted as the intermediate representation to maximize the representation ability of the model. For natural head motion, a novel learnable head pose codebook with a two-phase training mechanism is proposed. In the second stage, we proposed a dual branch motion-vae and a generator to transform the meshes into dense motion and synthesize high-quality video frame-by-frame. Extensive experiments show that the proposed VividTalk can generate high-visual quality talking head videos with lip-sync and realistic enhanced by a large margin, and outperforms previous state-of-the-art works in objective and subjective comparisons.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.01841"
  },
  "2312.01840": {
    "title": "An AI-based solution for the cold start and data sparsity problems in the recommendation systems",
    "authors": [
      "Shahriar Shakir Sumit"
    ],
    "abstract": "In recent years, the amount of data available on the internet and the number of users who utilize the Internet have increased at an unparalleled pace. The exponential development in the quantity of digital information accessible and the number of Internet users has created the possibility for information overload, impeding fast access to items of interest on the Internet. Information retrieval systems like as Google, DevilFinder, and Altavista have partly overcome this challenge, but prioritizing and customization of information (where a system maps accessible material to a user's interests and preferences) were lacking. This has resulted in a higher-than-ever need for recommender systems. Recommender systems are information filtering systems that address the issue of information overload by filtering important information fragments from a huge volume of dynamically produced data based on the user's interests, favorite things, preferences and ratings on the desired item. Recommender systems can figure out if a person would like an item or not based on their profile.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2312.01840"
  },
  "2312.01837": {
    "title": "Prompting Disentangled Embeddings for Knowledge Graph Completion with Pre-trained Language Model",
    "authors": [
      "Yuxia Geng",
      "Jiaoyan Chen",
      "Yuhang Zeng",
      "Zhuo Chen",
      "Wen Zhang",
      "Jeff Z. Pan",
      "Yuxiang Wang",
      "Xiaoliang Xu"
    ],
    "abstract": "Both graph structures and textual information play a critical role in Knowledge Graph Completion (KGC). With the success of Pre-trained Language Models (PLMs) such as BERT, they have been applied for text encoding for KGC. However, the current methods mostly prefer to fine-tune PLMs, leading to huge training costs and limited scalability to larger PLMs. In contrast, we propose to utilize prompts and perform KGC on a frozen PLM with only the prompts trained. Accordingly, we propose a new KGC method named PDKGC with two prompts -- a hard task prompt which is to adapt the KGC task to the PLM pre-training task of token prediction, and a disentangled structure prompt which learns disentangled graph representation so as to enable the PLM to combine more relevant structure knowledge with the text information. With the two prompts, PDKGC builds a textual predictor and a structural predictor, respectively, and their combination leads to more comprehensive entity prediction. Solid evaluation on two widely used KGC datasets has shown that PDKGC often outperforms the baselines including the state-of-the-art, and its components are all effective. Our codes and data are available at https://github.com/genggengcss/PDKGC.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01837"
  },
  "2312.01836": {
    "title": "Integrated Drill Boom Hole-Seeking Control via Reinforcement Learning",
    "authors": [
      "Haoqi Yan",
      "Haoyuan Xu",
      "Hongbo Gao",
      "Fei Ma",
      "Shengbo Eben Li",
      "Jingliang Duan"
    ],
    "abstract": "Intelligent drill boom hole-seeking is a promising technology for enhancing drilling efficiency, mitigating potential safety hazards, and relieving human operators. Most existing intelligent drill boom control methods rely on a hierarchical control framework based on inverse kinematics. However, these methods are generally time-consuming due to the computational complexity of inverse kinematics and the inefficiency of the sequential execution of multiple joints. To tackle these challenges, this study proposes an integrated drill boom control method based on Reinforcement Learning (RL). We develop an integrated drill boom control framework that utilizes a parameterized policy to directly generate control inputs for all joints at each time step, taking advantage of joint posture and target hole information. By formulating the hole-seeking task as a Markov decision process, contemporary mainstream RL algorithms can be directly employed to learn a hole-seeking policy, thus eliminating the need for inverse kinematics solutions and promoting cooperative multi-joint control. To enhance the drilling accuracy throughout the entire drilling process, we devise a state representation that combines Denavit-Hartenberg joint information and preview hole-seeking discrepancy data. Simulation results show that the proposed method significantly outperforms traditional methods in terms of hole-seeking accuracy and time efficiency.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01836"
  },
  "2312.01835": {
    "title": "Few Clicks Suffice: Active Test-Time Adaptation for Semantic Segmentation",
    "authors": [
      "Longhui Yuan",
      "Shuang Li",
      "Zhuo He",
      "Binhui Xie"
    ],
    "abstract": "Test-time adaptation (TTA) adapts the pre-trained models during inference using unlabeled test data and has received a lot of research attention due to its potential practical value. Unfortunately, without any label supervision, existing TTA methods rely heavily on heuristic or empirical studies. Where to update the model always falls into suboptimal or brings more computational resource consumption. Meanwhile, there is still a significant performance gap between the TTA approaches and their supervised counterparts. Motivated by active learning, in this work, we propose the active test-time adaptation for semantic segmentation setup. Specifically, we introduce the human-in-the-loop pattern during the testing phase, which queries very few labels to facilitate predictions and model updates in an online manner. To do so, we propose a simple but effective ATASeg framework, which consists of two parts, i.e., model adapter and label annotator. Extensive experiments demonstrate that ATASeg bridges the performance gap between TTA methods and their supervised counterparts with only extremely few annotations, even one click for labeling surpasses known SOTA TTA methods by 2.6% average mIoU on ACDC benchmark. Empirical results imply that progress in either the model adapter or the label annotator will bring improvements to the ATASeg framework, giving it large research and reality potential.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01835"
  },
  "2312.01832": {
    "title": "SPECRUN: The Danger of Speculative Runahead Execution in Processors",
    "authors": [
      "Chaoqun Shen",
      "Gang Qu",
      "Jiliang Zhang"
    ],
    "abstract": "Runahead execution is a continuously evolving microarchitectural technique for processor performance. This paper introduces the first transient execution attack on the runahead execution, called SPECRUN, which exploits the unresolved branch prediction during runahead execution. We show that SPECRUN eliminates the limitation on the number of transient instructions posed by the reorder buffer size, enhancing the exploitability and harmfulness of the attack. We concretely demonstrate a proof-of-concept attack that causes leaking secrets from a victim process, validate the merit of SPECRUN, and design a secure runahead execution scheme. This paper highlights the need to consider the security of potential optimization techniques before implementing them in a processor.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01832"
  },
  "2312.01826": {
    "title": "Terrain-based Coverage Manifold Estimation: Machine Learning, Stochastic Geometry, or Simulation?",
    "authors": [
      "Ruibo Wang",
      "Washim Uddin Mondal",
      "Mustafa A. Kishk",
      "Vaneet Aggarwal",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "Given the necessity of connecting the unconnected, covering blind spots has emerged as a critical task in the next-generation wireless communication network. A direct solution involves obtaining a coverage manifold that visually showcases network coverage performance at each position. Our goal is to devise different methods that minimize the absolute error between the estimated coverage manifold and the actual coverage manifold (referred to as accuracy), while simultaneously maximizing the reduction in computational complexity (measured by computational latency). Simulation is a common method for acquiring coverage manifolds. Although accurate, it is computationally expensive, making it challenging to extend to large-scale networks. In this paper, we expedite traditional simulation methods by introducing a statistical model termed line-of-sight probability-based accelerated simulation. Stochastic geometry is suitable for evaluating the performance of large-scale networks, albeit in a coarse-grained manner. Therefore, we propose a second method wherein a model training approach is applied to the stochastic geometry framework to enhance accuracy and reduce complexity. Additionally, we propose a machine learning-based method that ensures both low complexity and high accuracy, albeit with a significant demand for the size and quality of the dataset. Furthermore, we describe the relationships between these three methods, compare their complexity and accuracy as performance verification, and discuss their application scenarios.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.01826"
  },
  "2312.01823": {
    "title": "Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication",
    "authors": [
      "Zhangyue Yin",
      "Qiushi Sun",
      "Cheng Chang",
      "Qipeng Guo",
      "Junqi Dai",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "abstract": "Large Language Models (LLMs) have recently made significant strides in complex reasoning tasks through the Chain-of-Thought technique. Despite this progress, their reasoning is often constrained by their intrinsic understanding, lacking external insights. To address this, we propose Exchange-of-Thought (EoT), a novel framework that enables cross-model communication during problem-solving. Drawing inspiration from network topology, EoT integrates four unique communication paradigms: Memory, Report, Relay, and Debate. This paper delves into the communication dynamics and volume associated with each paradigm. To counterbalance the risks of incorrect reasoning chains, we implement a robust confidence evaluation mechanism within these communications. Our experiments across diverse complex reasoning tasks demonstrate that EoT significantly surpasses established baselines, underscoring the value of external insights in enhancing LLM performance. Furthermore, we show that EoT achieves these superior results in a cost-effective manner, marking a promising advancement for efficient and collaborative AI problem-solving.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01823"
  },
  "2312.01819": {
    "title": "On the Completely Monotone Conjecture for R\u00e9nyi Entropy",
    "authors": [
      "Hao Wu",
      "Lei Yu",
      "Laigang Guo"
    ],
    "abstract": "In this paper, we generalize the completely monotone conjecture from Shannon entropy to the R\u00e9nyi entropy. We confirm this conjecture for the order of derivative up to $3$, when the order of R\u00e9nyi entropy is in certain regimes. We also investigate concavity of R\u00e9nyi entropy power and the completely monotone conjecture for Tsallis entropy. We observe that the completely monotone conjecture is true for Tsallis entropy of order $2$. Our proofs in this paper are based on the techniques of integration-by-parts and sum-of-squares.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01819"
  },
  "2312.01811": {
    "title": "Energy-based Potential Games for Joint Motion Forecasting and Control",
    "authors": [
      "Christopher Diehl",
      "Tobias Klosek",
      "Martin Kr\u00fcger",
      "Nils Murzyn",
      "Timo Osterburg",
      "Torsten Bertram"
    ],
    "abstract": "This work uses game theory as a mathematical framework to address interaction modeling in multi-agent motion forecasting and control. Despite its interpretability, applying game theory to real-world robotics, like automated driving, faces challenges such as unknown game parameters. To tackle these, we establish a connection between differential games, optimal control, and energy-based models, demonstrating how existing approaches can be unified under our proposed Energy-based Potential Game formulation. Building upon this, we introduce a new end-to-end learning application that combines neural networks for game-parameter inference with a differentiable game-theoretic optimization layer, acting as an inductive bias. The analysis provides empirical evidence that the game-theoretic layer adds interpretability and improves the predictive performance of various neural network backbones using two simulations and two real-world driving datasets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01811"
  },
  "2312.01810": {
    "title": "Experimental and numerical investigations on the acoustoelastic effect in hyperelastic waveguides",
    "authors": [
      "Tilmann Barth",
      "Natalie Rauter",
      "Rolf Lammering"
    ],
    "abstract": "Guided ultrasonic wave based structural health monitoring has been of interest over decades. However, the influence of pre-stress states on the propagation of Lamb waves in thin-walled structures is not fully covered, yet. So far experimental work presented in the literature only focuses on a few individual frequencies, which does not allow a comprehensive verification of the numerous numerical investigations. Furthermore, most work is based on the strain-energy density function by Murnaghan. To validate the common modeling approach and to investigate the suitability of other non-linear strain-energy density functions an extensive experimental and numerical investigation covering a large frequency range is presented here. The numerical simulation comprises the use of the Neo-Hooke as well as the Murnaghan material model. It is found that these two material models show qualitatively similar results. Furthermore, the comparison with the experimental results reveals, that the Neo-Hooke material model reproduces the effect of pre-stress on the difference in the Lamb wave phase velocity very well in most cases. For the $A_0$ wave mode at higher frequencies, however, the sign of this difference is only correctly predicted by the Murnaghan model. In contrast to this the Murnaghan material model fails to predict the sign change for the $S_0$ wave mode.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01810"
  },
  "2312.01809": {
    "title": "SE-LIO: Semantics-enhanced Solid-State-LiDAR-Inertial Odometry for Tree-rich Environments",
    "authors": [
      "Tisheng Zhang",
      "Linfu Wei",
      "Hailiang Tang",
      "Liqiang Wang",
      "Man Yuan",
      "Xiaoji Niu"
    ],
    "abstract": "In this letter, we propose a semantics-enhanced solid-state-LiDAR-inertial odometry (SE-LIO) in tree-rich environments. Multiple LiDAR frames are first merged and compensated with the inertial navigation system (INS) to increase the point-cloud coverage, thus improving the accuracy of semantic segmentation. The unstructured point clouds, such as tree leaves and dynamic objects, are then removed with the semantic information. Furthermore, the pole-like point clouds, primarily tree trunks, are modeled as cylinders to improve positioning accuracy. An adaptive piecewise cylinder-fitting method is proposed to accommodate environments with a high prevalence of curved tree trunks. Finally, the iterated error-state Kalman filter (IESKF) is employed for state estimation. Point-to-cylinder and point-to-plane constraints are tightly coupled with the prior constraints provided by the INS to obtain the maximum a posteriori estimation. Targeted experiments are conducted in complex campus and park environments to evaluate the performance of SE-LIO. The proposed methods, including removing the unstructured point clouds and the adaptive cylinder fitting, yield improved accuracy. Specifically, the positioning accuracy of the proposed SE-LIO is improved by 43.1% compared to the plane-based LIO.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01809"
  },
  "2312.01808": {
    "title": "Head Orientation Estimation with Distributed Microphones Using Speech Radiation Patterns",
    "authors": [
      "Kaspar M\u00fcller",
      "Bilgesu \u00c7akmak",
      "Paul Didier",
      "Simon Doclo",
      "Jan \u00d8stergaard",
      "Tobias Wolff"
    ],
    "abstract": "Determining the head orientation of a talker is not only beneficial for various speech signal processing applications, such as source localization or speech enhancement, but also facilitates intuitive voice control and interaction with smart environments or modern car assistants. Most approaches for head orientation estimation are based on visual cues. However, this requires camera systems which often are not available. We present an approach which purely uses audio signals captured with only a few distributed microphones around the talker. Specifically, we propose a novel method that directly incorporates measured or modeled speech radiation patterns to infer the talker's orientation during active speech periods based on a cosine similarity measure. Moreover, an automatic gain adjustment technique is proposed for uncalibrated, irregular microphone setups, such as ad-hoc sensor networks. In experiments with signals recorded in both anechoic and reverberant environments, the proposed method outperforms state-of-the-art approaches, using either measured or modeled speech radiation patterns.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01808"
  },
  "2312.01801": {
    "title": "SPROUT: Authoring Programming Tutorials with Interactive Visualization of Large Language Model Generation Process",
    "authors": [
      "Yihan Liu",
      "Zhen Wen",
      "Luoxuan Weng",
      "Ollie Woodman",
      "Yi Yang",
      "Wei Chen"
    ],
    "abstract": "The rapid development of large language models (LLMs), such as ChatGPT, has revolutionized the efficiency of creating programming tutorials. LLMs can be instructed with text prompts to generate comprehensive text descriptions of code snippets. However, the lack of transparency in the end-to-end generation process has hindered the understanding of model behavior and limited user control over the generated results. To tackle this challenge, we introduce a novel approach that breaks down the programming tutorial creation task into actionable steps. By employing the tree-of-thought method, LLMs engage in an exploratory process to generate diverse and faithful programming tutorials. We then present SPROUT, an authoring tool equipped with a series of interactive visualizations that empower users to have greater control and understanding of the programming tutorial creation process. A formal user study demonstrated the effectiveness of SPROUT, showing that our tool assists users to actively participate in the programming tutorial creation process, leading to more reliable and customizable results. By providing users with greater control and understanding, SPROUT enhances the user experience and improves the overall quality of programming tutorial. A free copy of this paper and all supplemental materials are available at https://osf.io/uez2t/?view_only=5102e958802341daa414707646428f86.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01801"
  },
  "2312.01800": {
    "title": "Collaborative Neural Painting",
    "authors": [
      "Nicola Dall'Asen",
      "Willi Menapace",
      "Elia Peruzzo",
      "Enver Sangineto",
      "Yiming Wang",
      "Elisa Ricci"
    ],
    "abstract": "The process of painting fosters creativity and rational planning. However, existing generative AI mostly focuses on producing visually pleasant artworks, without emphasizing the painting process. We introduce a novel task, Collaborative Neural Painting (CNP), to facilitate collaborative art painting generation between humans and machines. Given any number of user-input brushstrokes as the context or just the desired object class, CNP should produce a sequence of strokes supporting the completion of a coherent painting. Importantly, the process can be gradual and iterative, so allowing users' modifications at any phase until the completion. Moreover, we propose to solve this task using a painting representation based on a sequence of parametrized strokes, which makes it easy both editing and composition operations. These parametrized strokes are processed by a Transformer-based architecture with a novel attention mechanism to model the relationship between the input strokes and the strokes to complete. We also propose a new masking scheme to reflect the interactive nature of CNP and adopt diffusion models as the basic learning process for its effectiveness and diversity in the generative field. Finally, to develop and validate methods on the novel task, we introduce a new dataset of painted objects and an evaluation protocol to benchmark CNP both quantitatively and qualitatively. We demonstrate the effectiveness of our approach and the potential of the CNP task as a promising avenue for future research.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01800"
  },
  "2312.01795": {
    "title": "Distributed Continual Learning with CoCoA in High-dimensional Linear Regression",
    "authors": [
      "Martin Hellkvist",
      "Ay\u00e7a \u00d6z\u00e7elikkale",
      "Anders Ahl\u00e9n"
    ],
    "abstract": "We consider estimation under scenarios where the signals of interest exhibit change of characteristics over time. In particular, we consider the continual learning problem where different tasks, e.g., data with different distributions, arrive sequentially and the aim is to perform well on the newly arrived task without performance degradation on the previously seen tasks. In contrast to the continual learning literature focusing on the centralized setting, we investigate the problem from a distributed estimation perspective. We consider the well-established distributed learning algorithm COCOA, which distributes the model parameters and the corresponding features over the network. We provide exact analytical characterization for the generalization error of COCOA under continual learning for linear regression in a range of scenarios, where overparameterization is of particular interest. These analytical results characterize how the generalization error depends on the network structure, the task similarity and the number of tasks, and show how these dependencies are intertwined. In particular, our results show that the generalization error can be significantly reduced by adjusting the network size, where the most favorable network size depends on task similarity and the number of tasks. We present numerical results verifying the theoretical analysis and illustrate the continual learning performance of COCOA with a digit classification task.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01795"
  },
  "2312.01792": {
    "title": "Wild-Tab: A Benchmark For Out-Of-Distribution Generalization In Tabular Regression",
    "authors": [
      "Sergey Kolesnikov"
    ],
    "abstract": "Out-of-Distribution (OOD) generalization, a cornerstone for building robust machine learning models capable of handling data diverging from the training set's distribution, is an ongoing challenge in deep learning. While significant progress has been observed in computer vision and natural language processing, its exploration in tabular data, ubiquitous in many industrial applications, remains nascent. To bridge this gap, we present Wild-Tab, a large-scale benchmark tailored for OOD generalization in tabular regression tasks. The benchmark incorporates 3 industrial datasets sourced from fields like weather prediction and power consumption estimation, providing a challenging testbed for evaluating OOD performance under real-world conditions. Our extensive experiments, evaluating 10 distinct OOD generalization methods on Wild-Tab, reveal nuanced insights. We observe that many of these methods often struggle to maintain high-performance levels on unseen data, with OOD performance showing a marked drop compared to in-distribution performance. At the same time, Empirical Risk Minimization (ERM), despite its simplicity, delivers robust performance across all evaluations, rivaling the results of state-of-the-art methods. Looking forward, we hope that the release of Wild-Tab will facilitate further research on OOD generalization and aid in the deployment of machine learning models in various real-world contexts where handling distribution shifts is a crucial requirement.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01792"
  },
  "2312.01790": {
    "title": "Exploring Multi-Modal Fusion for Image Manipulation Detection and Localization",
    "authors": [
      "Konstantinos Triaridis",
      "Vasileios Mezaris"
    ],
    "abstract": "Recent image manipulation localization and detection techniques usually leverage forensic artifacts and traces that are produced by a noise-sensitive filter, such as SRM and Bayar convolution. In this paper, we showcase that different filters commonly used in such approaches excel at unveiling different types of manipulations and provide complementary forensic traces. Thus, we explore ways of merging the outputs of such filters and aim to leverage the complementary nature of the artifacts produced to perform image manipulation localization and detection (IMLD). We propose two distinct methods: one that produces independent features from each forensic filter and then fuses them (this is referred to as late fusion) and one that performs early mixing of different modal outputs and produces early combined features (this is referred to as early fusion). We demonstrate that both approaches achieve competitive performance for both image manipulation localization and detection, outperforming state-of-the-art models across several datasets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01790"
  },
  "2312.01789": {
    "title": "Two-stage optimized unified adversarial patch for attacking visible-infrared cross-modal detectors in the physical world",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "abstract": "Currently, many studies have addressed security concerns related to visible and infrared detectors independently. In practical scenarios, utilizing cross-modal detectors for tasks proves more reliable than relying on single-modal detectors. Despite this, there is a lack of comprehensive security evaluations for cross-modal detectors. While existing research has explored the feasibility of attacks against cross-modal detectors, the implementation of a robust attack remains unaddressed. This work introduces the Two-stage Optimized Unified Adversarial Patch (TOUAP) designed for performing attacks against visible-infrared cross-modal detectors in real-world, black-box settings. The TOUAP employs a two-stage optimization process: firstly, PSO optimizes an irregular polygonal infrared patch to attack the infrared detector; secondly, the color QR code is optimized, and the shape information of the infrared patch from the first stage is used as a mask. The resulting irregular polygon visible modal patch executes an attack on the visible detector. Through extensive experiments conducted in both digital and physical environments, we validate the effectiveness and robustness of the proposed method. As the TOUAP surpasses baseline performance, we advocate for its widespread attention.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01789"
  },
  "2312.01787": {
    "title": "Developing Linguistic Patterns to Mitigate Inherent Human Bias in Offensive Language Detection",
    "authors": [
      "Toygar Tanyel",
      "Besher Alkurdi",
      "Serkan Ayvaz"
    ],
    "abstract": "With the proliferation of social media, there has been a sharp increase in offensive content, particularly targeting vulnerable groups, exacerbating social problems such as hatred, racism, and sexism. Detecting offensive language use is crucial to prevent offensive language from being widely shared on social media. However, the accurate detection of irony, implication, and various forms of hate speech on social media remains a challenge. Natural language-based deep learning models require extensive training with large, comprehensive, and labeled datasets. Unfortunately, manually creating such datasets is both costly and error-prone. Additionally, the presence of human-bias in offensive language datasets is a major concern for deep learning models. In this paper, we propose a linguistic data augmentation approach to reduce bias in labeling processes, which aims to mitigate the influence of human bias by leveraging the power of machines to improve the accuracy and fairness of labeling processes. This approach has the potential to improve offensive language classification tasks across multiple languages and reduce the prevalence of offensive content on social media.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01787"
  },
  "2312.01786": {
    "title": "Output-sensitive Complexity of Multi-Objective Integer Network Flow Problems",
    "authors": [
      "David K\u00f6nen",
      "Michael Stiglmayr"
    ],
    "abstract": "This paper addresses the output-sensitive complexity for linear multi-objective integer minimum cost flow (MOIMCF) problems and provides insights about the time complexity for enumerating all supported nondominated vectors. The paper shows that there can not exist an output-polynomial time algorithm for the enumeration of all supported nondominated vectors that determine the vectors in an ordered way in the outcome space unless NP = P. Moreover, novel methods for identifying supported nondominated vectors in bi-objective minimum cost flow (BOIMCF) problems are proposed, accompanied by a numerical comparison between decision- and objective-space methods. A novel, equivalent and more compact formulation of the minimum cost flow ILP formulation used in the e-constrained-scalarization approach is introduced, demonstrating enhanced efficiency in the numerical tests\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01786"
  },
  "2312.01779": {
    "title": "Viral transmission in pedestrian crowds: Coupling an open-source code assessing the risks of airborne contagion with diverse pedestrian dynamics models",
    "authors": [
      "Alexandre Nicolas",
      "Simon Mendez"
    ],
    "abstract": "We study viral transmission in crowds via the short-ranged airborne pathway using a purely model-based approach. Our goal is two-pronged. Firstly, we illustrate with a concrete and pedagogical case study how to estimate the risks of new viral infections by coupling pedestrian simulations with the transmission algorithm that we recently released as open-source code. The algorithm hinges on pre-computed viral concentration maps derived from computational fluid dynamics (CFD) simulations. Secondly, we investigate to what extent the transmission risk predictions depend on the pedestrian dynamics model in use. For the simple bidirectional flow under consideration, the predictions are found to be surprisingly stable across initial conditions and models, despite the different microscopic arrangements of the simulated crowd, as long as the crowd evolves in a qualitatively similarly way. On the other hand, when major changes are observed in the crowd's behaviour, notably whenever a jam occurs at the centre of the channel, the estimated risks surge drastically.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01779"
  },
  "2312.01777": {
    "title": "Doubly 1-Bit Quantized Massive MIMO",
    "authors": [
      "Italo Atzeni",
      "Antti T\u00f6lli",
      "Duy H. N. Nguyen",
      "A. Lee Swindlehurst"
    ],
    "abstract": "Enabling communications in the (sub-)THz band will call for massive multiple-input multiple-output (MIMO) arrays at either the transmit- or receive-side, or at both. To scale down the complexity and power consumption when operating across massive frequency and antenna dimensions, a sacrifice in the resolution of the digital-to-analog/analog-to-digital converters (DACs/ADCs) will be inevitable. In this paper, we analyze the extreme scenario where both the transmit- and receive-side are equipped with fully digital massive MIMO arrays and 1-bit DACs/ADCs, which leads to a system with minimum radio-frequency complexity, cost, and power consumption. Building upon the Bussgang decomposition, we derive a tractable approximation of the mean squared error (MSE) between the transmitted data symbols and their soft estimates. Numerical results show that, despite its simplicity, a doubly 1-bit quantized massive MIMO system with very large antenna arrays can deliver an impressive performance in terms of MSE and symbol error rate.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01777"
  },
  "2312.01771": {
    "title": "IMProv: Inpainting-based Multimodal Prompting for Computer Vision Tasks",
    "authors": [
      "Jiarui Xu",
      "Yossi Gandelsman",
      "Amir Bar",
      "Jianwei Yang",
      "Jianfeng Gao",
      "Trevor Darrell",
      "Xiaolong Wang"
    ],
    "abstract": "In-context learning allows adapting a model to new tasks given a task description at test time. In this paper, we present IMProv - a generative model that is able to in-context learn visual tasks from multimodal prompts. Given a textual description of a visual task (e.g. \"Left: input image, Right: foreground segmentation\"), a few input-output visual examples, or both, the model in-context learns to solve it for a new test input. We train a masked generative transformer on a new dataset of figures from computer vision papers and their associated captions, together with a captioned large-scale image-text dataset. During inference time, we prompt the model with text and/or image task example(s) and have the model inpaint the corresponding output. We show that training our model with text conditioning and scaling the dataset size improves in-context learning for computer vision tasks by over +10\\% AP for Foreground Segmentation, over +5\\% gains in AP for Single Object Detection, and almost 20\\% lower LPIPS in Colorization. Our empirical results suggest that vision and language prompts are complementary and it is advantageous to use both to achieve better in-context learning performance. Project page is available at https://jerryxu.net/IMProv .\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01771"
  },
  "2312.01768": {
    "title": "Localizing and Assessing Node Significance in Default Mode Network using Sub-Community Detection in Mild Cognitive Impairment",
    "authors": [
      "Ameiy Acharya",
      "Chakka Sai Pradeep",
      "Neelam Sinha"
    ],
    "abstract": "Our study aims to utilize fMRI to identify the affected brain regions within the Default Mode Network (DMN) in subjects with Mild Cognitive Impairment (MCI), using a novel Node Significance Score (NSS). We construct subject-specific DMN graphs by employing partial correlation of Regions of Interest (ROIs) that make-up the DMN. For the DMN graph, ROIs are the nodes and edges are determined based on partial correlation. Four popular community detection algorithms (Clique Percolation Method (CPM), Louvain algorithm, Greedy Modularity and Leading Eigenvectors) are applied to determine the largest sub-community. NSS ratings are derived for each node, considering (I) frequency in the largest sub-community within a class across all subjects and (II) occurrence in the largest sub-community according to all four methods. After computing the NSS of each ROI in both healthy and MCI subjects, we quantify the score disparity to identify nodes most impacted by MCI. The results reveal a disparity exceeding 20% for 10 DMN nodes, maximally for PCC and Fusiform, showing 45.69% and 43.08% disparity. This aligns with existing medical literature, additionally providing a quantitative measure that enables the ordering of the affected ROIs. These findings offer valuable insights and could lead to treatment strategies aggressively targeting the affected nodes.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01768"
  },
  "2312.01764": {
    "title": "Dynamic Erasing Network Based on Multi-Scale Temporal Features for Weakly Supervised Video Anomaly Detection",
    "authors": [
      "Chen Zhang",
      "Guorong Li",
      "Yuankai Qi",
      "Hanhua Ye",
      "Laiyun Qing",
      "Ming-Hsuan Yang",
      "Qingming Huang"
    ],
    "abstract": "The goal of weakly supervised video anomaly detection is to learn a detection model using only video-level labeled data. However, prior studies typically divide videos into fixed-length segments without considering the complexity or duration of anomalies. Moreover, these studies usually just detect the most abnormal segments, potentially overlooking the completeness of anomalies. To address these limitations, we propose a Dynamic Erasing Network (DE-Net) for weakly supervised video anomaly detection, which learns multi-scale temporal features. Specifically, to handle duration variations of abnormal events, we first propose a multi-scale temporal modeling module, capable of extracting features from segments of varying lengths and capturing both local and global visual information across different temporal scales. Then, we design a dynamic erasing strategy, which dynamically assesses the completeness of the detected anomalies and erases prominent abnormal segments in order to encourage the model to discover gentle abnormal segments in a video. The proposed method obtains favorable performance compared to several state-of-the-art approaches on three datasets: XD-Violence, TAD, and UCF-Crime. Code will be made available at https://github.com/ArielZc/DE-Net.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01764"
  },
  "2312.01761": {
    "title": "Light Field Imaging in the Restrictive Object Space based on Flexible Angular Plane",
    "authors": [
      "Ping Zhou",
      "Nuo Chen",
      "Yuda Xu",
      "Chengcai Xu"
    ],
    "abstract": "In some applications, the object space of light field imaging system is restrictive, such as industrial and medical endoscopes. If the traditional light field imaging system is used in the restrictive object space (ROS) directly but without any specific considerations, the ROS will lead to severe microlens image distortions and then affects light field decoding, calibration and 3D reconstruction. The light field imaging in restrictive object space (ROS-LF) is complicated but significant. In this paper, we first deduce that the reason of the microlens image deviation is the position variation of the angular plane, then we propose the flexible angular plane for ROS-LF, while in the traditional light field the angular plane always coincides with the main lens plane. Subsequently, we propose the microlens image non-distortion principle for ROS-LF and introduce the ROS-LF imaging principle. We demonstrate that the difference is an aperture constant term between the ROS-LF and traditional light field imaging models. At last, we design a ROS-LF simulated system and calibrate it to verify principles proposed in this paper.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01761"
  },
  "2312.01760": {
    "title": "On Gradient Boosted Decision Trees and Neural Rankers: A Case-Study on Short-Video Recommendations at ShareChat",
    "authors": [
      "Olivier Jeunen",
      "Hitesh Sagtani",
      "Himanshu Doi",
      "Rasul Karimov",
      "Neeti Pokharna",
      "Danish Kalim",
      "Aleksei Ustimenko",
      "Christopher Green",
      "Wenzhe Shi",
      "Rishabh Mehrotra"
    ],
    "abstract": "Practitioners who wish to build real-world applications that rely on ranking models, need to decide which modelling paradigm to follow. This is not an easy choice to make, as the research literature on this topic has been shifting in recent years. In particular, whilst Gradient Boosted Decision Trees (GBDTs) have reigned supreme for more than a decade, the flexibility of neural networks has allowed them to catch up, and recent works report accuracy metrics that are on par. Nevertheless, practical systems require considerations beyond mere accuracy metrics to decide on a modelling approach.\n  This work describes our experiences in balancing some of the trade-offs that arise, presenting a case study on a short-video recommendation application. We highlight (1) neural networks' ability to handle large training data size, user- and item-embeddings allows for more accurate models than GBDTs in this setting, and (2) because GBDTs are less reliant on specialised hardware, they can provide an equally accurate model at a lower cost. We believe these findings are of relevance to researchers in both academia and industry, and hope they can inspire practitioners who need to make similar modelling choices in the future.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01760"
  },
  "2312.01759": {
    "title": "Faster Sublinear-Time Edit Distance",
    "authors": [
      "Karl Bringmann",
      "Alejandro Cassis",
      "Nick Fischer",
      "Tomasz Kociumaka"
    ],
    "abstract": "We study the fundamental problem of approximating the edit distance of two strings. After an extensive line of research led to the development of a constant-factor approximation algorithm in almost-linear time, recent years have witnessed a notable shift in focus towards sublinear-time algorithms. Here, the task is typically formalized as the $(k, K)$-gap edit distance problem: Distinguish whether the edit distance of two strings is at most $k$ or more than $K$.\n  Surprisingly, it is still possible to compute meaningful approximations in this challenging regime. Nevertheless, in almost all previous work, truly sublinear running time of $O(n^{1-\\varepsilon})$ (for a constant $\\varepsilon > 0$) comes at the price of at least polynomial gap $K \\ge k \\cdot n^{\u03a9(\\varepsilon)}$. Only recently, [Bringmann, Cassis, Fischer, and Nakos; STOC'22] broke through this barrier and solved the sub-polynomial $(k, k^{1+o(1)})$-gap edit distance problem in time $O(n/k + k^{4+o(1)})$, which is truly sublinear if $n^{\u03a9(1)} \\le k \\le n^{\\frac14-\u03a9(1)}$.The $n/k$ term is inevitable (already for Hamming distance), but it remains an important task to optimize the $\\mathrm{poly}(k)$ term and, in general, solve the $(k, k^{1+o(1)})$-gap edit distance problem in sublinear-time for larger values of $k$.\n  In this work, we design an improved algorithm for the $(k, k^{1+o(1)})$-gap edit distance problem in sublinear time $O(n/k + k^{2+o(1)})$, yielding a significant quadratic speed-up over the previous $O(n/k + k^{4+o(1)})$-time algorithm. Notably, our algorithm is unconditionally almost-optimal (up to subpolynomial factors) in the regime where $k \\leq n^{\\frac13}$ and improves upon the state of the art for $k \\leq n^{\\frac12-o(1)}$.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01759"
  },
  "2312.01756": {
    "title": "A Comprehensive Literature Review on Sweet Orange Leaf Diseases",
    "authors": [
      "Yousuf Rayhan Emon",
      "Md Golam Rabbani",
      "Md. Taimur Ahad",
      "Faruk Ahmed"
    ],
    "abstract": "Sweet orange leaf diseases are significant to agricultural productivity. Leaf diseases impact fruit quality in the citrus industry. The apparition of machine learning makes the development of disease finder. Early detection and diagnosis are necessary for leaf management. Sweet orange leaf disease-predicting automated systems have already been developed using different image-processing techniques. This comprehensive literature review is systematically based on leaf disease and machine learning methodologies applied to the detection of damaged leaves via image classification. The benefits and limitations of different machine learning models, including Vision Transformer (ViT), Neural Network (CNN), CNN with SoftMax and RBF SVM, Hybrid CNN-SVM, HLB-ConvMLP, EfficientNet-b0, YOLOv5, YOLOv7, Convolutional, Deep CNN. These machine learning models tested on various datasets and detected the disease. This comprehensive review study related to leaf disease compares the performance of the models; those models' accuracy, precision, recall, etc., were used in the subsisting studies\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01756"
  },
  "2312.01752": {
    "title": "Cybersecurity threats in FinTech: A systematic review",
    "authors": [
      "Danial Javaheri",
      "Mahdi Fahmideh",
      "Hassan Chizari",
      "Pooia Lalbakhsh",
      "Junbeom Hur"
    ],
    "abstract": "The rapid evolution of the Smart-everything movement and Artificial Intelligence (AI) advancements have given rise to sophisticated cyber threats that traditional methods cannot counteract. Cyber threats are extremely critical in financial technology (FinTech) as a data-centric sector expected to provide 24/7 services. This paper introduces a novel and refined taxonomy of security threats in FinTech and conducts a comprehensive systematic review of defensive strategies. Through PRISMA methodology applied to 74 selected studies and topic modeling, we identified 11 central cyber threats, with 43 papers detailing them, and pinpointed 9 corresponding defense strategies, as covered in 31 papers. This in-depth analysis offers invaluable insights for stakeholders ranging from banks and enterprises to global governmental bodies, highlighting both the current challenges in FinTech and effective countermeasures, as well as directions for future research.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01752"
  },
  "2312.01751": {
    "title": "Joint Task Partitioning and Parallel Scheduling in Device-Assisted Mobile Edge Networks",
    "authors": [
      "Yang Li",
      "Xinlei Ge",
      "Bo Lei",
      "Xing Zhang",
      "Wenbo Wang"
    ],
    "abstract": "With the development of the Internet of Things (IoT), certain IoT devices have the capability to not only accomplish their own tasks but also simultaneously assist other resource-constrained devices. Therefore, this paper considers a device-assisted mobile edge computing system that leverages auxiliary IoT devices to alleviate the computational burden on the edge computing server and enhance the overall system performance. In this study, computationally intensive tasks are decomposed into multiple partitions, and each task partition can be processed in parallel on an IoT device or the edge server. The objective of this research is to develop an efficient online algorithm that addresses the joint optimization of task partitioning and parallel scheduling under time-varying system states, posing challenges to conventional numerical optimization methods. To address these challenges, a framework called online task partitioning action and parallel scheduling policy generation (OTPPS) is proposed, which is based on deep reinforcement learning (DRL). Specifically, the framework leverages a deep neural network (DNN) to learn the optimal partitioning action for each task by mapping input states. Furthermore, it is demonstrated that the remaining parallel scheduling problem exhibits NP-hard complexity when considering a specific task partitioning action. To address this subproblem, a fair and delay-minimized task scheduling (FDMTS) algorithm is designed. Extensive evaluation results demonstrate that OTPPS achieves near-optimal average delay performance and consistently high fairness levels in various environmental states compared to other baseline schemes.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01751"
  },
  "2312.01748": {
    "title": "Deep CNN for Coherent Seismic Noise Removal: A Perspective",
    "authors": [
      "Rohit Shrivastava",
      "Ashish Asgekar",
      "Evert Kramer"
    ],
    "abstract": "Seismic denoising is an important processing step before subsequent imaging and interpretation, which consumes a significant amount of time, whether it is for Quality control or for the associated computations. We present results of our work in training convolutional neural networks for denoising seismic data, specifically attenuation of surface related multiples and removal of overlap of shot energies during simultaneous-shooting survey. The proposed methodology is being explored not only for its ability to minimize human involvement but also because of the trained filter's ability to accelerate the process, hence, reduce processing time.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01748"
  },
  "2312.01747": {
    "title": "Autonomous and Adaptive Role Selection for Multi-robot Collaborative Area Search Based on Deep Reinforcement Learning",
    "authors": [
      "Lina Zhu",
      "Jiyu Cheng",
      "Hao Zhang",
      "Zhichao Cui",
      "Wei Zhang",
      "Yuehu Liu"
    ],
    "abstract": "In the tasks of multi-robot collaborative area search, we propose the unified approach for simultaneous mapping for sensing more targets (exploration) while searching and locating the targets (coverage). Specifically, we implement a hierarchical multi-agent reinforcement learning algorithm to decouple task planning from task execution. The role concept is integrated into the upper-level task planning for role selection, which enables robots to learn the role based on the state status from the upper-view. Besides, an intelligent role switching mechanism enables the role selection module to function between two timesteps, promoting both exploration and coverage interchangeably. Then the primitive policy learns how to plan based on their assigned roles and local observation for sub-task execution. The well-designed experiments show the scalability and generalization of our method compared with state-of-the-art approaches in the scenes with varying complexity and number of robots.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01747"
  },
  "2312.01746": {
    "title": "Open-DDVM: A Reproduction and Extension of Diffusion Model for Optical Flow Estimation",
    "authors": [
      "Qiaole Dong",
      "Bo Zhao",
      "Yanwei Fu"
    ],
    "abstract": "Recently, Google proposes DDVM which for the first time demonstrates that a general diffusion model for image-to-image translation task works impressively well on optical flow estimation task without any specific designs like RAFT. However, DDVM is still a closed-source model with the expensive and private Palette-style pretraining. In this technical report, we present the first open-source DDVM by reproducing it. We study several design choices and find those important ones. By training on 40k public data with 4 GPUs, our reproduction achieves comparable performance to the closed-source DDVM. The code and model have been released in https://github.com/DQiaole/FlowDiffusion_pytorch.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01746"
  },
  "2312.01745": {
    "title": "Cross-Modal Adaptive Dual Association for Text-to-Image Person Retrieval",
    "authors": [
      "Dixuan Lin",
      "Yixing Peng",
      "Jingke Meng",
      "Wei-Shi Zheng"
    ],
    "abstract": "Text-to-image person re-identification (ReID) aims to retrieve images of a person based on a given textual description. The key challenge is to learn the relations between detailed information from visual and textual modalities. Existing works focus on learning a latent space to narrow the modality gap and further build local correspondences between two modalities. However, these methods assume that image-to-text and text-to-image associations are modality-agnostic, resulting in suboptimal associations. In this work, we show the discrepancy between image-to-text association and text-to-image association and propose CADA: Cross-Modal Adaptive Dual Association that finely builds bidirectional image-text detailed associations. Our approach features a decoder-based adaptive dual association module that enables full interaction between visual and textual modalities, allowing for bidirectional and adaptive cross-modal correspondence associations. Specifically, the paper proposes a bidirectional association mechanism: Association of text Tokens to image Patches (ATP) and Association of image Regions to text Attributes (ARA). We adaptively model the ATP based on the fact that aggregating cross-modal features based on mistaken associations will lead to feature distortion. For modeling the ARA, since the attributes are typically the first distinguishing cues of a person, we propose to explore the attribute-level association by predicting the masked text phrase using the related image region. Finally, we learn the dual associations between texts and images, and the experimental results demonstrate the superiority of our dual formulation. Codes will be made publicly available.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01745"
  },
  "2312.01742": {
    "title": "Fully Spiking Denoising Diffusion Implicit Models",
    "authors": [
      "Ryo Watanabe",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "abstract": "Spiking neural networks (SNNs) have garnered considerable attention owing to their ability to run on neuromorphic devices with super-high speeds and remarkable energy efficiencies. SNNs can be used in conventional neural network-based time- and energy-consuming applications. However, research on generative models within SNNs remains limited, despite their advantages. In particular, diffusion models are a powerful class of generative models, whose image generation quality surpass that of the other generative models, such as GANs. However, diffusion models are characterized by high computational costs and long inference times owing to their iterative denoising feature. Therefore, we propose a novel approach fully spiking denoising diffusion implicit model (FSDDIM) to construct a diffusion model within SNNs and leverage the high speed and low energy consumption features of SNNs via synaptic current learning (SCL). SCL fills the gap in that diffusion models use a neural network to estimate real-valued parameters of a predefined probabilistic distribution, whereas SNNs output binary spike trains. The SCL enables us to complete the entire generative process of diffusion models exclusively using SNNs. We demonstrate that the proposed method outperforms the state-of-the-art fully spiking generative model.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01742"
  },
  "2312.01741": {
    "title": "SRSNetwork: Siamese Reconstruction-Segmentation Networks based on Dynamic-Parameter Convolution",
    "authors": [
      "Bingkun Nian",
      "Fenghe Tang",
      "Jianrui Ding",
      "Pingping Zhang",
      "Jie Yang",
      "S. Kevin Zhou",
      "Wei Liu"
    ],
    "abstract": "In this paper, we present a high-performance deep neural network for weak target image segmentation, including medical image segmentation and infrared image segmentation. To this end, this work analyzes the existing dynamic convolutions and proposes dynamic parameter convolution (DPConv). Furthermore, it reevaluates the relationship between reconstruction tasks and segmentation tasks from the perspective of DPConv, leading to the proposal of a dual-network model called the Siamese Reconstruction-Segmentation Network (SRSNet). The proposed model is not only a universal network but also enhances the segmentation performance without altering its structure, leveraging the reconstruction task. Additionally, as the amount of training data for the reconstruction network increases, the performance of the segmentation network also improves synchronously. On seven datasets including five medical datasets and two infrared image datasets, our SRSNet consistently achieves the best segmentation results. The code is released at https://github.com/fidshu/SRSNet.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01741"
  },
  "2312.01740": {
    "title": "MobileUtr: Revisiting the relationship between light-weight CNN and Transformer for efficient medical image segmentation",
    "authors": [
      "Fenghe Tang",
      "Bingkun Nian",
      "Jianrui Ding",
      "Quan Quan",
      "Jie Yang",
      "Wei Liu",
      "S. Kevin Zhou"
    ],
    "abstract": "Due to the scarcity and specific imaging characteristics in medical images, light-weighting Vision Transformers (ViTs) for efficient medical image segmentation is a significant challenge, and current studies have not yet paid attention to this issue. This work revisits the relationship between CNNs and Transformers in lightweight universal networks for medical image segmentation, aiming to integrate the advantages of both worlds at the infrastructure design level. In order to leverage the inductive bias inherent in CNNs, we abstract a Transformer-like lightweight CNNs block (ConvUtr) as the patch embeddings of ViTs, feeding Transformer with denoised, non-redundant and highly condensed semantic information. Moreover, an adaptive Local-Global-Local (LGL) block is introduced to facilitate efficient local-to-global information flow exchange, maximizing Transformer's global context information extraction capabilities. Finally, we build an efficient medical image segmentation model (MobileUtr) based on CNN and Transformer. Extensive experiments on five public medical image datasets with three different modalities demonstrate the superiority of MobileUtr over the state-of-the-art methods, while boasting lighter weights and lower computational cost. Code is available at https://github.com/FengheTan9/MobileUtr.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01740"
  },
  "2312.01739": {
    "title": "Divide-and-Conquer Strategy for Large-Scale Dynamic Bayesian Network Structure Learning",
    "authors": [
      "Hui Ouyang",
      "Cheng Chen",
      "Ke Tang"
    ],
    "abstract": "Dynamic Bayesian Networks (DBNs), renowned for their interpretability, have become increasingly vital in representing complex stochastic processes in various domains such as gene expression analysis, healthcare, and traffic prediction. Structure learning of DBNs from data is challenging, particularly for datasets with thousands of variables. Most current algorithms for DBN structure learning are adaptations from those used in static Bayesian Networks (BNs), and are typically focused on small-scale problems. In order to solve large-scale problems while taking full advantage of existing algorithms, this paper introduces a novel divide-and-conquer strategy, originally developed for static BNs, and adapts it for large-scale DBN structure learning. In this work, we specifically concentrate on 2 Time-sliced Bayesian Networks (2-TBNs), a special class of DBNs. Furthermore, we leverage the prior knowledge of 2-TBNs to enhance the performance of the strategy we introduce. Our approach significantly improves the scalability and accuracy of 2-TBN structure learning. Experimental results demonstrate the effectiveness of our method, showing substantial improvements over existing algorithms in both computational efficiency and structure learning accuracy. On problem instances with more than 1,000 variables, our approach improves two accuracy metrics by 74.45% and 110.94% on average , respectively, while reducing runtime by 93.65% on average.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01739"
  },
  "2312.01738": {
    "title": "Generalizing Political Leaning Inference to Multi-Party Systems: Insights from the UK Political Landscape",
    "authors": [
      "Joseba Fernandez de Landa",
      "Arkaitz Zubiaga",
      "Rodrigo Agerri"
    ],
    "abstract": "An ability to infer the political leaning of social media users can help in gathering opinion polls thereby leading to a better understanding of public opinion. While there has been a body of research attempting to infer the political leaning of social media users, this has been typically simplified as a binary classification problem (e.g. left vs right) and has been limited to a single location, leading to a dearth of investigation into more complex, multiclass classification and its generalizability to different locations, particularly those with multi-party systems. Our work performs the first such effort by studying political leaning inference in three of the UK's nations (Scotland, Wales and Northern Ireland), each of which has a different political landscape composed of multiple parties. To do so, we collect and release a dataset comprising users labelled by their political leaning as well as interactions with one another. We investigate the ability to predict the political leaning of users by leveraging these interactions in challenging scenarios such as few-shot learning, where training data is scarce, as well as assessing the applicability to users with different levels of political engagement. We show that interactions in the form of retweets between users can be a very powerful feature to enable political leaning inference, leading to consistent and robust results across different regions with multi-party systems. However, we also see that there is room for improvement in predicting the political leaning of users who are less engaged in politics.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01738"
  },
  "2312.01732": {
    "title": "Likelihood-Aware Semantic Alignment for Full-Spectrum Out-of-Distribution Detection",
    "authors": [
      "Fan Lu",
      "Kai Zhu",
      "Kecheng Zheng",
      "Wei Zhai",
      "Yang Cao"
    ],
    "abstract": "Full-spectrum out-of-distribution (F-OOD) detection aims to accurately recognize in-distribution (ID) samples while encountering semantic and covariate shifts simultaneously. However, existing out-of-distribution (OOD) detectors tend to overfit the covariance information and ignore intrinsic semantic correlation, inadequate for adapting to complex domain transformations. To address this issue, we propose a Likelihood-Aware Semantic Alignment (LSA) framework to promote the image-text correspondence into semantically high-likelihood regions. LSA consists of an offline Gaussian sampling strategy which efficiently samples semantic-relevant visual embeddings from the class-conditional Gaussian distribution, and a bidirectional prompt customization mechanism that adjusts both ID-related and negative context for discriminative ID/OOD boundary. Extensive experiments demonstrate the remarkable OOD detection performance of our proposed LSA especially on the intractable Near-OOD setting, surpassing existing methods by a margin of $15.26\\%$ and $18.88\\%$ on two F-OOD benchmarks, respectively.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01732"
  },
  "2312.01729": {
    "title": "EdgeConvFormer: Dynamic Graph CNN and Transformer based Anomaly Detection in Multivariate Time Series",
    "authors": [
      "Jie Liu",
      "Qilin Li",
      "Senjian An",
      "Bradley Ezard",
      "Ling Li"
    ],
    "abstract": "Transformer-based models for anomaly detection in multivariate time series can benefit from the self-attention mechanism due to its advantage in modeling long-term dependencies. However, Transformer-based anomaly detection models have problems such as a large amount of data being required for training, standard positional encoding is not suitable for multivariate time series data, and the interdependence between time series is not considered. To address these limitations, we propose a novel anomaly detection method, named EdgeConvFormer, which integrates Time2vec embedding, stacked dynamic graph CNN, and Transformer to extract global and local spatial-time information. This design of EdgeConvFormer empowers it with decomposition capacities for complex time series, progressive spatiotemporal correlation discovery between time series, and representation aggregation of multi-scale features. Experiments demonstrate that EdgeConvFormer can learn the spatial-temporal correlations from multivariate time series data and achieve better anomaly detection performance than the state-of-the-art approaches on many real-world datasets of different scales.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01729"
  },
  "2312.01726": {
    "title": "Simultaneous Alignment and Surface Regression Using Hybrid 2D-3D Networks for 3D Coherent Layer Segmentation of Retinal OCT Images with Full and Sparse Annotations",
    "authors": [
      "Hong Liu",
      "Dong Wei",
      "Donghuan Lu",
      "Xiaoying Tang",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "abstract": "Layer segmentation is important to quantitative analysis of retinal optical coherence tomography (OCT). Recently, deep learning based methods have been developed to automate this task and yield remarkable performance. However, due to the large spatial gap and potential mismatch between the B-scans of an OCT volume, all of them were based on 2D segmentation of individual B-scans, which may lose the continuity and diagnostic information of the retinal layers in 3D space. Besides, most of these methods required dense annotation of the OCT volumes, which is labor-intensive and expertise-demanding. This work presents a novel framework based on hybrid 2D-3D convolutional neural networks (CNNs) to obtain continuous 3D retinal layer surfaces from OCT volumes, which works well with both full and sparse annotations. The 2D features of individual B-scans are extracted by an encoder consisting of 2D convolutions. These 2D features are then used to produce the alignment displacement vectors and layer segmentation by two 3D decoders coupled via a spatial transformer module. Two losses are proposed to utilize the retinal layers' natural property of being smooth for B-scan alignment and layer segmentation, respectively, and are the key to the semi-supervised learning with sparse annotation. The entire framework is trained end-to-end. To the best of our knowledge, this is the first work that attempts 3D retinal layer segmentation in volumetric OCT images based on CNNs. Experiments on a synthetic dataset and three public clinical datasets show that our framework can effectively align the B-scans for potential motion correction, and achieves superior performance to state-of-the-art 2D deep learning methods in terms of both layer segmentation accuracy and cross-B-scan 3D continuity in both fully and semi-supervised settings, thus offering more clinical values than previous works.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01726"
  },
  "2312.01725": {
    "title": "StableVITON: Learning Semantic Correspondence with Latent Diffusion Model for Virtual Try-On",
    "authors": [
      "Jeongho Kim",
      "Gyojung Gu",
      "Minho Park",
      "Sunghyun Park",
      "Jaegul Choo"
    ],
    "abstract": "Given a clothing image and a person image, an image-based virtual try-on aims to generate a customized image that appears natural and accurately reflects the characteristics of the clothing image. In this work, we aim to expand the applicability of the pre-trained diffusion model so that it can be utilized independently for the virtual try-on task.The main challenge is to preserve the clothing details while effectively utilizing the robust generative capability of the pre-trained model. In order to tackle these issues, we propose StableVITON, learning the semantic correspondence between the clothing and the human body within the latent space of the pre-trained diffusion model in an end-to-end manner. Our proposed zero cross-attention blocks not only preserve the clothing details by learning the semantic correspondence but also generate high-fidelity images by utilizing the inherent knowledge of the pre-trained model in the warping process. Through our proposed novel attention total variation loss and applying augmentation, we achieve the sharp attention map, resulting in a more precise representation of clothing details. StableVITON outperforms the baselines in qualitative and quantitative evaluation, showing promising quality in arbitrary person images. Our code is available at https://github.com/rlawjdghek/StableVITON.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01725"
  },
  "2312.01721": {
    "title": "The Self-Loop Paradox: Investigating the Impact of Self-Loops on Graph Neural Networks",
    "authors": [
      "Moritz Lampert",
      "Ingo Scholtes"
    ],
    "abstract": "Many Graph Neural Networks (GNNs) add self-loops to a graph to include feature information about a node itself at each layer. However, if the GNN consists of more than one layer, this information can return to its origin via cycles in the graph topology. Intuition suggests that this \"backflow\" of information should be larger in graphs with self-loops compared to graphs without. In this work, we counter this intuition and show that for certain GNN architectures, the information a node gains from itself can be smaller in graphs with self-loops compared to the same graphs without. We adopt an analytical approach for the study of statistical graph ensembles with a given degree sequence and show that this phenomenon, which we call the self-loop paradox, can depend both on the number of GNN layers $k$ and whether $k$ is even or odd. We experimentally validate our theoretical findings in a synthetic node classification task and investigate its practical relevance in 23 real-world graphs.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01721"
  },
  "2312.01720": {
    "title": "Secure-ISAC: Secure V2X Communication: An Integrated Sensing and Communication Perspective",
    "authors": [
      "Kan Yu",
      "Zhiyong Feng",
      "Dong Li",
      "Jiguo Yu"
    ],
    "abstract": "In Vehicle-to-Everything (V2X) systems, reliable and secure information exchange plays a pivotal role in road safety and traffic management. Due to the open nature of the wireless medium and the constant or intermittent mobility of vehicles, the security of transmissions in V2X is more challenging compared to traditional wireless networks. Physical layer security (PLS) leverages the inherent randomness of wireless communication channels to ensure the confidentiality and security of information transmission. Current PLS schemes in integrated communications and sensing (ISAC) enabled V2X systems is to utilize communication interference to significantly impact the eavesdropping channel more than the legitimate channel. However, in an ISAC-enabled V2X system, it is crucial to prioritize and address the issue of interference coupling as it significantly impacts the confidentiality and security of information exchange. This goes beyond simply relying on the communication interference. Until now, no discussions or studies on integrating security with ISAC (Seucue-ISAC) in ISAC-enabled V2X systems, specifically regarding the exploitation of sensing interference or coupling interference. In this article, we provide a comprehensive review on PLS metrics and security threats encountered in V2X communication. And then, we discuss and analyze four popular PLS techniques and the main challenges associated with their implementation in ISAC-enabled V2X systems. Finally, we share our vision for PLS studies in ISAC-based V2X systems to promote Secure-ISAC.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01720"
  },
  "2312.01713": {
    "title": "Disentangled Interaction Representation for One-Stage Human-Object Interaction Detection",
    "authors": [
      "Xubin Zhong",
      "Changxing Ding",
      "Yupeng Hu",
      "Dacheng Tao"
    ],
    "abstract": "Human-Object Interaction (HOI) detection is a core task for human-centric image understanding. Recent one-stage methods adopt a transformer decoder to collect image-wide cues that are useful for interaction prediction; however, the interaction representations obtained using this method are entangled and lack interpretability. In contrast, traditional two-stage methods benefit significantly from their ability to compose interaction features in a disentangled and explainable manner. In this paper, we improve the performance of one-stage methods by enabling them to extract disentangled interaction representations. First, we propose Shunted Cross-Attention (SCA) to extract human appearance, object appearance, and global context features using different cross-attention heads. This is achieved by imposing different masks on the cross-attention maps produced by the different heads. Second, we introduce the Interaction-aware Pose Estimation (IPE) task to learn interaction-relevant human pose features using a disentangled decoder. This is achieved with a novel attention module that accurately captures the human keypoints relevant to the current interaction category. Finally, our approach fuses the appearance feature and pose feature via element-wise addition to form the interaction representation. Experimental results show that our approach can be readily applied to existing one-stage HOI detectors. Moreover, we achieve state-of-the-art performance on two benchmarks: HICO-DET and V-COCO.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01713"
  },
  "2312.01712": {
    "title": "JUNO: Optimizing High-Dimensional Approximate Nearest Neighbour Search with Sparsity-Aware Algorithm and Ray-Tracing Core Mapping",
    "authors": [
      "Zihan Liu",
      "Wentao Ni",
      "Jingwen Leng",
      "Yu Feng",
      "Cong Guo",
      "Quan Chen",
      "Chao Li",
      "Minyi Guo",
      "Yuhao Zhu"
    ],
    "abstract": "Approximate nearest neighbor (ANN) search is a widely applied technique in modern intelligent applications, such as recommendation systems and vector databases. Therefore, efficient and high-throughput execution of ANN search has become increasingly important. In this paper, we first characterize the state-of-the-art product quantization-based method of ANN search and identify a significant source of inefficiency in the form of unnecessary pairwise distance calculations and accumulations. To improve efficiency, we propose JUNO, an end-to-end ANN search system that adopts a carefully designed sparsity- and locality-aware search algorithm. We also present an efficient hardware mapping that utilizes ray tracing cores in modern GPUs with pipelined execution on tensor cores to execute our sparsity-aware ANN search algorithm. Our evaluations on four datasets ranging in size from 1 to 100 million search points demonstrate 2.2x-8.5x improvements in search throughput. Moreover, our algorithmic enhancements alone achieve a maximal 2.6x improvement on the hardware without the acceleration of the RT core.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01712"
  },
  "2312.01711": {
    "title": "Regressor-Segmenter Mutual Prompt Learning for Crowd Counting",
    "authors": [
      "Mingyue Guo",
      "Li Yuan",
      "Zhaoyi Yan",
      "Binghui Chen",
      "Yaowei Wang",
      "Qixiang Ye"
    ],
    "abstract": "Crowd counting has achieved significant progress by training regressors to predict instance positions. In heavily crowded scenarios, however, regressors are challenged by uncontrollable annotation variance, which causes density map bias and context information inaccuracy. In this study, we propose mutual prompt learning (mPrompt), which leverages a regressor and a segmenter as guidance for each other, solving bias and inaccuracy caused by annotation variance while distinguishing foreground from background. In specific, mPrompt leverages point annotations to tune the segmenter and predict pseudo head masks in a way of point prompt learning. It then uses the predicted segmentation masks, which serve as spatial constraint, to rectify biased point annotations as context prompt learning. mPrompt defines a way of mutual information maximization from prompt learning, mitigating the impact of annotation variance while improving model accuracy. Experiments show that mPrompt significantly reduces the Mean Average Error (MAE), demonstrating the potential to be general framework for down-stream vision tasks.\n        \u25b3 Less",
    "submission_date": "3 January, 2024",
    "eprint_id": "2312.01711"
  },
  "2312.01707": {
    "title": "Perceptual Dimensions of Physical Properties of Handheld Objects Induced by Impedance Changes",
    "authors": [
      "Takeru Hashimoto",
      "Shigeo Yoshida",
      "Takuji Narumi"
    ],
    "abstract": "Haptics in virtual reality is the emerging dimension after audiovisual experiences. Researchers designed several handheld VR controllers to simulate haptic experiences in virtual reality environments. Some of these devices, equipped to deliver active force, can dynamically alter the timing and intensity of force feedback, potentially offering a wide array of haptic sensations. Past research primarily used a single index to evaluate how users perceive physical property parameters, potentially limiting the assessment to the designer's intended scope and neglecting other potential perceptual experiences.\n  Therefore, this study evaluates not how much but how humans feel a physical property when stimuli are changed. We conducted interviews to investigate how people feel when a haptic device changes motion impedance. We used thematic analysis to abstract the results of the interviews and gain an understanding of how humans attribute force feedback to a phenomenon. We also generated a vocabulary from the themes obtained from the interviews and asked users to evaluate force feedback using the semantic difference method. A factor analysis was used to investigate how changing the basic elements of motion, such as inertia, viscosity, and stiffness of the motion system, affects haptic perception. As a result, we obtained four critical factors: size, viscosity, weight, and flexibility factor, and clarified the correspondence between these factors and the change of impedance.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01707"
  },
  "2312.01701": {
    "title": "Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites",
    "authors": [
      "Lei Wang",
      "Jiabang He",
      "Shenshen Li",
      "Ning Liu",
      "Ee-Peng Lim"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance in natural language processing (NLP) tasks. To comprehend and execute diverse human instructions over image data, instruction-tuned large vision-language models (LVLMs) have been introduced. However, LVLMs may suffer from different types of object hallucinations. Nevertheless, LVLMs are evaluated for coarse-grained object hallucinations only (i.e., generated objects non-existent in the input image). The fine-grained object attributes and behaviors non-existent in the image may still be generated but not measured by the current evaluation methods. In this paper, we thus focus on reducing fine-grained hallucinations of LVLMs. We propose \\textit{ReCaption}, a framework that consists of two components: rewriting captions using ChatGPT and fine-tuning the instruction-tuned LVLMs on the rewritten captions. We also propose a fine-grained probing-based evaluation method named \\textit{Fine-Grained Object Hallucination Evaluation} (\\textit{FGHE}). Our experiment results demonstrate that ReCaption effectively reduces fine-grained object hallucination for different LVLM options and improves their text generation quality. The code can be found at https://github.com/Anonymousanoy/FOHE.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01701"
  },
  "2312.01699": {
    "title": "Rethinking Urban Mobility Prediction: A Super-Multivariate Time Series Forecasting Approach",
    "authors": [
      "Jinguo Cheng",
      "Ke Li",
      "Yuxuan Liang",
      "Lijun Sun",
      "Junchi Yan",
      "Yuankai Wu"
    ],
    "abstract": "Long-term urban mobility predictions play a crucial role in the effective management of urban facilities and services. Conventionally, urban mobility data has been structured as spatiotemporal videos, treating longitude and latitude grids as fundamental pixels. Consequently, video prediction methods, relying on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs), have been instrumental in this domain. In our research, we introduce a fresh perspective on urban mobility prediction. Instead of oversimplifying urban mobility data as traditional video data, we regard it as a complex multivariate time series. This perspective involves treating the time-varying values of each grid in each channel as individual time series, necessitating a thorough examination of temporal dynamics, cross-variable correlations, and frequency-domain insights for precise and reliable predictions. To address this challenge, we present the Super-Multivariate Urban Mobility Transformer (SUMformer), which utilizes a specially designed attention mechanism to calculate temporal and cross-variable correlations and reduce computational costs stemming from a large number of time series. SUMformer also employs low-frequency filters to extract essential information for long-term predictions. Furthermore, SUMformer is structured with a temporal patch merge mechanism, forming a hierarchical framework that enables the capture of multi-scale correlations. Consequently, it excels in urban mobility pattern modeling and long-term prediction, outperforming current state-of-the-art methods across three real-world datasets.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01699"
  },
  "2312.01692": {
    "title": "Risk-Controlling Model Selection via Guided Bayesian Optimization",
    "authors": [
      "Bracha Laufer-Goldshtein",
      "Adam Fisch",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "abstract": "Adjustable hyperparameters of machine learning models typically impact various key trade-offs such as accuracy, fairness, robustness, or inference cost. Our goal in this paper is to find a configuration that adheres to user-specified limits on certain risks while being useful with respect to other conflicting metrics. We solve this by combining Bayesian Optimization (BO) with rigorous risk-controlling procedures, where our core idea is to steer BO towards an efficient testing strategy. Our BO method identifies a set of Pareto optimal configurations residing in a designated region of interest. The resulting candidates are statistically verified and the best-performing configuration is selected with guaranteed risk levels. We demonstrate the effectiveness of our approach on a range of tasks with multiple desiderata, including low error rates, equitable predictions, handling spurious correlations, managing rate and distortion in generative models, and reducing computational costs.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01692"
  },
  "2312.01691": {
    "title": "Estimating Coronal Mass Ejection Mass and Kinetic Energy by Fusion of Multiple Deep-learning Models",
    "authors": [
      "Khalid A. Alobaid",
      "Yasser Abduallah",
      "Jason T. L. Wang",
      "Haimin Wang",
      "Shen Fan",
      "Jialiang Li",
      "Huseyin Cavus",
      "Vasyl Yurchyshyn"
    ],
    "abstract": "Coronal mass ejections (CMEs) are massive solar eruptions, which have a significant impact on Earth. In this paper, we propose a new method, called DeepCME, to estimate two properties of CMEs, namely, CME mass and kinetic energy. Being able to estimate these properties helps better understand CME dynamics. Our study is based on the CME catalog maintained at the Coordinated Data Analysis Workshops (CDAW) Data Center, which contains all CMEs manually identified since 1996 using the Large Angle and Spectrometric Coronagraph (LASCO) on board the Solar and Heliospheric Observatory (SOHO). We use LASCO C2 data in the period between January 1996 and December 2020 to train, validate and test DeepCME through 10-fold cross validation. The DeepCME method is a fusion of three deep learning models, including ResNet, InceptionNet, and InceptionResNet. Our fusion model extracts features from LASCO C2 images, effectively combining the learning capabilities of the three component models to jointly estimate the mass and kinetic energy of CMEs. Experimental results show that the fusion model yields a mean relative error (MRE) of 0.013 (0.009, respectively) compared to the MRE of 0.019 (0.017, respectively) of the best component model InceptionResNet (InceptionNet, respectively) in estimating the CME mass (kinetic energy, respectively). To our knowledge, this is the first time that deep learning has been used for CME mass and kinetic energy estimations.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01691"
  },
  "2312.01689": {
    "title": "Fast and accurate sparse-view CBCT reconstruction using meta-learned neural attenuation field and hash-encoding regularization",
    "authors": [
      "Heejun Shin",
      "Taehee Kim",
      "Jongho Lee",
      "Se Young Chun",
      "Seungryung Cho",
      "Dongmyung Shin"
    ],
    "abstract": "Cone beam computed tomography (CBCT) is an emerging medical imaging technique to visualize the internal anatomical structures of patients. During a CBCT scan, several projection images of different angles or views are collectively utilized to reconstruct a tomographic image. However, reducing the number of projections in a CBCT scan while preserving the quality of a reconstructed image is challenging due to the nature of an ill-posed inverse problem. Recently, a neural attenuation field (NAF) method was proposed by adopting a neural radiance field algorithm as a new way for CBCT reconstruction, demonstrating fast and promising results using only 50 views. However, decreasing the number of projections is still preferable to reduce potential radiation exposure, and a faster reconstruction time is required considering a typical scan time. In this work, we propose a fast and accurate sparse-view CBCT reconstruction (FACT) method to provide better reconstruction quality and faster optimization speed in the minimal number of view acquisitions ($<$ 50 views). In the FACT method, we meta-trained a neural network and a hash-encoder using a few scans (= 15), and a new regularization technique is utilized to reconstruct the details of an anatomical structure. In conclusion, we have shown that the FACT method produced better, and faster reconstruction results over the other conventional algorithms based on CBCT scans of different body parts (chest, head, and abdomen) and CT vendors (Siemens, Phillips, and GE).\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2312.01689"
  },
  "2312.01688": {
    "title": "Tab-Attention: Self-Attention-based Stacked Generalization for Imbalanced Credit Default Prediction",
    "authors": [
      "Yandan Tan",
      "Hongbin Zhu",
      "JieWu",
      "Hongfeng Chai"
    ],
    "abstract": "Accurately credit default prediction faces challenges due to imbalanced data and low correlation between features and labels. Existing default prediction studies on the basis of gradient boosting decision trees (GBDT), deep learning techniques, and feature selection strategies can have varying degrees of success depending on the specific task. Motivated by this, we propose Tab-Attention, a novel self-attention-based stacked generalization method for credit default prediction. This approach ensembles the potential proprietary knowledge contributions from multi-view feature spaces, to cope with low feature correlation and imbalance. We organize multi-view feature spaces according to the latent linear or nonlinear strengths between features and labels. Meanwhile, the f1 score assists the model in imbalance training to find the optimal state for identifying minority default samples. Our Tab-Attention achieves superior Recall_1 and f1_1 of default intention recognition than existing GBDT-based models and advanced deep learning by about 32.92% and 16.05% on average, respectively, while maintaining outstanding overall performance and prediction performance for non-default samples. The proposed method could ensemble essential knowledge through the self-attention mechanism, which is of great significance for a more robust future prediction system.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01688"
  },
  "2312.01687": {
    "title": "Optimizing Bus Travel: A Novel Approach to Feature Mining with P-KMEANS and P-LDA Algorithms",
    "authors": [
      "Hongjie Liu",
      "Haotian Shi",
      "Sicheng Fu",
      "Tengfei Yuan",
      "Xinhuan Zhang",
      "Hongzhe Xu",
      "Bin Ran"
    ],
    "abstract": "Customizing services for bus travel can bolster its attractiveness, optimize usage, alleviate traffic congestion, and diminish carbon emissions. This potential is realized by harnessing recent advancements in positioning communication facilities, the Internet of Things, and artificial intelligence for feature mining in public transportation. However, the inherent complexities of disorganized and unstructured public transportation data introduce substantial challenges to travel feature extraction. This study presents a bus travel feature extraction method rooted in Point of Interest (POI) data, employing enhanced P-KMENAS and P-LDA algorithms to overcome these limitations. While the KMEANS algorithm adeptly segments passenger travel paths into distinct clusters, its outcomes can be influenced by the initial K value. On the other hand, Latent Dirichlet Allocation (LDA) excels at feature identification and probabilistic interpretations yet encounters difficulties with feature intermingling and nuanced sub-feature interactions. Incorporating the POI dimension enhances our understanding of travel behavior, aligning it more closely with passenger attributes and facilitating easier data analysis. By incorporating POI data, our refined P-KMENAS and P-LDA algorithms grant a holistic insight into travel behaviors and attributes, effectively mitigating the limitations above. Consequently, this POI-centric algorithm effectively amalgamates diverse POI attributes, delineates varied travel contexts, and imparts probabilistic metrics to feature properties. Our method successfully mines the diverse aspects of bus travel, such as age, occupation, gender, sports, cost, safety, and personality traits. It effectively calculates relationships between individual travel behaviors and assigns explanatory and evaluative probabilities to POI labels, thereby enhancing bus travel optimization.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01687"
  },
  "2312.01682": {
    "title": "ResEnsemble-DDPM: Residual Denoising Diffusion Probabilistic Models for Ensemble Learning",
    "authors": [
      "Shi Zhenning",
      "Dong Changsheng",
      "Xie Xueshuo",
      "Pan Bin",
      "He Along",
      "Li Tao"
    ],
    "abstract": "Nowadays, denoising diffusion probabilistic models have been adapted for many image segmentation tasks. However, existing end-to-end models have already demonstrated remarkable capabilities. Rather than using denoising diffusion probabilistic models alone, integrating the abilities of both denoising diffusion probabilistic models and existing end-to-end models can better improve the performance of image segmentation. Based on this, we implicitly introduce residual term into the diffusion process and propose ResEnsemble-DDPM, which seamlessly integrates the diffusion model and the end-to-end model through ensemble learning. The output distributions of these two models are strictly symmetric with respect to the ground truth distribution, allowing us to integrate the two models by reducing the residual term. Experimental results demonstrate that our ResEnsemble-DDPM can further improve the capabilities of existing models. Furthermore, its ensemble learning strategy can be generalized to other downstream tasks in image generation and get strong competitiveness.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01682"
  },
  "2312.01681": {
    "title": "Malicious Lateral Movement in 5G Core With Network Slicing And Its Detection",
    "authors": [
      "Ayush Kumar",
      "Vrizlynn L. L. Thing"
    ],
    "abstract": "5G networks are susceptible to cyber attacks due to reasons such as implementation issues and vulnerabilities in 3GPP standard specifications. In this work, we propose lateral movement strategies in a 5G Core (5GC) with network slicing enabled, as part of a larger attack campaign by well-resourced adversaries such as APT groups. Further, we present 5GLatte, a system to detect such malicious lateral movement. 5GLatte operates on a host-container access graph built using host/NF container logs collected from the 5GC. Paths inferred from the access graph are scored based on selected filtering criteria and subsequently presented as input to a threshold-based anomaly detection algorithm to reveal malicious lateral movement paths. We evaluate 5GLatte on a dataset containing attack campaigns (based on MITRE ATT&CK and FiGHT frameworks) launched in a 5G test environment which shows that compared to other lateral movement detectors based on state-of-the-art, it can achieve higher true positive rates with similar false positive rates.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01681"
  },
  "2312.01680": {
    "title": "With Great Humor Comes Great Developer Engagement",
    "authors": [
      "Deepika Tiwari",
      "Tim Toady",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "abstract": "The worldwide collaborative effort for the creation of software is technically and socially demanding. The more engaged developers are, the more value they impart to the software they create. Engaged developers, such as Margaret Hamilton programming Apollo 11, can succeed in tackling the most difficult engineering tasks. In this paper, we dive deep into an original vector of engagement - humor - and study how it fuels developer engagement. First, we collect qualitative and quantitative data about the humorous elements present within three significant, real-world software projects: faker, which helps developers introduce humor within their tests; lolcommits, which captures a photograph after each contribution made by a developer; and volkswagen, an exercise in satire, which accidentally led to the invention of an impactful software tool. Second, through a developer survey, we receive unique insights from 125 developers, who share their real-life experiences with humor in software. Our analysis of the three case studies highlights the prevalence of humor in software, and unveils the worldwide community of developers who are enthusiastic about both software and humor. We also learn about the caveats of humor in software through the valuable insights shared by our survey respondents. We report clear evidence that, when practiced responsibly, humor increases developer engagement and supports them in addressing hard engineering and cognitive tasks. The most actionable highlight of our work is that software tests and documentation are the best locations in code to practice humor.\n        \u25b3 Less",
    "submission_date": "16 January, 2024",
    "eprint_id": "2312.01680"
  },
  "2312.01679": {
    "title": "Adversarial Medical Image with Hierarchical Feature Hiding",
    "authors": [
      "Qingsong Yao",
      "Zecheng He",
      "Yuexiang Li",
      "Yi Lin",
      "Kai Ma",
      "Yefeng Zheng",
      "S. Kevin Zhou"
    ],
    "abstract": "Deep learning based methods for medical images can be easily compromised by adversarial examples (AEs), posing a great security flaw in clinical decision-making. It has been discovered that conventional adversarial attacks like PGD which optimize the classification logits, are easy to distinguish in the feature space, resulting in accurate reactive defenses. To better understand this phenomenon and reassess the reliability of the reactive defenses for medical AEs, we thoroughly investigate the characteristic of conventional medical AEs. Specifically, we first theoretically prove that conventional adversarial attacks change the outputs by continuously optimizing vulnerable features in a fixed direction, thereby leading to outlier representations in the feature space. Then, a stress test is conducted to reveal the vulnerability of medical images, by comparing with natural images. Interestingly, this vulnerability is a double-edged sword, which can be exploited to hide AEs. We then propose a simple-yet-effective hierarchical feature constraint (HFC), a novel add-on to conventional white-box attacks, which assists to hide the adversarial feature in the target feature distribution. The proposed method is evaluated on three medical datasets, both 2D and 3D, with different modalities. The experimental results demonstrate the superiority of HFC, \\emph{i.e.,} it bypasses an array of state-of-the-art adversarial medical AE detectors more efficiently than competing adaptive attacks, which reveals the deficiencies of medical reactive defense and allows to develop more robust defenses in future.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01679"
  },
  "2312.01674": {
    "title": "EDALearn: A Comprehensive RTL-to-Signoff EDA Benchmark for Democratized and Reproducible ML for EDA Research",
    "authors": [
      "Jingyu Pan",
      "Chen-Chia Chang",
      "Zhiyao Xie",
      "Yiran Chen"
    ],
    "abstract": "The application of Machine Learning (ML) in Electronic Design Automation (EDA) for Very Large-Scale Integration (VLSI) design has garnered significant research attention. Despite the requirement for extensive datasets to build effective ML models, most studies are limited to smaller, internally generated datasets due to the lack of comprehensive public resources. In response, we introduce EDALearn, the first holistic, open-source benchmark suite specifically for ML tasks in EDA. This benchmark suite presents an end-to-end flow from synthesis to physical implementation, enriching data collection across various stages. It fosters reproducibility and promotes research into ML transferability across different technology nodes. Accommodating a wide range of VLSI design instances and sizes, our benchmark aptly represents the complexity of contemporary VLSI designs. Additionally, we provide an in-depth data analysis, enabling users to fully comprehend the attributes and distribution of our data, which is essential for creating efficient ML models. Our contributions aim to encourage further advances in the ML-EDA domain.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01674"
  },
  "2312.01672": {
    "title": "STADEE: STAtistics-based DEEp Detection of Machine Generated Text",
    "authors": [
      "Zheng Chen",
      "Huming Liu"
    ],
    "abstract": "We present STADEE, a \\textbf{STA}tistics-based \\textbf{DEE}p detection method to identify machine-generated text, addressing the limitations of current methods that rely heavily on fine-tuning pre-trained language models (PLMs). STADEE integrates key statistical text features with a deep classifier, focusing on aspects like token probability and cumulative probability, crucial for handling nucleus sampling. Tested across diverse datasets and scenarios (in-domain, out-of-domain, and in-the-wild), STADEE demonstrates superior performance, achieving an 87.05% F1 score in-domain and outperforming both traditional statistical methods and fine-tuned PLMs, especially in out-of-domain and in-the-wild settings, highlighting its effectiveness and generalizability.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01672"
  },
  "2312.01671": {
    "title": "Multimodality-guided Image Style Transfer using Cross-modal GAN Inversion",
    "authors": [
      "Hanyu Wang",
      "Pengxiang Wu",
      "Kevin Dela Rosa",
      "Chen Wang",
      "Abhinav Shrivastava"
    ],
    "abstract": "Image Style Transfer (IST) is an interdisciplinary topic of computer vision and art that continuously attracts researchers' interests. Different from traditional Image-guided Image Style Transfer (IIST) methods that require a style reference image as input to define the desired style, recent works start to tackle the problem in a text-guided manner, i.e., Text-guided Image Style Transfer (TIST). Compared to IIST, such approaches provide more flexibility with text-specified styles, which are useful in scenarios where the style is hard to define with reference images. Unfortunately, many TIST approaches produce undesirable artifacts in the transferred images. To address this issue, we present a novel method to achieve much improved style transfer based on text guidance. Meanwhile, to offer more flexibility than IIST and TIST, our method allows style inputs from multiple sources and modalities, enabling MultiModality-guided Image Style Transfer (MMIST). Specifically, we realize MMIST with a novel cross-modal GAN inversion method, which generates style representations consistent with specified styles. Such style representations facilitate style transfer and in principle generalize any IIST methods to MMIST. Large-scale experiments and user studies demonstrate that our method achieves state-of-the-art performance on TIST task. Furthermore, comprehensive qualitative results confirm the effectiveness of our method on MMIST task and cross-modal style interpolation.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01671"
  },
  "2312.01669": {
    "title": "Analyze Drivers' Intervention Behavior During Autonomous Driving -- A VR-incorporated Approach",
    "authors": [
      "Zheng Xu"
    ],
    "abstract": "Given the rapid advance in ITS technologies, future mobility is pointing to vehicular autonomy. However, there is still a long way before full automation, and human intervention is required. This work sheds light on understanding human drivers' intervention behavior involved in the operation of autonomous vehicles (AVs) and utilizes this knowledge to improve the perception of critical driving scenarios. Experiment environments were implemented where the virtual reality (VR) and traffic micro-simulation are integrated, and tests were carried out under typical and diverse traffic scenes. Performance indicators such as the probability of intervention, accident rates are defined and used to quantify and compare the risk levels. By offering novel insights into drivers' intervention behavior, this work will help improve the performances of the automated control under similar scenarios. Furthermore, such an integrated and immersive tool for autonomous driving studies will be valuable for research on human-to-automation trust. To the best knowledge of the authors, this work is among the pioneer works making efforts into such types of tools.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01669"
  },
  "2312.01663": {
    "title": "Customize your NeRF: Adaptive Source Driven 3D Scene Editing via Local-Global Iterative Training",
    "authors": [
      "Runze He",
      "Shaofei Huang",
      "Xuecheng Nie",
      "Tianrui Hui",
      "Luoqi Liu",
      "Jiao Dai",
      "Jizhong Han",
      "Guanbin Li",
      "Si Liu"
    ],
    "abstract": "In this paper, we target the adaptive source driven 3D scene editing task by proposing a CustomNeRF model that unifies a text description or a reference image as the editing prompt. However, obtaining desired editing results conformed with the editing prompt is nontrivial since there exist two significant challenges, including accurate editing of only foreground regions and multi-view consistency given a single-view reference image. To tackle the first challenge, we propose a Local-Global Iterative Editing (LGIE) training scheme that alternates between foreground region editing and full-image editing, aimed at foreground-only manipulation while preserving the background. For the second challenge, we also design a class-guided regularization that exploits class priors within the generation model to alleviate the inconsistency problem among different views in image-driven editing. Extensive experiments show that our CustomNeRF produces precise editing results under various real scenes for both text- and image-driven settings.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01663"
  },
  "2312.01662": {
    "title": "Universal Deoxidation of Semiconductor Substrates Assisted by Machine-Learning and Real-Time-Feedback-Control",
    "authors": [
      "Chao Shen",
      "Wenkang Zhan",
      "Jian Tang",
      "Zhaofeng Wu",
      "Bo Xu",
      "Chao Zhao",
      "Zhanguo Wang"
    ],
    "abstract": "Thin film deposition is an essential step in the semiconductor process. During preparation or loading, the substrate is exposed to the air unavoidably, which has motivated studies of the process control to remove the surface oxide before thin film deposition. Optimizing the deoxidation process in molecular beam epitaxy (MBE) for a random substrate is a multidimensional challenge and sometimes controversial. Due to variations in semiconductor materials and growth processes, the determination of substrate deoxidation temperature is highly dependent on the grower's expertise; the same substrate may yield inconsistent results when evaluated by different growers. Here, we employ a machine learning (ML) hybrid convolution and vision transformer (CNN-ViT) model. This model utilizes reflection high-energy electron diffraction (RHEED) video as input to determine the deoxidation status of the substrate as output, enabling automated substrate deoxidation under a controlled architecture. This also extends to the successful application of deoxidation processes on other substrates. Furthermore, we showcase the potential of models trained on data from a single MBE equipment to achieve high-accuracy deployment on other equipment. In contrast to traditional methods, our approach holds exceptional practical value. It standardizes deoxidation temperatures across various equipment and substrate materials, advancing the standardization research process in semiconductor preparation, a significant milestone in thin film growth technology. The concepts and methods demonstrated in this work are anticipated to revolutionize semiconductor manufacturing in optoelectronics and microelectronics industries by applying them to diverse material growth processes.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01662"
  },
  "2312.01658": {
    "title": "AGD: an Auto-switchable Optimizer using Stepwise Gradient Difference for Preconditioning Matrix",
    "authors": [
      "Yun Yue",
      "Zhiling Ye",
      "Jiadi Jiang",
      "Yongchao Liu",
      "Ke Zhang"
    ],
    "abstract": "Adaptive optimizers, such as Adam, have achieved remarkable success in deep learning. A key component of these optimizers is the so-called preconditioning matrix, providing enhanced gradient information and regulating the step size of each gradient direction. In this paper, we propose a novel approach to designing the preconditioning matrix by utilizing the gradient difference between two successive steps as the diagonal elements. These diagonal elements are closely related to the Hessian and can be perceived as an approximation of the inner product between the Hessian row vectors and difference of the adjacent parameter vectors. Additionally, we introduce an auto-switching function that enables the preconditioning matrix to switch dynamically between Stochastic Gradient Descent (SGD) and the adaptive optimizer. Based on these two techniques, we develop a new optimizer named AGD that enhances the generalization performance. We evaluate AGD on public datasets of Natural Language Processing (NLP), Computer Vision (CV), and Recommendation Systems (RecSys). Our experimental results demonstrate that AGD outperforms the state-of-the-art (SOTA) optimizers, achieving highly competitive or significantly better predictive performance. Furthermore, we analyze how AGD is able to switch automatically between SGD and the adaptive optimizer and its actual effects on various scenarios. The code is available at https://github.com/intelligent-machine-learning/dlrover/tree/master/atorch/atorch/optimizers.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01658"
  },
  "2312.01657": {
    "title": "On Tuning Neural ODE for Stability, Consistency and Faster Convergence",
    "authors": [
      "Sheikh Waqas Akhtar"
    ],
    "abstract": "Neural-ODE parameterize a differential equation using continuous depth neural network and solve it using numerical ODE-integrator. These models offer a constant memory cost compared to models with discrete sequence of hidden layers in which memory cost increases linearly with the number of layers. In addition to memory efficiency, other benefits of neural-ode include adaptability of evaluation approach to input, and flexibility to choose numerical precision or fast training. However, despite having all these benefits, it still has some limitations. We identify the ODE-integrator (also called ODE-solver) as the weakest link in the chain as it may have stability, consistency and convergence (CCS) issues and may suffer from slower convergence or may not converge at all. We propose a first-order Nesterov's accelerated gradient (NAG) based ODE-solver which is proven to be tuned vis-a-vis CCS conditions. We empirically demonstrate the efficacy of our approach by training faster, while achieving better or comparable performance against neural-ode employing other fixed-step explicit ODE-solvers as well discrete depth models such as ResNet in three different tasks including supervised classification, density estimation, and time-series modelling.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01657"
  },
  "2312.01656": {
    "title": "The Contemporary Art of Image Search: Iterative User Intent Expansion via Vision-Language Model",
    "authors": [
      "Yilin Ye",
      "Qian Zhu",
      "Shishi Xiao",
      "Kang Zhang",
      "Wei Zeng"
    ],
    "abstract": "Image search is an essential and user-friendly method to explore vast galleries of digital images. However, existing image search methods heavily rely on proximity measurements like tag matching or image similarity, requiring precise user inputs for satisfactory results. To meet the growing demand for a contemporary image search engine that enables accurate comprehension of users' search intentions, we introduce an innovative user intent expansion framework. Our framework leverages visual-language models to parse and compose multi-modal user inputs to provide more accurate and satisfying results. It comprises two-stage processes: 1) a parsing stage that incorporates a language parsing module with large language models to enhance the comprehension of textual inputs, along with a visual parsing module that integrates an interactive segmentation module to swiftly identify detailed visual elements within images; and 2) a logic composition stage that combines multiple user search intents into a unified logic expression for more sophisticated operations in complex searching scenarios. Moreover, the intent expansion framework enables users to perform flexible contextualized interactions with the search results to further specify or adjust their detailed search intents iteratively. We implemented the framework into an image search system for NFT (non-fungible token) search and conducted a user study to evaluate its usability and novel properties. The results indicate that the proposed framework significantly improves users' image search experience. Particularly the parsing and contextualized interactions prove useful in allowing users to express their search intents more accurately and engage in a more enjoyable iterative search experience.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01656"
  },
  "2312.01653": {
    "title": "An End-to-End Network Pruning Pipeline with Sparsity Enforcement",
    "authors": [
      "Evan Dogariu"
    ],
    "abstract": "Neural networks have emerged as a powerful tool for solving complex tasks across various domains, but their increasing size and computational requirements have posed significant challenges in deploying them on resource-constrained devices. Neural network sparsification, and in particular pruning, has emerged as an effective technique to alleviate these challenges by reducing model size, computational complexity, and memory footprint while maintaining competitive performance. However, many pruning pipelines modify the standard training pipeline at only a single stage, if at all. In this work, we look to develop an end-to-end training pipeline that befits neural network pruning and sparsification at all stages of training. To do so, we make use of nonstandard model parameter initialization, pre-pruning training methodologies, and post-pruning training optimizations. We conduct experiments utilizing combinations of these methods, in addition to different techniques used in the pruning step, and find that our combined pipeline can achieve significant gains over current state of the art approaches to neural network sparsification.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01653"
  },
  "2312.01652": {
    "title": "On the Expressive Power of Behavior Structure",
    "authors": [
      "Cheng Wang",
      "Hangyu Zhu",
      "Yuhang Lin",
      "Changjun Jiang"
    ],
    "abstract": "Efforts toward a comprehensive description of behavior have indeed facilitated the development of representation-based approaches that utilize deep learning to capture behavioral information. As behavior complexity increases, the expressive power of these models reaches a bottleneck. We coin the term ``behavioral molecular structure\" and propose a new model called the Behavioral Molecular Structure (BMS). The model characterizes behaviors at the atomic level, analogizes behavioral attributes to atoms, and concretizes interrelations at the granularity of atoms using graphs. Here, we design three different downstream tasks to test the performance of the BMS model on public datasets. Additionally, we provide a preliminary theoretical analysis demonstrating that the BMS can offer effective expressiveness for complex behaviors.\n        \u25b3 Less",
    "submission_date": "29 December, 2023",
    "eprint_id": "2312.01652"
  },
  "2312.01650": {
    "title": "Adaptive Confidence Threshold for ByteTrack in Multi-Object Tracking",
    "authors": [
      "Linh Van Ma",
      "Muhammad Ishfaq Hussain",
      "JongHyun Park",
      "Jeongbae Kim",
      "Moongu Jeon"
    ],
    "abstract": "We investigate the application of ByteTrack in the realm of multiple object tracking. ByteTrack, a simple tracking algorithm, enables the simultaneous tracking of multiple objects by strategically incorporating detections with a low confidence threshold. Conventionally, objects are initially associated with high confidence threshold detections. When the association between objects and detections becomes ambiguous, ByteTrack extends the association to lower confidence threshold detections. One notable drawback of the existing ByteTrack approach is its reliance on a fixed threshold to differentiate between high and low-confidence detections. In response to this limitation, we introduce a novel and adaptive approach. Our proposed method entails a dynamic adjustment of the confidence threshold, leveraging insights derived from overall detections. Through experimentation, we demonstrate the effectiveness of our adaptive confidence threshold technique while maintaining running time compared to ByteTrack.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01650"
  },
  "2312.01645": {
    "title": "A text-dependent speaker verification application framework based on Chinese numerical string corpus",
    "authors": [
      "Litong Zheng",
      "Feng Hong",
      "Weijie Xu"
    ],
    "abstract": "Researches indicate that text-dependent speaker verification (TD-SV) often outperforms text-independent verification (TI-SV) in short speech scenarios. However, collecting large-scale fixed text speech data is challenging, and as speech length increases, factors like sentence rhythm and pauses affect TDSV's sensitivity to text sequence. Based on these factors, We propose the hypothesis that strategies such as more fine-grained pooling methods on time scales and decoupled representations of speech speaker embedding and text embedding are more suitable for TD-SV. We have introduced an end-to-end TD-SV system based on a dataset comprising longer Chinese numerical string texts. It contains a text embedding network, a speaker embedding network, and back-end fusion. First, we recorded a dataset consisting of long Chinese numerical text named SHAL, which is publicly available on the Open-SLR website. We addressed the issue of dataset scarcity by augmenting it using Tacotron2 and HiFi-GAN. Next, we introduced a dual representation of speech with text embedding and speaker embedding. In the text embedding network, we employed an enhanced Transformer and introduced a triple loss that includes text classification loss, CTC loss, and decoder loss. For the speaker embedding network, we enhanced a sliding window attentive statistics pooling (SWASP), combined with attentive statistics pooling (ASP) to create a multi-scale pooling method. Finally, we fused text embedding and speaker embedding. Our pooling methods achieved an equal error rate (EER) performance improvement of 49.2% on Hi-Mia and 75.0% on SHAL, respectively.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01645"
  },
  "2312.01644": {
    "title": "TMSR: Tiny Multi-path CNNs for Super Resolution",
    "authors": [
      "Chia-Hung Liu",
      "Tzu-Hsin Hsieh",
      "Kuan-Yu Huang",
      "Pei-Yin Chen"
    ],
    "abstract": "In this paper, we proposed a tiny multi-path CNN-based Super-Resolution (SR) method, called TMSR. We mainly refer to some tiny CNN-based SR methods, under 5k parameters. The main contribution of the proposed method is the improved multi-path learning and self-defined activated function. The experimental results show that TMSR obtains competitive image quality (i.e. PSNR and SSIM) compared to the related works under 5k parameters.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01644"
  },
  "2312.01643": {
    "title": "Enriching meta-analyses through scoping review, bibliometrics, and alternative impact metrics: Visualizing study characteristics, hidden risk of bias, societal influence, and research translation",
    "authors": [
      "Yefeng Yang",
      "Malgorzata Lagisz",
      "Shinichi Nakagawa"
    ],
    "abstract": "We present a framework consisting of three approaches that can enhance meta-analyses: 1) scoping reviews (evidence map), 2) bibliometrics, and 3) alternative impact metrics. These three \"enrichment\" approaches facilitate the research synthesis of both quantitative and qualitative evidence, along with academic and non-academic influences. While the meta-analysis yields quantitative insights (e.g., overall estimates), the enrichment analyses provide user-friendly summaries of qualitative information on the evidence base. Scoping reviews can visualize study characteristics, unravelling knowledge gaps and methodological differences. Bibliometric analysis offers a visual assessment of the non-independent evidence, such as hyper-dominant authors and countries, and funding sources, potentially informing the risk of bias. Impact metric analysis employs alternative metrics to gauge societal influence and research translation (e.g., policy and patent citations) of studies in the meta-analysis. To illustrate the application of this framework, we provide sample visualizations and R code.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01643"
  },
  "2312.01642": {
    "title": "Voice-Based Smart Assistant System for Vehicles using RASA",
    "authors": [
      "Aditya Paranjape",
      "Yash Patwardhan",
      "Vedant Deshpande",
      "Aniket Darp",
      "Jayashree Jagdale"
    ],
    "abstract": "Conversational AIs, or chatbots, mimic human speech when conversing. Smart assistants facilitate the automation of several tasks that needed human intervention earlier. Because of their accuracy, absence of dependence on human resources, and accessibility around the clock, chatbots can be employed in vehicles too. Due to people's propensity to divert their attention away from the task of driving while engaging in other activities like calling, playing music, navigation, and getting updates on the weather forecast and latest news, road safety has declined and accidents have increased as a result. It would be advantageous to automate these tasks using voice commands rather than carrying them out manually. This paper focuses on the development of a voice-based smart assistance application for vehicles based on the RASA framework. The smart assistant provides functionalities like navigation, communication via calls, getting weather forecasts and the latest news updates, and music that are completely voice-based in nature.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01642"
  },
  "2312.01641": {
    "title": "A fluid-particle decomposition approach to matching market design for crowdsourced delivery systems",
    "authors": [
      "Takashi Akamatsu",
      "Yuki Oyama"
    ],
    "abstract": "This paper considers a crowdsourced delivery (CSD) system that effectively utilizes the existing trips to fulfill parcel delivery as a matching problem between CSD drivers and delivery tasks. This matching problem has two major challenges. First, it is a large-scale combinatorial optimization problem that is hard to solve in a reasonable computational time. Second, the evaluation of the objective function for socially optimal matching contains the utility of drivers for performing the tasks, which is generally unobservable private information. To address these challenges, this paper proposes a hierarchical distribution mechanism of CSD tasks that decomposes the matching problem into the task partition (master problem) and individual task-driver matching within smaller groups of drivers (sub-problems). We incorporate an auction mechanism with truth-telling and efficiency into the sub-problems so that the drivers' perceived utilities are revealed through their bids. Furthermore, we formulate the master problem as a fluid model based on continuously approximated decision variables. By exploiting the random utility framework, we analytically represent the objective function of the problem using continuous variables, without explicitly knowing the drivers' utilities. The numerical experiment shows that the proposed approach solved large-scale matching problems at least 100 times faster than a naive LP solver and approximated the original objective value with errors of less than 1%.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01641"
  },
  "2312.01640": {
    "title": "SequencePAR: Understanding Pedestrian Attributes via A Sequence Generation Paradigm",
    "authors": [
      "Jiandong Jin",
      "Xiao Wang",
      "Chenglong Li",
      "Lili Huang",
      "Jin Tang"
    ],
    "abstract": "Current pedestrian attribute recognition (PAR) algorithms are developed based on multi-label or multi-task learning frameworks, which aim to discriminate the attributes using specific classification heads. However, these discriminative models are easily influenced by imbalanced data or noisy samples. Inspired by the success of generative models, we rethink the pedestrian attribute recognition scheme and believe the generative models may perform better on modeling dependencies and complexity between human attributes. In this paper, we propose a novel sequence generation paradigm for pedestrian attribute recognition, termed SequencePAR. It extracts the pedestrian features using a pre-trained CLIP model and embeds the attribute set into query tokens under the guidance of text prompts. Then, a Transformer decoder is proposed to generate the human attributes by incorporating the visual features and attribute query tokens. The masked multi-head attention layer is introduced into the decoder module to prevent the model from remembering the next attribute while making attribute predictions during training. Extensive experiments on multiple widely used pedestrian attribute recognition datasets fully validated the effectiveness of our proposed SequencePAR. The source code and pre-trained models will be released at https://github.com/Event-AHU/OpenPAR.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01640"
  },
  "2312.01638": {
    "title": "J-Net: Improved U-Net for Terahertz Image Super-Resolution",
    "authors": [
      "Woon-Ha Yeo",
      "Seung-Hwan Jung",
      "Seung Jae Oh",
      "Inhee Maeng",
      "Eui Su Lee",
      "Han-Cheol Ryu"
    ],
    "abstract": "Terahertz (THz) waves are electromagnetic waves in the 0.1 to 10 THz frequency range, and THz imaging is utilized in a range of applications, including security inspections, biomedical fields, and the non-destructive examination of materials. However, THz images have low resolution due to the long wavelength of THz waves. Therefore, improving the resolution of THz images is one of the current hot research topics. We propose a novel network architecture called J-Net which is improved version of U-Net to solve the THz image super-resolution. It employs the simple baseline blocks which can extract low resolution (LR) image features and learn the mapping of LR images to highresolution (HR) images efficiently. All training was conducted using the DIV2K+Flickr2K dataset, and we employed the peak signal-to-noise ratio (PSNR) for quantitative comparison. In our comparisons with other THz image super-resolution methods, JNet achieved a PSNR of 32.52 dB, surpassing other techniques by more than 1 dB. J-Net also demonstrates superior performance on real THz images compared to other methods. Experiments show that the proposed J-Net achieves better PSNR and visual improvement compared with other THz image super-resolution methods.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01638"
  },
  "2312.01634": {
    "title": "Robust Streaming, Sampling, and a Perspective on Online Learning",
    "authors": [
      "Evan Dogariu",
      "Jiatong Yu"
    ],
    "abstract": "In this work we present an overview of statistical learning, followed by a survey of robust streaming techniques and challenges, culminating in several rigorous results proving the relationship that we motivate and hint at throughout the journey. Furthermore, we unify often disjoint theorems in a shared framework and notation to clarify the deep connections that are discovered. We hope that by approaching these results from a shared perspective, already aware of the technical connections that exist, we can enlighten the study of both fields and perhaps motivate new and previously unconsidered directions of research.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01634"
  },
  "2312.01631": {
    "title": "Cooperative vs. Teleoperation Control of the Steady Hand Eye Robot with Adaptive Sclera Force Control: A Comparative Study",
    "authors": [
      "Mojtaba Esfandiari",
      "Ji Woong Kim",
      "Botao Zhao",
      "Golchehr Amirkhani",
      "Muhammad Hadi",
      "Peter Gehlbach",
      "Russell H. Taylor",
      "Iulian Iordachita"
    ],
    "abstract": "A surgeon's physiological hand tremor can significantly impact the outcome of delicate and precise retinal surgery, such as retinal vein cannulation (RVC) and epiretinal membrane peeling. Robot-assisted eye surgery technology provides ophthalmologists with advanced capabilities such as hand tremor cancellation, hand motion scaling, and safety constraints that enable them to perform these otherwise challenging and high-risk surgeries with high precision and safety. Steady-Hand Eye Robot (SHER) with cooperative control mode can filter out surgeon's hand tremor, yet another important safety feature, that is, minimizing the contact force between the surgical instrument and sclera surface for avoiding tissue damage cannot be met in this control mode. Also, other capabilities, such as hand motion scaling and haptic feedback, require a teleoperation control framework. In this work, for the first time, we implemented a teleoperation control mode incorporated with an adaptive sclera force control algorithm using a PHANTOM Omni haptic device and a force-sensing surgical instrument equipped with Fiber Bragg Grating (FBG) sensors attached to the SHER 2.1 end-effector. This adaptive sclera force control algorithm allows the robot to dynamically minimize the tool-sclera contact force. Moreover, for the first time, we compared the performance of the proposed adaptive teleoperation mode with the cooperative mode by conducting a vessel-following experiment inside an eye phantom under a microscope.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01631"
  },
  "2312.01624": {
    "title": "GVFs in the Real World: Making Predictions Online for Water Treatment",
    "authors": [
      "Muhammad Kamran Janjua",
      "Haseeb Shah",
      "Martha White",
      "Erfan Miahi",
      "Marlos C. Machado",
      "Adam White"
    ],
    "abstract": "In this paper we investigate the use of reinforcement-learning based prediction approaches for a real drinking-water treatment plant. Developing such a prediction system is a critical step on the path to optimizing and automating water treatment. Before that, there are many questions to answer about the predictability of the data, suitable neural network architectures, how to overcome partial observability and more. We first describe this dataset, and highlight challenges with seasonality, nonstationarity, partial observability, and heterogeneity across sensors and operation modes of the plant. We then describe General Value Function (GVF) predictions -- discounted cumulative sums of observations -- and highlight why they might be preferable to classical n-step predictions common in time series prediction. We discuss how to use offline data to appropriately pre-train our temporal difference learning (TD) agents that learn these GVF predictions, including how to select hyperparameters for online fine-tuning in deployment. We find that the TD-prediction agent obtains an overall lower normalized mean-squared error than the n-step prediction agent. Finally, we show the importance of learning in deployment, by comparing a TD agent trained purely offline with no online updating to a TD agent that learns online. This final result is one of the first to motivate the importance of adapting predictions in real-time, for non-stationary high-volume systems in the real world.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01624"
  },
  "2312.01623": {
    "title": "Universal Segmentation at Arbitrary Granularity with Language Instruction",
    "authors": [
      "Yong Liu",
      "Cairong Zhang",
      "Yitong Wang",
      "Jiahao Wang",
      "Yujiu Yang",
      "Yansong Tang"
    ],
    "abstract": "This paper aims to achieve universal segmentation of arbitrary semantic level. Despite significant progress in recent years, specialist segmentation approaches are limited to specific tasks and data distribution. Retraining a new model for adaptation to new scenarios or settings takes expensive computation and time cost, which raises the demand for versatile and universal segmentation model that can cater to various granularity. Although some attempts have been made for unifying different segmentation tasks or generalization to various scenarios, limitations in the definition of paradigms and input-output spaces make it difficult for them to achieve accurate understanding of content at arbitrary granularity. To this end, we present UniLSeg, a universal segmentation model that can perform segmentation at any semantic level with the guidance of language instructions. For training UniLSeg, we reorganize a group of tasks from original diverse distributions into a unified data format, where images with texts describing segmentation targets as input and corresponding masks are output. Combined with a automatic annotation engine for utilizing numerous unlabeled data, UniLSeg achieves excellent performance on various tasks and settings, surpassing both specialist and unified segmentation models.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.01623"
  },
  "2312.01617": {
    "title": "Heroes: Lightweight Federated Learning with Neural Composition and Adaptive Local Update in Heterogeneous Edge Networks",
    "authors": [
      "Jiaming Yan",
      "Jianchun Liu",
      "Shilong Wang",
      "Hongli Xu",
      "Haifeng Liu",
      "Jianhua Zhou"
    ],
    "abstract": "Federated Learning (FL) enables distributed clients to collaboratively train models without exposing their private data. However, it is difficult to implement efficient FL due to limited resources. Most existing works compress the transmitted gradients or prune the global model to reduce the resource cost, but leave the compressed or pruned parameters under-optimized, which degrades the training performance. To address this issue, the neural composition technique constructs size-adjustable models by composing low-rank tensors, allowing every parameter in the global model to learn the knowledge from all clients. Nevertheless, some tensors can only be optimized by a small fraction of clients, thus the global model may get insufficient training, leading to a long completion time, especially in heterogeneous edge scenarios. To this end, we enhance the neural composition technique, enabling all parameters to be fully trained. Further, we propose a lightweight FL framework, called Heroes, with enhanced neural composition and adaptive local update. A greedy-based algorithm is designed to adaptively assign the proper tensors and local update frequencies for participating clients according to their heterogeneous capabilities and resource budgets. Extensive experiments demonstrate that Heroes can reduce traffic consumption by about 72.05\\% and provide up to 2.97$\\times$ speedup compared to the baselines.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01617"
  },
  "2312.01612": {
    "title": "xNeuSM: Explainable Neural Subgraph Matching with Graph Learnable Multi-hop Attention Networks",
    "authors": [
      "Duc Q. Nguyen",
      "Thanh Toan Nguyen",
      "Tho quan"
    ],
    "abstract": "Subgraph matching is a challenging problem with a wide range of applications in database systems, biochemistry, and cognitive science. It involves determining whether a given query graph is present within a larger target graph. Traditional graph-matching algorithms provide precise results but face challenges in large graph instances due to the NP-complete problem, limiting their practical applicability. In contrast, recent neural network-based approximations offer more scalable solutions, but often lack interpretable node correspondences. To address these limitations, this article presents xNeuSM: Explainable Neural Subgraph Matching which introduces Graph Learnable Multi-hop Attention Networks (GLeMA) that adaptively learns the parameters governing the attention factor decay for each node across hops rather than relying on fixed hyperparameters. We provide a theoretical analysis establishing error bounds for GLeMA's approximation of multi-hop attention as a function of the number of hops. Additionally, we prove that learning distinct attention decay factors for each node leads to a correct approximation of multi-hop attention. Empirical evaluation on real-world datasets shows that xNeuSM achieves substantial improvements in prediction accuracy of up to 34% compared to approximate baselines and, notably, at least a seven-fold faster query time than exact algorithms. The source code of our implementation is available at https://github.com/martinakaduc/xNeuSM.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01612"
  },
  "2312.01607": {
    "title": "Monte Carlo Experiments of Network Effects in Randomized Controlled Trials",
    "authors": [
      "M\u00e1rton Trencs\u00e9ni"
    ],
    "abstract": "I run Monte Carlo simulations of content production over random Watts-Strogatz graphs to show various effects relevant to modeling and understanding Randomized Controlled Trials on social networks: the network effect, spillover effect, experiment dampening effect, intrinsic dampening effect, clustering effect, degree distribution effect and the experiment size effect. I will also define some simple metrics to measure their strength. When running experiments these potentially unexpected effects must be understood and controlled for in some manner, such as modeling the underlying graph structure to establish a baseline.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01607"
  },
  "2312.01605": {
    "title": "TextAug: Test time Text Augmentation for Multimodal Person Re-identification",
    "authors": [
      "Mulham Fawakherji",
      "Eduard Vazquez",
      "Pasquale Giampa",
      "Binod Bhattarai"
    ],
    "abstract": "Multimodal Person Reidentification is gaining popularity in the research community due to its effectiveness compared to counter-part unimodal frameworks. However, the bottleneck for multimodal deep learning is the need for a large volume of multimodal training examples. Data augmentation techniques such as cropping, flipping, rotation, etc. are often employed in the image domain to improve the generalization of deep learning models. Augmenting in other modalities than images, such as text, is challenging and requires significant computational resources and external data sources. In this study, we investigate the effectiveness of two computer vision data augmentation techniques: cutout and cutmix, for text augmentation in multi-modal person re-identification. Our approach merges these two augmentation strategies into one strategy called CutMixOut which involves randomly removing words or sub-phrases from a sentence (Cutout) and blending parts of two or more sentences to create diverse examples (CutMix) with a certain probability assigned to each operation. This augmentation was implemented at inference time without any prior training. Our results demonstrate that the proposed technique is simple and effective in improving the performance on multiple multimodal person re-identification benchmarks.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01605"
  },
  "2312.01601": {
    "title": "Local-Global History-aware Contrastive Learning for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Wei Chen",
      "Huaiyu Wan",
      "Yuting Wu",
      "Shuyuan Zhao",
      "Jiayaqi Cheng",
      "Yuxin Li",
      "Youfang Lin"
    ],
    "abstract": "Temporal knowledge graphs (TKGs) have been identified as a promising approach to represent the dynamics of facts along the timeline. The extrapolation of TKG is to predict unknowable facts happening in the future, holding significant practical value across diverse fields. Most extrapolation studies in TKGs focus on modeling global historical fact repeating and cyclic patterns, as well as local historical adjacent fact evolution patterns, showing promising performance in predicting future unknown facts. Yet, existing methods still face two major challenges: (1) They usually neglect the importance of historical information in KG snapshots related to the queries when encoding the local and global historical information; (2) They exhibit weak anti-noise capabilities, which hinders their performance when the inputs are contaminated with noise.To this end, we propose a novel \\blue{Lo}cal-\\blue{g}lobal history-aware \\blue{C}ontrastive \\blue{L}earning model (\\blue{LogCL}) for TKG reasoning, which adopts contrastive learning to better guide the fusion of local and global historical information and enhance the ability to resist interference. Specifically, for the first challenge, LogCL proposes an entity-aware attention mechanism applied to the local and global historical facts encoder, which captures the key historical information related to queries. For the latter issue, LogCL designs four historical query contrast patterns, effectively improving the robustness of the model. The experimental results on four benchmark datasets demonstrate that LogCL delivers better and more robust performance than the state-of-the-art baselines.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01601"
  },
  "2312.01598": {
    "title": "Good Questions Help Zero-Shot Image Reasoning",
    "authors": [
      "Kaiwen Yang",
      "Tao Shen",
      "Xinmei Tian",
      "Xiubo Geng",
      "Chongyang Tao",
      "Dacheng Tao",
      "Tianyi Zhou"
    ],
    "abstract": "Aligning the recent large language models (LLMs) with computer vision models leads to large vision-language models (LVLMs), which have paved the way for zero-shot image reasoning tasks. However, LVLMs are usually trained on short high-level captions only referring to sparse focus regions in images. Such a ``tunnel vision'' limits LVLMs to exploring other relevant contexts in complex scenes. To address this challenge, we introduce Question-Driven Visual Exploration (QVix), a novel prompting strategy that enhances the exploratory capabilities of LVLMs in zero-shot reasoning tasks. QVix leverages LLMs' strong language prior to generate input-exploratory questions with more details than the original query, guiding LVLMs to explore visual content more comprehensively and uncover subtle or peripheral details. QVix enables a wider exploration of visual scenes, improving the LVLMs' reasoning accuracy and depth in tasks such as visual question answering and visual entailment. Our evaluations on various challenging zero-shot vision-language benchmarks, including ScienceQA and fine-grained visual classification, demonstrate that QVix significantly outperforms existing methods, highlighting its effectiveness in bridging the gap between complex visual data and LVLMs' exploratory abilities.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.01598"
  },
  "2312.01597": {
    "title": "SCLIP: Rethinking Self-Attention for Dense Vision-Language Inference",
    "authors": [
      "Feng Wang",
      "Jieru Mei",
      "Alan Yuille"
    ],
    "abstract": "Recent advances in contrastive language-image pretraining (CLIP) have demonstrated strong capabilities in zero-shot classification by aligning visual representations with target text embeddings in an image level. However, in dense prediction tasks, CLIP often struggles to localize visual features within an image and fails to give accurate pixel-level predictions, which prevents it from functioning as a generalized visual foundation model. In this work, we aim to enhance CLIP's potential for semantic segmentation with minimal modifications to its pretrained models. By rethinking self-attention, we surprisingly find that CLIP can adapt to dense prediction tasks by simply introducing a novel Correlative Self-Attention (CSA) mechanism. Specifically, we replace the traditional self-attention block of CLIP vision encoder's last layer by our CSA module and reuse its pretrained projection matrices of query, key, and value, leading to a training-free adaptation approach for CLIP's zero-shot semantic segmentation. Extensive experiments show the advantage of CSA: we obtain a 38.2% average zero-shot mIoU across eight semantic segmentation benchmarks highlighted in this paper, significantly outperforming the existing SoTA's 33.9% and the vanilla CLIP's 14.1%.\n        \u25b3 Less",
    "submission_date": "2 January, 2024",
    "eprint_id": "2312.01597"
  },
  "2312.01592": {
    "title": "Expand BERT Representation with Visual Information via Grounded Language Learning with Multimodal Partial Alignment",
    "authors": [
      "Cong-Duy Nguyen",
      "The-Anh Vu-Le",
      "Thong Nguyen",
      "Tho Quan",
      "Luu Anh Tuan"
    ],
    "abstract": "Language models have been supervised with both language-only objective and visual grounding in existing studies of visual-grounded language learning. However, due to differences in the distribution and scale of visual-grounded datasets and language corpora, the language model tends to mix up the context of the tokens that occurred in the grounded data with those that do not. As a result, during representation learning, there is a mismatch between the visual information and the contextual meaning of the sentence. To overcome this limitation, we propose GroundedBERT - a grounded language learning method that enhances the BERT representation with visually grounded information. GroundedBERT comprises two components: (i) the original BERT which captures the contextual representation of words learned from the language corpora, and (ii) a visual grounding module which captures visual information learned from visual-grounded datasets. Moreover, we employ Optimal Transport (OT), specifically its partial variant, to solve the fractional alignment problem between the two modalities. Our proposed method significantly outperforms the baseline language models on various language tasks of the GLUE and SQuAD datasets.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2312.01592"
  },
  "2312.01589": {
    "title": "Euclidean Bottleneck Steiner Tree is Fixed-Parameter Tractable",
    "authors": [
      "Sayan Bandyapadhyay",
      "William Lochet",
      "Daniel Lokshtanov",
      "Saket Saurabh",
      "Jie Xue"
    ],
    "abstract": "In the Euclidean Bottleneck Steiner Tree problem, the input consists of a set of $n$ points in $\\mathbb{R}^2$ called terminals and a parameter $k$, and the goal is to compute a Steiner tree that spans all the terminals and contains at most $k$ points of $\\mathbb{R}^2$ as Steiner points such that the maximum edge-length of the Steiner tree is minimized, where the length of a tree edge is the Euclidean distance between its two endpoints. The problem is well-studied and is known to be NP-hard. In this paper, we give a $k^{O(k)} n^{O(1)}$-time algorithm for Euclidean Bottleneck Steiner Tree, which implies that the problem is fixed-parameter tractable (FPT). This settles an open question explicitly asked by Bae et al. [Algorithmica, 2011], who showed that the $\\ell_1$ and $\\ell_{\\infty}$ variants of the problem are FPT. Our approach can be generalized to the problem with $\\ell_p$ metric for any rational $1 \\le p \\le \\infty$, or even other metrics on $\\mathbb{R}^2$.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01589"
  },
  "2312.01588": {
    "title": "ActiveClean: Generating Line-Level Vulnerability Data via Active Learning",
    "authors": [
      "Ashwin Kallingal Joshy",
      "Mirza Sanjida Alam",
      "Shaila Sharmin",
      "Qi Li",
      "Wei Le"
    ],
    "abstract": "Deep learning vulnerability detection tools are increasing in popularity and have been shown to be effective. These tools rely on large volume of high quality training data, which are very hard to get. Most of the currently available datasets provide function-level labels, reporting whether a function is vulnerable or not vulnerable. However, for a vulnerability detection to be useful, we need to also know the lines that are relevant to the vulnerability. This paper makes efforts towards developing systematic tools and proposes. ActiveClean to generate the large volume of line-level vulnerability data from commits. That is, in addition to function-level labels, it also reports which lines in the function are likely responsible for vulnerability detection. In the past, static analysis has been applied to clean commits to generate line-level data. Our approach based on active learning, which is easy to use and scalable, provide a complementary approach to static analysis. We designed semantic and syntactic properties from commit lines and use them to train the model. We evaluated our approach on both Java and C datasets processing more than 4.3K commits and 119K commit lines. AcitveClean achieved an F1 score between 70-74. Further, we also show that active learning is effective by using just 400 training data to reach F1 score of 70.23. Using ActiveClean, we generate the line-level labels for the entire FFMpeg project in the Devign dataset, including 5K functions, and also detected incorrect function-level labels. We demonstrated that using our cleaned data, LineVul, a SOTA line-level vulnerability detection tool, detected 70 more vulnerable lines and 18 more vulnerable functions, and improved Top 10 accuracy from 66% to 73%.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01588"
  },
  "2312.01587": {
    "title": "Scalable and Independent Learning of Nash Equilibrium Policies in $n$-Player Stochastic Games with Unknown Independent Chains",
    "authors": [
      "Tiancheng Qin",
      "S. Rasoul Etesami"
    ],
    "abstract": "We study a subclass of $n$-player stochastic games, namely, stochastic games with independent chains and unknown transition matrices. In this class of games, players control their own internal Markov chains whose transitions do not depend on the states/actions of other players. However, players' decisions are coupled through their payoff functions. We assume players can receive only realizations of their payoffs, and that the players can not observe the states and actions of other players, nor do they know the transition probability matrices of their own Markov chain. Relying on a compact dual formulation of the game based on occupancy measures and the technique of confidence set to maintain high-probability estimates of the unknown transition matrices, we propose a fully decentralized mirror descent algorithm to learn an $\u03b5$-NE for this class of games. The proposed algorithm has the desired properties of independence, scalability, and convergence. Specifically, under no assumptions on the reward functions, we show the proposed algorithm converges in polynomial time in a weaker distance (namely, the averaged Nikaido-Isoda gap) to the set of $\u03b5$-NE policies with arbitrarily high probability. Moreover, assuming the existence of a variationally stable Nash equilibrium policy, we show that the proposed algorithm converges asymptotically to the stable $\u03b5$-NE policy with arbitrarily high probability. In addition to Markov potential games and linear-quadratic stochastic games, this work provides another subclass of $n$-player stochastic games that, under some mild assumptions, admit polynomial-time learning algorithms for finding their stationary $\u03b5$-NE policies.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01587"
  },
  "2312.01583": {
    "title": "Efficient Collision Detection Oriented Motion Primitives for Path Planning",
    "authors": [
      "Fabio DallaLibera",
      "Shinya Abe",
      "Takeshi Ando"
    ],
    "abstract": "Mobile robots in dynamic environments require fast planning, especially when onboard computational resources are limited. While classic potential field based algorithms may suffice in simple scenarios, in most cases algorithms able to escape local minima are necessary. Configuration-space search algorithms have proven to provide a good trade-off between quality of the solutions and search time. Literature presents a wide variety of approaches that speed up this search by reducing the number of edges that need to be inspected. Much less attention was instead given to reducing the time necessary to evaluate the cost of a single edge. This paper addresses this point by associating edges to motion primitives that prioritize fast collision detection. We show how biarcs can be used as motion primitives that enable fast collision detection, while still providing smooth, tangent continuous paths. The proposed approach does not assume a disc shaped hitbox, making it appealing for all robots with very different width and length or for differential drive robots with active wheels located far from the robot's center.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01583"
  },
  "2312.01582": {
    "title": "Explaining with Contrastive Phrasal Highlighting: A Case Study in Assisting Humans to Detect Translation Differences",
    "authors": [
      "Eleftheria Briakou",
      "Navita Goyal",
      "Marine Carpuat"
    ],
    "abstract": "Explainable NLP techniques primarily explain by answering \"Which tokens in the input are responsible for this prediction?''. We argue that for NLP models that make predictions by comparing two input texts, it is more useful to explain by answering \"What differences between the two inputs explain this prediction?''. We introduce a technique to generate contrastive highlights that explain the predictions of a semantic divergence model via phrase-alignment-guided erasure. We show that the resulting highlights match human rationales of cross-lingual semantic differences better than popular post-hoc saliency techniques and that they successfully help people detect fine-grained meaning differences in human translations and critical machine translation errors.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01582"
  },
  "2312.01581": {
    "title": "Signed Binarization: Unlocking Efficiency Through Repetition-Sparsity Trade-Off",
    "authors": [
      "Sachit Kuhar",
      "Yash Jain",
      "Alexey Tumanov"
    ],
    "abstract": "Efficient inference of Deep Neural Networks (DNNs) on resource-constrained edge devices is essential. Quantization and sparsity are key algorithmic techniques that translate to repetition and sparsity within tensors at the hardware-software interface. This paper introduces the concept of repetition-sparsity trade-off that helps explain computational efficiency during inference. We propose Signed Binarization, a unified co-design framework that synergistically integrates hardware-software systems, quantization functions, and representation learning techniques to address this trade-off. Our results demonstrate that Signed Binarization is more accurate than binarization with the same number of non-zero weights. Detailed analysis indicates that signed binarization generates a smaller distribution of effectual (non-zero) parameters nested within a larger distribution of total parameters, both of the same type, for a DNN block. Finally, our approach achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces density by 2.8x compared to binary methods for ResNet 18, presenting an alternative solution for deploying efficient models in resource-limited environments.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01581"
  },
  "2312.01577": {
    "title": "RJHMC-Tree for Exploration of the Bayesian Decision Tree Posterior",
    "authors": [
      "Jodie A. Cochrane",
      "Adrian G. Wills",
      "Sarah J. Johnson"
    ],
    "abstract": "Decision trees have found widespread application within the machine learning community due to their flexibility and interpretability. This paper is directed towards learning decision trees from data using a Bayesian approach, which is challenging due to the potentially enormous parameter space required to span all tree models. Several approaches have been proposed to combat this challenge, with one of the more successful being Markov chain Monte Carlo (MCMC) methods. The efficacy and efficiency of MCMC methods fundamentally rely on the quality of the so-called proposals, which is the focus of this paper. In particular, this paper investigates using a Hamiltonian Monte Carlo (HMC) approach to explore the posterior of Bayesian decision trees more efficiently by exploiting the geometry of the likelihood within a global update scheme. Two implementations of the novel algorithm are developed and compared to existing methods by testing against standard datasets in the machine learning and Bayesian decision tree literature. HMC-based methods are shown to perform favourably with respect to predictive test accuracy, acceptance rate, and tree complexity.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01577"
  },
  "2312.01576": {
    "title": "Learning Efficient Unsupervised Satellite Image-based Building Damage Detection",
    "authors": [
      "Yiyun Zhang",
      "Zijian Wang",
      "Yadan Luo",
      "Xin Yu",
      "Zi Huang"
    ],
    "abstract": "Existing Building Damage Detection (BDD) methods always require labour-intensive pixel-level annotations of buildings and their conditions, hence largely limiting their applications. In this paper, we investigate a challenging yet practical scenario of BDD, Unsupervised Building Damage Detection (U-BDD), where only unlabelled pre- and post-disaster satellite image pairs are provided. As a pilot study, we have first proposed an advanced U-BDD baseline that leverages pre-trained vision-language foundation models (i.e., Grounding DINO, SAM and CLIP) to address the U-BDD task. However, the apparent domain gap between satellite and generic images causes low confidence in the foundation models used to identify buildings and their damages. In response, we further present a novel self-supervised framework, U-BDD++, which improves upon the U-BDD baseline by addressing domain-specific issues associated with satellite imagery. Furthermore, the new Building Proposal Generation (BPG) module and the CLIP-enabled noisy Building Proposal Selection (CLIP-BPS) module in U-BDD++ ensure high-quality self-training. Extensive experiments on the widely used building damage assessment benchmark demonstrate the effectiveness of the proposed method for unsupervised building damage detection. The presented annotation-free and foundation model-based paradigm ensures an efficient learning phase. This study opens a new direction for real-world BDD and sets a strong baseline for future research.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01576"
  },
  "2312.01575": {
    "title": "A Challenging Multimodal Video Summary: Simultaneously Extracting and Generating Keyframe-Caption Pairs from Video",
    "authors": [
      "Keito Kudo",
      "Haruki Nagasawa",
      "Jun Suzuki",
      "Nobuyuki Shimizu"
    ],
    "abstract": "This paper proposes a practical multimodal video summarization task setting and a dataset to train and evaluate the task. The target task involves summarizing a given video into a predefined number of keyframe-caption pairs and displaying them in a listable format to grasp the video content quickly. This task aims to extract crucial scenes from the video in the form of images (keyframes) and generate corresponding captions explaining each keyframe's situation. This task is useful as a practical application and presents a highly challenging problem worthy of study. Specifically, achieving simultaneous optimization of the keyframe selection performance and caption quality necessitates careful consideration of the mutual dependence on both preceding and subsequent keyframes and captions. To facilitate subsequent research in this field, we also construct a dataset by expanding upon existing datasets and propose an evaluation framework. Furthermore, we develop two baseline systems and report their respective performance.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01575"
  },
  "2312.01573": {
    "title": "Survey on deep learning in multimodal medical imaging for cancer detection",
    "authors": [
      "Yan Tian",
      "Zhaocheng Xu",
      "Yujun Ma",
      "Weiping Ding",
      "Ruili Wang",
      "Zhihong Gao",
      "Guohua Cheng",
      "Linyang He",
      "Xuran Zhao"
    ],
    "abstract": "The task of multimodal cancer detection is to determine the locations and categories of lesions by using different imaging techniques, which is one of the key research methods for cancer diagnosis. Recently, deep learning-based object detection has made significant developments due to its strength in semantic feature extraction and nonlinear function fitting. However, multimodal cancer detection remains challenging due to morphological differences in lesions, interpatient variability, difficulty in annotation, and imaging artifacts. In this survey, we mainly investigate over 150 papers in recent years with respect to multimodal cancer detection using deep learning, with a focus on datasets and solutions to various challenges such as data annotation, variance between classes, small-scale lesions, and occlusion. We also provide an overview of the advantages and drawbacks of each approach. Finally, we discuss the current scope of work and provide directions for the future development of multimodal cancer detection.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01573"
  },
  "2312.01571": {
    "title": "How to Configure Good In-Context Sequence for Visual Question Answering",
    "authors": [
      "Li Li",
      "Jiawei Peng",
      "Huiyi Chen",
      "Chongyang Gao",
      "Xu Yang"
    ],
    "abstract": "Inspired by the success of Large Language Models in dealing with new tasks via In-Context Learning (ICL) in NLP, researchers have also developed Large Vision-Language Models (LVLMs) with ICL capabilities. However, when implementing ICL using these LVLMs, researchers usually resort to the simplest way like random sampling to configure the in-context sequence, thus leading to sub-optimal results. To enhance the ICL performance, in this study, we use Visual Question Answering (VQA) as case study to explore diverse in-context configurations to find the powerful ones. Additionally, through observing the changes of the LVLM outputs by altering the in-context sequence, we gain insights into the inner properties of LVLMs, improving our understanding of them. Specifically, to explore in-context configurations, we design diverse retrieval methods and employ different strategies to manipulate the retrieved demonstrations. Through exhaustive experiments on three VQA datasets: VQAv2, VizWiz, and OK-VQA, we uncover three important inner properties of the applied LVLM and demonstrate which strategies can consistently improve the ICL VQA performance. Our code is provided in: https://github.com/GaryJiajia/OFv2_ICL_VQA.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01571"
  },
  "2312.01570": {
    "title": "Parallelizing quantum simulation with decision diagrams",
    "authors": [
      "Shaowen Li",
      "Yusuke Kimura",
      "Hiroyuki Sato",
      "Junwei Yu",
      "Masahiro Fujita"
    ],
    "abstract": "Recent technological advancements show promise in leveraging quantum mechanical phenomena for computation. This brings substantial speed-ups to problems that are once considered to be intractable in the classical world. However, the physical realization of quantum computers is still far away from us, and a majority of research work is done using quantum simulators running on classical computers. Classical computers face a critical obstacle in simulating quantum algorithms. Quantum states reside in a Hilbert space whose size grows exponentially to the number of subsystems, i.e., qubits. As a result, the straightforward statevector approach does not scale due to the exponential growth of the memory requirement. Decision diagrams have gained attention in recent years for representing quantum states and operations in quantum simulations. The main advantage of this approach is its ability to exploit redundancy. However, mainstream quantum simulators still rely on statevectors or tensor networks. We consider the absence of decision diagrams due to the lack of parallelization strategies. This work explores several strategies for parallelizing decision diagram operations, specifically for quantum simulations. We propose optimal parallelization strategies. Based on the experiment results, our parallelization strategy achieves a 2-3 times faster simulation of Grover's algorithm and random circuits than the state-of-the-art single-thread DD-based simulator DDSIM.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01570"
  },
  "2312.01568": {
    "title": "Multimodal Speech Emotion Recognition Using Modality-specific Self-Supervised Frameworks",
    "authors": [
      "Rutherford Agbeshi Patamia",
      "Paulo E. Santos",
      "Kingsley Nketia Acheampong",
      "Favour Ekong",
      "Kwabena Sarpong",
      "She Kun"
    ],
    "abstract": "Emotion recognition is a topic of significant interest in assistive robotics due to the need to equip robots with the ability to comprehend human behavior, facilitating their effective interaction in our society. Consequently, efficient and dependable emotion recognition systems supporting optimal human-machine communication are required. Multi-modality (including speech, audio, text, images, and videos) is typically exploited in emotion recognition tasks. Much relevant research is based on merging multiple data modalities and training deep learning models utilizing low-level data representations. However, most existing emotion databases are not large (or complex) enough to allow machine learning approaches to learn detailed representations. This paper explores modalityspecific pre-trained transformer frameworks for self-supervised learning of speech and text representations for data-efficient emotion recognition while achieving state-of-the-art performance in recognizing emotions. This model applies feature-level fusion using nonverbal cue data points from motion capture to provide multimodal speech emotion recognition. The model was trained using the publicly available IEMOCAP dataset, achieving an overall accuracy of 77.58% for four emotions, outperforming state-of-the-art approaches\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01568"
  },
  "2312.01567": {
    "title": "Toward Automated Quantum Variational Machine Learning",
    "authors": [
      "Omer Subasi"
    ],
    "abstract": "In this work, we address the problem of automating quantum variational machine learning. We develop a multi-locality parallelizable search algorithm, called MUSE, to find the initial points and the sets of parameters that achieve the best performance for quantum variational circuit learning. Simulations with five real-world classification datasets indicate that on average, MUSE improves the detection accuracy of quantum variational classifiers 2.3 times with respect to the observed lowest scores. Moreover, when applied to two real-world regression datasets, MUSE improves the quality of the predictions from negative coefficients of determination to positive ones. Furthermore, the classification and regression scores of the quantum variational models trained with MUSE are on par with the classical counterparts.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01567"
  },
  "2312.01564": {
    "title": "APoLLo: Unified Adapter and Prompt Learning for Vision Language Models",
    "authors": [
      "Sanjoy Chowdhury",
      "Sayan Nag",
      "Dinesh Manocha"
    ],
    "abstract": "The choice of input text prompt plays a critical role in the performance of Vision-Language Pretrained (VLP) models such as CLIP. We present APoLLo, a unified multi-modal approach that combines Adapter and Prompt learning for Vision-Language models. Our method is designed to substantially improve the generalization capabilities of VLP models when they are fine-tuned in a few-shot setting. We introduce trainable cross-attention-based adapter layers in conjunction with vision and language encoders to strengthen the alignment between the two modalities. We enforce consistency between the respective encoder branches (receiving augmented inputs) to prevent overfitting in downstream tasks. Our method is evaluated on three representative tasks: generalization to novel classes, cross-dataset evaluation, and unseen domain shifts. In practice, APoLLo achieves a relative gain up to 6.03% over MaPLe (SOTA) on novel classes for 10 diverse image recognition datasets.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01564"
  },
  "2312.01561": {
    "title": "Multi-View Person Matching and 3D Pose Estimation with Arbitrary Uncalibrated Camera Networks",
    "authors": [
      "Yan Xu",
      "Kris Kitani"
    ],
    "abstract": "Cross-view person matching and 3D human pose estimation in multi-camera networks are particularly difficult when the cameras are extrinsically uncalibrated. Existing efforts generally require large amounts of 3D data for training neural networks or known camera poses for geometric constraints to solve the problem. However, camera poses and 3D data annotation are usually expensive and not always available. We present a method, PME, that solves the two tasks without requiring either information. Our idea is to address cross-view person matching as a clustering problem using each person as a cluster center, then obtain correspondences from person matches, and estimate 3D human poses through multi-view triangulation and bundle adjustment. We solve the clustering problem by introducing a \"size constraint\" using the number of cameras and a \"source constraint\" using the fact that two people from the same camera view should not match, to narrow the solution space to a small feasible region. The 2D human poses used in clustering are obtained through a pre-trained 2D pose detector, so our method does not require expensive 3D training data for each new scene. We extensively evaluate our method on three open datasets and two indoor and outdoor datasets collected using arbitrarily set cameras. Our method outperforms other methods by a large margin on cross-view person matching, reaches SOTA performance on 3D human pose estimation without using either camera poses or 3D training data, and shows good generalization ability across five datasets of various environment settings.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01561"
  },
  "2312.01560": {
    "title": "RaftGP: Random Fast Graph Partitioning",
    "authors": [
      "Yu Gao",
      "Meng Qin",
      "Yibin Ding",
      "Li Zeng",
      "Chaorui Zhang",
      "Weixi Zhang",
      "Wei Han",
      "Rongqian Zhao",
      "Bo Bai"
    ],
    "abstract": "Graph partitioning (GP), a.k.a. community detection, is a classic problem that divides the node set of a graph into densely-connected blocks. Following prior work on the IEEE HPEC Graph Challenge benchmark and recent advances in graph machine learning, we propose a novel RAndom FasT Graph Partitioning (RaftGP) method based on an efficient graph embedding scheme. It uses the Gaussian random projection to extract community-preserving features from classic GP objectives. These features are fed into a graph neural network (GNN) to derive low-dimensional node embeddings. Surprisingly, our experiments demonstrate that a randomly initialized GNN even without training is enough for RaftGP to derive informative community-preserving embeddings and support high-quality GP. To enable the derived embeddings to tackle GP, we introduce a hierarchical model selection algorithm that simultaneously determines the number of blocks and the corresponding GP result. We evaluate RaftGP on the Graph Challenge benchmark and compare the performance with five baselines, where our method can achieve a better trade-off between quality and efficiency. In particular, compared to the baseline algorithm of the IEEE HPEC Graph Challenge, our method is 6.68x -- 23.9x faster on graphs with 1E3 -- 5E4 nodes and at least 64.5x faster on larger (1E5 node) graphs on which the baseline takes more than 1E4 seconds. Our method achieves better accuracy on all test cases. We also develop a new graph generator to address some limitations of the original generator in the benchmark.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01560"
  },
  "2312.01558": {
    "title": "Hyperspectral Image Compression Using Sampling and Implicit Neural Representations",
    "authors": [
      "Shima Rezasoltani",
      "Faisal Z. Qureshi"
    ],
    "abstract": "Hyperspectral images, which record the electromagnetic spectrum for a pixel in the image of a scene, often store hundreds of channels per pixel and contain an order of magnitude more information than a similarly-sized RBG color image. Consequently, concomitant with the decreasing cost of capturing these images, there is a need to develop efficient techniques for storing, transmitting, and analyzing hyperspectral images. This paper develops a method for hyperspectral image compression using implicit neural representations where a multilayer perceptron network F with sinusoidal activation functions \"learns\" to map pixel locations to pixel intensities for a given hyperspectral image I. F thus acts as a compressed encoding of this image, and the original image is reconstructed by evaluating F at each pixel location. We use a sampling method with two factors: window size and sampling rate to reduce the compression time. We have evaluated our method on four benchmarks -- Indian Pines, Jasper Ridge, Pavia University, and Cuprite using PSNR and SSIM -- and we show that the proposed method achieves better compression than JPEG, JPEG2000, and PCA-DCT at low bitrates. Besides, we compare our results with the learning-based methods like PCA+JPEG2000, FPCA+JPEG2000, 3D DCT, 3D DWT+SVR, and WSRC and show the corresponding results in the \"Compression Results\" section. We also show that our methods with sampling achieve better speed and performance than our method without sampling.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01558"
  },
  "2312.01556": {
    "title": "Searching Dense Representations with Inverted Indexes",
    "authors": [
      "Jimmy Lin",
      "Tommaso Teofili"
    ],
    "abstract": "Nearly all implementations of top-$k$ retrieval with dense vector representations today take advantage of hierarchical navigable small-world network (HNSW) indexes. However, the generation of vector representations and efficiently searching large collections of vectors are distinct challenges that can be decoupled. In this work, we explore the contrarian approach of performing top-$k$ retrieval on dense vector representations using inverted indexes. We present experiments on the MS MARCO passage ranking dataset, evaluating three dimensions of interest: output quality, speed, and index size. Results show that searching dense representations using inverted indexes is possible. Our approach exhibits reasonable effectiveness with compact indexes, but is impractically slow. Thus, while workable, our solution does not provide a compelling tradeoff and is perhaps best characterized today as a \"technical curiosity\".\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01556"
  },
  "2312.01555": {
    "title": "Explainable AI is Responsible AI: How Explainability Creates Trustworthy and Socially Responsible Artificial Intelligence",
    "authors": [
      "Stephanie Baker",
      "Wei Xiang"
    ],
    "abstract": "Artificial intelligence (AI) has been clearly established as a technology with the potential to revolutionize fields from healthcare to finance - if developed and deployed responsibly. This is the topic of responsible AI, which emphasizes the need to develop trustworthy AI systems that minimize bias, protect privacy, support security, and enhance transparency and accountability. Explainable AI (XAI) has been broadly considered as a building block for responsible AI (RAI), with most of the literature considering it as a solution for improved transparency. This work proposes that XAI and responsible AI are significantly more deeply entwined. In this work, we explore state-of-the-art literature on RAI and XAI technologies. Based on our findings, we demonstrate that XAI can be utilized to ensure fairness, robustness, privacy, security, and transparency in a wide range of contexts. Our findings lead us to conclude that XAI is an essential foundation for every pillar of RAI.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01555"
  },
  "2312.01554": {
    "title": "Building Ears for Robots: Machine Hearing in the Age of Autonomy",
    "authors": [
      "Xuan Zhong"
    ],
    "abstract": "This study explores the significance of robot hearing systems, emphasizing their importance for robots operating in diverse and uncertain environments. It introduces the hardware design principles using robotaxis as an example, where exterior microphone arrays are employed to detect sound events such as sirens. The challenges, goals, and test methods are discussed, focusing on achieving a suitable signal-to-noise ratio (SNR). Additionally, it presents a preliminary software framework rooted in probabilistic robotics theory, advocating for the integration of robot hearing into the broader context of perception and decision-making. It discusses various models, including Bayes filters, partially observable Markov decision processes (POMDP), and multiagent systems, highlighting the multifaceted roles that robot hearing can play. In conclusion, as service robots continue to evolve, robot hearing research will expand, offering new perspectives and challenges for future development beyond simple sound event classification.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01554"
  },
  "2312.01552": {
    "title": "The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning",
    "authors": [
      "Bill Yuchen Lin",
      "Abhilasha Ravichander",
      "Ximing Lu",
      "Nouha Dziri",
      "Melanie Sclar",
      "Khyathi Chandu",
      "Chandra Bhagavatula",
      "Yejin Choi"
    ],
    "abstract": "The alignment tuning process of large language models (LLMs) typically involves instruction learning through supervised fine-tuning (SFT) and preference tuning via reinforcement learning from human feedback (RLHF). A recent study, LIMA (Zhou et al. 2023), shows that using merely 1K examples for SFT can achieve significant alignment performance as well, suggesting that the effect of alignment tuning might be \"superficial.\" This raises questions about how exactly the alignment tuning transforms a base LLM.\n  We analyze the effect of alignment tuning by examining the token distribution shift between base LLMs and their aligned counterpart. Our findings reveal that base LLMs and their alignment-tuned versions perform nearly identically in decoding on the majority of token positions. Most distribution shifts occur with stylistic tokens. These direct evidence strongly supports the Superficial Alignment Hypothesis suggested by LIMA.\n  Based on these findings, we rethink the alignment of LLMs by posing the research question: how effectively can we align base LLMs without SFT or RLHF? To address this, we introduce a simple, tuning-free alignment method, URIAL. URIAL achieves effective alignment purely through in-context learning (ICL) with base LLMs, requiring as few as three constant stylistic examples and a system prompt. We conduct a fine-grained and interpretable evaluation on a diverse set of examples, named JUST-EVAL-INSTRUCT. Results demonstrate that base LLMs with URIAL can match or even surpass the performance of LLMs aligned with SFT or SFT+RLHF. We show that the gap between tuning-free and tuning-based alignment methods can be significantly reduced through strategic prompting and ICL. Our findings on the superficial nature of alignment tuning and results with URIAL suggest that deeper analysis and theoretical understanding of alignment is crucial to future LLM research.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01552"
  },
  "2312.01550": {
    "title": "Using human and robot synthetic data for training smart hand tools",
    "authors": [
      "Jose Bendana",
      "Sundar Sripada V. S.",
      "Carlos D. Salazar",
      "Sandeep Chinchali",
      "Raul G. Longoria"
    ],
    "abstract": "The future of work does not require a choice between human and robot. Aside from explicit human-robot collaboration, robotics can play an increasingly important role in helping train workers as well as the tools they may use, especially in complex tasks that may be difficult to automate or effectively roboticize. This paper introduces a form of smart tool for use by human workers and shows how training the tool for task recognition, one of the key requirements, can be accomplished. Machine learning (ML) with purely human-based data can be extremely laborious and time-consuming. First, we show how data synthetically-generated by a robot can be leveraged in the ML training process. Later, we demonstrate how fine-tuning ML models for individual physical tasks and workers can significantly scale up the benefits of using ML to provide this feedback. Experimental results show the effectiveness and scalability of our approach, as we test data size versus accuracy. Smart hand tools of the type introduced here can provide insights and real-time analytics on efficient and safe tool usage and operation, thereby enhancing human participation and skill in a wide range of work environments. Using robotic platforms to help train smart tools will be essential, particularly given the diverse types of applications for which smart hand tools are envisioned for human use.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01550"
  },
  "2312.01547": {
    "title": "Near-Optimal Algorithms for Gaussians with Huber Contamination: Mean Estimation and Linear Regression",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Ankit Pensia",
      "Thanasis Pittas"
    ],
    "abstract": "We study the fundamental problems of Gaussian mean estimation and linear regression with Gaussian covariates in the presence of Huber contamination. Our main contribution is the design of the first sample near-optimal and almost linear-time algorithms with optimal error guarantees for both of these problems. Specifically, for Gaussian robust mean estimation on $\\mathbb{R}^d$ with contamination parameter $\u03b5\\in (0, \u03b5_0)$ for a small absolute constant $\u03b5_0$, we give an algorithm with sample complexity $n = \\tilde{O}(d/\u03b5^2)$ and almost linear runtime that approximates the target mean within $\\ell_2$-error $O(\u03b5)$. This improves on prior work that achieved this error guarantee with polynomially suboptimal sample and time complexity. For robust linear regression, we give the first algorithm with sample complexity $n = \\tilde{O}(d/\u03b5^2)$ and almost linear runtime that approximates the target regressor within $\\ell_2$-error $O(\u03b5)$. This is the first polynomial sample and time algorithm achieving the optimal error guarantee, answering an open question in the literature. At the technical level, we develop a methodology that yields almost-linear time algorithms for multi-directional filtering that may be of broader interest.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01547"
  },
  "2312.01546": {
    "title": "Learning Channel Capacity with Neural Mutual Information Estimator Based on Message Importance Measure",
    "authors": [
      "Zhefan Li",
      "Rui She",
      "Pingyi Fan",
      "Chenghui Peng",
      "Khaled B. Letaief"
    ],
    "abstract": "Channel capacity estimation plays a crucial role in beyond 5G intelligent communications. Despite its significance, this task is challenging for a majority of channels, especially for the complex channels not modeled as the well-known typical ones. Recently, neural networks have been used in mutual information estimation and optimization. They are particularly considered as efficient tools for learning channel capacity. In this paper, we propose a cooperative framework to simultaneously estimate channel capacity and design the optimal codebook. First, we will leverage MIM-based GAN, a novel form of generative adversarial network (GAN) using message importance measure (MIM) as the information distance, into mutual information estimation, and develop a novel method, named MIM-based mutual information estimator (MMIE). Then, we design a generalized cooperative framework for channel capacity learning, in which a generator is regarded as an encoder producing the channel input, while a discriminator is the mutual information estimator that assesses the performance of the generator. Through the adversarial training, the generator automatically learns the optimal codebook and the discriminator estimates the channel capacity. Numerical experiments will demonstrate that compared with several conventional estimators, the MMIE achieves state-of-the-art performance in terms of accuracy and stability.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01546"
  },
  "2312.01544": {
    "title": "KEEC: Embed to Control on An Equivariant Geometry",
    "authors": [
      "Xiaoyuan Cheng",
      "Yiming Yang",
      "Wei Jiang",
      "Yukun Hu"
    ],
    "abstract": "This paper investigates how representation learning can enable optimal control in unknown and complex dynamics, such as chaotic and non-linear systems, without relying on prior domain knowledge of the dynamics. The core idea is to establish an equivariant geometry that is diffeomorphic to the manifold defined by a dynamical system and to perform optimal control within this corresponding geometry, which is a non-trivial task. To address this challenge, Koopman Embed to Equivariant Control (KEEC) is proposed for model learning and control. Inspired by Lie theory, KEEC begins by learning a non-linear dynamical system defined on a manifold and embedding trajectories into a Lie group. Subsequently, KEEC formulates an equivariant value function equation in reinforcement learning on the equivariant geometry, ensuring an invariant effect as the value function on the original manifold. By deriving analytical-form optimal actions on the equivariant value function, KEEC theoretically achieves quadratic convergence for the optimal equivariant value function by leveraging the differential information on the equivariant geometry. The effectiveness of KEEC is demonstrated in challenging dynamical systems, including chaotic ones like Lorenz-63. Notably, our results show that isometric functions, which maintain the compactness and completeness of geometry while preserving metric and differential information, consistently outperform loss functions lacking these characteristics.\n        \u25b3 Less",
    "submission_date": "10 December, 2023",
    "eprint_id": "2312.01544"
  },
  "2312.01543": {
    "title": "Torso-Based Control Interface for Standing Mobility-Assistive Devices",
    "authors": [
      "Yang Chen",
      "Diego Paez-Granados",
      "Modar Hassan",
      "Kenji Suzuki"
    ],
    "abstract": "Wheelchairs and mobility devices have transformed our bodies into cybernic systems, extending our well-being by enabling individuals with reduced mobility to regain freedom. Notwithstanding, current interfaces of control require to use the hands, therefore constraining the user from performing functional activities of daily living. In this work, we present a unique design of torso-based control interface with compliant coupling support for standing mobility assistive devices. We take the coupling between the human and robot into consideration in the interface design. The design includes a compliant support mechanism and a mapping between the body movement space and the velocity space. We present experiments including multiple conditions, with a joystick for comparison with the proposed torso control interface. The results of a path-following experiment showed that users were able to control the device naturally using the hands-free interface, and the performance was comparable with the joystick, with 10% more consumed time, an average cross error of 0.116 m and 4.9% less average acceleration. The result of an object-transferring experiment showed the advantage of using the proposed interface in case users needed to manipulate objects while locomotion. The torso control scored 15% less in the System Usability Scale than the joystick in the path following task but 3.3% more in the object transferring task.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01543"
  },
  "2312.01540": {
    "title": "Robust Computer Vision in an Ever-Changing World: A Survey of Techniques for Tackling Distribution Shifts",
    "authors": [
      "Eashan Adhikarla",
      "Kai Zhang",
      "Jun Yu",
      "Lichao Sun",
      "John Nicholson",
      "Brian D. Davison"
    ],
    "abstract": "AI applications are becoming increasingly visible to the general public. There is a notable gap between the theoretical assumptions researchers make about computer vision models and the reality those models face when deployed in the real world. One of the critical reasons for this gap is a challenging problem known as distribution shift. Distribution shifts tend to vary with complexity of the data, dataset size, and application type. In our paper, we discuss the identification of such a prominent gap, exploring the concept of distribution shift and its critical significance. We provide an in-depth overview of various types of distribution shifts, elucidate their distinctions, and explore techniques within the realm of the data-centric domain employed to address them. Distribution shifts can occur during every phase of the machine learning pipeline, from the data collection stage to the stage of training a machine learning model to the stage of final model deployment. As a result, it raises concerns about the overall robustness of the machine learning techniques for computer vision applications that are deployed publicly for consumers. Different deep learning models each tailored for specific type of data and tasks, architectural pipelines; highlighting how variations in data preprocessing and feature extraction can impact robustness., data augmentation strategies (e.g. geometric, synthetic and learning-based); demonstrating their role in enhancing model generalization, and training mechanisms (e.g. transfer learning, zero-shot) fall under the umbrella of data-centric methods. Each of these components form an integral part of the neural-network we analyze contributing uniquely to strengthening model robustness against distribution shifts. We compare and contrast numerous AI models that are built for mitigating shifts in hidden stratification and spurious correlations, ...\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01540"
  },
  "2312.01537": {
    "title": "Unlocking the Potential of Federated Learning: The Symphony of Dataset Distillation via Deep Generative Latents",
    "authors": [
      "Yuqi Jia",
      "Saeed Vahidian",
      "Jingwei Sun",
      "Jianyi Zhang",
      "Vyacheslav Kungurtsev",
      "Neil Zhenqiang Gong",
      "Yiran Chen"
    ],
    "abstract": "Data heterogeneity presents significant challenges for federated learning (FL). Recently, dataset distillation techniques have been introduced, and performed at the client level, to attempt to mitigate some of these challenges. In this paper, we propose a highly efficient FL dataset distillation framework on the server side, significantly reducing both the computational and communication demands on local devices while enhancing the clients' privacy. Unlike previous strategies that perform dataset distillation on local devices and upload synthetic data to the server, our technique enables the server to leverage prior knowledge from pre-trained deep generative models to synthesize essential data representations from a heterogeneous model architecture. This process allows local devices to train smaller surrogate models while enabling the training of a larger global model on the server, effectively minimizing resource utilization. We substantiate our claim with a theoretical analysis, demonstrating the asymptotic resemblance of the process to the hypothetical ideal of completely centralized training on a heterogeneous dataset. Empirical evidence from our comprehensive experiments indicates our method's superiority, delivering an accuracy enhancement of up to 40% over non-dataset-distillation techniques in highly heterogeneous FL contexts, and surpassing existing dataset-distillation methods by 18%. In addition to the high accuracy, our framework converges faster than the baselines because rather than the server trains on several sets of heterogeneous data distributions, it trains on a multi-modal distribution. Our code is available at https://github.com/FedDG23/FedDG-main.git\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01537"
  },
  "2312.01536": {
    "title": "CalliPaint: Chinese Calligraphy Inpainting with Diffusion Model",
    "authors": [
      "Qisheng Liao",
      "Zhinuo Wang",
      "Muhammad Abdul-Mageed",
      "Gus Xia"
    ],
    "abstract": "Chinese calligraphy can be viewed as a unique form of visual art. Recent advancements in computer vision hold significant potential for the future development of generative models in the realm of Chinese calligraphy. Nevertheless, methods of Chinese calligraphy inpainting, which can be effectively used in the art and education fields, remain relatively unexplored. In this paper, we introduce a new model that harnesses recent advancements in both Chinese calligraphy generation and image inpainting. We demonstrate that our proposed model CalliPaint can produce convincing Chinese calligraphy.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01536"
  },
  "2312.01532": {
    "title": "Using Large Language Models to Accelerate Communication for Users with Severe Motor Impairments",
    "authors": [
      "Shanqing Cai",
      "Subhashini Venugopalan",
      "Katie Seaver",
      "Xiang Xiao",
      "Katrin Tomanek",
      "Sri Jalasutram",
      "Meredith Ringel Morris",
      "Shaun Kane",
      "Ajit Narayanan",
      "Robert L. MacDonald",
      "Emily Kornman",
      "Daniel Vance",
      "Blair Casey",
      "Steve M. Gleason",
      "Philip Q. Nelson",
      "Michael P. Brenner"
    ],
    "abstract": "Finding ways to accelerate text input for individuals with profound motor impairments has been a long-standing area of research. Closing the speed gap for augmentative and alternative communication (AAC) devices such as eye-tracking keyboards is important for improving the quality of life for such individuals. Recent advances in neural networks of natural language pose new opportunities for re-thinking strategies and user interfaces for enhanced text-entry for AAC users. In this paper, we present SpeakFaster, consisting of large language models (LLMs) and a co-designed user interface for text entry in a highly-abbreviated form, allowing saving 57% more motor actions than traditional predictive keyboards in offline simulation. A pilot study with 19 non-AAC participants typing on a mobile device by hand demonstrated gains in motor savings in line with the offline simulation, while introducing relatively small effects on overall typing speed. Lab and field testing on two eye-gaze typing users with amyotrophic lateral sclerosis (ALS) demonstrated text-entry rates 29-60% faster than traditional baselines, due to significant saving of expensive keystrokes achieved through phrase and word predictions from context-aware LLMs. These findings provide a strong foundation for further exploration of substantially-accelerated text communication for motor-impaired users and demonstrate a direction for applying LLMs to text-based user interfaces.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01532"
  },
  "2312.01530": {
    "title": "Evaluation of Active Feature Acquisition Methods for Time-varying Feature Settings",
    "authors": [
      "Henrik von Kleist",
      "Alireza Zamanian",
      "Ilya Shpitser",
      "Narges Ahmidi"
    ],
    "abstract": "Machine learning methods often assume input features are available at no cost. However, in domains like healthcare, where acquiring features could be expensive or harmful, it is necessary to balance a feature's acquisition cost against its predictive value. The task of training an AI agent to decide which features to acquire is called active feature acquisition (AFA). By deploying an AFA agent, we effectively alter the acquisition strategy and trigger a distribution shift. To safely deploy AFA agents under this distribution shift, we present the problem of active feature acquisition performance evaluation (AFAPE). We examine AFAPE under i) a no direct effect (NDE) assumption, stating that acquisitions don't affect the underlying feature values; and ii) a no unobserved confounding (NUC) assumption, stating that retrospective feature acquisition decisions were only based on observed features. We show that one can apply offline reinforcement learning under the NUC assumption and missing data methods under the NDE assumption. When NUC and NDE hold, we propose a novel semi-offline reinforcement learning framework, which requires a weaker positivity assumption and yields more data-efficient estimators. We introduce three novel estimators: a direct method (DM), an inverse probability weighting (IPW), and a double reinforcement learning (DRL) estimator.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.01530"
  },
  "2312.01529": {
    "title": "T3D: Towards 3D Medical Image Understanding through Vision-Language Pre-training",
    "authors": [
      "Che Liu",
      "Cheng Ouyang",
      "Yinda Chen",
      "Cesar C\u00e9sar Quilodr\u00e1n-Casas",
      "Lei Ma",
      "Jie Fu",
      "Yike Guo",
      "Anand Shah",
      "Wenjia Bai",
      "Rossella Arcucci"
    ],
    "abstract": "Expert annotation of 3D medical image for downstream analysis is resource-intensive, posing challenges in clinical applications. Visual self-supervised learning (vSSL), though effective for learning visual invariance, neglects the incorporation of domain knowledge from medicine. To incorporate medical knowledge into visual representation learning, vision-language pre-training (VLP) has shown promising results in 2D image. However, existing VLP approaches become generally impractical when applied to high-resolution 3D medical images due to GPU hardware constraints and the potential loss of critical details caused by downsampling, which is the intuitive solution to hardware constraints. To address the above limitations, we introduce T3D, the first VLP framework designed for high-resolution 3D medical images. T3D incorporates two text-informed pretext tasks: (\\lowerromannumeral{1}) text-informed contrastive learning; (\\lowerromannumeral{2}) text-informed image restoration. These tasks focus on learning 3D visual representations from high-resolution 3D medical images and integrating clinical knowledge from radiology reports, without distorting information through forced alignment of downsampled volumes with detailed anatomical text. Trained on a newly curated large-scale dataset of 3D medical images and radiology reports, T3D significantly outperforms current vSSL methods in tasks like organ and tumor segmentation, as well as disease classification. This underlines T3D's potential in representation learning for 3D medical image analysis. All data and code will be available upon acceptance.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01529"
  },
  "2312.01527": {
    "title": "NovoMol: Recurrent Neural Network for Orally Bioavailable Drug Design and Validation on PDGFR\u03b1 Receptor",
    "authors": [
      "Ishir Rao"
    ],
    "abstract": "Longer timelines and lower success rates of drug candidates limit the productivity of clinical trials in the pharmaceutical industry. Promising de novo drug design techniques help solve this by exploring a broader chemical space, efficiently generating new molecules, and providing improved therapies. However, optimizing for molecular characteristics found in approved oral drugs remains a challenge, limiting de novo usage. In this work, we propose NovoMol, a novel de novo method using recurrent neural networks to mass-generate drug molecules with high oral bioavailability, increasing clinical trial time efficiency. Molecules were optimized for desirable traits and ranked using the quantitative estimate of drug-likeness (QED). Generated molecules meeting QED's oral bioavailability threshold were used to retrain the neural network, and, after five training cycles, 76% of generated molecules passed this strict threshold and 96% passed the traditionally used Lipinski's Rule of Five. The trained model was then used to generate specific drug candidates for the cancer-related PDGFR\u03b1 receptor and 44% of generated candidates had better binding affinity than the current state-of-the-art drug, Imatinib (with a receptor binding affinity of -9.4 kcal/mol), and the best-generated candidate at -12.9 kcal/mol. NovoMol provides a time/cost-efficient AI-based de novo method offering promising drug candidates for clinical trials.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01527"
  },
  "2312.01524": {
    "title": "Code Swarm: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set",
    "authors": [
      "Hina Mahmood",
      "Atif Aftab Jilani",
      "Abdul Rauf"
    ],
    "abstract": "Automatic generation of software code from system design models remains an actively explored research area for the past several years. A number of tools are currently available to facilitate and automate the task of generating code from software models. To the best of our knowledge, existing software tools rely on an explicitly defined transformation rule set to perform the model-to-code transformation process. In this paper, we introduce a novel tool named Code Swarm, abbreviated as CodS, that automatically generates implementation code from system design models by utilizing a swarm-based approach. Specifically, CodS is capable of generating Java code from the class and state models of the software system by making use of the previously solved model-to-code transformation examples. Our tool enables the designers to specify behavioural actions in the input models using the Action Specification Language (ASL). We use an industrial case study of the Elevator Control System (ECS) to perform the experimental validation of our tool. Our results indicate that the code generated by CodS is correct and consistent with the input design models. CodS performs the process of automatic code generation without taking the explicit transformation rule set or languages metamodels information as input, which distinguishes it from all the existing automatic code generation tools.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01524"
  },
  "2312.01523": {
    "title": "SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise",
    "authors": [
      "Abhay Kumar Yadav",
      "Arjun Singh"
    ],
    "abstract": "In this paper, we introduce a novel fine-tuning technique for language models, which involves incorporating symmetric noise into the embedding process. This method aims to enhance the model's function by more stringently regulating its local curvature, demonstrating superior performance over the current method, NEFTune. When fine-tuning the LLaMA-2-7B model using Alpaca, standard techniques yield a 29.79% score on AlpacaEval. However, our approach, SymNoise, increases this score significantly to 69.04%, using symmetric noisy embeddings. This is a 6.7% improvement over the state-of-the-art method, NEFTune~(64.69%). Furthermore, when tested on various models and stronger baseline instruction datasets, such as Evol-Instruct, ShareGPT, OpenPlatypus, SymNoise consistently outperforms NEFTune. The current literature, including NEFTune, has underscored the importance of more in-depth research into the application of noise-based strategies in the fine-tuning of language models. Our approach, SymNoise, is another significant step towards this direction, showing notable improvement over the existing state-of-the-art method.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.01523"
  },
  "2312.01521": {
    "title": "Neural Markov Prolog",
    "authors": [
      "Alexander Thomson",
      "David Page"
    ],
    "abstract": "The recent rapid advance of AI has been driven largely by innovations in neural network architectures. A concomitant concern is how to understand these resulting systems. In this paper, we propose a tool to assist in both the design of further innovative architectures and the simple yet precise communication of their structure. We propose the language Neural Markov Prolog (NMP), based on both Markov logic and Prolog, as a means to both bridge first order logic and neural network design and to allow for the easy generation and presentation of architectures for images, text, relational databases, or other target data types or their mixtures.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.01521"
  },
  "2312.01520": {
    "title": "Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation",
    "authors": [
      "Marco Scutari"
    ],
    "abstract": "Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.\n        \u25b3 Less",
    "submission_date": "15 January, 2024",
    "eprint_id": "2312.01520"
  },
  "2312.01515": {
    "title": "Bigger is not Always Better: The Effect of Context Size on Speech Pre-Training",
    "authors": [
      "Sean Robertson",
      "Ewan Dunbar"
    ],
    "abstract": "It has been generally assumed in the automatic speech recognition (ASR) literature that it is better for models to have access to wider context windows. Yet, many of the potential reasons this might be true in the supervised setting do not necessarily transfer over to the case of unsupervised learning. We investigate how much context is necessary to achieve high-quality pre-trained acoustic models using self-supervised learning. We principally investigate contrastive predictive coding (CPC), which we adapt to be able to precisely control the amount of context visible to the model during training and inference. We find that phone discriminability in the resulting model representations peaks at around 40~ms of preceding context, and that having too much context (beyond around 320 ms) substantially degrades the quality of the representations. Surprisingly, we find that this pattern also transfers to supervised ASR when the pre-trained representations are used as frozen input features. Our results point to potential changes in the design of current upstream architectures to better facilitate a variety of downstream tasks.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01515"
  },
  "2312.01513": {
    "title": "When Effort May Fail: Equilibria of Shared Effort with a Threshold",
    "authors": [
      "Gleb Polevoy",
      "Stojan Trajanovski",
      "Mathijs de Weerdt"
    ],
    "abstract": "Shared effort games model people investing resources in public projects, where the share of the generated values is predefined. In linear $\u03b8$ sharing (effort) games, a project's value is linear in the total contribution, while the threshold $\u03b8$ for effort defines which contributors win and receive their (equal) share. Thresholds between 0 and 1 model games such as paper co-authorship and shared assignments, where a minimum positive contribution is required for sharing in the value. We constructively characterise the conditions for the existence of a pure equilibrium for $\u03b8\\in\\{0,1\\}$, and for two-player games with a general threshold,% and find the prices of anarchy and stability. For more players, we also provide existence and efficiency results, and use generalised fictitious play simulations to show when a pure equilibrium exists and what its efficiency is. We also prove mixed equilibria always exist and bound their efficiency. This facilitates reaching socially efficient equilibria.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01513"
  },
  "2312.01511": {
    "title": "SoK: The Gap Between Data Rights Ideals and Reality",
    "authors": [
      "Yujin Kwon",
      "Ella Corren",
      "Gonzalo Munilla Garrido",
      "Chris Hoofnagle",
      "Dawn Song"
    ],
    "abstract": "As information economies burgeon, they unlock innovation and economic wealth while posing novel threats to civil liberties and altering power dynamics between individuals, companies, and governments. Legislatures have reacted with privacy laws designed to empower individuals over their data. These laws typically create rights for \"data subjects\" (individuals) to make requests of data collectors (companies and governments). The European Union General Data Protection Regulation (GDPR) exemplifies this, granting extensive data rights to data subjects, a model embraced globally. However, the question remains: do these rights-based privacy laws effectively empower individuals over their data? This paper scrutinizes these approaches by reviewing 201 interdisciplinary empirical studies, news articles, and blog posts. We pinpoint 15 key questions concerning the efficacy of rights allocations. The literature often presents conflicting results regarding the effectiveness of rights-based frameworks, but it generally emphasizes their limitations. We offer recommendations to policymakers and Computer Science (CS) groups committed to these frameworks, and suggest alternative privacy regulation approaches.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01511"
  },
  "2312.01509": {
    "title": "Tackling Bias in Pre-trained Language Models: Current Trends and Under-represented Societies",
    "authors": [
      "Vithya Yogarajan",
      "Gillian Dobbie",
      "Te Taka Keegan",
      "Rostam J. Neuwirth"
    ],
    "abstract": "The benefits and capabilities of pre-trained language models (LLMs) in current and future innovations are vital to any society. However, introducing and using LLMs comes with biases and discrimination, resulting in concerns about equality, diversity and fairness, and must be addressed. While understanding and acknowledging bias in LLMs and developing mitigation strategies are crucial, the generalised assumptions towards societal needs can result in disadvantages towards under-represented societies and indigenous populations. Furthermore, the ongoing changes to actual and proposed amendments to regulations and laws worldwide also impact research capabilities in tackling the bias problem. This research presents a comprehensive survey synthesising the current trends and limitations in techniques used for identifying and mitigating bias in LLMs, where the overview of methods for tackling bias are grouped into metrics, benchmark datasets, and mitigation strategies. The importance and novelty of this survey are that it explores the perspective of under-represented societies. We argue that current practices tackling the bias problem cannot simply be 'plugged in' to address the needs of under-represented societies. We use examples from New Zealand to present requirements for adopting existing techniques to under-represented societies.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01509"
  },
  "2312.01508": {
    "title": "CityGen: Infinite and Controllable 3D City Layout Generation",
    "authors": [
      "Jie Deng",
      "Wenhao Chai",
      "Jianshu Guo",
      "Qixuan Huang",
      "Wenhao Hu",
      "Jenq-Neng Hwang",
      "Gaoang Wang"
    ],
    "abstract": "City layout generation has recently gained significant attention. The goal of this task is to automatically generate the layout of a city scene, including elements such as roads, buildings, vegetation, as well as other urban infrastructures. Previous methods using VAEs or GANs for 3D city layout generation offer limited diversity and constrained interactivity, only allowing users to selectively regenerate parts of the layout, which greatly limits customization. In this paper, we propose CityGen, a novel end-to-end framework for infinite, diverse and controllable 3D city layout generation.First, we propose an outpainting pipeline to extend the local layout to an infinite city layout. Then, we utilize a multi-scale diffusion model to generate diverse and controllable local semantic layout patches. The extensive experiments show that CityGen achieves state-of-the-art (SOTA) performance under FID and KID in generating an infinite and controllable 3D city layout. CityGen demonstrates promising applicability in fields like smart cities, urban planning, and digital simulation.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01508"
  },
  "2312.01507": {
    "title": "Learn2Extend: Extending sequences by retaining their statistical properties with mixture models",
    "authors": [
      "Dimitris Vartziotis",
      "George Dasoulas",
      "Florian Pausinger"
    ],
    "abstract": "This paper addresses the challenge of extending general finite sequences of real numbers within a subinterval of the real line, maintaining their inherent statistical properties by employing machine learning. Our focus lies on preserving the gap distribution and pair correlation function of these point sets. Leveraging advancements in deep learning applied to point processes, this paper explores the use of an auto-regressive \\textit{Sequence Extension Mixture Model} (SEMM) for extending finite sequences, by estimating directly the conditional density, instead of the intensity function. We perform comparative experiments on multiple types of point processes, including Poisson, locally attractive, and locally repelling sequences, and we perform a case study on the prediction of Riemann $\u03b6$ function zeroes. The results indicate that the proposed mixture model outperforms traditional neural network architectures in sequence extension with the retention of statistical properties. Given this motivation, we showcase the capabilities of a mixture model to extend sequences, maintaining specific statistical properties, i.e. the gap distribution, and pair correlation indicators.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01507"
  },
  "2312.01504": {
    "title": "Effectively Fine-tune to Improve Large Multimodal Models for Radiology Report Generation",
    "authors": [
      "Yuzhe Lu",
      "Sungmin Hong",
      "Yash Shah",
      "Panpan Xu"
    ],
    "abstract": "Writing radiology reports from medical images requires a high level of domain expertise. It is time-consuming even for trained radiologists and can be error-prone for inexperienced radiologists. It would be appealing to automate this task by leveraging generative AI, which has shown drastic progress in vision and language understanding. In particular, Large Language Models (LLM) have demonstrated impressive capabilities recently and continued to set new state-of-the-art performance on almost all natural language tasks. While many have proposed architectures to combine vision models with LLMs for multimodal tasks, few have explored practical fine-tuning strategies. In this work, we proposed a simple yet effective two-stage fine-tuning protocol to align visual features to LLM's text embedding space as soft visual prompts. Our framework with OpenLLaMA-7B achieved state-of-the-art level performance without domain-specific pretraining. Moreover, we provide detailed analyses of soft visual prompts and attention mechanisms, shedding light on future research directions.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01504"
  },
  "2312.01502": {
    "title": "Normed Spaces for Graph Embedding",
    "authors": [
      "Diaaeldin Taha",
      "Wei Zhao",
      "J. Maxwell Riestenberg",
      "Michael Strube"
    ],
    "abstract": "Theoretical results from discrete geometry suggest that normed spaces can abstractly embed finite metric spaces with surprisingly low theoretical bounds on distortion in low dimensions. In this paper, inspired by this theoretical insight, we highlight normed spaces as a more flexible and computationally efficient alternative to several popular Riemannian manifolds for learning graph embeddings. Normed space embeddings significantly outperform several popular manifolds on a large range of synthetic and real-world graph reconstruction benchmark datasets while requiring significantly fewer computational resources. We also empirically verify the superiority of normed space embeddings on growing families of graphs associated with negative, zero, and positive curvature, further reinforcing the flexibility of normed spaces in capturing diverse graph structures as graph sizes increase. Lastly, we demonstrate the utility of normed space embeddings on two applied graph embedding tasks, namely, link prediction and recommender systems. Our work highlights the potential of normed spaces for geometric graph representation learning, raises new research questions, and offers a valuable tool for experimental mathematics in the field of finite metric space embeddings. We make our code and data publically available.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01502"
  },
  "2312.01500": {
    "title": "Unsupervised Approach to Evaluate Sentence-Level Fluency: Do We Really Need Reference?",
    "authors": [
      "Gopichand Kanumolu",
      "Lokesh Madasu",
      "Pavan Baswani",
      "Ananya Mukherjee",
      "Manish Shrivastava"
    ],
    "abstract": "Fluency is a crucial goal of all Natural Language Generation (NLG) systems. Widely used automatic evaluation metrics fall short in capturing the fluency of machine-generated text. Assessing the fluency of NLG systems poses a challenge since these models are not limited to simply reusing words from the input but may also generate abstractions. Existing reference-based fluency evaluations, such as word overlap measures, often exhibit weak correlations with human judgments. This paper adapts an existing unsupervised technique for measuring text fluency without the need for any reference. Our approach leverages various word embeddings and trains language models using Recurrent Neural Network (RNN) architectures. We also experiment with other available multilingual Language Models (LMs). To assess the performance of the models, we conduct a comparative analysis across 10 Indic languages, correlating the obtained fluency scores with human judgments. Our code and human-annotated benchmark test-set for fluency is available at https://github.com/AnanyaCoder/TextFluencyForIndicLanaguges.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01500"
  },
  "2312.01499": {
    "title": "Towards Decentralized Task Offloading and Resource Allocation in User-Centric Mobile Edge Computing",
    "authors": [
      "Langtian Qin",
      "Hancheng Lu",
      "Yuang Chen",
      "Baolin Chong",
      "Feng Wu"
    ],
    "abstract": "In the traditional cellular-based mobile edge computing (MEC), users at the edge of the cell are prone to suffer severe inter-cell interference and signal attenuation, leading to low throughput even transmission interruptions. Such edge effect severely obstructs offloading of tasks to MEC servers. To address this issue, we propose user-centric mobile edge computing (UCMEC), a novel MEC architecture integrating user-centric transmission, which can ensure high throughput and reliable communication for task offloading. Then, we formulate an optimization problem with joint consideration of task offloading, power control, and computing resource allocation in UCMEC, aiming at obtaining the optimal performance in terms of long-term average total delay. To solve the intractable problem, we propose two decentralized joint optimization schemes based on multi-agent deep reinforcement learning (MADRL) and convex optimization, which consider both cooperation and non-cooperation among network nodes. Simulation results demonstrate that the proposed schemes in UCMEC can significantly improve the uplink transmission rate by at most 343.56% and reduce the long-term average total delay by at most 45.57% compared to traditional cellular-based MEC.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01499"
  },
  "2312.01498": {
    "title": "Learning Neural Traffic Rules",
    "authors": [
      "Xuan Zhang",
      "Xifeng Gao",
      "Kui Wu",
      "Zherong Pan"
    ],
    "abstract": "Extensive research has been devoted to the field of multi-agent navigation. Recently, there has been remarkable progress attributed to the emergence of learning-based techniques with substantially elevated intelligence and realism. Nonetheless, prevailing learned models face limitations in terms of scalability and effectiveness, primarily due to their agent-centric nature, i.e., the learned neural policy is individually deployed on each agent. Inspired by the efficiency observed in real-world traffic networks, we present an environment-centric navigation policy. Our method learns a set of traffic rules to coordinate a vast group of unintelligent agents that possess only basic collision-avoidance capabilities. Our method segments the environment into distinct blocks and parameterizes the traffic rule using a Graph Recurrent Neural Network (GRNN) over the block network. Each GRNN node is trained to modulate the velocities of agents as they traverse through. Using either Imitation Learning (IL) or Reinforcement Learning (RL) schemes, we demonstrate the efficacy of our neural traffic rules in resolving agent congestion, closely resembling real-world traffic regulations. Our method handles up to $240$ agents at real-time and generalizes across diverse agent and environment configurations.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01498"
  },
  "2312.01488": {
    "title": "ADT: Agent-based Dynamic Thresholding for Anomaly Detection",
    "authors": [
      "Xue Yang",
      "Enda Howley",
      "Micheal Schukat"
    ],
    "abstract": "The complexity and scale of IT systems are increasing dramatically, posing many challenges to real-world anomaly detection. Deep learning anomaly detection has emerged, aiming at feature learning and anomaly scoring, which has gained tremendous success. However, little work has been done on the thresholding problem despite it being a critical factor for the effectiveness of anomaly detection. In this paper, we model thresholding in anomaly detection as a Markov Decision Process and propose an agent-based dynamic thresholding (ADT) framework based on a deep Q-network. The proposed method can be integrated into many systems that require dynamic thresholding. An auto-encoder is utilized in this study to obtain feature representations and produce anomaly scores for complex input data. ADT can adjust thresholds adaptively by utilizing the anomaly scores from the auto-encoder and significantly improve anomaly detection performance. The properties of ADT are studied through experiments on three real-world datasets and compared with benchmarks, hence demonstrating its thresholding capability, data-efficient learning, stability, and robustness. Our study validates the effectiveness of reinforcement learning in optimal thresholding control in anomaly detection.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01488"
  },
  "2312.01487": {
    "title": "BetterMinton Service: Analyzing the Badminton Service using Open Kinetic Chain",
    "authors": [
      "Eden Cong-He Xu",
      "Lung-Pan Cheng"
    ],
    "abstract": "We present a badminton training system that focuses on the backhand short service. Unlike the prior motor skill training systems which focus on the trainee's posture, our system analyzes the process of moving joints with the open kinetic chain (OKC), which helps align movement and minimize muscle use for better joint control. We process the users' mocap data to visually show their last service process comparing to 4 ideal OKC characteristics that we collected from a 6-sub-elite formative study as well as recommended contact posture. We validate our system through a 12-user study that measures serving accuracy, qualitative feedback, and skeletal data with users at various skill levels and open source our skeletal analysis model for future use. While the participants' overall service accuracy was not significantly improved, our results show that our system helps participants in the short term to fine-tune their service motion closer to our ideal 4 OKC characteristics.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01487"
  },
  "2312.01482": {
    "title": "FeltingReel: Density Varying Soft Fabrication with Reeling and Felting",
    "authors": [
      "Ping-Yi Wang",
      "Lung-Pan Cheng"
    ],
    "abstract": "FeltingReel is a soft fabrication system that allows users to create a 3D non-woven textile with various structural strengths. Our system coils wool yarn onto a central reel to form a basic shape and uses actuated barbed needles to refine it. By controlling the coiling tension and the felting times, our system varies the density of the workpiece in a target area to achieve various structural strengths. Specifically, our system controls the tilt of coiling and felting using a Stewart platform around a motorized rotating reel. Our system also allows different basic shapes with hollow internal structures to be formed by changing the detachable reel core. We investigate the effects of different felting needles, frequencies, and coiling directions that influence the density, structural strength, and fabrication time of a workpiece. We propose three methods to combine felting and reeling. We evaluate their performances and final products by producing two example workpieces using our system. We demonstrate several objects made by our working system and discuss its capabilities and limitations.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01482"
  },
  "2312.01476": {
    "title": "Context-Enhanced Relational Operators with Vector Embeddings",
    "authors": [
      "Viktor Sanca",
      "Manos Chatzakis",
      "Anastasia Ailamaki"
    ],
    "abstract": "Collecting data, extracting value, and combining insights from relational and context-rich multi-modal sources in data processing pipelines presents a challenge for traditional relational DBMS. While relational operators allow declarative and optimizable query specification, they are limited to data transformations unsuitable for capturing or analyzing context. On the other hand, representation learning models can map context-rich data into embeddings, allowing machine-automated context processing but requiring imperative data transformation integration with the analytical query.\n  To bridge this dichotomy, we present a context-enhanced relational join and introduce an embedding operator composable with relational operators. This enables hybrid relational and context-rich vector data processing, with algebraic equivalences compatible with relational algebra and corresponding logical and physical optimizations. We investigate model-operator interaction with vector data processing and study the characteristics of the E-join operator. Using an example of string embeddings, we demonstrate enabling hybrid context-enhanced processing on relational join operators with vector embeddings. The importance of holistic optimization, from logical to physical, is demonstrated in an order of magnitude execution time improvement.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01476"
  },
  "2312.01473": {
    "title": "Regularity as Intrinsic Reward for Free Play",
    "authors": [
      "Cansu Sancaktar",
      "Justus Piater",
      "Georg Martius"
    ],
    "abstract": "We propose regularity as a novel reward signal for intrinsically-motivated reinforcement learning. Taking inspiration from child development, we postulate that striving for structure and order helps guide exploration towards a subspace of tasks that are not favored by naive uncertainty-based intrinsic rewards. Our generalized formulation of Regularity as Intrinsic Reward (RaIR) allows us to operationalize it within model-based reinforcement learning. In a synthetic environment, we showcase the plethora of structured patterns that can emerge from pursuing this regularity objective. We also demonstrate the strength of our method in a multi-object robotic manipulation environment. We incorporate RaIR into free play and use it to complement the model's epistemic uncertainty as an intrinsic reward. Doing so, we witness the autonomous construction of towers and other regular structures during free play, which leads to a substantial improvement in zero-shot downstream task performance on assembly tasks.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01473"
  },
  "2312.01468": {
    "title": "Exploring Adversarial Robustness of LiDAR-Camera Fusion Model in Autonomous Driving",
    "authors": [
      "Bo Yang",
      "Xiaoyu Ji",
      "Zizhi Jin",
      "Yushi Cheng",
      "Wenyuan Xu"
    ],
    "abstract": "Our study assesses the adversarial robustness of LiDAR-camera fusion models in 3D object detection. We introduce an attack technique that, by simply adding a limited number of physically constrained adversarial points above a car, can make the car undetectable by the fusion model. Experimental results reveal that even without changes to the image data channel, the fusion model can be deceived solely by manipulating the LiDAR data channel. This finding raises safety concerns in the field of autonomous driving. Further, we explore how the quantity of adversarial points, the distance between the front-near car and the LiDAR-equipped car, and various angular factors affect the attack success rate. We believe our research can contribute to the understanding of multi-sensor robustness, offering insights and guidance to enhance the safety of autonomous driving.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2312.01468"
  },
  "2312.01467": {
    "title": "Online Dominating Set and Coloring for Geometric Intersection Graphs",
    "authors": [
      "Minati De",
      "Sambhav Khurana",
      "Satyam Singh"
    ],
    "abstract": "We present online deterministic algorithms for minimum coloring and minimum dominating set problems in the context of geometric intersection graphs. We consider a graph parameter: the independent kissing number $\u03b6$, which is a number equal to `the size of the largest induced star in the graph $-1$'. For a graph with an independent kissing number at most $\u03b6$, we show that the famous greedy algorithm achieves an optimal competitive ratio of $\u03b6$ for the minimum dominating set and the minimum independent dominating set problems. However, for the minimum connected dominating set problem, we obtain a competitive ratio of at most $2\u03b6$. To complement this, we prove that for the minimum connected dominating set problem, any deterministic online algorithm has a competitive ratio of at least $2(\u03b6-1)$ for the geometric intersection graph of translates of a convex object in $\\mathbb{R}^2$. Next, for the minimum coloring problem, we obtain algorithms having a competitive ratio of $O\\left({\u03b6'}{\\log m}\\right)$ for geometric intersection graphs of bounded scaled $\u03b1$-fat objects in $\\mathbb{R}^d$ having widths in the interval $[1,m]$, where $\u03b6'$ is the independent kissing number of the geometric intersection graph of bounded scaled $\u03b1$-fat objects having widths in the interval $[1,2]$. Finally, we investigate the value of $\u03b6$ for geometric intersection graphs of various families of geometric objects.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01467"
  },
  "2312.01460": {
    "title": "Towards an accurate and generalizable multiple sclerosis lesion segmentation model using self-ensembled lesion fusion",
    "authors": [
      "Jinwei Zhang",
      "Lianrui Zuo",
      "Blake E. Dewey",
      "Samuel W. Remedios",
      "Dzung L. Pham",
      "Aaron Carass",
      "Jerry L. Prince"
    ],
    "abstract": "Automatic multiple sclerosis (MS) lesion segmentation using multi-contrast magnetic resonance (MR) images provides improved efficiency and reproducibility compared to manual delineation. Current state-of-the-art automatic MS lesion segmentation methods utilize modified U-Net-like architectures. However, in the literature, dedicated architecture modifications were always required to maximize their performance. In addition, the best-performing methods have not proven to be generalizable to diverse test datasets with contrast variations and image artifacts. In this work, we developed an accurate and generalizable MS lesion segmentation model using the well-known U-Net architecture without further modification. A novel test-time self-ensembled lesion fusion strategy is proposed that not only achieved the best performance using the ISBI 2015 MS segmentation challenge data but also demonstrated robustness across various self-ensemble parameter choices. Moreover, equipped with instance normalization rather than batch normalization widely used in literature, the model trained on the ISBI challenge data generalized well on clinical test datasets from different scanners.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01460"
  },
  "2312.01457": {
    "title": "Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits",
    "authors": [
      "Muhammad Faaiz Taufiq",
      "Arnaud Doucet",
      "Rob Cornish",
      "Jean-Francois Ton"
    ],
    "abstract": "Off-Policy Evaluation (OPE) in contextual bandits is crucial for assessing new policies using existing data without costly experimentation. However, current OPE methods, such as Inverse Probability Weighting (IPW) and Doubly Robust (DR) estimators, suffer from high variance, particularly in cases of low overlap between target and behavior policies or large action and context spaces. In this paper, we introduce a new OPE estimator for contextual bandits, the Marginal Ratio (MR) estimator, which focuses on the shift in the marginal distribution of outcomes $Y$ instead of the policies themselves. Through rigorous theoretical analysis, we demonstrate the benefits of the MR estimator compared to conventional methods like IPW and DR in terms of variance reduction. Additionally, we establish a connection between the MR estimator and the state-of-the-art Marginalized Inverse Propensity Score (MIPS) estimator, proving that MR achieves lower variance among a generalized family of MIPS estimators. We further illustrate the utility of the MR estimator in causal inference settings, where it exhibits enhanced performance in estimating Average Treatment Effects (ATE). Our experiments on synthetic and real-world datasets corroborate our theoretical findings and highlight the practical advantages of the MR estimator in OPE for contextual bandits.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01457"
  },
  "2312.01456": {
    "title": "Compositional Policy Learning in Stochastic Control Systems with Formal Guarantees",
    "authors": [
      "\u0110or\u0111e \u017dikeli\u0107",
      "Mathias Lechner",
      "Abhinav Verma",
      "Krishnendu Chatterjee",
      "Thomas A. Henzinger"
    ],
    "abstract": "Reinforcement learning has shown promising results in learning neural network policies for complicated control tasks. However, the lack of formal guarantees about the behavior of such policies remains an impediment to their deployment. We propose a novel method for learning a composition of neural network policies in stochastic environments, along with a formal certificate which guarantees that a specification over the policy's behavior is satisfied with the desired probability. Unlike prior work on verifiable RL, our approach leverages the compositional nature of logical specifications provided in SpectRL, to learn over graphs of probabilistic reach-avoid specifications. The formal guarantees are provided by learning neural network policies together with reach-avoid supermartingales (RASM) for the graph's sub-tasks and then composing them into a global policy. We also derive a tighter lower bound compared to previous work on the probability of reach-avoidance implied by a RASM, which is required to find a compositional policy with an acceptable probabilistic threshold for complex tasks with multiple edge policies. We implement a prototype of our approach and evaluate it on a Stochastic Nine Rooms environment.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01456"
  },
  "2312.01455": {
    "title": "32-Bit RISC-V CPU Core on Logisim",
    "authors": [
      "Siddesh D. Patil",
      "Premraj V. Jadhav",
      "Siddharth Sankhe"
    ],
    "abstract": "This project focuses on making a RISC-V CPU Core using the Logisim software. RISC-V is significant because it will allow smaller device manufacturers to build hardware without paying royalties and allow developers and researchers to design and experiment with a proven and freely available instruction set architecture. RISC-V is ideal for a variety of applications from IOTs to Embedded systems such as disks, CPUs, Calculators, SOCs, etc. RISC-V(Reduced Instruction Set Architecture) is an open standard instruction set architecture (ISA) based on established reduced instruction set computer (RISC) principles. Unlike most other ISA designs, the RISC-V ISA is provided under open source licenses that do not require fees to use.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01455"
  },
  "2312.01454": {
    "title": "D-Bot: Database Diagnosis System using Large Language Models",
    "authors": [
      "Xuanhe Zhou",
      "Guoliang Li",
      "Zhaoyan Sun",
      "Zhiyuan Liu",
      "Weize Chen",
      "Jianming Wu",
      "Jiesi Liu",
      "Ruohang Feng",
      "Guoyang Zeng"
    ],
    "abstract": "Database administrators (DBAs) play an important role in managing, maintaining and optimizing database systems. However, it is hard and tedious for DBAs to manage a large number of databases and give timely response (waiting for hours is intolerable in many online cases). In addition, existing empirical methods only support limited diagnosis scenarios, which are also labor-intensive to update the diagnosis rules for database version updates. Recently large language models (LLMs) have shown great potential in various fields. Thus, we propose D-Bot, an LLM-based database diagnosis system that can automatically acquire knowledge from diagnosis documents, and generate reasonable and well-founded diagnosis report (i.e., identifying the root causes and solutions) within acceptable time (e.g., under 10 minutes compared to hours by a DBA). The techniques in D-Bot include (i) offline knowledge extraction from documents, (ii) automatic prompt generation (e.g., knowledge matching, tool retrieval), (iii) root cause analysis using tree search algorithm, and (iv) collaborative mechanism for complex anomalies with multiple root causes. We verify D-Bot on real benchmarks (including 539 anomalies of six typical applications), and the results show that D-Bot can effectively analyze the root causes of unseen anomalies and significantly outperforms traditional methods and vanilla models like GPT-4.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01454"
  },
  "2312.01450": {
    "title": "Foveation in the Era of Deep Learning",
    "authors": [
      "George Killick",
      "Paul Henderson",
      "Paul Siebert",
      "Gerardo Aragon-Camarasa"
    ],
    "abstract": "In this paper, we tackle the challenge of actively attending to visual scenes using a foveated sensor. We introduce an end-to-end differentiable foveated active vision architecture that leverages a graph convolutional network to process foveated images, and a simple yet effective formulation for foveated image sampling. Our model learns to iteratively attend to regions of the image relevant for classification. We conduct detailed experiments on a variety of image datasets, comparing the performance of our method with previous approaches to foveated vision while measuring how the impact of different choices, such as the degree of foveation, and the number of fixations the network performs, affect object recognition performance. We find that our model outperforms a state-of-the-art CNN and foveated vision architectures of comparable parameters and a given pixel or computation budget\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01450"
  },
  "2312.01445": {
    "title": "Classification of Home Network Problems with Transformers",
    "authors": [
      "Jeremias D\u00f6tterl",
      "Zahra Hemmati Fard"
    ],
    "abstract": "We propose a classifier that can identify ten common home network problems based on the raw textual output of networking tools such as ping, dig, and ip. Our deep learning model uses an encoder-only transformer architecture with a particular pre-tokenizer that we propose for splitting the tool output into token sequences. The use of transformers distinguishes our approach from related work on network problem classification, which still primarily relies on non-deep-learning methods. Our model achieves high accuracy in our experiments, demonstrating the high potential of transformer-based problem classification for the home network.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01445"
  },
  "2312.01444": {
    "title": "Looking Inside Out: Anticipating Driver Intent From Videos",
    "authors": [
      "Yung-chi Kung",
      "Arthur Zhang",
      "Junmin Wang",
      "Joydeep Biswas"
    ],
    "abstract": "Anticipating driver intention is an important task when vehicles of mixed and varying levels of human/machine autonomy share roadways. Driver intention can be leveraged to improve road safety, such as warning surrounding vehicles in the event the driver is attempting a dangerous maneuver. In this work, we propose a novel method of utilizing in-cabin and external camera data to improve state-of-the-art (SOTA) performance in predicting future driver actions. Compared to existing methods, our approach explicitly extracts object and road-level features from external camera data, which we demonstrate are important features for predicting driver intention. Using our handcrafted features as inputs for both a transformer and an LSTM-based architecture, we empirically show that jointly utilizing in-cabin and external features improves performance compared to using in-cabin features alone. Furthermore, our models predict driver maneuvers more accurately and earlier than existing approaches, with an accuracy of 87.5% and an average prediction time of 4.35 seconds before the maneuver takes place. We release our model configurations and training scripts on https://github.com/ykung83/Driver-Intent-Prediction\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01444"
  },
  "2312.01436": {
    "title": "Robust Resource Partitioning Approach for ARINC 653 RTOS",
    "authors": [
      "Vitaly Cheptsov",
      "Alexey Khoroshilov"
    ],
    "abstract": "Modern airborne operating systems implement the concept of robust time and resource partitioning imposed by the standards for aerospace and airborne-embedded software systems, such as ARINC 653. While these standards do provide a considerable amount of design choices in regards to resource partitioning on the architectural and API levels, such as isolated memory spaces between the application partitions, predefined resource configuration, and unidirectional ports with limited queue and message sizes for inter-partition communication, they do not specify how an operating system should implement them in software. Furthermore, they often tend to set the minimal level of the required guarantees, for example, in terms of memory permissions, and disregard the hardware state of the art, which presently can provide considerably stronger guarantees at no extra cost. In the paper we present an architecture of robust resource partitioning for ARINC 653 real-time operating systems based on completely static MMU configuration. The architecture was implemented on different types of airborne hardware, including platforms with TLB-based and page table-based MMU. Key benefits of the proposed approach include minimised run-time overhead and simpler verification of the memory subsystem.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01436"
  },
  "2312.01432": {
    "title": "Fast Dual Subgradient Optimization of the Integrated Transportation Distance Between Stochastic Kernels",
    "authors": [
      "Zhengqi Lin",
      "Andrzej Ruszczynski"
    ],
    "abstract": "A generalization of the Wasserstein metric, the integrated transportation distance, establishes a novel distance between probability kernels of Markov systems. This metric serves as the foundation for an efficient approximation technique, enabling the replacement of the original system's kernel with a kernel with a discrete support of limited cardinality. To facilitate practical implementation, we present a specialized dual algorithm capable of constructing these approximate kernels quickly and efficiently, without requiring computationally expensive matrix operations. Finally, we demonstrate the efficacy of our method through several illustrative examples, showcasing its utility in practical scenarios. This advancement offers new possibilities for the streamlined analysis and manipulation of stochastic systems represented by kernels.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01432"
  },
  "2312.01429": {
    "title": "Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars",
    "authors": [
      "Kaiyue Wen",
      "Yuchen Li",
      "Bingbin Liu",
      "Andrej Risteski"
    ],
    "abstract": "Interpretability methods aim to understand the algorithm implemented by a trained model (e.g., a Transofmer) by examining various aspects of the model, such as the weight matrices or the attention patterns. In this work, through a combination of theoretical results and carefully controlled experiments on synthetic data, we take a critical view of methods that exclusively focus on individual parts of the model, rather than consider the network as a whole. We consider a simple synthetic setup of learning a (bounded) Dyck language. Theoretically, we show that the set of models that (exactly or approximately) solve this task satisfy a structural characterization derived from ideas in formal languages (the pumping lemma). We use this characterization to show that the set of optima is qualitatively rich; in particular, the attention pattern of a single layer can be ``nearly randomized'', while preserving the functionality of the network. We also show via extensive experiments that these constructions are not merely a theoretical artifact: even after severely constraining the architecture of the model, vastly different solutions can be reached via standard training. Thus, interpretability claims based on inspecting individual heads or weight matrices in the Transformer can be misleading.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01429"
  },
  "2312.01424": {
    "title": "Batch Hop-Constrained s-t Simple Path Query Processing in Large Graphs",
    "authors": [
      "Long Yuan",
      "Kongzhang Hao",
      "Xuemin Lin",
      "Wenjie Zhang"
    ],
    "abstract": "Hop-constrained s-t simple path (HC-s-t path) enumeration is a fundamental problem in graph analysis. Existing solutions for this problem focus on optimizing the processing performance of a single query. However, in practice, it is more often that multiple HC-s-t path queries are issued simultaneously and processed as a batch. Therefore, we study the problem of batch HC-s-t path query processing in this paper and aim to compute the results of all queries concurrently and efficiently as a batch. To achieve this goal, we first propose the concept of HC-s path query which can precisely characterize the common computation among different queries.We then devise a two-phase HC-s path query detection algorithm to identify the common HC-s path queries for the given HC-s-t path queries. Based on the detected HC-s path queries, we further devise an efficient HC-s-t path enumeration algorithm in which the common computation represented by HC-s path queries are effectively shared. We conduct extensive experiments on real-world graphs and the experimental results demonstrate that our proposed algorithm is efficient and scalable regarding processing multiple HC-s-t path queries in large graphs at billion-scale.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2312.01424"
  },
  "2312.01421": {
    "title": "RobotGPT: Robot Manipulation Learning from ChatGPT",
    "authors": [
      "Yixiang Jin",
      "Dingzhe Li",
      "Yong A",
      "Jun Shi",
      "Peng Hao",
      "Fuchun Sun",
      "Jianwei Zhang",
      "Bin Fang"
    ],
    "abstract": "We present RobotGPT, an innovative decision framework for robotic manipulation that prioritizes stability and safety. The execution code generated by ChatGPT cannot guarantee the stability and safety of the system. ChatGPT may provide different answers for the same task, leading to unpredictability. This instability prevents the direct integration of ChatGPT into the robot manipulation loop. Although setting the temperature to 0 can generate more consistent outputs, it may cause ChatGPT to lose diversity and creativity. Our objective is to leverage ChatGPT's problem-solving capabilities in robot manipulation and train a reliable agent. The framework includes an effective prompt structure and a robust learning model. Additionally, we introduce a metric for measuring task difficulty to evaluate ChatGPT's performance in robot manipulation. Furthermore, we evaluate RobotGPT in both simulation and real-world environments. Compared to directly using ChatGPT to generate code, our framework significantly improves task success rates, with an average increase from 38.5% to 91.5%. Therefore, training a RobotGPT by utilizing ChatGPT as an expert is a more stable approach compared to directly using ChatGPT as a task planner.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01421"
  },
  "2312.01419": {
    "title": "Finding and counting small tournaments in large tournaments",
    "authors": [
      "Raphael Yuster"
    ],
    "abstract": "We present new algorithms for counting and detecting small tournaments in a given tournament. In particular, it is proved that every tournament on four vertices (there are four) can be detected in $O(n^2)$ time and counted in $O(n^\u03c9)$ time where $\u03c9< 2.373$ is the matrix multiplication exponent. It is also proved that any tournament on five vertices (there are $12$) can be counted in $O(n^{\u03c9+1})$ time. As for lower-bounds, we prove that for almost all $k$-vertex tournaments, the complexity of the detection problem is not easier than the complexity of the corresponding well-studied counting problem for {\\em undirected cliques} of order $k-O(\\log k)$.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01419"
  },
  "2312.01409": {
    "title": "Generative Rendering: Controllable 4D-Guided Video Generation with 2D Diffusion Models",
    "authors": [
      "Shengqu Cai",
      "Duygu Ceylan",
      "Matheus Gadelha",
      "Chun-Hao Paul Huang",
      "Tuanfeng Yang Wang",
      "Gordon Wetzstein"
    ],
    "abstract": "Traditional 3D content creation tools empower users to bring their imagination to life by giving them direct control over a scene's geometry, appearance, motion, and camera path. Creating computer-generated videos, however, is a tedious manual process, which can be automated by emerging text-to-video diffusion models. Despite great promise, video diffusion models are difficult to control, hindering a user to apply their own creativity rather than amplifying it. To address this challenge, we present a novel approach that combines the controllability of dynamic 3D meshes with the expressivity and editability of emerging diffusion models. For this purpose, our approach takes an animated, low-fidelity rendered mesh as input and injects the ground truth correspondence information obtained from the dynamic mesh into various stages of a pre-trained text-to-image generation model to output high-quality and temporally consistent frames. We demonstrate our approach on various examples where motion can be obtained by animating rigged assets or changing the camera path.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01409"
  },
  "2312.01408": {
    "title": "Improving In-Context Learning in Diffusion Models with Visual Context-Modulated Prompts",
    "authors": [
      "Tianqi Chen",
      "Yongfei Liu",
      "Zhendong Wang",
      "Jianbo Yuan",
      "Quanzeng You",
      "Hongxia Yang",
      "Mingyuan Zhou"
    ],
    "abstract": "In light of the remarkable success of in-context learning in large language models, its potential extension to the vision domain, particularly with visual foundation models like Stable Diffusion, has sparked considerable interest. Existing approaches in visual in-context learning frequently face hurdles such as expensive pretraining, limiting frameworks, inadequate visual comprehension, and limited adaptability to new tasks. In response to these challenges, we introduce improved Prompt Diffusion (iPromptDiff) in this study. iPromptDiff integrates an end-to-end trained vision encoder that converts visual context into an embedding vector. This vector is subsequently used to modulate the token embeddings of text prompts. We show that a diffusion-based vision foundation model, when equipped with this visual context-modulated text guidance and a standard ControlNet structure, exhibits versatility and robustness across a variety of training tasks and excels in in-context learning for novel vision tasks, such as normal-to-image or image-to-line transformations. The effectiveness of these capabilities relies heavily on a deep visual understanding, which is achieved through relevant visual demonstrations processed by our proposed in-context learning architecture.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01408"
  },
  "2312.01407": {
    "title": "VideoRF: Rendering Dynamic Radiance Fields as 2D Feature Video Streams",
    "authors": [
      "Liao Wang",
      "Kaixin Yao",
      "Chengcheng Guo",
      "Zhirui Zhang",
      "Qiang Hu",
      "Jingyi Yu",
      "Lan Xu",
      "Minye Wu"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) excel in photorealistically rendering static scenes. However, rendering dynamic, long-duration radiance fields on ubiquitous devices remains challenging, due to data storage and computational constraints. In this paper, we introduce VideoRF, the first approach to enable real-time streaming and rendering of dynamic radiance fields on mobile platforms. At the core is a serialized 2D feature image stream representing the 4D radiance field all in one. We introduce a tailored training scheme directly applied to this 2D domain to impose the temporal and spatial redundancy of the feature image stream. By leveraging the redundancy, we show that the feature image stream can be efficiently compressed by 2D video codecs, which allows us to exploit video hardware accelerators to achieve real-time decoding. On the other hand, based on the feature image stream, we propose a novel rendering pipeline for VideoRF, which has specialized space mappings to query radiance properties efficiently. Paired with a deferred shading model, VideoRF has the capability of real-time rendering on mobile devices thanks to its efficiency. We have developed a real-time interactive player that enables online streaming and rendering of dynamic scenes, offering a seamless and immersive free-viewpoint experience across a range of devices, from desktops to mobile phones.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01407"
  },
  "2312.01398": {
    "title": "Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal Stakeholder's Perspective",
    "authors": [
      "Anmol Singhal",
      "Preethu Rose Anish",
      "Shirish Karande",
      "Smita Ghaisas"
    ],
    "abstract": "Commercial contracts are known to be a valuable source for deriving project-specific requirements. However, contract negotiations mainly occur among the legal counsel of the parties involved. The participation of non-legal stakeholders, including requirement analysts, engineers, and solution architects, whose primary responsibility lies in ensuring the seamless implementation of contractual terms, is often indirect and inadequate. Consequently, a significant number of sentences in contractual clauses, though legally accurate, can appear unfair from an implementation perspective to non-legal stakeholders. This perception poses a problem since requirements indicated in the clauses are obligatory and can involve punitive measures and penalties if not implemented as committed in the contract. Therefore, the identification of potentially unfair clauses in contracts becomes crucial. In this work, we conduct an empirical study to analyze the perspectives of different stakeholders regarding contractual fairness. We then investigate the ability of Pre-trained Language Models (PLMs) to identify unfairness in contractual sentences by comparing chain of thought prompting and semi-supervised fine-tuning approaches. Using BERT-based fine-tuning, we achieved an accuracy of 84% on a dataset consisting of proprietary contracts. It outperformed chain of thought prompting using Vicuna-13B by a margin of 9%.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01398"
  },
  "2312.01394": {
    "title": "Hiders' Game",
    "authors": [
      "Gleb Polevoy",
      "Tomasz Michalak"
    ],
    "abstract": "Consider spies infiltrating a network or dissidents secretly organising under a dictatorship. Such scenarios can be cast as adversarial social network analysis problems involving nodes connecting while evading network analysis tools, e.g., centrality measures or community detection algorithms. While most works consider unilateral actions of an evader, we define a network formation game. Here, several newcomers attempt to rewire the existing social network, to become directly tied with the high centrality players, while keeping their own centrality small. This extends the network formation literature, including the Jackson and Wolinsky model, by considering additional strategies and new utility functions. We algorithmically demonstrate that the pairwise Nash stable networks (\\PANS) constitute a lattice, where the stronger \\PANS{} lattice is nested in the weaker \\PANS. We also prove that inclusion in \\PANS{} implies less utility for everyone. Furthermore, we bound the social efficiency of \\PANS{} and directly connect efficiency to the strength of \\PANS. Finally, we characterise the \\PANS{} in practically important settings, deriving tight efficiency bounds. Our results suggest the hiders how to interconnect stably and efficiently. Additionally, the results let us detect infiltrated networks, enhancing the social network analysis tools. Besides the theoretical development, this is applicable to fighting terrorism and espionage.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01394"
  },
  "2312.01392": {
    "title": "Neural Network Characterization and Entropy Regulated Data Balancing through Principal Component Analysis",
    "authors": [
      "David Yevick",
      "Karolina Hutchison"
    ],
    "abstract": "This paper examines the relationship between the behavior of a neural network and the distribution formed from the projections of the data records into the space spanned by the low-order principal components of the training data. For example, in a benchmark calculation involving rotated and unrotated MNIST digits, classes (digits) that are mapped far from the origin in a low-dimensional principal component space and that overlap minimally with other digits converge rapidly and exhibit high degrees of accuracy in neural network calculations that employ the associated components of each data record as inputs. Further, if the space spanned by these low-order principal components is divided into bins and the input data records that are mapped into a given bin averaged, the resulting pattern can be distinguished by its geometric features which interpolate between those of adjacent bins in an analogous manner to variational autoencoders. Based on this observation, a simply realized data balancing procedure can be realized by evaluating the entropy associated with each histogram bin and subsequently repeating the original image data associated with the bin by a number of times that is determined from this entropy.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01392"
  },
  "2312.01386": {
    "title": "Regret Optimality of GP-UCB",
    "authors": [
      "Wenjia Wang",
      "Xiaowei Zhang",
      "Lu Zou"
    ],
    "abstract": "Gaussian Process Upper Confidence Bound (GP-UCB) is one of the most popular methods for optimizing black-box functions with noisy observations, due to its simple structure and superior performance. Its empirical successes lead to a natural, yet unresolved question: Is GP-UCB regret optimal? In this paper, we offer the first generally affirmative answer to this important open question in the Bayesian optimization literature. We establish new upper bounds on both the simple and cumulative regret of GP-UCB when the objective function to optimize admits certain smoothness property. These upper bounds match the known minimax lower bounds (up to logarithmic factors independent of the feasible region's dimensionality) for optimizing functions with the same smoothness. Intriguingly, our findings indicate that, with the same level of exploration, GP-UCB can simultaneously achieve optimality in both simple and cumulative regret. The crux of our analysis hinges on a refined uniform error bound for online estimation of functions in reproducing kernel Hilbert spaces. This error bound, which we derive from empirical process theory, is of independent interest, and its potential applications may reach beyond the scope of this study.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01386"
  },
  "2312.01381": {
    "title": "Language-driven All-in-one Adverse Weather Removal",
    "authors": [
      "Hao Yang",
      "Liyuan Pan",
      "Yan Yang",
      "Wei Liang"
    ],
    "abstract": "All-in-one (AiO) frameworks restore various adverse weather degradations with a single set of networks jointly. To handle various weather conditions, an AiO framework is expected to adaptively learn weather-specific knowledge for different degradations and shared knowledge for common patterns. However, existing methods: 1) rely on extra supervision signals, which are usually unknown in real-world applications; 2) employ fixed network structures, which restrict the diversity of weather-specific knowledge. In this paper, we propose a Language-driven Restoration framework (LDR) to alleviate the aforementioned issues. First, we leverage the power of pre-trained vision-language (PVL) models to enrich the diversity of weather-specific knowledge by reasoning about the occurrence, type, and severity of degradation, generating description-based degradation priors. Then, with the guidance of degradation prior, we sparsely select restoration experts from a candidate list dynamically based on a Mixture-of-Experts (MoE) structure. This enables us to adaptively learn the weather-specific and shared knowledge to handle various weather conditions (e.g., unknown or mixed weather). Experiments on extensive restoration scenarios show our superior performance (see Fig. 1). The source code will be made available.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01381"
  },
  "2312.01379": {
    "title": "Relation between PLS and OLS regression in terms of the eigenvalue distribution of the regressor covariance matrix",
    "authors": [
      "David del Val",
      "Jos\u00e9 R. Berrendero",
      "Alberto Su\u00e1rez"
    ],
    "abstract": "Partial least squares (PLS) is a dimensionality reduction technique introduced in the field of chemometrics and successfully employed in many other areas. The PLS components are obtained by maximizing the covariance between linear combinations of the regressors and of the target variables. In this work, we focus on its application to scalar regression problems. PLS regression consists in finding the least squares predictor that is a linear combination of a subset of the PLS components. Alternatively, PLS regression can be formulated as a least squares problem restricted to a Krylov subspace. This equivalent formulation is employed to analyze the distance between ${\\hat{\\boldsymbol\u03b2}\\;}_{\\mathrm{PLS}}^{\\scriptscriptstyle {(L)}}$, the PLS estimator of the vector of coefficients of the linear regression model based on $L$ PLS components, and $\\hat{\\boldsymbol \u03b2}_{\\mathrm{OLS}}$, the one obtained by ordinary least squares (OLS), as a function of $L$. Specifically, ${\\hat{\\boldsymbol\u03b2}\\;}_{\\mathrm{PLS}}^{\\scriptscriptstyle {(L)}}$ is the vector of coefficients in the aforementioned Krylov subspace that is closest to $\\hat{\\boldsymbol \u03b2}_{\\mathrm{OLS}}$ in terms of the Mahalanobis distance with respect to the covariance matrix of the OLS estimate. We provide a bound on this distance that depends only on the distribution of the eigenvalues of the regressor covariance matrix. Numerical examples on synthetic and real-world data are used to illustrate how the distance between ${\\hat{\\boldsymbol\u03b2}\\;}_{\\mathrm{PLS}}^{\\scriptscriptstyle {(L)}}$ and $\\hat{\\boldsymbol \u03b2}_{\\mathrm{OLS}}$ depends on the number of clusters in which the eigenvalues of the regressor covariance matrix are grouped.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01379"
  },
  "2312.01367": {
    "title": "DiFace: Cross-Modal Face Recognition through Controlled Diffusion",
    "authors": [
      "Bowen Sun",
      "Shibao Zheng"
    ],
    "abstract": "Diffusion probabilistic models (DPMs) have exhibited exceptional proficiency in generating visual media of outstanding quality and realism. Nonetheless, their potential in non-generative domains, such as face recognition, has yet to be thoroughly investigated. Meanwhile, despite the extensive development of multi-modal face recognition methods, their emphasis has predominantly centered on visual modalities. In this context, face recognition through textual description presents a unique and promising solution that not only transcends the limitations from application scenarios but also expands the potential for research in the field of cross-modal face recognition. It is regrettable that this avenue remains unexplored and underutilized, a consequence from the challenges mainly associated with three aspects: 1) the intrinsic imprecision of verbal descriptions; 2) the significant gaps between texts and images; and 3) the immense hurdle posed by insufficient databases.To tackle this problem, we present DiFace, a solution that effectively achieves face recognition via text through a controllable diffusion process, by establishing its theoretical connection with probability transport. Our approach not only unleashes the potential of DPMs across a broader spectrum of tasks but also achieves, to the best of our knowledge, a significant accuracy in text-to-image face recognition for the first time, as demonstrated by our experiments on verification and identification.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01367"
  },
  "2312.01364": {
    "title": "Tradeoff of age-of-information and power under reliability constraint for short-packet communication with block-length adaptation",
    "authors": [
      "Sudarsanan A. K.",
      "Vineeth B. S.",
      "Chandra R. Murthy"
    ],
    "abstract": "In applications such as remote estimation and monitoring, update packets are transmitted by power-constrained devices using short-packet codes over wireless networks. Therefore, networks need to be end-to-end optimized using information freshness metrics such as age of information under transmit power and reliability constraints to ensure support for such applications. For short-packet coding, modelling and understanding the effect of block codeword length on transmit power and other performance metrics is important. To understand the above optimization for short-packet coding, we consider the optimal tradeoff problem between age of information and transmit power under reliability constraints for short packet point-to-point communication model with an exogenous packet generation process. In contrast to prior work, we consider scheduling policies that can possibly adapt the block-length or transmission time of short packet codes in order to achieve the optimal tradeoff. We characterize the tradeoff using a semi-Markov decision process formulation. We also obtain analytical upper bounds as well as numerical, analytical, and asymptotic lower bounds on the optimal tradeoff. We show that in certain regimes, such as high reliability and high packet generation rate, non-adaptive scheduling policies (fixed transmission time policies) are close-to-optimal. Furthermore, in a high-power or in a low-power regime, non-adaptive as well as state-independent randomized scheduling policies are order-optimal. These results are corroborated by numerical and simulation experiments. The tradeoff is then characterized for a wireless point-to-point channel with block fading as well as for other packet generation models (including an age-dependent packet generation model).\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01364"
  },
  "2312.01361": {
    "title": "MoEC: Mixture of Experts Implicit Neural Compression",
    "authors": [
      "Jianchen Zhao",
      "Cheng-Ching Tseng",
      "Ming Lu",
      "Ruichuan An",
      "Xiaobao Wei",
      "He Sun",
      "Shanghang Zhang"
    ],
    "abstract": "Emerging Implicit Neural Representation (INR) is a promising data compression technique, which represents the data using the parameters of a Deep Neural Network (DNN). Existing methods manually partition a complex scene into local regions and overfit the INRs into those regions. However, manually designing the partition scheme for a complex scene is very challenging and fails to jointly learn the partition and INRs. To solve the problem, we propose MoEC, a novel implicit neural compression method based on the theory of mixture of experts. Specifically, we use a gating network to automatically assign a specific INR to a 3D point in the scene. The gating network is trained jointly with the INRs of different local regions. Compared with block-wise and tree-structured partitions, our learnable partition can adaptively find the optimal partition in an end-to-end manner. We conduct detailed experiments on massive and diverse biomedical data to demonstrate the advantages of MoEC against existing approaches. In most of experiment settings, we have achieved state-of-the-art results. Especially in cases of extreme compression ratios, such as 6000x, we are able to uphold the PSNR of 48.16.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01361"
  },
  "2312.01358": {
    "title": "Formations organization in robotic swarm using the thermal motion equivalent method",
    "authors": [
      "Eduard Heiss",
      "Andrey Kozyr",
      "Oleg Morozov"
    ],
    "abstract": "Due to its decentralised, distributed and scalable nature, swarm robotics has great potential for applications ranging from agriculture to environmental monitoring and logistics. Various swarm control methods and algorithms are currently known, such as virtual leader, vector and potential field, and others. Such methods often show good results in specific conditions and tasks. The variety of tasks solved by the swarm requires the development of a universal control algorithm. In this paper, we propose an evolution of a thermal motion equivalent method (TMEM) inspired by the behavioural similarity of thermodynamic interactions between molecules. Previous research has shown the high efficiency of such a method for terrain monitoring tasks. This work addresses the problem of swarm formation of geometric structures, as required for logistics and formation movement tasks. It is shown that the formation of swarm geometric structures using the TMEM is possible with a special nonlinear interaction function of the agents. A piecewise linear interaction function is proposed that allows the formation of a stable group of agents. The results of the paper are validated by numerical modelling of the swarm dynamics. A linear quadrocopter model is considered as an agent. The fairness of the choice of the interaction function is shown.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01358"
  },
  "2312.01357": {
    "title": "Analyze the robustness of three NMF algorithms (Robust NMF with L1 norm, L2-1 norm NMF, L2 NMF)",
    "authors": [
      "Cheng Zeng",
      "Jiaqi Tian",
      "Yixuan Xu"
    ],
    "abstract": "Non-negative matrix factorization (NMF) and its variants have been widely employed in clustering and classification tasks (Long, & Jian , 2021). However, noises can seriously affect the results of our experiments. Our research is dedicated to investigating the noise robustness of non-negative matrix factorization (NMF) in the face of different types of noise. Specifically, we adopt three different NMF algorithms, namely L1 NMF, L2 NMF, and L21 NMF, and use the ORL and YaleB data sets to simulate a series of experiments with salt-and-pepper noise and Block-occlusion noise separately. In the experiment, we use a variety of evaluation indicators, including root mean square error (RMSE), accuracy (ACC), and normalized mutual information (NMI), to evaluate the performance of different NMF algorithms in noisy environments. Through these indicators, we quantify the resistance of NMF algorithms to noise and gain insights into their feasibility in practical applications.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01357"
  },
  "2312.01356": {
    "title": "CEScore: Simple and Efficient Confidence Estimation Model for Evaluating Split and Rephrase",
    "authors": [
      "AlMotasem Bellah Al Ajlouni",
      "Jinlong Li"
    ],
    "abstract": "The split and rephrase (SR) task aims to divide a long, complex sentence into a set of shorter, simpler sentences that convey the same meaning. This challenging problem in NLP has gained increased attention recently because of its benefits as a pre-processing step in other NLP tasks. Evaluating quality of SR is challenging, as there no automatic metric fit to evaluate this task. In this work, we introduce CEScore, as novel statistical model to automatically evaluate SR task. By mimicking the way humans evaluate SR, CEScore provides 4 metrics (Sscore, Gscore, Mscore, and CEscore) to assess simplicity, grammaticality, meaning preservation, and overall quality, respectively. In experiments with 26 models, CEScore correlates strongly with human evaluations, achieving 0.98 in Spearman correlations at model-level. This underscores the potential of CEScore as a simple and effective metric for assessing the overall quality of SR models.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01356"
  },
  "2312.01354": {
    "title": "Protecting Sensitive Tabular Data in Hybrid Clouds",
    "authors": [
      "Maya Anderson",
      "Gidon Gershinsky",
      "Eliot Salant",
      "Salvador Garcia"
    ],
    "abstract": "Regulated industries, such as Healthcare and Finance, are starting to move parts of their data and workloads to the public cloud. However, they are still reluctant to trust the public cloud with their most sensitive records, and hence leave them in their premises, leveraging the hybrid cloud architecture. We address the security and performance challenges of big data analytics using a hybrid cloud in a real-life use case from a hospital. In this use case, the hospital collects sensitive patient data and wants to run analytics on it in order to lower antibiotics resistance, a significant challenge in healthcare. We show that it is possible to run large-scale analytics on data that is securely stored in the public cloud encrypted using Apache Parquet Modular Encryption (PME), without significant performance losses even if the secret encryption keys are stored on-premises. PME is a standard mechanism for data encryption and key management, not specific to any public cloud, and therefore helps prevent vendor lock-in. It also provides privacy and integrity guarantees, and enables granular access control to the data. We also present an innovation in PME for lowering the performance hit incurred by calls to the Key Management Service. Our solution therefore enables protecting large amounts of sensitive data in hybrid clouds and still allows to efficiently gain valuable insights from it.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01354"
  },
  "2312.01351": {
    "title": "Deep learning and traditional-based CAD schemes for the pulmonary embolism diagnosis: A survey",
    "authors": [
      "Seyed Hesamoddin Hosseini",
      "Amir Hossein Taherinia",
      "Mahdi Saadatmand"
    ],
    "abstract": "Nowadays, pulmonary Computed Tomography Angiography (CTA) is the main tool for detecting Pulmonary Embolism (PE). However, manual interpretation of CTA volume requires a radiologist, which is time-consuming and error-prone due to the specific conditions of lung tissue, large volume of data, lack of experience, and eye fatigue. Therefore, Computer-Aided Design (CAD) systems are used as a second opinion for the diagnosis of PE. The purpose of this article is to review, evaluate, and compare the performance of deep learning and traditional-based CAD system for diagnosis PE and to help physicians and researchers in this field. In this study, all articles available in databases such as IEEE, ScienceDirect, Wiley, Springer, Nature, and Wolters Kluwer in the field of PE diagnosis were examined using traditional and deep learning methods. From 2002 to 2023, 23 papers were studied to extract the articles with the considered limitations. Each paper presents an automatic PE detection system that we evaluate using criteria such as sensitivity, False Positives (FP), and the number of datasets. This research work includes recent studies, state-of-the-art research works, and a more comprehensive overview compared to previously published review articles in this research area.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01351"
  },
  "2312.01350": {
    "title": "Honesty Is the Best Policy: Defining and Mitigating AI Deception",
    "authors": [
      "Francis Rhys Ward",
      "Francesco Belardinelli",
      "Francesca Toni",
      "Tom Everitt"
    ],
    "abstract": "Deceptive agents are a challenge for the safety, trustworthiness, and cooperation of AI systems. We focus on the problem that agents might deceive in order to achieve their goals (for instance, in our experiments with language models, the goal of being evaluated as truthful). There are a number of existing definitions of deception in the literature on game theory and symbolic AI, but there is no overarching theory of deception for learning agents in games. We introduce a formal definition of deception in structural causal games, grounded in the philosophy literature, and applicable to real-world machine learning systems. Several examples and results illustrate that our formal definition aligns with the philosophical and commonsense meaning of deception. Our main technical result is to provide graphical criteria for deception. We show, experimentally, that these results can be used to mitigate deception in reinforcement learning agents and language models.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01350"
  },
  "2312.01344": {
    "title": "tsMorph: generation of semi-synthetic time series to understand algorithm performance",
    "authors": [
      "Mois\u00e9s Santos",
      "Andr\u00e9 de Carvalho",
      "Carlos Soares"
    ],
    "abstract": "Time series forecasting is a subject of significant scientific and industrial importance. Despite the widespread utilization of forecasting methods, there is a dearth of research aimed at comprehending the conditions under which these methods yield favorable or unfavorable performances. Empirical studies, although common, encounter challenges due to the limited availability of datasets, impeding the extraction of reliable insights. To address this, we present tsMorph, a straightforward approach for generating semi-synthetic time series through dataset morphing. tsMorph operates by creating a sequence of datasets derived from two original datasets. These newly generated datasets exhibit a progressive departure from the characteristics of one dataset and a convergence toward the attributes of the other. This method provides a valuable alternative for obtaining substantial datasets. In this paper, we demonstrate the utility of tsMorph by assessing the performance of the Long Short-Term Memory Network forecasting algorithm. The time series under examination are sourced from the NN5 Competition. The findings reveal compelling insights. Notably, the performance of the Long Short-Term Memory Network improves proportionally with the frequency of the time series. These experiments affirm that tsMorph serves as an effective tool for gaining an understanding of forecasting algorithm behaviors, offering a pathway to overcome the limitations posed by empirical studies and enabling more extensive and reliable experimentation.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01344"
  },
  "2312.01342": {
    "title": "Graph Coordinates and Conventional Neural Networks -- An Alternative for Graph Neural Networks",
    "authors": [
      "Zheyi Qin",
      "Randy Paffenroth",
      "Anura P. Jayasumana"
    ],
    "abstract": "Graph-based data present unique challenges and opportunities for machine learning. Graph Neural Networks (GNNs), and especially those algorithms that capture graph topology through message passing for neighborhood aggregation, have been a leading solution. However, these networks often require substantial computational resources and may not optimally leverage the information contained in the graph's topology, particularly for large-scale or complex graphs. We propose Topology Coordinate Neural Network (TCNN) and Directional Virtual Coordinate Neural Network (DVCNN) as novel and efficient alternatives to message passing GNNs, that directly leverage the graph's topology, sidestepping the computational challenges presented by competing algorithms. Our proposed methods can be viewed as a reprise of classic techniques for graph embedding for neural network feature engineering, but they are novel in that our embedding techniques leverage ideas in Graph Coordinates (GC) that are lacking in current practice. Experimental results, benchmarked against the Open Graph Benchmark Leaderboard, demonstrate that TCNN and DVCNN achieve competitive or superior performance to message passing GNNs. For similar levels of accuracy and ROC-AUC, TCNN and DVCNN need far fewer trainable parameters than contenders of the OGBN Leaderboard. The proposed TCNN architecture requires fewer parameters than any neural network method currently listed in the OGBN Leaderboard for both OGBN-Proteins and OGBN-Products datasets. Conversely, our methods achieve higher performance for a similar number of trainable parameters. By providing an efficient and effective alternative to message passing GNNs, our work expands the toolbox of techniques for graph-based machine learning.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01342"
  },
  "2312.01338": {
    "title": "Enhancing and Adapting in the Clinic: Source-free Unsupervised Domain Adaptation for Medical Image Enhancement",
    "authors": [
      "Heng Li",
      "Ziqin Lin",
      "Zhongxi Qiu",
      "Zinan Li",
      "Huazhu Fu",
      "Yan Hu",
      "Jiang Liu"
    ],
    "abstract": "Medical imaging provides many valuable clues involving anatomical structure and pathological characteristics. However, image degradation is a common issue in clinical practice, which can adversely impact the observation and diagnosis by physicians and algorithms. Although extensive enhancement models have been developed, these models require a well pre-training before deployment, while failing to take advantage of the potential value of inference data after deployment. In this paper, we raise an algorithm for source-free unsupervised domain adaptive medical image enhancement (SAME), which adapts and optimizes enhancement models using test data in the inference phase. A structure-preserving enhancement network is first constructed to learn a robust source model from synthesized training data. Then a teacher-student model is initialized with the source model and conducts source-free unsupervised domain adaptation (SFUDA) by knowledge distillation with the test data. Additionally, a pseudo-label picker is developed to boost the knowledge distillation of enhancement tasks. Experiments were implemented on ten datasets from three medical image modalities to validate the advantage of the proposed algorithm, and setting analysis and ablation studies were also carried out to interpret the effectiveness of SAME. The remarkable enhancement performance and benefits for downstream tasks demonstrate the potential and generalizability of SAME. The code is available at https://github.com/liamheng/Annotation-free-Medical-Image-Enhancement.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01338"
  },
  "2312.01335": {
    "title": "Facial Emotion Recognition Under Mask Coverage Using a Data Augmentation Technique",
    "authors": [
      "Aref Farhadipour",
      "Pouya Taghipour"
    ],
    "abstract": "Identifying human emotions using AI-based computer vision systems, when individuals wear face masks, presents a new challenge in the current Covid-19 pandemic. In this study, we propose a facial emotion recognition system capable of recognizing emotions from individuals wearing different face masks. A novel data augmentation technique was utilized to improve the performance of our model using four mask types for each face image. We evaluated the effectiveness of four convolutional neural networks, Alexnet, Squeezenet, Resnet50 and VGGFace2 that were trained using transfer learning. The experimental findings revealed that our model works effectively in multi-mask mode compared to single-mask mode. The VGGFace2 network achieved the highest accuracy rate, with 97.82% for the person-dependent mode and 74.21% for the person-independent mode using the JAFFE dataset. However, we evaluated our proposed model using the UIBVFED dataset. The Resnet50 has demonstrated superior performance, with accuracies of 73.68% for the person-dependent mode and 59.57% for the person-independent mode. Moreover, we employed metrics such as precision, sensitivity, specificity, AUC, F1 score, and confusion matrix to measure our system's efficiency in detail. Additionally, the LIME algorithm was used to visualize CNN's decision-making strategy.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01335"
  },
  "2312.01330": {
    "title": "Evaluating the Security of Satellite Systems",
    "authors": [
      "Roy Peled",
      "Eran Aizikovich",
      "Edan Habler",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "Satellite systems are facing an ever-increasing amount of cybersecurity threats as their role in communications, navigation, and other services expands. Recent papers have examined attacks targeting satellites and space systems; however, they did not comprehensively analyze the threats to satellites and systematically identify adversarial techniques across the attack lifecycle. This paper presents a comprehensive taxonomy of adversarial tactics, techniques, and procedures explicitly targeting LEO satellites. First, we analyze the space ecosystem including the ground, space, Communication, and user segments, highlighting their architectures, functions, and vulnerabilities. Then, we examine the threat landscape, including adversary types, and capabilities, and survey historical and recent attacks such as jamming, spoofing, and supply chain. Finally, we propose a novel extension of the MITRE ATT&CK framework to categorize satellite attack techniques across the adversary lifecycle from reconnaissance to impact. The taxonomy is demonstrated by modeling high-profile incidents, including the Viasat attack that disrupted Ukraine's communications. The taxonomy provides the foundation for the development of defenses against emerging cyber risks to space assets. The proposed threat model will advance research in the space domain and contribute to the security of the space domain against sophisticated attacks.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01330"
  },
  "2312.01326": {
    "title": "OA-ECBVC: A Cooperative Collision-free Encirclement and Capture Approach in Cluttered Environments",
    "authors": [
      "Xinyi Wang",
      "Yulong Ding",
      "Yizhou Chen",
      "Ruihua Han",
      "Lele Xi",
      "Ben M. Chen"
    ],
    "abstract": "This article investigates the practical scenarios of chasing an adversarial evader in an unbounded environment with cluttered obstacles. We propose a Voronoi-based decentralized algorithm for multiple pursuers to encircle and capture the evader by reacting to collisions. An efficient approach is presented for constructing an obstacle-aware evader-centered bounded Voronoi cell (OA-ECBVC), which strictly ensures collision avoidance in various obstacle scenarios when pursuing the evader. The evader can be efficiently enclosed in a convex hull given random initial configurations. Furthermore, to cooperatively capture the evader, each pursuer continually compresses the boundary of its OA-ECBVC to quickly reduce the movement space of the evader while maintaining encirclement. Our OA-ECBVC algorithm is validated in various simulated environments with different dynamic systems of robots. Real-time performance of resisting uncertainties shows the superior reliability of our method for deployment on multiple robot platforms.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01326"
  },
  "2312.01324": {
    "title": "MABViT -- Modified Attention Block Enhances Vision Transformers",
    "authors": [
      "Mahesh Ramesh",
      "Aswinkumar Ramkumar"
    ],
    "abstract": "Recent studies have demonstrated the effectiveness of Gated Linear Units (GLU) in enhancing transformer models, particularly in Large Language Models (LLMs). Additionally, utilizing a parallel configuration within each Transformer block rather than the conventional serialized method has been revealed to accelerate the training of LLMs without significantly impacting performance. However, when the MLP and attention block were run in parallel for the image classification task, we observed a noticeable decline in performance. We propose a novel transformer variant that integrates non-linearity within the attention block to tackle this problem. We implemented the GLU-based activation function on the Value tensor, and this new technique surpasses the current state-of-the-art S/16 variant of Vision Transformers by 0.6% on the ImageNet-1K dataset while utilizing fewer parameters. It also supersedes the B/16 variant while using only half the parameters. Furthermore, we provide results with the GELU activation function variant to confirm our assertions. Lastly, we showcase that the MABViT variants exhibit greater potential when utilized in deep transformers compared to the standard architecture.\n        \u25b3 Less",
    "submission_date": "1 January, 2024",
    "eprint_id": "2312.01324"
  },
  "2312.01315": {
    "title": "Few-shot Shape Recognition by Learning Deep Shape-aware Features",
    "authors": [
      "Wenlong Shi",
      "Changsheng Lu",
      "Ming Shao",
      "Yinjie Zhang",
      "Siyu Xia",
      "Piotr Koniusz"
    ],
    "abstract": "Traditional shape descriptors have been gradually replaced by convolutional neural networks due to their superior performance in feature extraction and classification. The state-of-the-art methods recognize object shapes via image reconstruction or pixel classification. However , these methods are biased toward texture information and overlook the essential shape descriptions, thus, they fail to generalize to unseen shapes. We are the first to propose a fewshot shape descriptor (FSSD) to recognize object shapes given only one or a few samples. We employ an embedding module for FSSD to extract transformation-invariant shape features. Secondly, we develop a dual attention mechanism to decompose and reconstruct the shape features via learnable shape primitives. In this way, any shape can be formed through a finite set basis, and the learned representation model is highly interpretable and extendable to unseen shapes. Thirdly, we propose a decoding module to include the supervision of shape masks and edges and align the original and reconstructed shape features, enforcing the learned features to be more shape-aware. Lastly, all the proposed modules are assembled into a few-shot shape recognition scheme. Experiments on five datasets show that our FSSD significantly improves the shape classification compared to the state-of-the-art under the few-shot setting.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01315"
  },
  "2312.01308": {
    "title": "Bridging Background Knowledge Gaps in Translation with Automatic Explicitation",
    "authors": [
      "HyoJung Han",
      "Jordan Lee Boyd-Graber",
      "Marine Carpuat"
    ],
    "abstract": "Translations help people understand content written in another language. However, even correct literal translations do not fulfill that goal when people lack the necessary background to understand them. Professional translators incorporate explicitations to explain the missing context by considering cultural differences between source and target audiences. Despite its potential to help users, NLP research on explicitation is limited because of the dearth of adequate evaluation methods. This work introduces techniques for automatically generating explicitations, motivated by WikiExpl: a dataset that we collect from Wikipedia and annotate with human translators. The resulting explicitations are useful as they help answer questions more accurately in a multilingual question answering framework.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01308"
  },
  "2312.01306": {
    "title": "On Significance of Subword tokenization for Low Resource and Efficient Named Entity Recognition: A case study in Marathi",
    "authors": [
      "Harsh Chaudhari",
      "Anuja Patil",
      "Dhanashree Lavekar",
      "Pranav Khairnar",
      "Raviraj Joshi",
      "Sachin Pande"
    ],
    "abstract": "Named Entity Recognition (NER) systems play a vital role in NLP applications such as machine translation, summarization, and question-answering. These systems identify named entities, which encompass real-world concepts like locations, persons, and organizations. Despite extensive research on NER systems for the English language, they have not received adequate attention in the context of low resource languages. In this work, we focus on NER for low-resource language and present our case study in the context of the Indian language Marathi. The advancement of NLP research revolves around the utilization of pre-trained transformer models such as BERT for the development of NER models. However, we focus on improving the performance of shallow models based on CNN, and LSTM by combining the best of both worlds. In the era of transformers, these traditional deep learning models are still relevant because of their high computational efficiency. We propose a hybrid approach for efficient NER by integrating a BERT-based subword tokenizer into vanilla CNN/LSTM models. We show that this simple approach of replacing a traditional word-based tokenizer with a BERT-tokenizer brings the accuracy of vanilla single-layer models closer to that of deep pre-trained models like BERT. We show the importance of using sub-word tokenization for NER and present our study toward building efficient NLP systems. The evaluation is performed on L3Cube-MahaNER dataset using tokenizers from MahaBERT, MahaGPT, IndicBERT, and mBERT.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01306"
  },
  "2312.01305": {
    "title": "ViVid-1-to-3: Novel View Synthesis with Video Diffusion Models",
    "authors": [
      "Jeong-gi Kwak",
      "Erqun Dong",
      "Yuhe Jin",
      "Hanseok Ko",
      "Shweta Mahajan",
      "Kwang Moo Yi"
    ],
    "abstract": "Generating novel views of an object from a single image is a challenging task. It requires an understanding of the underlying 3D structure of the object from an image and rendering high-quality, spatially consistent new views. While recent methods for view synthesis based on diffusion have shown great progress, achieving consistency among various view estimates and at the same time abiding by the desired camera pose remains a critical problem yet to be solved. In this work, we demonstrate a strikingly simple method, where we utilize a pre-trained video diffusion model to solve this problem. Our key idea is that synthesizing a novel view could be reformulated as synthesizing a video of a camera going around the object of interest -- a scanning video -- which then allows us to leverage the powerful priors that a video diffusion model would have learned. Thus, to perform novel-view synthesis, we create a smooth camera trajectory to the target view that we wish to render, and denoise using both a view-conditioned diffusion model and a video diffusion model. By doing so, we obtain a highly consistent novel view synthesis, outperforming the state of the art.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01305"
  },
  "2312.01304": {
    "title": "Jut: A Framework for Just-in-Time Data Access",
    "authors": [
      "Silvery Fu",
      "Siyuan Dong",
      "Jamsheed Mistri",
      "Steve McCanne",
      "Amy Ousterhout",
      "Sylvia Ratnasamy"
    ],
    "abstract": "With the proliferation of sensor and personal devices, our physical spaces are now awash in potential data sources. In principle this data could serve a wide range of applications and services. However, leveraging these data sources is challenging with today's systems because they are not typically designed to consume data opportunistically, from a new device that happens to arrive in the vicinity.\n  In this paper, we present the design and implementation of Jut, a system designed for \"Just-in-Time\" data access - in which an application is able to discover and consume data from any available source, even ones not known at development or installation time. Jut combines two novel design choices: modularizing data processing systems to better reflect the physical world, and a new form of application-data integration that equips data processing pipelines with the information they need to process new and evolving data formats and schemas. We show that these choices greatly simplify the development and use of smart-space and IoT applications. For a representative set of devices and application scenarios, we show that Jut can implement use-cases not easily supported today, or can do so with 3.2-14.8x less development effort and 3-12x lower query complexity than current systems.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01304"
  },
  "2312.01302": {
    "title": "Smart safety watch for elderly people and pregnant women",
    "authors": [
      "Balachandra D S",
      "Maithreyee M S",
      "Saipavan B M",
      "Shashank S",
      "P Devaki",
      "Ms. Ashwini M"
    ],
    "abstract": "Falls represent one of the most detrimental occurrences for the elderly. Given the continually increasing ageing demographic, there is a pressing demand for advancing fall detection systems. The swift progress in sensor networks and the Internet of Things (IoT) has made human-computer interaction through sensor fusion an acknowledged and potent approach for tackling the issue of fall detection. Even IoT-enabled systems can deliver economical health monitoring solutions tailored to pregnant women within their daily environments. Recent research indicates that these remote health monitoring setups have the potential to enhance the well-being of both the mother and the infant throughout the pregnancy and postpartum phases. One more emerging advancement is the integration of 'panic buttons,' which are gaining popularity due to the escalating emphasis on safety. These buttons instantly transmit the user's real-time location to pre-designated emergency contacts when activated. Our solution focuses on the above three challenges we see every day. Fall detection for the elderly helps the elderly in case they fall and have nobody around for help. Sleep pattern sensing is helpful for pregnant women based on the SPO2 sensors integrated within our device. It is also bundled with heart rate monitoring. Our third solution focuses on a panic situation; upon pressing the determined buttons, a panic alert would be sent to the emergency contacts listed. The device also comes with a mobile app developed using Flutter that takes care of all the heavy processing rather than the device itself.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01302"
  },
  "2312.01301": {
    "title": "Churn Prediction via Multimodal Fusion Learning:Integrating Customer Financial Literacy, Voice, and Behavioral Data",
    "authors": [
      "David Hason Rudd",
      "Huan Huo",
      "Md Rafiqul Islam",
      "Guandong Xu"
    ],
    "abstract": "In todays competitive landscape, businesses grapple with customer retention. Churn prediction models, although beneficial, often lack accuracy due to the reliance on a single data source. The intricate nature of human behavior and high dimensional customer data further complicate these efforts. To address these concerns, this paper proposes a multimodal fusion learning model for identifying customer churn risk levels in financial service providers. Our multimodal approach integrates customer sentiments financial literacy (FL) level, and financial behavioral data, enabling more accurate and bias-free churn prediction models. The proposed FL model utilizes a SMOGN COREG supervised model to gauge customer FL levels from their financial data. The baseline churn model applies an ensemble artificial neural network and oversampling techniques to predict churn propensity in high-dimensional financial data. We also incorporate a speech emotion recognition model employing a pre-trained CNN-VGG16 to recognize customer emotions based on pitch, energy, and tone. To integrate these diverse features while retaining unique insights, we introduced late and hybrid fusion techniques that complementary boost coordinated multimodal co learning. Robust metrics were utilized to evaluate the proposed multimodal fusion model and hence the approach validity, including mean average precision and macro-averaged F1 score. Our novel approach demonstrates a marked improvement in churn prediction, achieving a test accuracy of 91.2%, a Mean Average Precision (MAP) score of 66, and a Macro-Averaged F1 score of 54 through the proposed hybrid fusion learning technique compared with late fusion and baseline models. Furthermore, the analysis demonstrates a positive correlation between negative emotions, low FL scores, and high-risk customers.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01301"
  },
  "2312.01299": {
    "title": "Robust Non-parametric Knowledge-based Diffusion Least Mean Squares over Adaptive Networks",
    "authors": [
      "Soheil Ashkezari-Toussi",
      "Hadi sadoghi-Yazdi"
    ],
    "abstract": "The present study proposes incorporating non-parametric knowledge into the diffusion least-mean-squares algorithm in the framework of a maximum a posteriori (MAP) estimation. The proposed algorithm leads to a robust estimation of an unknown parameter vector in a group of cooperative estimators. Utilizing kernel density estimation and buffering some intermediate estimations, the prior distribution and conditional likelihood of the parameters vector in each node are calculated. Pseudo Huber loss function is used for designing the likelihood function. Also, an error thresholding function is defined to reduce the computational overhead as well as more relaxation against noise, which stops the update every time an error is less than a predefined threshold. The performance of the proposed algorithm is examined in the stationary and non-stationary scenarios in the presence of Gaussian and non-Gaussian noise. Results show the robustness of the proposed algorithm in the presence of different noise types.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01299"
  },
  "2312.01297": {
    "title": "FlatProxy: A DPU-centric Service Mesh Architecture for Hyperscale Cloud-native Application",
    "authors": [
      "Ming Li",
      "Wenyan Lu",
      "Hanyue Lin",
      "Jingya Wu",
      "Yu Zhang",
      "Guihai Yan"
    ],
    "abstract": "Service mesh is a fundamental technology for building cloud-native applications, which ensures the stable running of a large number of services by an intermediate layer that governs communication between services. However, service mesh is not well suited for high-performance scenarios. The root cause is that the current service mesh is not suitable for the evolution of cloud-native applications. On the one hand, the service mesh built on CPU cannot listen to communication bypassing the CPU. On the other hand, service mesh includes many I/O-intensive and computationally-intensive tasks that can overload CPU cores as traffic grows beyond CPU performance.\n  Therefore, we propose a data-centric service mesh that migrates the proxy of the service mesh to the entrance of the network. Moreover, we also design the DPU-centric FlatProxy, a data-centric service mesh based on DPU. There are three advantages to the DPU-centric service mesh. Firstly, it takes over all traffic flow in and out of the node, which expands the sense scale of the service mesh from container to node. Secondly, it improves communication performance and reduces host resource usage by offloading some functions and optimizing communication. Thirdly, it minimizes performance and security issues through the physical isolation of business services and cloud infrastructure.\n  Compared with Envoy, the current mainstream service mesh implementation, FlatProxy reduces latency by 90\\% and improves throughput by 4x in Gbps and 8x in qps, and it only occupies a small amount of CPU resources.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01297"
  },
  "2312.01296": {
    "title": "Anomaly Detection Under Uncertainty Using Distributionally Robust Optimization Approach",
    "authors": [
      "Amir Hossein Noormohammadia",
      "Seyed Ali MirHassania",
      "Farnaz Hooshmand Khaligh"
    ],
    "abstract": "Anomaly detection is defined as the problem of finding data points that do not follow the patterns of the majority. Among the various proposed methods for solving this problem, classification-based methods, including one-class Support Vector Machines (SVM) are considered effective and state-of-the-art. The one-class SVM method aims to find a decision boundary to distinguish between normal data points and anomalies using only the normal data. On the other hand, most real-world problems involve some degree of uncertainty, where the true probability distribution of each data point is unknown, and estimating it is often difficult and costly. Assuming partial distribution information such as the first and second-order moments is known, a distributionally robust chance-constrained model is proposed in which the probability of misclassification is low. By utilizing a mapping function to a higher dimensional space, the proposed model will be capable of classifying origin-inseparable datasets. Also, by adopting the kernel idea, the need for explicitly knowing the mapping is eliminated, computations can be performed in the input space, and computational complexity is reduced. Computational results validate the robustness of the proposed model under different probability distributions and also the superiority of the proposed model compared to the standard one-class SVM in terms of various evaluation metrics.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01296"
  },
  "2312.01295": {
    "title": "Two-stage dynamic creative optimization under sparse ambiguous samples for e-commerce advertising",
    "authors": [
      "Guandong Li",
      "Xian Yang"
    ],
    "abstract": "Ad creative is one of the main mediums for e-commerce advertising. In our approach we decouple this dynamic creative optimization into two stages, a cascaded structure that can trade off between effectiveness and efficiency. In the first stage, we train an automatic creative optimization architecture based on autoco to simulate complex interactions between creative elements. Although we obtained the ranking of different creatives under a sku, because we bucketed and merged historical data according to periods, this confuses the ctr diversity of the same ad creatives on different days and weakens the ability to separate ambiguous samples. Therefore, we propose a transformer-based rerank model. With the help of the rank model, we propose a distillation method to learn the relative order of ideas and extract the ranking knowledge to guide the rerank learning. The creative order soft labels under each sku are generated by the rank model to alleviate the dilemma that a large number of under-represented creatives cannot obtain real labels. Through the knowledge diffusion of rerank, the ambiguous samples are associated with the positive and negative samples. Cascade rerank and autoco to output the estimated value of the synthetic ad image. In the second stage, we designed a bandit model, and the bandit selected one of the output ad of the first stage for timely delivery. Experimental results show that our method can outperform competing baselines in terms of sctr. Online A/B testing shows that our method improves ctr by 10% compared to the baseline.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01295"
  },
  "2312.01292": {
    "title": "Joint Beam Scheduling and Power Optimization for Beam Hopping LEO Satellite Systems",
    "authors": [
      "Shuang Zheng",
      "Xing Zhang",
      "Peng Wang",
      "Wenbo Wang"
    ],
    "abstract": "Low earth orbit (LEO) satellite communications can provide ubiquitous and reliable services, making it an essential part of the Internet of Everything network. Beam hopping (BH) is an emerging technology for effectively addressing the issue of low resource utilization caused by the non-uniform spatio-temporal distribution of traffic demands. However, how to allocate multi-dimensional resources in a timely and efficient way for the highly dynamic LEO satellite systems remains a challenge. This paper proposes a joint beam scheduling and power optimization beam hopping (JBSPO-BH) algorithm considering the differences in the geographic distribution of sink nodes. The JBSPO-BH algorithm decouples the original problem into two sub-problems. The beam scheduling problem is modelled as a potential game, and the Nash equilibrium (NE) point is obtained as the beam scheduling strategy. Moreover, the penalty function interior point method is applied to optimize the power allocation. Simulation results show that the JBSPO-BH algorithm has low time complexity and fast convergence and achieves better performance both in throughput and fairness. Compared with greedy-based BH, greedy-based BH with the power optimization, round-robin BH, Max-SINR BH and satellite resource allocation algorithm, the throughput of the proposed algorithm is improved by 44.99%, 20.79%, 156.06%, 15.39% and 8.17%, respectively.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01292"
  },
  "2312.01291": {
    "title": "Opportunities for Retrieval and Tool Augmented Large Language Models in Scientific Facilities",
    "authors": [
      "Michael H. Prince",
      "Henry Chan",
      "Aikaterini Vriza",
      "Tao Zhou",
      "Varuni K. Sastry",
      "Matthew T. Dearing",
      "Ross J. Harder",
      "Rama K. Vasudevan",
      "Mathew J. Cherukara"
    ],
    "abstract": "Upgrades to advanced scientific user facilities such as next-generation x-ray light sources, nanoscience centers, and neutron facilities are revolutionizing our understanding of materials across the spectrum of the physical sciences, from life sciences to microelectronics. However, these facility and instrument upgrades come with a significant increase in complexity. Driven by more exacting scientific needs, instruments and experiments become more intricate each year. This increased operational complexity makes it ever more challenging for domain scientists to design experiments that effectively leverage the capabilities of and operate on these advanced instruments. Large language models (LLMs) can perform complex information retrieval, assist in knowledge-intensive tasks across applications, and provide guidance on tool usage. Using x-ray light sources, leadership computing, and nanoscience centers as representative examples, we describe preliminary experiments with a Context-Aware Language Model for Science (CALMS) to assist scientists with instrument operations and complex experimentation. With the ability to retrieve relevant information from facility documentation, CALMS can answer simple questions on scientific capabilities and other operational procedures. With the ability to interface with software tools and experimental hardware, CALMS can conversationally operate scientific instruments. By making information more accessible and acting on user needs, LLMs could expand and diversify scientific facilities' users and accelerate scientific output.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01291"
  },
  "2312.01288": {
    "title": "Task-Oriented Edge Networks: Decentralized Learning Over Wireless Fronthaul",
    "authors": [
      "Hoon Lee",
      "Seung-Wook Kim"
    ],
    "abstract": "This paper studies task-oriented edge networks where multiple edge internet-of-things nodes execute machine learning tasks with the help of powerful deep neural networks (DNNs) at a network cloud. Separate edge nodes (ENs) result in a partially observable system where they can only get partitioned features of the global network states. These local observations need to be forwarded to the cloud via resource-constrained wireless fronthual links. Individual ENs compress their local observations into uplink fronthaul messages using task-oriented encoder DNNs. Then, the cloud carries out a remote inference task by leveraging received signals. Such a distributed topology requests a decentralized training and decentralized execution (DTDE) learning framework for designing edge-cloud cooperative inference rules and their decentralized training strategies. First, we develop fronthaul-cooperative DNN architecture along with proper uplink coordination protocols suitable for wireless fronthaul interconnection. Inspired by the nomographic function, an efficient cloud inference model becomes an integration of a number of shallow DNNs. This modulized architecture brings versatile calculations that are independent of the number of ENs. Next, we present a decentralized training algorithm of separate edge-cloud DNNs over downlink wireless fronthaul channels. An appropriate downlink coordination protocol is proposed, which backpropagates gradient vectors wirelessly from the cloud to the ENs.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01288"
  },
  "2312.01286": {
    "title": "Continuous Convolutional Neural Networks for Disruption Prediction in Nuclear Fusion Plasmas",
    "authors": [
      "William F Arnold",
      "Lucas Spangher",
      "Christina Rea"
    ],
    "abstract": "Grid decarbonization for climate change requires dispatchable carbon-free energy like nuclear fusion. The tokamak concept offers a promising path for fusion, but one of the foremost challenges in implementation is the occurrence of energetic plasma disruptions. In this study, we delve into Machine Learning approaches to predict plasma state outcomes. Our contributions are twofold: (1) We present a novel application of Continuous Convolutional Neural Networks for disruption prediction and (2) We examine the advantages and disadvantages of continuous models over discrete models for disruption prediction by comparing our model with the previous, discrete state of the art, and show that continuous models offer significantly better performance (Area Under the Receiver Operating Characteristic Curve = 0.974 v.s. 0.799) with fewer parameters\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.01286"
  },
  "2312.01283": {
    "title": "Deeper into Self-Supervised Monocular Indoor Depth Estimation",
    "authors": [
      "Chao Fan",
      "Zhenyu Yin",
      "Yue Li",
      "Feiqing Zhang"
    ],
    "abstract": "Monocular depth estimation using Convolutional Neural Networks (CNNs) has shown impressive performance in outdoor driving scenes. However, self-supervised learning of indoor depth from monocular sequences is quite challenging for researchers because of the following two main reasons. One is the large areas of low-texture regions and the other is the complex ego-motion on indoor training datasets. In this work, our proposed method, named IndoorDepth, consists of two innovations. In particular, we first propose a novel photometric loss with improved structural similarity (SSIM) function to tackle the challenge from low-texture regions. Moreover, in order to further mitigate the issue of inaccurate ego-motion prediction, multiple photometric losses at different stages are used to train a deeper pose network with two residual pose blocks. Subsequent ablation study can validate the effectiveness of each new idea. Experiments on the NYUv2 benchmark demonstrate that our IndoorDepth outperforms the previous state-of-the-art methods by a large margin. In addition, we also validate the generalization ability of our method on ScanNet dataset. Code is availabe at https://github.com/fcntes/IndoorDepth.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01283"
  },
  "2312.01281": {
    "title": "Mendata: A Framework to Purify Manipulated Training Data",
    "authors": [
      "Zonghao Huang",
      "Neil Gong",
      "Michael K. Reiter"
    ],
    "abstract": "Untrusted data used to train a model might have been manipulated to endow the learned model with hidden properties that the data contributor might later exploit. Data purification aims to remove such manipulations prior to training the model. We propose Mendata, a novel framework to purify manipulated training data. Starting from a small reference dataset in which a large majority of the inputs are clean, Mendata perturbs the training inputs so that they retain their utility but are distributed similarly (as measured by Wasserstein distance) to the reference data, thereby eliminating hidden properties from the learned model. A key challenge is how to find such perturbations, which we address by formulating a min-max optimization problem and developing a two-step method to iteratively solve it. We demonstrate the effectiveness of Mendata by applying it to defeat state-of-the-art data poisoning and data tracing techniques.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01281"
  },
  "2312.01279": {
    "title": "TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents",
    "authors": [
      "James Enouen",
      "Hootan Nakhost",
      "Sayna Ebrahimi",
      "Sercan O Arik",
      "Yan Liu",
      "Tomas Pfister"
    ],
    "abstract": "Large language models (LLMs) have attracted huge interest in practical applications given their increasingly accurate responses and coherent reasoning abilities. Given their nature as black-boxes using complex reasoning processes on their inputs, it is inevitable that the demand for scalable and faithful explanations for LLMs' generated content will continue to grow. There have been major developments in the explainability of neural network models over the past decade. Among them, post-hoc explainability methods, especially Shapley values, have proven effective for interpreting deep learning models. However, there are major challenges in scaling up Shapley values for LLMs, particularly when dealing with long input contexts containing thousands of tokens and autoregressively generated output sequences. Furthermore, it is often unclear how to effectively utilize generated explanations to improve the performance of LLMs. In this paper, we introduce TextGenSHAP, an efficient post-hoc explanation method incorporating LM-specific techniques. We demonstrate that this leads to significant increases in speed compared to conventional Shapley value computations, reducing processing times from hours to minutes for token-level explanations, and to just seconds for document-level explanations. In addition, we demonstrate how real-time Shapley values can be utilized in two important scenarios, providing better understanding of long-document question answering by localizing important words and sentences; and improving existing document retrieval systems through enhancing the accuracy of selected passages and ultimately the final responses.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01279"
  },
  "2312.01276": {
    "title": "Running cognitive evaluations on large language models: The do's and the don'ts",
    "authors": [
      "Anna A. Ivanova"
    ],
    "abstract": "In this paper, I describe methodological considerations for studies that aim to evaluate the cognitive capacities of large language models (LLMs) using language-based behavioral assessments. Drawing on three case studies from the literature (a commonsense knowledge benchmark, a theory of mind evaluation, and a test of syntactic agreement), I describe common pitfalls that might arise when applying a cognitive test to an LLM. I then list 10 do's and don'ts that should help design high-quality cognitive evaluations for AI systems. I conclude by discussing four areas where the do's and don'ts are currently under active discussion -- prompt sensitivity, cultural and linguistic diversity, using LLMs as research assistants, and running evaluations on open vs. closed LLMs. Overall, the goal of the paper is to contribute to the broader discussion of best practices in the rapidly growing field of AI Psychology.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01276"
  },
  "2312.01275": {
    "title": "A Review of Link Prediction Applications in Network Biology",
    "authors": [
      "Ahmad F. Al Musawi",
      "Satyaki Roy",
      "Preetam Ghosh"
    ],
    "abstract": "In the domain of network biology, the interactions among heterogeneous genomic and molecular entities are represented through networks. Link prediction (LP) methodologies are instrumental in inferring missing or prospective associations within these biological networks. In this review, we systematically dissect the attributes of local, centrality, and embedding-based LP approaches, applied to static and dynamic biological networks. We undertake an examination of the current applications of LP metrics for predicting links between diseases, genes, proteins, RNA, microbiomes, drugs, and neurons. We carry out comprehensive performance evaluations on established biological network datasets to show the practical applications of standard LP models. Moreover, we compare the similarity in prediction trends among the models and the specific network attributes that contribute to effective link prediction, before underscoring the role of LP in addressing the formidable challenges prevalent in biological systems, ranging from noise, bias, and data sparseness to interpretability. We conclude the review with an exploration of the essential characteristics expected from future LP models, poised to advance our comprehension of the intricate interactions governing biological systems.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01275"
  },
  "2312.01274": {
    "title": "Learning to Compose SuperWeights for Neural Parameter Allocation Search",
    "authors": [
      "Piotr Teterwak",
      "Soren Nelson",
      "Nikoli Dryden",
      "Dina Bashkirova",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "abstract": "Neural parameter allocation search (NPAS) automates parameter sharing by obtaining weights for a network given an arbitrary, fixed parameter budget. Prior work has two major drawbacks we aim to address. First, there is a disconnect in the sharing pattern between the search and training steps, where weights are warped for layers of different sizes during the search to measure similarity, but not during training, resulting in reduced performance. To address this, we generate layer weights by learning to compose sets of SuperWeights, which represent a group of trainable parameters. These SuperWeights are created to be large enough so they can be used to represent any layer in the network, but small enough that they are computationally efficient. The second drawback we address is the method of measuring similarity between shared parameters. Whereas prior work compared the weights themselves, we argue this does not take into account the amount of conflict between the shared weights. Instead, we use gradient information to identify layers with shared weights that wish to diverge from each other. We demonstrate that our SuperWeight Networks consistently boost performance over the state-of-the-art on the ImageNet and CIFAR datasets in the NPAS setting. We further show that our approach can generate parameters for many network architectures using the same set of weights. This enables us to support tasks like efficient ensembling and anytime prediction, outperforming fully-parameterized ensembles with 17% fewer parameters.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01274"
  },
  "2312.01272": {
    "title": "Multiscale Topology in Interactomic Network: From Transcriptome to Antiaddiction Drug Repurposing",
    "authors": [
      "Hongyan Du",
      "Guo-Wei Wei",
      "Tingjun Hou"
    ],
    "abstract": "The escalating drug addiction crisis in the United States underscores the urgent need for innovative therapeutic strategies. This study embarked on an innovative and rigorous strategy to unearth potential drug repurposing candidates for opioid and cocaine addiction treatment, bridging the gap between transcriptomic data analysis and drug discovery. We initiated our approach by conducting differential gene expression analysis on addiction-related transcriptomic data to identify key genes. We propose a novel topological differentiation to identify key genes from a protein-protein interaction (PPI) network derived from DEGs. This method utilizes persistent Laplacians to accurately single out pivotal nodes within the network, conducting this analysis in a multiscale manner to ensure high reliability. Through rigorous literature validation, pathway analysis, and data-availability scrutiny, we identified three pivotal molecular targets, mTOR, mGluR5, and NMDAR, for drug repurposing from DrugBank. We crafted machine learning models employing two natural language processing (NLP)-based embeddings and a traditional 2D fingerprint, which demonstrated robust predictive ability in gauging binding affinities of DrugBank compounds to selected targets. Furthermore, we elucidated the interactions of promising drugs with the targets and evaluated their drug-likeness. This study delineates a multi-faceted and comprehensive analytical framework, amalgamating bioinformatics, topological data analysis and machine learning, for drug repurposing in addiction treatment, setting the stage for subsequent experimental validation. The versatility of the methods we developed allows for applications across a range of diseases and transcriptomic datasets.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01272"
  },
  "2312.01267": {
    "title": "Distributed Reinforcement Learning for Molecular Design: Antioxidant case",
    "authors": [
      "Huanyi Qin",
      "Denis Akhiyarov",
      "Sophie Loehle",
      "Kenneth Chiu",
      "Mauricio Araya-Polo"
    ],
    "abstract": "Deep reinforcement learning has successfully been applied for molecular discovery as shown by the Molecule Deep Q-network (MolDQN) algorithm. This algorithm has challenges when applied to optimizing new molecules: training such a model is limited in terms of scalability to larger datasets and the trained model cannot be generalized to different molecules in the same dataset. In this paper, a distributed reinforcement learning algorithm for antioxidants, called DA-MolDQN is proposed to address these problems. State-of-the-art bond dissociation energy (BDE) and ionization potential (IP) predictors are integrated into DA-MolDQN, which are critical chemical properties while optimizing antioxidants. Training time is reduced by algorithmic improvements for molecular modifications. The algorithm is distributed, scalable for up to 512 molecules, and generalizes the model to a diverse set of molecules. The proposed models are trained with a proprietary antioxidant dataset. The results have been reproduced with both proprietary and public datasets. The proposed molecules have been validated with DFT simulations and a subset of them confirmed in public \"unseen\" datasets. In summary, DA-MolDQN is up to 100x faster than previous algorithms and can discover new optimized molecules from proprietary and public antioxidants.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01267"
  },
  "2312.01262": {
    "title": "A Review and A Robust Framework of Data-Efficient 3D Scene Parsing with Traditional/Learned 3D Descriptors",
    "authors": [
      "Kangcheng Liu"
    ],
    "abstract": "Existing state-of-the-art 3D point cloud understanding methods merely perform well in a fully supervised manner. To the best of our knowledge, there exists no unified framework that simultaneously solves the downstream high-level understanding tasks including both segmentation and detection, especially when labels are extremely limited. This work presents a general and simple framework to tackle point cloud understanding when labels are limited. The first contribution is that we have done extensive methodology comparisons of traditional and learned 3D descriptors for the task of weakly supervised 3D scene understanding, and validated that our adapted traditional PFH-based 3D descriptors show excellent generalization ability across different domains. The second contribution is that we proposed a learning-based region merging strategy based on the affinity provided by both the traditional/learned 3D descriptors and learned semantics. The merging process takes both low-level geometric and high-level semantic feature correlations into consideration. Experimental results demonstrate that our framework has the best performance among the three most important weakly supervised point clouds understanding tasks including semantic segmentation, instance segmentation, and object detection even when very limited number of points are labeled. Our method, termed Region Merging 3D (RM3D), has superior performance on ScanNet data-efficient learning online benchmarks and other four large-scale 3D understanding benchmarks under various experimental settings, outperforming current arts by a margin for various 3D understanding tasks without complicated learning strategies such as active learning.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01262"
  },
  "2312.01256": {
    "title": "Breaking XOR Arbiter PUFs without Reliability Information",
    "authors": [
      "Niloufar Sayadi",
      "Phuong Ha Nguyen",
      "Marten van Dijk",
      "Chenglu Jin"
    ],
    "abstract": "Unreliable XOR Arbiter PUFs were broken by a machine learning attack, which targets the underlying Arbiter PUFs individually. However, reliability information from the PUF was required for this attack.\n  We show that, for the first time, a perfectly reliable XOR Arbiter PUF, where no reliability information is accessible, can be efficiently attacked in the same divide-and-conquer manner. Our key insight is that the responses of correlated challenges also reveal their distance to the decision boundary. This leads to a chosen challenge attack on XOR Arbiter PUFs. The effectiveness of our attack is confirmed through PUF simulation and FPGA implementation.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01256"
  },
  "2312.01255": {
    "title": "Meta ControlNet: Enhancing Task Adaptation via Meta Learning",
    "authors": [
      "Junjie Yang",
      "Jinze Zhao",
      "Peihao Wang",
      "Zhangyang Wang",
      "Yingbin Liang"
    ],
    "abstract": "Diffusion-based image synthesis has attracted extensive attention recently. In particular, ControlNet that uses image-based prompts exhibits powerful capability in image tasks such as canny edge detection and generates images well aligned with these prompts. However, vanilla ControlNet generally requires extensive training of around 5000 steps to achieve a desirable control for a single task. Recent context-learning approaches have improved its adaptability, but mainly for edge-based tasks, and rely on paired examples. Thus, two important open issues are yet to be addressed to reach the full potential of ControlNet: (i) zero-shot control for certain tasks and (ii) faster adaptation for non-edge-based tasks. In this paper, we introduce a novel Meta ControlNet method, which adopts the task-agnostic meta learning technique and features a new layer freezing design. Meta ControlNet significantly reduces learning steps to attain control ability from 5000 to 1000. Further, Meta ControlNet exhibits direct zero-shot adaptability in edge-based tasks without any finetuning, and achieves control within only 100 finetuning steps in more complex non-edge tasks such as Human Pose, outperforming all existing methods. The codes is available in https://github.com/JunjieYang97/Meta-ControlNet.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01255"
  },
  "2312.01252": {
    "title": "On Steiner Trees of the Regular Simplex",
    "authors": [
      "Henry Fleischmann",
      "Guillermo A. Gamboa Q.",
      "Karthik C. S.",
      "Josef Mat\u011bjka",
      "Jakub Petr"
    ],
    "abstract": "In the Euclidean Steiner Tree problem, we are given as input a set of points (called terminals) in the $\\ell_2$-metric space and the goal is to find the minimum-cost tree connecting them. Additional points (called Steiner points) from the space can be introduced as nodes in the solution.\n  The seminal works of Arora [JACM'98] and Mitchell [SICOMP'99] provide a Polynomial Time Approximation Scheme (PTAS) for solving the Euclidean Steiner Tree problem in fixed dimensions. However, the problem remains poorly understood in higher dimensions (such as when the dimension is logarithmic in the number of terminals) and ruling out a PTAS for the problem in high dimensions is a notoriously long standing open problem (for example, see Trevisan [SICOMP'00]). Moreover, the explicit construction of optimal Steiner trees remains unknown for almost all well-studied high-dimensional point configurations. Furthermore, a vast majority the state-of-the-art structural results on (high-dimensional) Euclidean Steiner trees were established in the 1960s, with no noteworthy update in over half a century.\n  In this paper, we revisit high-dimensional Euclidean Steiner trees, proving new structural results. We also establish a link between the computational hardness of the Euclidean Steiner Tree problem and understanding the optimal Steiner trees of regular simplices (and simplicial complexes), proposing several conjectures and showing that some of them suffice to resolve the status of the inapproximability of the Euclidean Steiner Tree problem. Motivated by this connection, we investigate optimal Steiner trees of regular simplices, proving new structural properties of their optimal Steiner trees, revisiting an old conjecture of Smith [Algorithmica'92] about their optimal topology, and providing the first explicit, general construction of candidate optimal Steiner trees for that topology.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01252"
  },
  "2312.01249": {
    "title": "A Multifidelity Sim-to-Real Pipeline for Verifiable and Compositional Reinforcement Learning",
    "authors": [
      "Cyrus Neary",
      "Christian Ellis",
      "Aryaman Singh Samyal",
      "Craig Lennon",
      "Ufuk Topcu"
    ],
    "abstract": "We propose and demonstrate a compositional framework for training and verifying reinforcement learning (RL) systems within a multifidelity sim-to-real pipeline, in order to deploy reliable and adaptable RL policies on physical hardware. By decomposing complex robotic tasks into component subtasks and defining mathematical interfaces between them, the framework allows for the independent training and testing of the corresponding subtask policies, while simultaneously providing guarantees on the overall behavior that results from their composition. By verifying the performance of these subtask policies using a multifidelity simulation pipeline, the framework not only allows for efficient RL training, but also for a refinement of the subtasks and their interfaces in response to challenges arising from discrepancies between simulation and reality. In an experimental case study we apply the framework to train and deploy a compositional RL system that successfully pilots a Warthog unmanned ground robot.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01249"
  },
  "2312.01244": {
    "title": "Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2023): Workshop and Shared Task Report",
    "authors": [
      "Ali H\u00fcrriyeto\u011flu",
      "Hristo Tanev",
      "Osman Mutlu",
      "Surendrabikram Thapa",
      "Fiona Anting Tan",
      "Erdem Y\u00f6r\u00fck"
    ],
    "abstract": "We provide a summary of the sixth edition of the CASE workshop that is held in the scope of RANLP 2023. The workshop consists of regular papers, three keynotes, working papers of shared task participants, and shared task overview papers. This workshop series has been bringing together all aspects of event information collection across technical and social science fields. In addition to contributing to the progress in text based event extraction, the workshop provides a space for the organization of a multimodal event information collection task.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01244"
  },
  "2312.01242": {
    "title": "DDxT: Deep Generative Transformer Models for Differential Diagnosis",
    "authors": [
      "Mohammad Mahmudul Alam",
      "Edward Raff",
      "Tim Oates",
      "Cynthia Matuszek"
    ],
    "abstract": "Differential Diagnosis (DDx) is the process of identifying the most likely medical condition among the possible pathologies through the process of elimination based on evidence. An automated process that narrows a large set of pathologies down to the most likely pathologies will be of great importance. The primary prior works have relied on the Reinforcement Learning (RL) paradigm under the intuition that it aligns better with how physicians perform DDx. In this paper, we show that a generative approach trained with simpler supervised and self-supervised learning signals can achieve superior results on the current benchmark. The proposed Transformer-based generative network, named DDxT, autoregressively produces a set of possible pathologies, i.e., DDx, and predicts the actual pathology using a neural network. Experiments are performed using the DDXPlus dataset. In the case of DDx, the proposed network has achieved a mean accuracy of 99.82% and a mean F1 score of 0.9472. Additionally, mean accuracy reaches 99.98% with a mean F1 score of 0.9949 while predicting ground truth pathology. The proposed DDxT outperformed the previous RL-based approaches by a big margin. Overall, the automated Transformer-based DDx generative model has the potential to become a useful tool for a physician in times of urgency.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01242"
  },
  "2312.01241": {
    "title": "Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation",
    "authors": [
      "Xunzhu Tang",
      "Zhenghan Chen",
      "Kisub Kim",
      "Haoye Tian",
      "Saad Ezzini",
      "Jacques Klein"
    ],
    "abstract": "In the face of growing vulnerabilities found in open-source software, the need to identify {discreet} security patches has become paramount. The lack of consistency in how software providers handle maintenance often leads to the release of security patches without comprehensive advisories, leaving users vulnerable to unaddressed security risks. To address this pressing issue, we introduce a novel security patch detection system, LLMDA, which capitalizes on Large Language Models (LLMs) and code-text alignment methodologies for patch review, data enhancement, and feature combination. Within LLMDA, we initially utilize LLMs for examining patches and expanding data of PatchDB and SPI-DB, two security patch datasets from recent literature. We then use labeled instructions to direct our LLMDA, differentiating patches based on security relevance. Following this, we apply a PTFormer to merge patches with code, formulating hybrid attributes that encompass both the innate details and the interconnections between the patches and the code. This distinctive combination method allows our system to capture more insights from the combined context of patches and code, hence improving detection precision. Finally, we devise a probabilistic batch contrastive learning mechanism within batches to augment the capability of the our LLMDA in discerning security patches. The results reveal that LLMDA significantly surpasses the start of the art techniques in detecting security patches, underscoring its promise in fortifying software maintenance.\n        \u25b3 Less",
    "submission_date": "12 December, 2023",
    "eprint_id": "2312.01241"
  },
  "2312.01238": {
    "title": "A deep learning pipeline for cross-sectional and longitudinal multiview data integration",
    "authors": [
      "Sarthak Jain",
      "Sandra E. Safo"
    ],
    "abstract": "Biomedical research now commonly integrates diverse data types or views from the same individuals to better understand the pathobiology of complex diseases, but the challenge lies in meaningfully integrating these diverse views. Existing methods often require the same type of data from all views (cross-sectional data only or longitudinal data only) or do not consider any class outcome in the integration method, presenting limitations. To overcome these limitations, we have developed a pipeline that harnesses the power of statistical and deep learning methods to integrate cross-sectional and longitudinal data from multiple sources. Additionally, it identifies key variables contributing to the association between views and the separation among classes, providing deeper biological insights. This pipeline includes variable selection/ranking using linear and nonlinear methods, feature extraction using functional principal component analysis and Euler characteristics, and joint integration and classification using dense feed-forward networks and recurrent neural networks. We applied this pipeline to cross-sectional and longitudinal multi-omics data (metagenomics, transcriptomics, and metabolomics) from an inflammatory bowel disease (IBD) study and we identified microbial pathways, metabolites, and genes that discriminate by IBD status, providing information on the etiology of IBD. We conducted simulations to compare the two feature extraction methods. The proposed pipeline is available from the following GitHub repository: https://github.com/lasandrall/DeepIDA-GRU.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01238"
  },
  "2312.01237": {
    "title": "PPAD-membership for Problems with Exact Rational Solutions: A General Approach via Convex Optimization",
    "authors": [
      "Aris Filos-Ratsikas",
      "Kristoffer Arnsfelt Hansen",
      "Kasper H\u00f8gh",
      "Alexandros Hollender"
    ],
    "abstract": "We introduce a general technique for proving membership of search problems with exact rational solutions in PPAD, one of the most well-known classes containing total search problems with polynomial-time verifiable solutions. In particular, we construct a \"pseudogate\", coined the linear-OPT-gate, which can be used as a \"plug-and-play\" component in a piecewise-linear (PL) arithmetic circuit, as an integral component of the \"Linear-FIXP\" equivalent definition of the class. The linear-OPT-gate can solve several convex optimization programs, including quadratic programs, which often appear organically in the simplest existence proofs for these problems. This effectively transforms existence proofs to PPAD-membership proofs, and consequently establishes the existence of solutions described by rational numbers.\n  Using the linear-OPT-gate, we are able to significantly simplify and generalize almost all known PPAD-membership proofs for finding exact solutions in the application domains of game theory, competitive markets, auto-bidding auctions, and fair division, as well as to obtain new PPAD-membership results for problems in these domains.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01237"
  },
  "2312.01235": {
    "title": "Strategic Data Revocation in Federated Unlearning",
    "authors": [
      "Ningning Ding",
      "Ermin Wei",
      "Randall Berry"
    ],
    "abstract": "By allowing users to erase their data's impact on federated learning models, federated unlearning protects users' right to be forgotten and data privacy. Despite a burgeoning body of research on federated unlearning's technical feasibility, there is a paucity of literature investigating the considerations behind users' requests for data revocation. This paper proposes a non-cooperative game framework to study users' data revocation strategies in federated unlearning. We prove the existence of a Nash equilibrium. However, users' best response strategies are coupled via model performance and unlearning costs, which makes the equilibrium computation challenging. We obtain the Nash equilibrium by establishing its equivalence with a much simpler auxiliary optimization problem. We also summarize users' multi-dimensional attributes into a single-dimensional metric and derive the closed-form characterization of an equilibrium, when users' unlearning costs are negligible. Moreover, we compare the cases of allowing and forbidding partial data revocation in federated unlearning. Interestingly, the results reveal that allowing partial revocation does not necessarily increase users' data contributions or payoffs due to the game structure. Additionally, we demonstrate that positive externalities may exist between users' data revocation decisions when users incur unlearning costs, while this is not the case when their unlearning costs are negligible.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.01235"
  },
  "2312.01232": {
    "title": "A Comprehensive Study of Vision Transformers in Image Classification Tasks",
    "authors": [
      "Mahmoud Khalil",
      "Ahmad Khalil",
      "Alioune Ngom"
    ],
    "abstract": "Image Classification is a fundamental task in the field of computer vision that frequently serves as a benchmark for gauging advancements in Computer Vision. Over the past few years, significant progress has been made in image classification due to the emergence of deep learning. However, challenges still exist, such as modeling fine-grained visual information, high computation costs, the parallelism of the model, and inconsistent evaluation protocols across datasets. In this paper, we conduct a comprehensive survey of existing papers on Vision Transformers for image classification. We first introduce the popular image classification datasets that influenced the design of models. Then, we present Vision Transformers models in chronological order, starting with early attempts at adapting attention mechanism to vision tasks followed by the adoption of vision transformers, as they have demonstrated success in capturing intricate patterns and long-range dependencies within images. Finally, we discuss open problems and shed light on opportunities for image classification to facilitate new research ideas.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.01232"
  },
  "2312.01229": {
    "title": "Fast Commitment for Geo-Distributed Transactions via Decentralized Co-coordinators",
    "authors": [
      "Zihao Zhang",
      "Huiqi Hu",
      "Xuan Zhou",
      "Yaofeng Tu",
      "Weining Qian",
      "Aoying Zhou"
    ],
    "abstract": "In a geo-distributed database, data shards and their respective replicas are deployed in distinct datacenters across multiple regions, enabling regional-level disaster recovery and the ability to serve global users locally. However, transaction processing in geo-distributed databases requires multiple cross-region communications, especially during the commit phase, which can significantly impact system performance.\n  To optimize the performance of geo-distributed transactions, we propose Decentralized Two-phase Commit (D2PC), a new transaction commit protocol aiming to minimize the negative impact of cross-region communication. In D2PC, we employ multiple co-coordinators that perform commit coordination in parallel. Each co-coordinator is responsible for collecting 2PC votes and making a PreCommit decision in its local region. This approach allows for the concurrent invocation of multiple cross-region network round trips, and each region can conclude its concurrency control locally before replication is complete, thus significantly reducing the chances of blocking and enhancing system concurrency. Moreover, we propose the bypass leader replication reply method, leveraging decentralized co-coordinators to bypass the leader for message transmission, thereby reducing the commit latency. Experimental results have demonstrated that D2PC can reduce commit latency by 43% and improve throughput by up to 2.43 times compared to the existing alternative geo-distributed transaction processing methods.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01229"
  },
  "2312.01228": {
    "title": "Mixed-Integer Optimisation of Graph Neural Networks for Computer-Aided Molecular Design",
    "authors": [
      "Tom McDonald",
      "Calvin Tsay",
      "Artur M. Schweidtmann",
      "Neil Yorke-Smith"
    ],
    "abstract": "ReLU neural networks have been modelled as constraints in mixed integer linear programming (MILP), enabling surrogate-based optimisation in various domains and efficient solution of machine learning certification problems. However, previous works are mostly limited to MLPs. Graph neural networks (GNNs) can learn from non-euclidean data structures such as molecular structures efficiently and are thus highly relevant to computer-aided molecular design (CAMD). We propose a bilinear formulation for ReLU Graph Convolutional Neural Networks and a MILP formulation for ReLU GraphSAGE models. These formulations enable solving optimisation problems with trained GNNs embedded to global optimality. We apply our optimization approach to an illustrative CAMD case study where the formulations of the trained GNNs are used to design molecules with optimal boiling points.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01228"
  },
  "2312.01227": {
    "title": "Distributed Bayesian Estimation in Sensor Networks: Consensus on Marginal Densities",
    "authors": [
      "Parth Paritosh",
      "Nikolay Atanasov",
      "Sonia Martinez"
    ],
    "abstract": "In this paper, we aim to design and analyze distributed Bayesian estimation algorithms for sensor networks. The challenges we address are to (i) derive a distributed provably-correct algorithm in the functional space of probability distributions over continuous variables, and (ii) leverage these results to obtain new distributed estimators restricted to subsets of variables observed by individual agents. This relates to applications such as cooperative localization and federated learning, where the data collected at any agent depends on a subset of all variables of interest. We present Bayesian density estimation algorithms using data from non-linear likelihoods at agents in centralized, distributed, and marginal distributed settings. After setting up a distributed estimation objective, we prove almost-sure convergence to the optimal set of pdfs at each agent. Then, we prove the same for a storage-aware algorithm estimating densities only over relevant variables at each agent. Finally, we present a Gaussian version of these algorithms and implement it in a mapping problem using variational inference to handle non-linear likelihood models associated with LiDAR sensing.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.01227"
  },
  "2312.01225": {
    "title": "UCE-FID: Using Large Unlabeled, Medium Crowdsourced-Labeled, and Small Expert-Labeled Tweets for Foodborne Illness Detection",
    "authors": [
      "Ruofan Hu",
      "Dongyu Zhang",
      "Dandan Tao",
      "Huayi Zhang",
      "Hao Feng",
      "Elke Rundensteiner"
    ],
    "abstract": "Foodborne illnesses significantly impact public health. Deep learning surveillance applications using social media data aim to detect early warning signals. However, labeling foodborne illness-related tweets for model training requires extensive human resources, making it challenging to collect a sufficient number of high-quality labels for tweets within a limited budget. The severe class imbalance resulting from the scarcity of foodborne illness-related tweets among the vast volume of social media further exacerbates the problem. Classifiers trained on a class-imbalanced dataset are biased towards the majority class, making accurate detection difficult. To overcome these challenges, we propose EGAL, a deep learning framework for foodborne illness detection that uses small expert-labeled tweets augmented by crowdsourced-labeled and massive unlabeled data. Specifically, by leveraging tweets labeled by experts as a reward set, EGAL learns to assign a weight of zero to incorrectly labeled tweets to mitigate their negative influence. Other tweets receive proportionate weights to counter-balance the unbalanced class distribution. Extensive experiments on real-world \\textit{TWEET-FID} data show that EGAL outperforms strong baseline models across different settings, including varying expert-labeled set sizes and class imbalance ratios. A case study on a multistate outbreak of Salmonella Typhimurium infection linked to packaged salad greens demonstrates how the trained model captures relevant tweets offering valuable outbreak insights. EGAL, funded by the U.S. Department of Agriculture (USDA), has the potential to be deployed for real-time analysis of tweet streaming, contributing to foodborne illness outbreak surveillance efforts.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01225"
  },
  "2312.01221": {
    "title": "Enabling Quantum Natural Language Processing for Hindi Language",
    "authors": [
      "Naman Srivastava",
      "Gaurang Belekar",
      "Sunil Saumya",
      "Aswath Babu H"
    ],
    "abstract": "Quantum Natural Language Processing (QNLP) is taking huge leaps in solving the shortcomings of classical Natural Language Processing (NLP) techniques and moving towards a more \"Explainable\" NLP system. The current literature around QNLP focuses primarily on implementing QNLP techniques in sentences in the English language. In this paper, we propose to enable the QNLP approach to HINDI, which is the third most spoken language in South Asia. We present the process of building the parameterized quantum circuits required to undertake QNLP on Hindi sentences. We use the pregroup representation of Hindi and the DisCoCat framework to draw sentence diagrams. Later, we translate these diagrams to Parameterised Quantum Circuits based on Instantaneous Quantum Polynomial (IQP) style ansatz. Using these parameterized quantum circuits allows one to train grammar and topic-aware sentence classifiers for the Hindi Language.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01221"
  },
  "2312.01219": {
    "title": "A Hierarchical Security Events Correlation Model for Real-time Cyber Threat Detection and Response",
    "authors": [
      "Herbert Maosa",
      "Karim Ouazzane",
      "Mohamed Chahine Ghanem"
    ],
    "abstract": "Intrusion detection systems perform post-compromise detection of security breaches whenever preventive measures such as firewalls do not avert an attack. However, these systems raise a vast number of alerts that must be analysed and triaged by security analysts. This process is largely manual, tedious and time-consuming. Alert correlation is a technique that tries to reduce the number of intrusion alerts by aggregating those that are related in some way. However, the correlation is performed outside the IDS through third-party systems and tools, after the high volume of alerts has already been raised. These other third-party systems add to the complexity of security operations. In this paper, we build on the very researched area of correlation techniques by developing a novel hierarchical event correlation model that promises to reduce the number of alerts issued by an Intrusion Detection System. This is achieved by correlating the events before the IDS classifies them. The proposed model takes the best of features from similarity and graph-based correlation techniques to deliver an ensemble capability not possible by either approach separately. Further, we propose a correlation process for correlation of events rather than alerts as is the case in current art. We further develop our own correlation and clustering algorithm which is tailor-made to the correlation and clustering of network event data. The model is implemented as a proof of concept with experiments run on the DARPA 99 Intrusion detection set. The correlation achieved 87 percent data reduction through aggregation, producing nearly 21000 clusters in about 30 seconds.\n        \u25b3 Less",
    "submission_date": "9 December, 2023",
    "eprint_id": "2312.01219"
  },
  "2312.01217": {
    "title": "Understanding Opinions Towards Climate Change on Social Media",
    "authors": [
      "Yashaswi Pupneja",
      "Joseph Zou",
      "Sacha L\u00e9vy",
      "Shenyang Huang"
    ],
    "abstract": "Social media platforms such as Twitter (now known as X) have revolutionized how the public engage with important societal and political topics. Recently, climate change discussions on social media became a catalyst for political polarization and the spreading of misinformation. In this work, we aim to understand how real world events influence the opinions of individuals towards climate change related topics on social media. To this end, we extracted and analyzed a dataset of 13.6 millions tweets sent by 3.6 million users from 2006 to 2019. Then, we construct a temporal graph from the user-user mentions network and utilize the Louvain community detection algorithm to analyze the changes in community structure around Conference of the Parties on Climate Change~(COP) events. Next, we also apply tools from the Natural Language Processing literature to perform sentiment analysis and topic modeling on the tweets. Our work acts as a first step towards understanding the evolution of pro-climate change communities around COP events. Answering these questions helps us understand how to raise people's awareness towards climate change thus hopefully calling on more individuals to join the collaborative effort in slowing down climate change.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01217"
  },
  "2312.01216": {
    "title": "Individual Behavioral Insights in Schizophrenia: A Network Analysis and Mobile Sensing Approach",
    "authors": [
      "Andy Davies",
      "Eiko Fried",
      "Hane Aung",
      "Omar Costilla-Reyes"
    ],
    "abstract": "Digital phenotyping in mental health often consists of collecting behavioral and experience-based information through sensory and self-reported data from devices such as smartphones. Such rich and comprehensive data could be used to develop insights into the relationships between daily behavior and a range of mental health conditions. However, current analytical approaches have shown limited application due to these datasets being both high dimensional and multimodal in nature. This study demonstrates the first use of a principled method which consolidates the complexities of subjective self-reported data (Ecological Momentary Assessments - EMAs) with concurrent sensor-based data. In this study the CrossCheck dataset is used to analyse data from 50 participants diagnosed with schizophrenia. Network Analysis is applied to EMAs at an individual (n-of-1) level while sensor data is used to identify periods of various behavioral context. Networks generated during periods of certain behavioral contexts, such as variations in the daily number of locations visited, were found to significantly differ from baseline networks and networks generated from randomly sampled periods of time. The framework presented here lays a foundation to reveal behavioural contexts and the concurrent impact of self-reporting at an n-of-1 level. These insights are valuable in the management of serious mental illnesses such as schizophrenia.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01216"
  },
  "2312.01214": {
    "title": "Model-Based Sensor Diagnostics for Robotic Manipulators",
    "authors": [
      "Astha Kukreja"
    ],
    "abstract": "Ensuring the safe and reliable operation of collaborative robots demands robust sensor diagnostics. This paper introduces a methodology for formulating model-based constraints tailored for sensor diagnostics, featuring analytical relationships extending across mechanical and electrical domains. While applicable to various robotic systems, the study specifically centers on a robotic joint employing a series elastic actuator. Three distinct constraints are imposed on the series elastic actuator: the Torsional Spring Constraint, Joint Dynamics Constraint, and Electrical Motor Constraint. Through a simulation example, we demonstrate the efficacy of the proposed model-based sensor diagnostics methodology. The study addresses two distinct types of sensor faults that may arise in the torque sensor of a robot joint, and delves into their respective detection methods. This insightful sensor diagnostic methodology is customizable and applicable across various components of robots, offering fault diagnostic and isolation capabilities. This research contributes valuable insights aimed at enhancing the diagnostic capabilities essential for the optimal performance of robotic manipulators in collaborative environments.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01214"
  },
  "2312.01213": {
    "title": "Recent Advances in Scalable Energy-Efficient and Trustworthy Spiking Neural networks: from Algorithms to Technology",
    "authors": [
      "Souvik Kundu",
      "Rui-Jie Zhu",
      "Akhilesh Jaiswal",
      "Peter A. Beerel"
    ],
    "abstract": "Neuromorphic computing and, in particular, spiking neural networks (SNNs) have become an attractive alternative to deep neural networks for a broad range of signal processing applications, processing static and/or temporal inputs from different sensory modalities, including audio and vision sensors. In this paper, we start with a description of recent advances in algorithmic and optimization innovations to efficiently train and scale low-latency, and energy-efficient spiking neural networks (SNNs) for complex machine learning applications. We then discuss the recent efforts in algorithm-architecture co-design that explores the inherent trade-offs between achieving high energy-efficiency and low latency while still providing high accuracy and trustworthiness. We then describe the underlying hardware that has been developed to leverage such algorithmic innovations in an efficient way. In particular, we describe a hybrid method to integrate significant portions of the model's computation within both memory components as well as the sensor itself. Finally, we discuss the potential path forward for research in building deployable SNN systems identifying key challenges in the algorithm-hardware-application co-design space with an emphasis on trustworthiness.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01213"
  },
  "2312.01212": {
    "title": "A Comparative Analysis Towards Melanoma Classification Using Transfer Learning by Analyzing Dermoscopic Images",
    "authors": [
      "Md. Fahim Uddin",
      "Nafisa Tafshir",
      "Mohammad Monirujjaman Khan"
    ],
    "abstract": "Melanoma is a sort of skin cancer that starts in the cells known as melanocytes. It is more dangerous than other types of skin cancer because it can spread to other organs. Melanoma can be fatal if it spreads to other parts of the body. Early detection is the key to cure, but it requires the skills of skilled doctors to diagnose it. This paper presents a system that combines deep learning techniques with established transfer learning methods to enable skin lesions classification and diagnosis of melanoma skin lesions. Using Convolutional Neural Networks, it presents a method for categorizing melanoma images into benign and malignant images in this research (CNNs). Researchers used 'Deep Learning' techniques to train an expansive number of photos & essentially to get the expected result deep neural networks to need to be trained with a huge number of parameters as dermoscopic images are sensitive & very hard to classify. This paper, has been emphasized building models with less complexity and comparatively better accuracy with limited datasets & partially fewer deep networks so that the system can predict Melanoma at ease from input dermoscopic images as correctly as possible within devices with less computational power. The dataset has been obtained from ISIC Archive. Multiple pre-trained models ResNet101, DenseNet, EfficientNet, InceptionV3 have been implemented using transfer learning techniques to complete the comparative analysis & every model achieved good accuracy. Before training the models, the data has been augmented by multiple parameters to improve the accuracy. Moreover, the results are better than the previous state-of-the-art approaches & adequate to predict melanoma. Among these architectures, DenseNet performed better than the others which gives a validation accuracy of 96.64%, validation loss of 9.43% & test set accuracy of 99.63%.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01212"
  },
  "2312.01202": {
    "title": "From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews",
    "authors": [
      "Alex Liu",
      "Min Sun"
    ],
    "abstract": "Obtaining stakeholders' diverse experiences and opinions about current policy in a timely manner is crucial for policymakers to identify strengths and gaps in resource allocation, thereby supporting effective policy design and implementation. However, manually coding even moderately sized interview texts or open-ended survey responses from stakeholders can often be labor-intensive and time-consuming. This study explores the integration of Large Language Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of stakeholder interviews regarding K-12 education policy within one U.S. state. Employing a mixed-methods approach, human experts developed a codebook and coding processes as informed by domain knowledge and unsupervised topic modeling results. They then designed prompts to guide GPT-4 analysis and iteratively evaluate different prompts' performances. This combined human-computer method enabled nuanced thematic and sentiment analysis. Results reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at specific themes, expanding to broader themes increased congruence to 96.02%, surpassing traditional Natural Language Processing (NLP) methods by over 25%. Additionally, GPT-4 is more closely matched to expert sentiment analysis than lexicon-based methods. Findings from quantitative measures and qualitative reviews underscore the complementary roles of human domain expertise and automated analysis as LLMs offer new perspectives and coding consistency. The human-computer interactive approach enhances efficiency, validity, and interpretability of educational policy research.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01202"
  },
  "2312.01200": {
    "title": "FRAUDability: Estimating Users' Susceptibility to Financial Fraud Using Adversarial Machine Learning",
    "authors": [
      "Chen Doytshman",
      "Satoru Momiyama",
      "Inderjeet Singh",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "In recent years, financial fraud detection systems have become very efficient at detecting fraud, which is a major threat faced by e-commerce platforms. Such systems often include machine learning-based algorithms aimed at detecting and reporting fraudulent activity. In this paper, we examine the application of adversarial learning based ranking techniques in the fraud detection domain and propose FRAUDability, a method for the estimation of a financial fraud detection system's performance for every user. We are motivated by the assumption that \"not all users are created equal\" -- while some users are well protected by fraud detection algorithms, others tend to pose a challenge to such systems. The proposed method produces scores, namely \"fraudability scores,\" which are numerical estimations of a fraud detection system's ability to detect financial fraud for a specific user, given his/her unique activity in the financial system. Our fraudability scores enable those tasked with defending users in a financial platform to focus their attention and resources on users with high fraudability scores to better protect them. We validate our method using a real e-commerce platform's dataset and demonstrate the application of fraudability scores from the attacker's perspective, on the platform, and more specifically, on the fraud detection systems used by the e-commerce enterprise. We show that the scores can also help attackers increase their financial profit by 54%, by engaging solely with users with high fraudability scores, avoiding those users whose spending habits enable more accurate fraud detection.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01200"
  },
  "2312.01197": {
    "title": "Short-term Precipitation Forecasting in The Netherlands: An Application of Convolutional LSTM neural networks to weather radar data",
    "authors": [
      "Petros Demetrakopoulos"
    ],
    "abstract": "This work addresses the challenge of short-term precipitation forecasting by applying Convolutional Long Short-Term Memory (ConvLSTM) neural networks to weather radar data from the Royal Netherlands Meteorological Institute (KNMI). The research exploits the combination of Convolutional Neural Networks (CNNs) layers for spatial pattern recognition and LSTM network layers for modelling temporal sequences, integrating these strengths into a ConvLSTM architecture. The model was trained and validated on weather radar data from the Netherlands. The model is an autoencoder consisting of nine layers, uniquely combining convolutional operations with LSTMs temporal processing, enabling it to capture the movement and intensity of precipitation systems. The training set comprised of sequences of radar images, with the model being tasked to predict precipitation patterns 1.5 hours ahead using the preceding data. Results indicate high accuracy in predicting the direction and intensity of precipitation movements. The findings of this study underscore the significant potential of ConvLSTM networks in meteorological forecasting, particularly in regions with complex weather patterns. It contributes to the field by offering a more accurate, data-driven approach to weather prediction, highlighting the broader applicability of ConvLSTM networks in meteorological tasks.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01197"
  },
  "2312.01195": {
    "title": "AIM: Automatic Interrupt Modeling for Dynamic Firmware Analysis",
    "authors": [
      "Bo Feng",
      "Meng Luo",
      "Changming Liu",
      "Long Lu",
      "Engin Kirda"
    ],
    "abstract": "The security of microcontrollers, which drive modern IoT and embedded devices, continues to raise major concerns. Within a microcontroller (MCU), the firmware is a monolithic piece of software that contains the whole software stack, whereas a variety of peripherals represent the hardware. As MCU firmware contains vulnerabilities, it is ideal to test firmware with off-the-shelf software testing techniques, such as dynamic symbolic execution and fuzzing. Nevertheless, no emulator can emulate the diverse MCU peripherals or execute/test the firmware. Specifically, the interrupt interface, among all I/O interfaces used by MCU peripherals, is extremely challenging to emulate.\n  In this paper, we present AIM -- a generic, scalable, and hardware-independent dynamic firmware analysis framework that supports unemulated MCU peripherals by a novel interrupt modeling mechanism. AIM effectively and efficiently covers interrupt-dependent code in firmware by a novel, firmware-guided, Just-in-Time Interrupt Firing technique. We implemented our framework in angr and performed dynamic symbolic execution for eight real-world MCU firmware. According to testing results, our framework covered up to 11.2 times more interrupt-dependent code than state-of-the-art approaches while accomplishing several challenging goals not feasible previously. Finally, a comparison with a state-of-the-art firmware fuzzer demonstrates dynamic symbolic execution and fuzzing together can achieve better firmware testing coverage.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01195"
  },
  "2312.01191": {
    "title": "Bootstrapping Interactive Image-Text Alignment for Remote Sensing Image Captioning",
    "authors": [
      "Cong Yang",
      "Zuchao Li",
      "Lefei Zhang"
    ],
    "abstract": "Recently, remote sensing image captioning has gained significant attention in the remote sensing community. Due to the significant differences in spatial resolution of remote sensing images, existing methods in this field have predominantly concentrated on the fine-grained extraction of remote sensing image features, but they cannot effectively handle the semantic consistency between visual features and textual features. To efficiently align the image-text, we propose a novel two-stage vision-language pre-training-based approach to bootstrap interactive image-text alignment for remote sensing image captioning, called BITA, which relies on the design of a lightweight interactive Fourier Transformer to better align remote sensing image-text features. The Fourier layer in the interactive Fourier Transformer is capable of extracting multi-scale features of remote sensing images in the frequency domain, thereby reducing the redundancy of remote sensing visual features. Specifically, the first stage involves preliminary alignment through image-text contrastive learning, which aligns the learned multi-scale remote sensing features from the interactive Fourier Transformer with textual features. In the second stage, the interactive Fourier Transformer connects the frozen image encoder with a large language model. Then, prefix causal language modeling is utilized to guide the text generation process using visual features. Ultimately, across the UCM-caption, RSICD, and NWPU-caption datasets, the experimental results clearly demonstrate that BITA outperforms other advanced comparative approaches. The code is available at https://github.com/yangcong356/BITA.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01191"
  },
  "2312.01188": {
    "title": "Efficient Expansion and Gradient Based Task Inference for Replay Free Incremental Learning",
    "authors": [
      "Soumya Roy",
      "Vinay K Verma",
      "Deepak Gupta"
    ],
    "abstract": "This paper proposes a simple but highly efficient expansion-based model for continual learning. The recent feature transformation, masking and factorization-based methods are efficient, but they grow the model only over the global or shared parameter. Therefore, these approaches do not fully utilize the previously learned information because the same task-specific parameter forgets the earlier knowledge. Thus, these approaches show limited transfer learning ability. Moreover, most of these models have constant parameter growth for all tasks, irrespective of the task complexity. Our work proposes a simple filter and channel expansion based method that grows the model over the previous task parameters and not just over the global parameter. Therefore, it fully utilizes all the previously learned information without forgetting, which results in better knowledge transfer. The growth rate in our proposed model is a function of task complexity; therefore for a simple task, the model has a smaller parameter growth while for complex tasks, the model requires more parameters to adapt to the current task. Recent expansion based models show promising results for task incremental learning (TIL). However, for class incremental learning (CIL), prediction of task id is a crucial challenge; hence, their results degrade rapidly as the number of tasks increase. In this work, we propose a robust task prediction method that leverages entropy weighted data augmentations and the models gradient using pseudo labels. We evaluate our model on various datasets and architectures in the TIL, CIL and generative continual learning settings. The proposed approach shows state-of-the-art results in all these settings. Our extensive ablation studies show the efficacy of the proposed components.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01188"
  },
  "2312.01180": {
    "title": "A Comparative Analysis of Text-to-Image Generative AI Models in Scientific Contexts: A Case Study on Nuclear Power",
    "authors": [
      "Veda Joynt",
      "Jacob Cooper",
      "Naman Bhargava",
      "Katie Vu",
      "O Hwang Kwon",
      "Todd R. Allen",
      "Aditi Verma",
      "Majdi I. Radaideh"
    ],
    "abstract": "In this work, we propose and assess the potential of generative artificial intelligence (AI) to generate public engagement around potential clean energy sources. Such an application could increase energy literacy -- an awareness of low-carbon energy sources among the public therefore leading to increased participation in decision-making about the future of energy systems. We explore the use of generative AI to communicate technical information about low-carbon energy sources to the general public, specifically in the realm of nuclear energy. We explored 20 AI-powered text-to-image generators and compared their individual performances on general and scientific nuclear-related prompts. Of these models, DALL-E, DreamStudio, and Craiyon demonstrated promising performance in generating relevant images from general-level text related to nuclear topics. However, these models fall short in three crucial ways: (1) they fail to accurately represent technical details of energy systems; (2) they reproduce existing biases surrounding gender and work in the energy sector; and (3) they fail to accurately represent indigenous landscapes -- which have historically been sites of resource extraction and waste deposition for energy industries. This work is performed to motivate the development of specialized generative tools and their captions to improve energy literacy and effectively engage the public with low-carbon energy sources.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01180"
  },
  "2312.01178": {
    "title": "Exploring a Hybrid Deep Learning Framework to Automatically Discover Topic and Sentiment in COVID-19 Tweets",
    "authors": [
      "Khandaker Tayef Shahriar",
      "Iqbal H. Sarker"
    ],
    "abstract": "COVID-19 has created a major public health problem worldwide and other problems such as economic crisis, unemployment, mental distress, etc. The pandemic is deadly in the world and involves many people not only with infection but also with problems, stress, wonder, fear, resentment, and hatred. Twitter is a highly influential social media platform and a significant source of health-related information, news, opinion and public sentiment where information is shared by both citizens and government sources. Therefore an effective analysis of COVID-19 tweets is essential for policymakers to make wise decisions. However, it is challenging to identify interesting and useful content from major streams of text to understand people's feelings about the important topics of the COVID-19 tweets. In this paper, we propose a new \\textit{framework} for analyzing topic-based sentiments by extracting key topics with significant labels and classifying positive, negative, or neutral tweets on each topic to quickly find common topics of public opinion and COVID-19-related attitudes. While building our model, we take into account hybridization of BiLSTM and GRU structures for sentiment analysis to achieve our goal. The experimental results show that our topic identification method extracts better topic labels and the sentiment analysis approach using our proposed hybrid deep learning model achieves the highest accuracy compared to traditional models.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01178"
  },
  "2312.01177": {
    "title": "IDPL-PFOD2: A New Large-Scale Dataset for Printed Farsi Optical Character Recognition",
    "authors": [
      "Fatemeh Asadi-zeydabadi",
      "Ali Afkari-Fahandari",
      "Amin Faraji",
      "Elham Shabaninia",
      "Hossein Nezamabadi-pour"
    ],
    "abstract": "Optical Character Recognition is a technique that converts document images into searchable and editable text, making it a valuable tool for processing scanned documents. While the Farsi language stands as a prominent and official language in Asia, efforts to develop efficient methods for recognizing Farsi printed text have been relatively limited. This is primarily attributed to the languages distinctive features, such as cursive form, the resemblance between certain alphabet characters, and the presence of numerous diacritics and dot placement. On the other hand, given the substantial training sample requirements of deep-based architectures for effective performance, the development of such datasets holds paramount significance. In light of these concerns, this paper aims to present a novel large-scale dataset, IDPL-PFOD2, tailored for Farsi printed text recognition. The dataset comprises 2003541 images featuring a wide variety of fonts, styles, and sizes. This dataset is an extension of the previously introduced IDPL-PFOD dataset, offering a substantial increase in both volume and diversity. Furthermore, the datasets effectiveness is assessed through the utilization of both CRNN-based and Vision Transformer architectures. The CRNN-based model achieves a baseline accuracy rate of 78.49% and a normalized edit distance of 97.72%, while the Vision Transformer architecture attains an accuracy of 81.32% and a normalized edit distance of 98.74%.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01177"
  },
  "2312.01172": {
    "title": "On-sensor Printed Machine Learning Classification via Bespoke ADC and Decision Tree Co-Design",
    "authors": [
      "Giorgos Armeniakos",
      "Paula L. Duarte",
      "Priyanjana Pal",
      "Georgios Zervakis",
      "Mehdi B. Tahoori",
      "Dimitrios Soudris"
    ],
    "abstract": "Printed electronics (PE) technology provides cost-effective hardware with unmet customization, due to their low non-recurring engineering and fabrication costs. PE exhibit features such as flexibility, stretchability, porosity, and conformality, which make them a prominent candidate for enabling ubiquitous computing. Still, the large feature sizes in PE limit the realization of complex printed circuits, such as machine learning classifiers, especially when processing sensor inputs is necessary, mainly due to the costly analog-to-digital converters (ADCs). To this end, we propose the design of fully customized ADCs and present, for the first time, a co-design framework for generating bespoke Decision Tree classifiers. Our comprehensive evaluation shows that our co-design enables self-powered operation of on-sensor printed classifiers in all benchmark cases.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01172"
  },
  "2312.01170": {
    "title": "Power-balanced Memristive Cryptographic Implementation Against Side Channel Attacks",
    "authors": [
      "Ziang Chen",
      "Li-Wei Chen",
      "Xianyue Zhao",
      "Kefeng Li",
      "Heidemarie Schmidt",
      "Ilia Polian",
      "Nan Du"
    ],
    "abstract": "Memristors, as emerging nano-devices, offer promising performance and exhibit rich electrical dynamic behavior. Having already found success in applications such as neuromorphic and in-memory computing, researchers are now exploring their potential for cryptographic implementations. In this study, we present a novel power-balanced hiding strategy utilizing memristor groups to conceal power consumption in cryptographic logic circuits. Our approach ensures consistent power costs of all 16 logic gates in Complementary-Resistive-Switching-with-Reading (CRS-R) logic family during writing and reading cycles regardless of Logic Input Variable (LIV) values. By constructing hiding groups, we enable an effective power balance in each gate hiding group. Furthermore, experimental validation of our strategy includes the implementation of a cryptographic construction, xor4SBox, using NOR gates. The circuit construction without the hiding strategy and with the hiding strategy undergo T-test analysis, confirming the significant improvement achieved with our approach. Our work presents a substantial advancement in power-balanced hiding methods, offering enhanced security and efficiency in logic circuits.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01170"
  },
  "2312.01167": {
    "title": "Meta-Learned Attribute Self-Interaction Network for Continual and Generalized Zero-Shot Learning",
    "authors": [
      "Vinay K Verma",
      "Nikhil Mehta",
      "Kevin J Liang",
      "Aakansha Mishra",
      "Lawrence Carin"
    ],
    "abstract": "Zero-shot learning (ZSL) is a promising approach to generalizing a model to categories unseen during training by leveraging class attributes, but challenges remain. Recently, methods using generative models to combat bias towards classes seen during training have pushed state of the art, but these generative models can be slow or computationally expensive to train. Also, these generative models assume that the attribute vector of each unseen class is available a priori at training, which is not always practical. Additionally, while many previous ZSL methods assume a one-time adaptation to unseen classes, in reality, the world is always changing, necessitating a constant adjustment of deployed models. Models unprepared to handle a sequential stream of data are likely to experience catastrophic forgetting. We propose a Meta-learned Attribute self-Interaction Network (MAIN) for continual ZSL. By pairing attribute self-interaction trained using meta-learning with inverse regularization of the attribute encoder, we are able to outperform state-of-the-art results without leveraging the unseen class attributes while also being able to train our models substantially faster (>100x) than expensive generative-based approaches. We demonstrate this with experiments on five standard ZSL datasets (CUB, aPY, AWA1, AWA2, and SUN) in the generalized zero-shot learning and continual (fixed/dynamic) zero-shot learning settings. Extensive ablations and analyses demonstrate the efficacy of various components proposed.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01167"
  },
  "2312.01164": {
    "title": "Telling stories with data -- A systematic review",
    "authors": [
      "Kay Schr\u00f6der",
      "Wiebke Eberhardt",
      "Poornima Belavadi",
      "Batoul Ajdadilish",
      "Nanette van Haften",
      "Ed Overes",
      "Taryn Brouns",
      "Andr\u00e9 Calero Valdez"
    ],
    "abstract": "The exponential growth of data has outpaced human ability to process information, necessitating innovative approaches for effective human-data interaction. To transform raw data into meaningful insights, storytelling, and visualization have emerged as powerful techniques for communicating complex information to decision-makers. This article offers a comprehensive, systematic review of the utilization of storytelling in visualizations. It organizes the existing literature into distinct categories, encompassing frameworks, data and visualization types, application domains, narrative structures, outcome measurements, and design principles. By providing a well-structured overview of this rapidly evolving field, the article serves as a valuable guide for educators, researchers, and practitioners seeking to harness the power of storytelling in data visualization.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01164"
  },
  "2312.01152": {
    "title": "Ultra-Resolution Cascaded Diffusion Model for Gigapixel Image Synthesis in Histopathology",
    "authors": [
      "Sarah Cechnicka",
      "Hadrien Reynaud",
      "James Ball",
      "Naomi Simmonds",
      "Catherine Horsfield",
      "Andrew Smith",
      "Candice Roufosse",
      "Bernhard Kainz"
    ],
    "abstract": "Diagnoses from histopathology images rely on information from both high and low resolutions of Whole Slide Images. Ultra-Resolution Cascaded Diffusion Models (URCDMs) allow for the synthesis of high-resolution images that are realistic at all magnification levels, focusing not only on fidelity but also on long-distance spatial coherency. Our model beats existing methods, improving the pFID-50k [2] score by 110.63 to 39.52 pFID-50k. Additionally, a human expert evaluation study was performed, reaching a weighted Mean Absolute Error (MAE) of 0.11 for the Lower Resolution Diffusion Models and a weighted MAE of 0.22 for the URCDM.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01152"
  },
  "2312.01151": {
    "title": "Here Is Not There: Measuring Entailment-Based Trajectory Similarity for Location-Privacy Protection and Beyond",
    "authors": [
      "Zilong Liu",
      "Krzysztof Janowicz",
      "Kitty Currier",
      "Meilin Shi",
      "Jinmeng Rao",
      "Song Gao",
      "Ling Cai",
      "Anita Graser"
    ],
    "abstract": "While the paths humans take play out in social as well as physical space, measures to describe and compare their trajectories are carried out in abstract, typically Euclidean, space. When these measures are applied to trajectories of actual individuals in an application area, alterations that are inconsequential in abstract space may suddenly become problematic once overlaid with geographic reality. In this work, we present a different view on trajectory similarity by introducing a measure that utilizes logical entailment. This is an inferential perspective that considers facts as triple statements deduced from the social and environmental context in which the travel takes place, and their practical implications. We suggest a formalization of entailment-based trajectory similarity, measured as the overlapping proportion of facts, which are spatial relation statements in our case study. With the proposed measure, we evaluate LSTM-TrajGAN, a privacy-preserving trajectory-generation model. The entailment-based model evaluation reveals potential consequences of disregarding the rich structure of geographic space (e.g., miscalculated insurance risk due to regional shifts in our toy example). Our work highlights the advantage of applying logical entailment to trajectory-similarity reasoning for location-privacy protection and beyond.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01151"
  },
  "2312.01149": {
    "title": "Disjoint Dominating and 2-Dominating Sets in Graphs: Hardness and Approximation results",
    "authors": [
      "Soumyashree Rana",
      "Sounaka Mishra",
      "Bhawani Sankar Panda"
    ],
    "abstract": "A set $D \\subseteq V$ of a graph $G=(V, E)$ is a dominating set of $G$ if each vertex $v\\in V\\setminus D$ is adjacent to at least one vertex in $D,$ whereas a set $D_2\\subseteq V$ is a $2$-dominating (double dominating) set of $G$ if each vertex $v\\in V \\setminus D_2$ is adjacent to at least two vertices in $D_2.$ A graph $G$ is a $DD_2$-graph if there exists a pair ($D, D_2$) of dominating set and $2$-dominating set of $G$ which are disjoint. In this paper, we solve some open problems posed by M.Miotk, J.~Topp and P.{\u017b}yli{\u0144}ski (Disjoint dominating and 2-dominating sets in graphs, Discrete Optimization, 35:100553, 2020) by giving approximation algorithms for the problem of determining a minimal spanning $DD_2$-graph of minimum size (Min-$DD_2$) with an approximation ratio of $3$; a minimal spanning $DD_2$-graph of maximum size (Max-$DD_2$) with an approximation ratio of $3$; and for the problem of adding minimum number of edges to a graph $G$ to make it a $DD_2$-graph (Min-to-$DD_2$) with an $O(\\log n)$ approximation ratio. Furthermore, we prove that Min-$DD_2$ and Max-$DD_2$ are APX-complete for graphs with maximum degree $4$. We also show that Min-$DD_2$ and Max-$DD_2$ are approximable within a factor of $1.8$ and $1.5$ respectively, for any $3$-regular graph. Finally, we show the inapproximability result of Max-Min-to-$DD_2$ for bipartite graphs, that this problem can not be approximated within $n^{\\frac{1}{6}-\\varepsilon}$ for any $\\varepsilon >0,$ unless P=NP.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01149"
  },
  "2312.01148": {
    "title": "Has Anything Changed? 3D Change Detection by 2D Segmentation Masks",
    "authors": [
      "Aikaterini Adam",
      "Konstantinos Karantzalos",
      "Lazaros Grammatikopoulos",
      "Torsten Sattler"
    ],
    "abstract": "As capturing devices become common, 3D scans of interior spaces are acquired on a daily basis. Through scene comparison over time, information about objects in the scene and their changes is inferred. This information is important for robots and AR and VR devices, in order to operate in an immersive virtual experience. We thus propose an unsupervised object discovery method that identifies added, moved, or removed objects without any prior knowledge of what objects exist in the scene. We model this problem as a combination of a 3D change detection and a 2D segmentation task. Our algorithm leverages generic 2D segmentation masks to refine an initial but incomplete set of 3D change detections. The initial changes, acquired through render-and-compare likely correspond to movable objects. The incomplete detections are refined through graph optimization, distilling the information of the 2D segmentation masks in the 3D space. Experiments on the 3Rscan dataset prove that our method outperforms competitive baselines, with SoTA results.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01148"
  },
  "2312.01143": {
    "title": "Towards leveraging LLMs for Conditional QA",
    "authors": [
      "Syed-Amad Hussain",
      "Parag Pravin Dakle",
      "SaiKrishna Rallabandi",
      "Preethi Raghavan"
    ],
    "abstract": "This study delves into the capabilities and limitations of Large Language Models (LLMs) in the challenging domain of conditional question-answering. Utilizing the Conditional Question Answering (CQA) dataset and focusing on generative models like T5 and UL2, we assess the performance of LLMs across diverse question types. Our findings reveal that fine-tuned LLMs can surpass the state-of-the-art (SOTA) performance in some cases, even without fully encoding all input context, with an increase of 7-8 points in Exact Match (EM) and F1 scores for Yes/No questions. However, these models encounter challenges in extractive question answering, where they lag behind the SOTA by over 10 points, and in mitigating the risk of injecting false information. A study with oracle-retrievers emphasizes the critical role of effective evidence retrieval, underscoring the necessity for advanced solutions in this area. Furthermore, we highlight the significant influence of evaluation metrics on performance assessments and advocate for a more comprehensive evaluation framework. The complexity of the task, the observed performance discrepancies, and the need for effective evidence retrieval underline the ongoing challenges in this field and underscore the need for future work focusing on refining training tasks and exploring prompt-based techniques to enhance LLM performance in conditional question-answering tasks.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01143"
  },
  "2312.01137": {
    "title": "Fast and Robust Sparsity-Aware Block Diagonal Representation",
    "authors": [
      "Aylin Tastan",
      "Michael Muma",
      "Abdelhak M. Zoubir"
    ],
    "abstract": "The block diagonal structure of an affinity matrix is a commonly desired property in cluster analysis because it represents clusters of feature vectors by non-zero coefficients that are concentrated in blocks. However, recovering a block diagonal affinity matrix is challenging in real-world applications, in which the data may be subject to outliers and heavy-tailed noise that obscure the hidden cluster structure. To address this issue, we first analyze the effect of different fundamental outlier types in graph-based cluster analysis. A key idea that simplifies the analysis is to introduce a vector that represents a block diagonal matrix as a piece-wise linear function of the similarity coefficients that form the affinity matrix. We reformulate the problem as a robust piece-wise linear fitting problem and propose a Fast and Robust Sparsity-Aware Block Diagonal Representation (FRS-BDR) method, which jointly estimates cluster memberships and the number of blocks. Comprehensive experiments on a variety of real-world applications demonstrate the effectiveness of FRS-BDR in terms of clustering accuracy, robustness against corrupted features, computation time and cluster enumeration performance.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01137"
  },
  "2312.01131": {
    "title": "FDM Printing: a Fabrication Method for Fluidic Soft Circuits?",
    "authors": [
      "Savita V. Kendre",
      "Lehong Wang",
      "Ethan Wilke",
      "Nicholas Pacheco",
      "Loris Fichera",
      "Markus P. Nemitz"
    ],
    "abstract": "Existing fluidic soft logic gates for the control of soft robots either rely on extensive manual fabrication processes or expensive printing techniques. In our work, we explore Fused Deposition Modeling for creating fully 3D printed fluidic logic gates. We print a soft bistable valve from thermoplastic polyurethane using a desktop FDM printer. We introduce a new printing nozzle for extruding tubing. Our fabrication strategy reduces the production time of soft bistable valves from 27 hours with replica molding to 3 hours with a FDM printer. Our rapid and cost-effective fabrication process for fluidic logic gates seeks to democratize fluidic circuitry for the control of soft robots.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01131"
  },
  "2312.01130": {
    "title": "STREAM: Software Tool for Routing Efficiently Advanced Macrofluidics",
    "authors": [
      "Lehong Wang",
      "Savita V. Kendre",
      "Haotian Liu",
      "Markus P. Nemitz"
    ],
    "abstract": "The current fabrication and assembly of fluidic circuits for soft robots relies heavily on manual processes; as the complexity of fluidic circuits increases, manual assembly becomes increasingly arduous, error-prone, and timeconsuming. We introduce a software tool that generates printable fluidic networks automatically. We provide a library of fluidic logic elements that are easily 3D printed from thermoplastic polyurethanes using Fused Deposition Modeling only. Our software tool and component library allow the development of arbitrary soft digital circuits. We demonstrate a variable frequency ring oscillator and a full adder. The simplicity of our approach using FDM printers only, democratizes fluidic circuit implementation beyond specialized laboratories. Our software is available on GitHub (https://github.com/roboticmaterialsgroup/FluidLogic).\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01130"
  },
  "2312.01128": {
    "title": "SPEEDNet: Salient Pyramidal Enhancement Encoder-Decoder Network for Colonoscopy Images",
    "authors": [
      "Tushir Sahu",
      "Vidhi Bhatt",
      "Sai Chandra Teja R",
      "Sparsh Mittal",
      "Nagesh Kumar S"
    ],
    "abstract": "Accurate identification and precise delineation of regions of significance, such as tumors or lesions, is a pivotal goal in medical imaging analysis. This paper proposes SPEEDNet, a novel architecture for precisely segmenting lesions within colonoscopy images. SPEEDNet uses a novel block named Dilated-Involutional Pyramidal Convolution Fusion (DIPC). A DIPC block combines the dilated involution layers pairwise into a pyramidal structure to convert the feature maps into a compact space. This lowers the total number of parameters while improving the learning of representations across an optimal receptive field, thereby reducing the blurring effect. On the EBHISeg dataset, SPEEDNet outperforms three previous networks: UNet, FeedNet, and AttesResDUNet. Specifically, SPEEDNet attains an average dice score of 0.952 and a recall of 0.971. Qualitative results and ablation studies provide additional insights into the effectiveness of SPEEDNet. The model size of SPEEDNet is 9.81 MB, significantly smaller than that of UNet (22.84 MB), FeedNet(185.58 MB), and AttesResDUNet (140.09 MB).\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01128"
  },
  "2312.01126": {
    "title": "BER Analysis of SCMA-OFDM Systems in the Presence of Carrier Frequency Offset",
    "authors": [
      "Haibo Liu",
      "Qu Luo",
      "Zilong Liu",
      "Shan Luo",
      "Pei Xiao",
      "Rongping Lin"
    ],
    "abstract": "Sparse code multiple access (SCMA) building upon orthogonal frequency division multiplexing (OFDM) is a promising wireless technology for supporting massive connectivity in future machine-type communication networks. However, the sensitivity of OFDM to carrier frequency offset (CFO) poses a major challenge because it leads to orthogonality loss and incurs intercarrier interference (ICI). In this paper, we investigate the bit error rate (BER) performance of SCMA-OFDM systems in the presence of CFO over both Gaussian and multipath Rayleigh fading channels. We first model the ICI in SCMA-OFDM as Gaussian variables conditioned on a single channel realization for fading channels. The BER is then evaluated by averaging over all codeword pairs considering the fading statistics. Through simulations, we validate the accuracy of our BER analysis and reveal that there is a significant BER degradation for SCMA-OFDM systems when the normalized CFO exceeds 0.02.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01126"
  },
  "2312.01125": {
    "title": "Design and Performance Analysis of Index Modulation Empowered AFDM System",
    "authors": [
      "Jing Zhu",
      "Qu Luo",
      "Gaojie Chen",
      "Pei Xiao",
      "Lixia Xiao"
    ],
    "abstract": "In this letter, we incorporate index modulation (IM) into affine frequency division multiplexing (AFDM), called AFDM-IM, to enhance the bit error rate (BER) and energy efficiency (EE) performance. In this scheme, the information bits are conveyed not only by $M$-ary constellation symbols, but also by the activation of the chirp subcarriers (SCs) indices, which are determined based on the incoming bit streams. Then, two power allocation strategies, namely power reallocation (PR) strategy and power saving (PS) strategy, are proposed to enhance BER and EE performance, respectively. Furthermore, the average bit error probability (ABEP) is theoretically analyzed. Simulation results demonstrate that the proposed AFDM-IM scheme achieves better BER performance than the conventional AFDM scheme.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01125"
  },
  "2312.01121": {
    "title": "Virtual reservoir acceleration for CPU and GPU: Case study for coupled spin-torque oscillator reservoir",
    "authors": [
      "Thomas Geert de Jong",
      "Nozomi Akashi",
      "Tomohiro Taniguchi",
      "Hirofumi Notsu",
      "Kohei Nakajima"
    ],
    "abstract": "We provide high-speed implementations for simulating reservoirs described by $N$-coupled spin-torque oscillators. Here $N$ also corresponds to the number of reservoir nodes. We benchmark a variety of implementations based on CPU and GPU. Our new methods are at least 2.6 times quicker than the baseline for $N$ in range $1$ to $10^4$. More specifically, over all implementations the best factor is 78.9 for $N=1$ which decreases to 2.6 for $N=10^3$ and finally increases to 23.8 for $N=10^4$. GPU outperforms CPU significantly at $N=2500$. Our results show that GPU implementations should be tested for reservoir simulations. The implementations considered here can be used for any reservoir with evolution that can be approximated using an explicit method.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01121"
  },
  "2312.01118": {
    "title": "Beyond Accuracy: Statistical Measures and Benchmark for Evaluation of Representation from Self-Supervised Learning",
    "authors": [
      "Jiantao Wu",
      "Shentong Mo",
      "Sara Atito",
      "Josef Kittler",
      "Zhenhua Feng",
      "Muhammad Awais"
    ],
    "abstract": "Recently, self-supervised metric learning has raised attention for the potential to learn a generic distance function. It overcomes the limitations of conventional supervised one, e.g., scalability and label biases. Despite progress in this domain, current benchmarks, incorporating a narrow scope of classes, stop the nuanced evaluation of semantic representations. To bridge this gap, we introduce a large-scale benchmark with diversity and granularity of classes, Statistical Metric Learning Benchmark (SMLB) built upon ImageNet-21K and WordNet. SMLB is designed to rigorously evaluate the discriminative discernment and generalizability across more than 14M images, 20K classes, and 16K taxonomic nodes. Alongside, we propose novel evaluation metrics -- `overlap' for separability and `aSTD' for consistency -- to measure distance statistical information, which are efficient and robust to the change of class number. Our benchmark offers a novel perspective of evaluating the quality of representations beyond accuracy. Our findings reveal the limitations of supervised learning and the class bias inherent in SSL models, offering insights into potential areas for future model enhancement.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01118"
  },
  "2312.01116": {
    "title": "Comparison of Deterministic and Nondeterministic Decision Trees for Decision Tables with Many-valued Decisions from Closed Classes",
    "authors": [
      "Azimkhon Ostonov",
      "Mikhail Moshkov"
    ],
    "abstract": "In this paper, we consider classes of decision tables with many-valued decisions closed relative to removal of attributes (columns) and changing sets of decisions assigned to rows. For tables from an arbitrary closed class, we study a function $\\mathcal{H}^{\\infty}_{\u03c8,A}(n)$ that characterizes the dependence in the worst case of the minimum complexity of deterministic decision trees on the minimum complexity of nondeterministic decision trees. Note that nondeterministic decision trees for a decision table can be interpreted as a way to represent an arbitrary system of true decision rules for this table that cover all rows. We indicate the condition for the function $\\mathcal{H}^{\\infty}_{\u03c8,A}(n)$ to be defined everywhere. If this function is everywhere defined, then it is either bounded from above by a constant or is greater than or equal to $n$ for infinitely many $n$. In particular, for any nondecreasing function $\\varphi$ such that $\\varphi (n)\\geq n$ and $\\varphi (0)=0$, the function $\\mathcal{H}^{\\infty}_{\u03c8,A}(n)$ can grow between $\\varphi (n)$ and $\\varphi (n)+n$. We indicate also conditions for the function $\\mathcal{H}^{\\infty}_{\u03c8,A}(n)$ to be bounded from above by a polynomial on $n$.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01116"
  },
  "2312.01114": {
    "title": "TURead: An eye movement dataset of Turkish reading",
    "authors": [
      "Cengiz Acarturk",
      "Aysegul Ozkan",
      "Tugce Nur Pekcetin",
      "Zuhal Ormanoglu",
      "Bilal Kirkici"
    ],
    "abstract": "In this study, we present TURead, an eye movement dataset of silent and oral sentence reading in Turkish, an agglutinative language with a shallow orthography understudied in reading research. TURead provides empirical data to investigate the relationship between morphology and oculomotor control. We employ a target-word approach in which target words are manipulated by word length and by the addition of two commonly used suffixes in Turkish. The dataset contains well-established eye movement variables; prelexical characteristics such as vowel harmony and bigram-trigram frequencies and word features, such as word length, predictability, frequency, eye voice span measures, Cloze test scores of the root word and suffix predictabilities, as well as the scores obtained from two working memory tests. Our findings on fixation parameters and word characteristics are in line with the patterns reported in the relevant literature.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01114"
  },
  "2312.01113": {
    "title": "Malicious code detection in android: the role of sequence characteristics and disassembling methods",
    "authors": [
      "Pinar G. Balikcioglu",
      "Melih Sirlanci",
      "Ozge A. Kucuk",
      "Bulut Ulukapi",
      "Ramazan K. Turkmen",
      "Cengiz Acarturk"
    ],
    "abstract": "The acceptance and widespread use of the Android operating system drew the attention of both legitimate developers and malware authors, which resulted in a significant number of benign and malicious applications available on various online markets. Since the signature-based methods fall short for detecting malicious software effectively considering the vast number of applications, machine learning techniques in this field have also become widespread. In this context, stating the acquired accuracy values in the contingency tables in malware detection studies has become a popular and efficient method and enabled researchers to evaluate their methodologies comparatively. In this study, we wanted to investigate and emphasize the factors that may affect the accuracy values of the models managed by researchers, particularly the disassembly method and the input data characteristics. Firstly, we developed a model that tackles the malware detection problem from a Natural Language Processing (NLP) perspective using Long Short-Term Memory (LSTM). Then, we experimented with different base units (instruction, basic block, method, and class) and representations of source code obtained from three commonly used disassembling tools (JEB, IDA, and Apktool) and examined the results. Our findings exhibit that the disassembly method and different input representations affect the model results. More specifically, the datasets collected by the Apktool achieved better results compared to the other two disassemblers.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01113"
  },
  "2312.01110": {
    "title": "Strong Duality Relations in Nonconvex Risk-Constrained Learning",
    "authors": [
      "Dionysis Kalogerias",
      "Spyridon Pougkakiotis"
    ],
    "abstract": "We establish strong duality relations for functional two-step compositional risk-constrained learning problems with multiple nonconvex loss functions and/or learning constraints, regardless of nonconvexity and under a minimal set of technical assumptions. Our results in particular imply zero duality gaps within the class of problems under study, both extending and improving on the state of the art in (risk-neutral) constrained learning. More specifically, we consider risk objectives/constraints which involve real-valued convex and positively homogeneous risk measures admitting dual representations with bounded risk envelopes, generalizing expectations and including popular examples, such as the conditional value-at-risk (CVaR), the mean-absolute deviation (MAD), and more generally all real-valued coherent risk measures on integrable losses as special cases. Our results are based on recent advances in risk-constrained nonconvex programming in infinite dimensions, which rely on a remarkable new application of J. J. Uhl's convexity theorem, which is an extension of A. A. Lyapunov's convexity theorem for general, infinite dimensional Banach spaces. By specializing to the risk-neutral setting, we demonstrate, for the first time, that constrained classification and regression can be treated under a unifying lens, while dispensing certain restrictive assumptions enforced in the current literature, yielding a new state-of-the-art strong duality framework for nonconvex constrained learning.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01110"
  },
  "2312.01109": {
    "title": "Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence",
    "authors": [
      "Nora Dunder",
      "Saga Lundborg",
      "Olga Viberg",
      "Jacqueline Wong"
    ],
    "abstract": "AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT's ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01109"
  },
  "2312.01107": {
    "title": "Rapid Speaker Adaptation in Low Resource Text to Speech Systems using Synthetic Data and Transfer learning",
    "authors": [
      "Raviraj Joshi",
      "Nikesh Garera"
    ],
    "abstract": "Text-to-speech (TTS) systems are being built using end-to-end deep learning approaches. However, these systems require huge amounts of training data. We present our approach to built production quality TTS and perform speaker adaptation in extremely low resource settings. We propose a transfer learning approach using high-resource language data and synthetically generated data. We transfer the learnings from the out-domain high-resource English language. Further, we make use of out-of-the-box single-speaker TTS in the target language to generate in-domain synthetic data. We employ a three-step approach to train a high-quality single-speaker TTS system in a low-resource Indian language Hindi. We use a Tacotron2 like setup with a spectrogram prediction network and a waveglow vocoder. The Tacotron2 acoustic model is trained on English data, followed by synthetic Hindi data from the existing TTS system. Finally, the decoder of this model is fine-tuned on only 3 hours of target Hindi speaker data to enable rapid speaker adaptation. We show the importance of this dual pre-training and decoder-only fine-tuning using subjective MOS evaluation. Using transfer learning from high-resource language and synthetic corpus we present a low-cost solution to train a custom TTS model.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01107"
  },
  "2312.01105": {
    "title": "S2P3: Self-Supervised Polarimetric Pose Prediction",
    "authors": [
      "Patrick Ruhkamp",
      "Daoyi Gao",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "abstract": "This paper proposes the first self-supervised 6D object pose prediction from multimodal RGB+polarimetric images. The novel training paradigm comprises 1) a physical model to extract geometric information of polarized light, 2) a teacher-student knowledge distillation scheme and 3) a self-supervised loss formulation through differentiable rendering and an invertible physical constraint. Both networks leverage the physical properties of polarized light to learn robust geometric representations by encoding shape priors and polarization characteristics derived from our physical model. Geometric pseudo-labels from the teacher support the student network without the need for annotated real data. Dense appearance and geometric information of objects are obtained through a differentiable renderer with the predicted pose for self-supervised direct coupling. The student network additionally features our proposed invertible formulation of the physical shape priors that enables end-to-end self-supervised training through physical constraints of derived polarization characteristics compared against polarimetric input images. We specifically focus on photometrically challenging objects with texture-less or reflective surfaces and transparent materials for which the most prominent performance gain is reported.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01105"
  },
  "2312.01104": {
    "title": "QPoser: Quantized Explicit Pose Prior Modeling for Controllable Pose Generation",
    "authors": [
      "Yumeng Li",
      "Yaoxiang Ding",
      "Zhong Ren",
      "Kun Zhou"
    ],
    "abstract": "Explicit pose prior models compress human poses into latent representations for using in pose-related downstream tasks. A desirable explicit pose prior model should satisfy three desirable abilities: 1) correctness, i.e. ensuring to generate physically possible poses; 2) expressiveness, i.e. ensuring to preserve details in generation; 3) controllability, meaning that generation from reference poses and explicit instructions should be convenient. Existing explicit pose prior models fail to achieve all of three properties, in special controllability. To break this situation, we propose QPoser, a highly controllable explicit pose prior model which guarantees correctness and expressiveness. In QPoser, a multi-head vector quantized autoencoder (MS-VQVAE) is proposed for obtaining expressive and distributed pose representations. Furthermore, a global-local feature integration mechanism (GLIF-AE) is utilized to disentangle the latent representation and integrate full-body information into local-joint features. Experimental results show that QPoser significantly outperforms state-of-the-art approaches in representing expressive and correct poses, meanwhile is easily to be used for detailed conditional generation from reference poses and prompting instructions.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01104"
  },
  "2312.01103": {
    "title": "Code-Mixed Text to Speech Synthesis under Low-Resource Constraints",
    "authors": [
      "Raviraj Joshi",
      "Nikesh Garera"
    ],
    "abstract": "Text-to-speech (TTS) systems are an important component in voice-based e-commerce applications. These applications include end-to-end voice assistant and customer experience (CX) voice bot. Code-mixed TTS is also relevant in these applications since the product names are commonly described in English while the surrounding text is in a regional language. In this work, we describe our approaches for production quality code-mixed Hindi-English TTS systems built for e-commerce applications. We propose a data-oriented approach by utilizing monolingual data sets in individual languages. We leverage a transliteration model to convert the Roman text into a common Devanagari script and then combine both datasets for training. We show that such single script bi-lingual training without any code-mixing works well for pure code-mixed test sets. We further present an exhaustive evaluation of single-speaker adaptation and multi-speaker training with Tacotron2 + Waveglow setup to show that the former approach works better. These approaches are also coupled with transfer learning and decoder-only fine-tuning to improve performance. We compare these approaches with the Google TTS and report a positive CMOS score of 0.02 with the proposed transfer learning approach. We also perform low-resource voice adaptation experiments to show that a new voice can be onboarded with just 3 hrs of data. This highlights the importance of our pre-trained models in resource-constrained settings. This subjective evaluation is performed on a large number of out-of-domain pure code-mixed sentences to demonstrate the high quality of the systems.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01103"
  },
  "2312.01100": {
    "title": "Prior-Aware Robust Beam Alignment for Low-SNR Millimeter-Wave Communications",
    "authors": [
      "Jihun Park",
      "Yongjeong Oh",
      "Jaewon Yun",
      "Seonjung Kim",
      "Yo-Seb Jeon"
    ],
    "abstract": "This paper presents a robust beam alignment technique for millimeter-wave communications in low signal-to-noise ratio (SNR) environments. The core strategy of our technique is to repeatedly transmit the most probable beam candidates to reduce beam misalignment probability induced by noise. Specifically, for a given beam training overhead, both the selection of candidates and the number of repetitions for each beam candidate are optimized based on channel prior information. To achieve this, a deep neural network is employed to learn the prior probability of the optimal beam at each location. The beam misalignment probability is then analyzed based on the channel prior, forming the basis for an optimization problem aimed at minimizing the analyzed beam misalignment probability. A closed-form solution is derived for a special case with two beam candidates, and an efficient algorithm is developed for general cases with multiple beam candidates. Simulation results using the DeepMIMO dataset demonstrate the superior performance of our technique in dynamic low-SNR communication environments when compared to existing beam alignment techniques.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01100"
  },
  "2312.01099": {
    "title": "Rethinking Multiple Instance Learning for Whole Slide Image Classification: A Bag-Level Classifier is a Good Instance-Level Teacher",
    "authors": [
      "Hongyi Wang",
      "Luyang Luo",
      "Fang Wang",
      "Ruofeng Tong",
      "Yen-Wei Chen",
      "Hongjie Hu",
      "Lanfen Lin",
      "Hao Chen"
    ],
    "abstract": "Multiple Instance Learning (MIL) has demonstrated promise in Whole Slide Image (WSI) classification. However, a major challenge persists due to the high computational cost associated with processing these gigapixel images. Existing methods generally adopt a two-stage approach, comprising a non-learnable feature embedding stage and a classifier training stage. Though it can greatly reduce the memory consumption by using a fixed feature embedder pre-trained on other domains, such scheme also results in a disparity between the two stages, leading to suboptimal classification accuracy. To address this issue, we propose that a bag-level classifier can be a good instance-level teacher. Based on this idea, we design Iteratively Coupled Multiple Instance Learning (ICMIL) to couple the embedder and the bag classifier at a low cost. ICMIL initially fix the patch embedder to train the bag classifier, followed by fixing the bag classifier to fine-tune the patch embedder. The refined embedder can then generate better representations in return, leading to a more accurate classifier for the next iteration. To realize more flexible and more effective embedder fine-tuning, we also introduce a teacher-student framework to efficiently distill the category knowledge in the bag classifier to help the instance-level embedder fine-tuning. Thorough experiments were conducted on four distinct datasets to validate the effectiveness of ICMIL. The experimental results consistently demonstrate that our method significantly improves the performance of existing MIL backbones, achieving state-of-the-art results. The code is available at: https://github.com/Dootmaan/ICMIL/tree/confidence_based\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01099"
  },
  "2312.01097": {
    "title": "Planning as In-Painting: A Diffusion-Based Embodied Task Planning Framework for Environments under Uncertainty",
    "authors": [
      "Cheng-Fu Yang",
      "Haoyang Xu",
      "Te-Lin Wu",
      "Xiaofeng Gao",
      "Kai-Wei Chang",
      "Feng Gao"
    ],
    "abstract": "Task planning for embodied AI has been one of the most challenging problems where the community does not meet a consensus in terms of formulation. In this paper, we aim to tackle this problem with a unified framework consisting of an end-to-end trainable method and a planning algorithm. Particularly, we propose a task-agnostic method named 'planning as in-painting'. In this method, we use a Denoising Diffusion Model (DDM) for plan generation, conditioned on both language instructions and perceptual inputs under partially observable environments. Partial observation often leads to the model hallucinating the planning. Therefore, our diffusion-based method jointly models both state trajectory and goal estimation to improve the reliability of the generated plan, given the limited available information at each step. To better leverage newly discovered information along the plan execution for a higher success rate, we propose an on-the-fly planning algorithm to collaborate with the diffusion-based planner. The proposed framework achieves promising performances in various embodied AI tasks, including vision-language navigation, object manipulation, and task planning in a photorealistic virtual environment. The code is available at: https://github.com/joeyy5588/planning-as-inpainting.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01097"
  },
  "2312.01093": {
    "title": "Predicting Postoperative Nausea And Vomiting Using Machine Learning: A Model Development and Validation Study",
    "authors": [
      "Maxim Glebov",
      "Teddy Lazebnik",
      "Boris Orkin",
      "Haim Berkenstadt",
      "Svetlana Bunimovich-Mendrazitsky"
    ],
    "abstract": "Background: Postoperative nausea and vomiting (PONV) is a frequently observed complication in patients undergoing surgery under general anesthesia. Moreover, it is a frequent cause of distress and dissatisfaction during the early postoperative period. The tools used for predicting PONV at present have not yielded satisfactory results. Therefore, prognostic tools for the prediction of early and delayed PONV were developed in this study with the aim of achieving satisfactory predictive performance.\n  Methods: The retrospective data of adult patients admitted to the post-anesthesia care unit after undergoing surgical procedures under general anesthesia at the Sheba Medical Center, Israel, between September 1, 2018, and September 1, 2023, were used in this study. An ensemble model of machine learning algorithms trained on the data of 54848 patients was developed. The k-fold cross-validation method was used followed by splitting the data to train and test sets that optimally preserve the sociodemographic features of the patients, such as age, sex, and smoking habits, using the Bee Colony algorithm.\n  Findings: Among the 54848 patients, early and delayed PONV were observed in 2706 (4.93%) and 8218 (14.98%) patients, respectively. The proposed PONV prediction tools could correctly predict early and delayed PONV in 84.0% and 77.3% of cases, respectively, outperforming the second-best PONV prediction tool (Koivuranta score) by 13.4% and 12.9%, respectively. Feature importance analysis revealed that the performance of the proposed prediction tools aligned with previous clinical knowledge, indicating their utility.\n  Interpretation: The machine learning-based tools developed in this study enabled improved PONV prediction, thereby facilitating personalized care and improved patient outcomes.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01093"
  },
  "2312.01092": {
    "title": "A Semi-Supervised Deep Learning Approach to Dataset Collection for Query-By-Humming Task",
    "authors": [
      "Amantur Amatov",
      "Dmitry Lamanov",
      "Maksim Titov",
      "Ivan Vovk",
      "Ilya Makarov",
      "Mikhail Kudinov"
    ],
    "abstract": "Query-by-Humming (QbH) is a task that involves finding the most relevant song based on a hummed or sung fragment. Despite recent successful commercial solutions, implementing QbH systems remains challenging due to the lack of high-quality datasets for training machine learning models. In this paper, we propose a deep learning data collection technique and introduce Covers and Hummings Aligned Dataset (CHAD), a novel dataset that contains 18 hours of short music fragments, paired with time-aligned hummed versions. To expand our dataset, we employ a semi-supervised model training pipeline that leverages the QbH task as a specialized case of cover song identification (CSI) task. Starting with a model trained on the initial dataset, we iteratively collect groups of fragments of cover versions of the same song and retrain the model on the extended data. Using this pipeline, we collect over 308 hours of additional music fragments, paired with time-aligned cover versions. The final model is successfully applied to the QbH task and achieves competitive results on benchmark datasets. Our study shows that the proposed dataset and training pipeline can effectively facilitate the implementation of QbH systems.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01092"
  },
  "2312.01091": {
    "title": "Demystifying DeFi MEV Activities in Flashbots Bundle",
    "authors": [
      "Zihao Li",
      "Jianfeng Li",
      "Zheyuan He",
      "Xiapu Luo",
      "Ting Wang",
      "Xiaoze Ni",
      "Wenwu Yang",
      "Xi Chen",
      "Ting Chen"
    ],
    "abstract": "Decentralized Finance, mushrooming in permissionless blockchains, has attracted a recent surge in popularity. Due to the transparency of permissionless blockchains, opportunistic traders can compete to earn revenue by extracting Miner Extractable Value (MEV), which undermines both the consensus security and efficiency of blockchain systems. The Flashbots bundle mechanism further aggravates the MEV competition because it empowers opportunistic traders with the capability of designing more sophisticated MEV extraction. In this paper, we conduct the first systematic study on DeFi MEV activities in Flashbots bundle by developing ActLifter, a novel automated tool for accurately identifying DeFi actions in transactions of each bundle, and ActCluster, a new approach that leverages iterative clustering to facilitate us to discover known/unknown DeFi MEV activities. Extensive experimental results show that ActLifter can achieve nearly 100% precision and recall in DeFi action identification, significantly outperforming state-of-the-art techniques. Moreover, with the help of ActCluster, we obtain many new observations and discover 17 new kinds of DeFi MEV activities, which occur in 53.12% of bundles but have not been reported in existing studies\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01091"
  },
  "2312.01090": {
    "title": "Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model",
    "authors": [
      "Y. Sun",
      "J. Zhao",
      "C. Yu",
      "W. Wang",
      "X. Zhou"
    ],
    "abstract": "The large language models represented by ChatGPT have a disruptive impact on the field of artificial intelligence. But it mainly focuses on natural language processing, speech recognition, machine learning and natural language understanding. This paper innovatively applies the large language model to the field of intelligent decision-making, places the large language model in the decision-making center, and constructs an agent architecture with the large language model as the core. Based on this, it further proposes a two-layer agent task planning, issues and executes decision commands through the interaction of natural language, and carries out simulation verification through the wargame simulation environment. Through the game confrontation simulation experiment, it is found that the intelligent decision-making ability of the large language model is significantly stronger than the commonly used reinforcement learning AI and rule AI, and the intelligence, understandability and generalization are all better. And through experiments, it was found that the intelligence of the large language model is closely related to prompt. This work also extends the large language model from previous human-computer interaction to the field of intelligent decision-making, which has important reference value and significance for the development of intelligent decision-making.\n        \u25b3 Less",
    "submission_date": "18 December, 2023",
    "eprint_id": "2312.01090"
  },
  "2312.01087": {
    "title": "Prompted Zero-Shot Multi-label Classification of Factual Incorrectness in Machine-Generated Summaries",
    "authors": [
      "Aniket Deroy",
      "Subhankar Maity",
      "Saptarshi Ghosh"
    ],
    "abstract": "This study addresses the critical issue of factual inaccuracies in machine-generated text summaries, an increasingly prevalent issue in information dissemination. Recognizing the potential of such errors to compromise information reliability, we investigate the nature of factual inconsistencies across machine-summarized content. We introduce a prompt-based classification system that categorizes errors into four distinct types: misrepresentation, inaccurate quantities or measurements, false attribution, and fabrication. The participants are tasked with evaluating a corpus of machine-generated summaries against their original articles. Our methodology employs qualitative judgements to identify the occurrence of factual distortions. The results show that our prompt-based approaches are able to detect the type of errors in the summaries to some extent, although there is scope for improvement in our classification systems.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01087"
  },
  "2312.01085": {
    "title": "RobustCalib: Robust Lidar-Camera Extrinsic Calibration with Consistency Learning",
    "authors": [
      "Shuang Xu",
      "Sifan Zhou",
      "Zhi Tian",
      "Jizhou Ma",
      "Qiong Nie",
      "Xiangxiang Chu"
    ],
    "abstract": "Current traditional methods for LiDAR-camera extrinsics estimation depend on offline targets and human efforts, while learning-based approaches resort to iterative refinement for calibration results, posing constraints on their generalization and application in on-board systems. In this paper, we propose a novel approach to address the extrinsic calibration problem in a robust, automatic, and single-shot manner. Instead of directly optimizing extrinsics, we leverage the consistency learning between LiDAR and camera to implement implicit re-calibartion. Specially, we introduce an appearance-consistency loss and a geometric-consistency loss to minimizing the inconsitency between the attrbutes (e.g., intensity and depth) of projected LiDAR points and the predicted ones. This design not only enhances adaptability to various scenarios but also enables a simple and efficient formulation during inference. We conduct comprehensive experiments on different datasets, and the results demonstrate that our method achieves accurate and robust performance. To promote further research and development in this area, we will release our model and code.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01085"
  },
  "2312.01083": {
    "title": "Consistency Prototype Module and Motion Compensation for Few-Shot Action Recognition (CLIP-CP$\\mathbf{M^2}$C)",
    "authors": [
      "Fei Guo",
      "Li Zhu",
      "YiKang Wang",
      "Han Qi"
    ],
    "abstract": "Recently, few-shot action recognition has significantly progressed by learning the feature discriminability and designing suitable comparison methods. Still, there are the following restrictions. (a) Previous works are mainly based on visual mono-modal. Although some multi-modal works use labels as supplementary to construct prototypes of support videos, they can not use this information for query videos. The labels are not used efficiently. (b) Most of the works ignore the motion feature of video, although the motion features are essential for distinguishing. We proposed a Consistency Prototype and Motion Compensation Network(CLIP-CP$M^2$C) to address these issues. Firstly, we use the CLIP for multi-modal few-shot action recognition with the text-image comparison for domain adaption. Secondly, in order to make the amount of information between the prototype and the query more similar, we propose a novel method to compensate for the text(prompt) information of query videos when text(prompt) does not exist, which depends on a Consistency Loss. Thirdly, we use the differential features of the adjacent frames in two directions as the motion features, which explicitly embeds the network with motion dynamics. We also apply the Consistency Loss to the motion features. Extensive experiments on standard benchmark datasets demonstrate that the proposed method can compete with state-of-the-art results. Our code is available at the URL: https://github.com/xxx/xxx.git.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01083"
  },
  "2312.01081": {
    "title": "Adaptive Resource Allocation for Semantic Communication Networks",
    "authors": [
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Zhaohui Yang",
      "Zhijin Qin"
    ],
    "abstract": "Semantic communication, recognized as a promising technology for future intelligent applications, has received widespread research attention. Despite the potential of semantic communication to enhance transmission reliability, especially in low signal-to-noise (SNR) environments, the critical issue of resource allocation and compatibility in the dynamic wireless environment remains largely unexplored. In this paper, we propose an adaptive semantic resource allocation paradigm with semantic-bit quantization (SBQ) compatibly for existing wireless communications, where the inaccurate environment perception introduced by the additional mapping relationship between semantic metrics and transmission metrics is solved. In order to investigate the performance of semantic communication networks, the quality of service for semantic communication (SC-QoS), including the semantic quantization efficiency (SQE) and transmission latency, is proposed for the first time. A problem of maximizing the overall effective SC-QoS is formulated by jointly optimizing the transmit beamforming of the base station, the bits for semantic representation, the subchannel assignment, and the bandwidth resource allocation. To address the non-convex formulated problem, an intelligent resource allocation scheme is proposed based on a hybrid deep reinforcement learning (DRL) algorithm, where the intelligent agent can perceive both semantic tasks and dynamic wireless environments. Simulation results demonstrate that our design can effectively combat semantic noise and achieve superior performance in wireless communications compared to several benchmark schemes. Furthermore, compared to mapping-guided paradigm based resource allocation schemes, our proposed adaptive scheme can achieve up to 13% performance improvement in terms of SC-QoS.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01081"
  },
  "2312.01080": {
    "title": "A Novel Residual-guided Learning Method for Image Steganography",
    "authors": [
      "Miaoxin Ye",
      "Dongxia Huang",
      "Kangkang Wei",
      "Weiqi Luo"
    ],
    "abstract": "Traditional steganographic techniques have often relied on manually crafted attributes related to image residuals. These methods demand a significant level of expertise and face challenges in integrating diverse image residual characteristics. In this paper, we introduce an innovative deep learning-based methodology that seamlessly integrates image residuals, residual distances, and image local variance to autonomously learn embedding probabilities. Our framework includes an embedding probability generator and three pivotal guiding components: Residual guidance strives to facilitate embedding in complex-textured areas. Residual distance guidance aims to minimize the residual differences between cover and stego images. Local variance guidance effectively safeguards against modifications in regions characterized by uncomplicated or uniform textures. The three components collectively guide the learning process, enhancing the security performance. Comprehensive experimental findings underscore the superiority of our approach when compared to traditional steganographic methods and randomly initialized ReLOAD in the spatial domain.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01080"
  },
  "2312.01071": {
    "title": "Hybrid Hierarchical DRL Enabled Resource Allocation for Secure Transmission in Multi-IRS-Assisted Sensing-Enhanced Spectrum Sharing Networks",
    "authors": [
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Qihui Wu",
      "Octavia A. Dobre",
      "Tony Q. S. Quek"
    ],
    "abstract": "Secure communications are of paramount importance in spectrum sharing networks due to the allocation and sharing characteristics of spectrum resources. To further explore the potential of intelligent reflective surfaces (IRSs) in enhancing spectrum sharing and secure transmission performance, a multiple intelligent reflection surface (multi-IRS)-assisted sensing-enhanced wideband spectrum sharing network is investigated by considering physical layer security techniques. An intelligent resource allocation scheme based on double deep Q networks (D3QN) algorithm and soft Actor-Critic (SAC) algorithm is proposed to maximize the secure transmission rate of the secondary network by jointly optimizing IRS pairings, subchannel assignment, transmit beamforming of the secondary base station, reflection coefficients of IRSs and the sensing time. To tackle the sparse reward problem caused by a significant amount of reflection elements of multiple IRSs, the method of hierarchical reinforcement learning is exploited. An alternative optimization (AO)-based conventional mathematical scheme is introduced to verify the computational complexity advantage of our proposed intelligent scheme. Simulation results demonstrate the efficiency of our proposed intelligent scheme as well as the superiority of multi-IRS design in enhancing secrecy rate and spectrum utilization. It is shown that inappropriate deployment of IRSs can reduce the security performance with the presence of multiple eavesdroppers (Eves), and the arrangement of IRSs deserves further consideration.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01071"
  },
  "2312.01067": {
    "title": "Painterly Reality: Enhancing Audience Experience with Paintings through Interactive Art",
    "authors": [
      "Aven Le Zhou",
      "Kang Zhang",
      "David Yip"
    ],
    "abstract": "Perceiving paintings entails more than merely engaging the audience's eyes and brains; their perceptions and experiences of a painting can be intricately connected with body movement. This paper proposes an interactive art approach entitled \"Painterly Reality\" that facilitates the perception and interaction with paintings in a three-dimensional manner. Its objective is to promote bodily engagement with the painting (i.e., embedded body embodiment and its movement and interaction) to enhance the audience's experience, while maintaining its essence. Unlike two-dimensional interactions, this approach constructs the Painterly Reality by capturing the audience's body embodiment in real-time and embedding into a three-dimensional painterly world derived from a given painting input. Through their body embodiment, the audience can navigate the painterly world and play with the magical realism (i.e., interactive painterly objects), fostering meaningful experiences via interactions. The Painterly Reality is subsequently projected through an Augmented Reality Mirror as a live painting and displayed in front of the audience. Hence, the audience can gain enhanced experiences through bodily engagement while simultaneously viewing and appreciating the live painting. The paper implements the proposed approach as an interactive artwork, entitled \"Everyday Conjunctive,\" with Fong Tse Ka's painting and installs in a local museum, which successfully enhances audience experience through bodily engagement.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01067"
  },
  "2312.01066": {
    "title": "A Database System for State Management in Stateful Network Service Function Chains [Vision]",
    "authors": [
      "Zhonghao Yang",
      "Shuhao Zhang"
    ],
    "abstract": "Network Function Virtualization (NFV) heralds a transformative era in network function deployment, enabling the orchestration of Service Function Chains (SFCs) for delivering complex and dynamic network services. Yet, the development and sustenance of stateful SFCs remain challenging, with intricate demands for usability in SFC development, performance, and execution correctness. In this paper, we present DB4NFV, a database system designed to address these challenges. Central to DB4NFV is the integration of transactional semantics into the entire lifecycle of stateful SFC, a core idea that enhances all aspects of the system. This integration provides an intuitive and well-structured API, which greatly simplifies the development of stateful SFCs. Concurrently, transactional semantics facilitate the optimization of runtime performance by efficiently leveraging modern multicore architectures. Moreover, by encapsulating state operations as transactions, DB4NFV achieves robustness, even at the entire chain level, ensuring reliable operation across varying network conditions. Consequently, DB4NFV marks a substantial forward leap in NFV state management, leveraging transactional semantics to achieve a harmonious blend of usability, efficiency, and robustness, thus facilitating the effective deployment of stateful SFCs in contemporary network infrastructures.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01066"
  },
  "2312.01065": {
    "title": "Scholarly Knowledge Graph Construction from Published Software Packages",
    "authors": [
      "Muhammad Haris",
      "S\u00f6ren Auer",
      "Markus Stocker"
    ],
    "abstract": "The value of structured scholarly knowledge for research and society at large is well understood, but producing scholarly knowledge (i.e., knowledge traditionally published in articles) in structured form remains a challenge. We propose an approach for automatically extracting scholarly knowledge from published software packages by static analysis of their metadata and contents (scripts and data) and populating a scholarly knowledge graph with the extracted knowledge. Our approach is based on mining scientific software packages linked to article publications by extracting metadata and analyzing the Abstract Syntax Tree (AST) of the source code to obtain information about the used and produced data as well as operations performed on data. The resulting knowledge graph includes articles, software packages metadata, and computational techniques applied to input data utilized as materials in research work. The knowledge graph also includes the results reported as scholarly knowledge in articles.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01065"
  },
  "2312.01062": {
    "title": "Acoustic Signal Analysis with Deep Neural Network for Detecting Fault Diagnosis in Industrial Machines",
    "authors": [
      "Mustafa Yurdakul",
      "Sakir Tasdemir"
    ],
    "abstract": "Detecting machine malfunctions at an early stage is crucial for reducing interruptions in operational processes within industrial settings. Recently, the deep learning approach has started to be preferred for the detection of failures in machines. Deep learning provides an effective solution in fault detection processes thanks to automatic feature extraction. In this study, a deep learning-based system was designed to analyze the sound signals produced by industrial machines. Acoustic sound signals were converted into Mel spectrograms. For the purpose of classifying spectrogram images, the DenseNet-169 model, a deep learning architecture recognized for its effectiveness in image classification tasks, was used. The model was trained using the transfer learning method on the MIMII dataset including sounds from four types of industrial machines. The results showed that the proposed method reached an accuracy rate varying between 97.17% and 99.87% at different Sound Noise Rate levels.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01062"
  },
  "2312.01061": {
    "title": "Spectral-wise Implicit Neural Representation for Hyperspectral Image Reconstruction",
    "authors": [
      "Huan Chen",
      "Wangcai Zhao",
      "Tingfa Xu",
      "Shiyun Zhou",
      "Peifu Liu",
      "Jianan Li"
    ],
    "abstract": "Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to recover the 3D spatial-spectral signal from 2D measurement. Existing methods for reconstructing Hyperspectral Image (HSI) typically involve learning mappings from a 2D compressed image to a predetermined set of discrete spectral bands. However, this approach overlooks the inherent continuity of the spectral information. In this study, we propose an innovative method called Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward addressing this limitation. SINR introduces a continuous spectral amplification process for HSI reconstruction, enabling spectral super-resolution with customizable magnification factors. To achieve this, we leverage the concept of implicit neural representation. Specifically, our approach introduces a spectral-wise attention mechanism that treats individual channels as distinct tokens, thereby capturing global spectral dependencies. Additionally, our approach incorporates two components, namely a Fourier coordinate encoder and a spectral scale factor module. The Fourier coordinate encoder enhances the SINR's ability to emphasize high-frequency components, while the spectral scale factor module guides the SINR to adapt to the variable number of spectral channels. Notably, the SINR framework enhances the flexibility of CASSI reconstruction by accommodating an unlimited number of spectral bands in the desired output. Extensive experiments demonstrate that our SINR outperforms baseline methods. By enabling continuous reconstruction within the CASSI framework, we take the initial stride toward integrating implicit neural representation into the field.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01061"
  },
  "2312.01060": {
    "title": "Spectrum-driven Mixed-frequency Network for Hyperspectral Salient Object Detection",
    "authors": [
      "Peifu Liu",
      "Tingfa Xu",
      "Huan Chen",
      "Shiyun Zhou",
      "Haolin Qin",
      "Jianan Li"
    ],
    "abstract": "Hyperspectral salient object detection (HSOD) aims to detect spectrally salient objects in hyperspectral images (HSIs). However, existing methods inadequately utilize spectral information by either converting HSIs into false-color images or converging neural networks with clustering. We propose a novel approach that fully leverages the spectral characteristics by extracting two distinct frequency components from the spectrum: low-frequency Spectral Saliency and high-frequency Spectral Edge. The Spectral Saliency approximates the region of salient objects, while the Spectral Edge captures edge information of salient objects. These two complementary components, crucial for HSOD, are derived by computing from the inter-layer spectral angular distance of the Gaussian pyramid and the intra-neighborhood spectral angular gradients, respectively. To effectively utilize this dual-frequency information, we introduce a novel lightweight Spectrum-driven Mixed-frequency Network (SMN). SMN incorporates two parameter-free plug-and-play operators, namely Spectral Saliency Generator and Spectral Edge Operator, to extract the Spectral Saliency and Spectral Edge components from the input HSI independently. Subsequently, the Mixed-frequency Attention module, comprised of two frequency-dependent heads, intelligently combines the embedded features of edge and saliency information, resulting in a mixed-frequency feature representation. Furthermore, a saliency-edge-aware decoder progressively scales up the mixed-frequency feature while preserving rich detail and saliency information for accurate salient object prediction. Extensive experiments conducted on the HS-SOD benchmark and our custom dataset HSOD-BIT demonstrate that our SMN outperforms state-of-the-art methods regarding HSOD performance. Code and dataset will be available at https://github.com/laprf/SMN.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01060"
  },
  "2312.01059": {
    "title": "Swarm-GPT: Combining Large Language Models with Safe Motion Planning for Robot Choreography Design",
    "authors": [
      "Aoran Jiao",
      "Tanmay P. Patel",
      "Sanjmi Khurana",
      "Anna-Mariya Korol",
      "Lukas Brunke",
      "Vivek K. Adajania",
      "Utku Culha",
      "Siqi Zhou",
      "Angela P. Schoellig"
    ],
    "abstract": "This paper presents Swarm-GPT, a system that integrates large language models (LLMs) with safe swarm motion planning - offering an automated and novel approach to deployable drone swarm choreography. Swarm-GPT enables users to automatically generate synchronized drone performances through natural language instructions. With an emphasis on safety and creativity, Swarm-GPT addresses a critical gap in the field of drone choreography by integrating the creative power of generative models with the effectiveness and safety of model-based planning algorithms. This goal is achieved by prompting the LLM to generate a unique set of waypoints based on extracted audio data. A trajectory planner processes these waypoints to guarantee collision-free and feasible motion. Results can be viewed in simulation prior to execution and modified through dynamic re-prompting. Sim-to-real transfer experiments demonstrate Swarm-GPT's ability to accurately replicate simulated drone trajectories, with a mean sim-to-real root mean square error (RMSE) of 28.7 mm. To date, Swarm-GPT has been successfully showcased at three live events, exemplifying safe real-world deployment of pre-trained models.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01059"
  },
  "2312.01058": {
    "title": "A Survey of Progress on Cooperative Multi-agent Reinforcement Learning in Open Environment",
    "authors": [
      "Lei Yuan",
      "Ziqian Zhang",
      "Lihe Li",
      "Cong Guan",
      "Yang Yu"
    ],
    "abstract": "Multi-agent Reinforcement Learning (MARL) has gained wide attention in recent years and has made progress in various fields. Specifically, cooperative MARL focuses on training a team of agents to cooperatively achieve tasks that are difficult for a single agent to handle. It has shown great potential in applications such as path planning, autonomous driving, active voltage control, and dynamic algorithm configuration. One of the research focuses in the field of cooperative MARL is how to improve the coordination efficiency of the system, while research work has mainly been conducted in simple, static, and closed environment settings. To promote the application of artificial intelligence in real-world, some research has begun to explore multi-agent coordination in open environments. These works have made progress in exploring and researching the environments where important factors might change. However, the mainstream work still lacks a comprehensive review of the research direction. In this paper, starting from the concept of reinforcement learning, we subsequently introduce multi-agent systems (MAS), cooperative MARL, typical methods, and test environments. Then, we summarize the research work of cooperative MARL from closed to open environments, extract multiple research directions, and introduce typical works. Finally, we summarize the strengths and weaknesses of the current research, and look forward to the future development direction and research problems in cooperative MARL in open environments.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01058"
  },
  "2312.01056": {
    "title": "Investigating the Surrogate Modeling Capabilities of Continuous Time Echo State Networks",
    "authors": [
      "Saakaar Bhatnagar"
    ],
    "abstract": "Continuous Time Echo State Networks (CTESNs) are a promising yet under-explored surrogate modeling technique for dynamical systems, particularly those governed by stiff Ordinary Differential Equations (ODEs). A key determinant of the generalization accuracy of a CTESN surrogate is the method of projecting the reservoir state to the output. This paper shows that of the two common projection methods (linear and nonlinear), the surrogates developed via the nonlinear projection consistently outperform those developed via the linear method. CTESN surrogates are developed for several challenging benchmark cases governed by stiff ODEs, and for each case, the performance of the linear and nonlinear projections is compared. The results of this paper demonstrate the applicability of CTESNs to a variety of problems while serving as a reference for important algorithmic and hyper-parameter choices for CTESNs\n        \u25b3 Less",
    "submission_date": "5 January, 2024",
    "eprint_id": "2312.01056"
  },
  "2312.01054": {
    "title": "Exploring and Improving the Spatial Reasoning Abilities of Large Language Models",
    "authors": [
      "Manasi Sharma"
    ],
    "abstract": "Large Language Models (LLMs) represent formidable tools for sequence modeling, boasting an innate capacity for general pattern recognition. Nevertheless, their broader spatial reasoning capabilities, especially applied to numerical trajectory data, remain insufficiently explored. In this paper, we investigate the out-of-the-box performance of ChatGPT-3.5, ChatGPT-4 and Llama 2 7B models when confronted with 3D robotic trajectory data from the CALVIN baseline and associated tasks, including 2D directional and shape labeling. Additionally, we introduce a novel prefix-based prompting mechanism, which yields a 33% improvement on the 3D trajectory data and an increase of up to 10% on SpartQA tasks over zero-shot prompting (with gains for other prompting types as well). The experimentation with 3D trajectory data offers an intriguing glimpse into the manner in which LLMs engage with numerical and spatial information, thus laying a solid foundation for the identification of target areas for future enhancements.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01054"
  },
  "2312.01049": {
    "title": "Joint User Association and Resource Allocation for Multi-Cell Networks with Adaptive Semantic Communication",
    "authors": [
      "Xingqiu He",
      "Chaoqun You",
      "Tony Q. S. Quek"
    ],
    "abstract": "Semantic communication is a promising communication paradigm that utilizes Deep Neural Networks (DNNs) to extract the information relevant to downstream tasks, hence significantly reducing the amount of transmitted data. In current practice, the semantic communication transmitter for a specific task is typically pre-trained and shared by all users. However, due to user heterogeneity, it is desirable to use different transmitters according to the available computational and communication resources of users. In this paper, we first show that it is possible to dynamically adjust the computational and communication overhead of DNN-based transmitters, thereby achieving adaptive semantic communication. After that, we investigate the user association and resource allocation problem in a multi-cell network where users are equipped with adaptive semantic communication transmitters. To solve this problem, we decompose it into three subproblems involving the scheduling of each user, the resource allocation of each base station (BS), and the user association between users and BSs. Then we solve each problem progressively based on the solution of the previous subproblem. The final algorithm can obtain near-optimal solutions in polynomial time. Numerical results show that our algorithm outperforms benchmarks under various situations.\n        \u25b3 Less",
    "submission_date": "4 January, 2024",
    "eprint_id": "2312.01049"
  },
  "2312.01045": {
    "title": "PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks",
    "authors": [
      "Yisheng Zhong",
      "Li-Ping Wang"
    ],
    "abstract": "Federated Learning (FL) faces two major issues: privacy leakage and poisoning attacks, which may seriously undermine the reliability and security of the system. Overcoming them simultaneously poses a great challenge. This is because privacy protection policies prohibit access to users' local gradients to avoid privacy leakage, while Byzantine-robust methods necessitate access to these gradients to defend against poisoning attacks. To address these problems, we propose a novel privacy-preserving Byzantine-robust FL framework PROFL. PROFL is based on the two-trapdoor additional homomorphic encryption algorithm and blinding techniques to ensure the data privacy of the entire FL process. During the defense process, PROFL first utilize secure Multi-Krum algorithm to remove malicious gradients at the user level. Then, according to the Pauta criterion, we innovatively propose a statistic-based privacy-preserving defense algorithm to eliminate outlier interference at the feature level and resist impersonation poisoning attacks with stronger concealment. Detailed theoretical analysis proves the security and efficiency of the proposed method. We conducted extensive experiments on two benchmark datasets, and PROFL improved accuracy by 39% to 75% across different attack settings compared to similar privacy-preserving robust methods, demonstrating its significant advantage in robustness.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01045"
  },
  "2312.01044": {
    "title": "Large Language Models Are Zero-Shot Text Classifiers",
    "authors": [
      "Zhiqiang Wang",
      "Yiran Pang",
      "Yanbin Lin"
    ],
    "abstract": "Retrained large language models (LLMs) have become extensively used across various sub-disciplines of natural language processing (NLP). In NLP, text classification problems have garnered considerable focus, but still faced with some limitations related to expensive computational cost, time consumption, and robust performance to unseen classes. With the proposal of chain of thought prompting (CoT), LLMs can be implemented using zero-shot learning (ZSL) with the step by step reasoning prompts, instead of conventional question and answer formats. The zero-shot LLMs in the text classification problems can alleviate these limitations by directly utilizing pretrained models to predict both seen and unseen classes. Our research primarily validates the capability of GPT models in text classification. We focus on effectively utilizing prompt strategies to various text classification scenarios. Besides, we compare the performance of zero shot LLMs with other state of the art text classification methods, including traditional machine learning methods, deep learning methods, and ZSL methods. Experimental results demonstrate that the performance of LLMs underscores their effectiveness as zero-shot text classifiers in three of the four datasets analyzed. The proficiency is especially advantageous for small businesses or teams that may not have extensive knowledge in text classification.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01044"
  },
  "2312.01042": {
    "title": "Covert Communications in STAR-RIS-Aided Rate-Splitting Multiple Access Systems",
    "authors": [
      "Heng Chang",
      "Hai Yang",
      "Shuobo Xu",
      "Xiyu Pang",
      "Hongwu Liu"
    ],
    "abstract": "In this paper, we investigate covert communications in a simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS)-aided rate-splitting multiple access (RSMA) system. Under the RSMA principles, the messages for the covert user (Bob) and public user (Grace) are converted to the common and private streams at the legitimate transmitter (Alice) to realize downlink transmissions, while the STAR-RIS is deployed not only to aid the public transmissions from Alice to Grace, but also to shield the covert transmissions from Alice to Bob against the warden (Willie). To characterize the covert performance of the considered STAR-RIS-aided RSMA (STAR-RIS-RSMA) system, we derive analytical expression for the minimum average detection error probability of Willie, based on which a covert rate maximization problem is formulated. To maximize Bob's covert rate while confusing Willie's monitoring, the transmit power allocation, common rate allocation, and STAR-RIS reflection/transmission beamforming are jointly optimized subject to Grace's quality of service (QoS) requirements. The non-convex covert rate maximization problem, consisting of highly coupled system parameters are decoupled into three sub-problems of transmit power allocation, common rate allocation, and STAR-RIS reflection/transmission beamforming, respectively. To obtain the rank-one constrained optimal solution for the sub-problem of optimizing the STAR-RIS reflection/transmission beamforming, a penalty-based successive convex approximation scheme is developed. Moreover, an alternative optimization (AO) algorithm is designed to determine the optimal solution for the sub-problem of optimizing the transmit power allocation, while the original problem is overall solved by a new AO algorithm.\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01042"
  },
  "2312.01040": {
    "title": "From Beginner to Expert: Modeling Medical Knowledge into General LLMs",
    "authors": [
      "Qiang Li",
      "Xiaoyan Yang",
      "Haowen Wang",
      "Qin Wang",
      "Lei Liu",
      "Junjie Wang",
      "Yang Zhang",
      "Mingyuan Chu",
      "Sen Hu",
      "Yicheng Chen",
      "Yue Shen",
      "Cong Fan",
      "Wangshu Zhang",
      "Teng Xu",
      "Jinjie Gu",
      "Jing Zheng",
      "Guannan Zhang Ant Group"
    ],
    "abstract": "Recently, large language model (LLM) based artificial intelligence (AI) systems have demonstrated remarkable capabilities in natural language understanding and generation. However, these models face a significant challenge when it comes to sensitive applications, such as reasoning over medical knowledge and answering medical questions in a physician-like manner. Prior studies attempted to overcome this challenge by increasing the model size (>100B) to learn more general medical knowledge, while there is still room for improvement in LLMs with smaller-scale model sizes (<100B). In this work, we start from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a medical beginner towards a medical expert (called AntGLM-Med-10B), which leverages a 3-stage optimization procedure, i.e., general medical knowledge injection, medical domain instruction tuning, and specific medical task adaptation. Our contributions are threefold: (1) We specifically investigate how to adapt a pre-trained general LLM in medical domain, especially for a specific medical task. (2) We collect and construct large-scale medical datasets for each stage of the optimization process. These datasets encompass various data types and tasks, such as question-answering, medical reasoning, multi-choice questions, and medical conversations. (3) Specifically for multi-choice questions in the medical domain, we propose a novel Verification-of-Choice approach for prompting engineering, which significantly enhances the reasoning ability of LLMs. Remarkably, by combining the above approaches, our AntGLM-Med-10B model can outperform the most of LLMs on PubMedQA, including both general and medical LLMs, even when these LLMs have larger model size.\n        \u25b3 Less",
    "submission_date": "7 January, 2024",
    "eprint_id": "2312.01040"
  },
  "2312.01032": {
    "title": "Harnessing the Power of Prompt-based Techniques for Generating School-Level Questions using Large Language Models",
    "authors": [
      "Subhankar Maity",
      "Aniket Deroy",
      "Sudeshna Sarkar"
    ],
    "abstract": "Designing high-quality educational questions is a challenging and time-consuming task. In this work, we propose a novel approach that utilizes prompt-based techniques to generate descriptive and reasoning-based questions. However, current question-answering (QA) datasets are inadequate for conducting our experiments on prompt-based question generation (QG) in an educational setting. Therefore, we curate a new QG dataset called EduProbe for school-level subjects, by leveraging the rich content of NCERT textbooks. We carefully annotate this dataset as quadruples of 1) Context: a segment upon which the question is formed; 2) Long Prompt: a long textual cue for the question (i.e., a longer sequence of words or phrases, covering the main theme of the context); 3) Short Prompt: a short textual cue for the question (i.e., a condensed representation of the key information or focus of the context); 4) Question: a deep question that aligns with the context and is coherent with the prompts. We investigate several prompt-based QG methods by fine-tuning pre-trained transformer-based large language models (LLMs), namely PEGASUS, T5, MBART, and BART. Moreover, we explore the performance of two general-purpose pre-trained LLMs such as Text-Davinci-003 and GPT-3.5-Turbo without any further training. By performing automatic evaluation, we show that T5 (with long prompt) outperforms all other models, but still falls short of the human baseline. Under human evaluation criteria, TextDavinci-003 usually shows better results than other models under various prompt settings. Even in the case of human evaluation criteria, QG models mostly fall short of the human baseline. Our code and dataset are available at: https://github.com/my625/PromptQG\n        \u25b3 Less",
    "submission_date": "2 December, 2023",
    "eprint_id": "2312.01032"
  },
  "2312.01029": {
    "title": "RNN-BOF: A Multivariate Global Recurrent Neural Network for Binary Outcome Forecasting of Inpatient Aggression",
    "authors": [
      "Aidan Quinn",
      "Melanie Simmons",
      "Benjamin Spivak",
      "Christoph Bergmeir"
    ],
    "abstract": "Psychometric assessment instruments aid clinicians by providing methods of assessing the future risk of adverse events such as aggression. Existing machine learning approaches have treated this as a classification problem, predicting the probability of an adverse event in a fixed future time period from the scores produced by both psychometric instruments and clinical and demographic covariates. We instead propose modelling a patient's future risk using a time series methodology that learns from longitudinal data and produces a probabilistic binary forecast that indicates the presence of the adverse event in the next time period. Based on the recent success of Deep Neural Nets for globally forecasting across many time series, we introduce a global multivariate Recurrent Neural Network for Binary Outcome Forecasting, that trains from and for a population of patient time series to produce individual probabilistic risk assessments. We use a moving window training scheme on a real world dataset of 83 patients, where the main binary time series represents the presence of aggressive events and covariate time series represent clinical or demographic features and psychometric measures. On this dataset our approach was capable of a significant performance increase against both benchmark psychometric instruments and previously used machine learning methodologies.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01029"
  },
  "2312.01028": {
    "title": "A structure theorem for pseudo-segments and its applications",
    "authors": [
      "Jacob Fox",
      "Janos Pach",
      "Andrew Suk"
    ],
    "abstract": "We prove a far-reaching strengthening of Szemer\u00e9di's regularity lemma for intersection graphs of pseudo-segments. It shows that the vertex set of such a graph can be partitioned into a bounded number of parts of roughly the same size such that almost all bipartite graphs between different pairs of parts are complete or empty. We use this to get an improved bound on disjoint edges in simple topological graphs, showing that every $n$-vertex simple topological graph with no $k$ pairwise disjoint edges has at most $n(\\log n)^{O(\\log k)}$ edges.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01028"
  },
  "2312.01026": {
    "title": "Token Fusion: Bridging the Gap between Token Pruning and Token Merging",
    "authors": [
      "Minchul Kim",
      "Shangqian Gao",
      "Yen-Chang Hsu",
      "Yilin Shen",
      "Hongxia Jin"
    ],
    "abstract": "Vision Transformers (ViTs) have emerged as powerful backbones in computer vision, outperforming many traditional CNNs. However, their computational overhead, largely attributed to the self-attention mechanism, makes deployment on resource-constrained edge devices challenging. Multiple solutions rely on token pruning or token merging. In this paper, we introduce \"Token Fusion\" (ToFu), a method that amalgamates the benefits of both token pruning and token merging. Token pruning proves advantageous when the model exhibits sensitivity to input interpolations, while token merging is effective when the model manifests close to linear responses to inputs. We combine this to propose a new scheme called Token Fusion. Moreover, we tackle the limitations of average merging, which doesn't preserve the intrinsic feature norm, resulting in distributional shifts. To mitigate this, we introduce MLERP merging, a variant of the SLERP technique, tailored to merge multiple tokens while maintaining the norm distribution. ToFu is versatile, applicable to ViTs with or without additional training. Our empirical evaluations indicate that ToFu establishes new benchmarks in both classification and image generation tasks concerning computational efficiency and model accuracy.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01026"
  },
  "2312.01025": {
    "title": "Adding Domain Knowledge to Query-Driven Learned Databases",
    "authors": [
      "Peizhi Wu",
      "Ryan Marcus",
      "Zachary G. Ives"
    ],
    "abstract": "In recent years, \\emph{learned cardinality estimation} has emerged as an alternative to traditional query optimization methods: by training machine learning models over observed query performance, learned cardinality estimation techniques can accurately predict query cardinalities and costs -- accounting for skew, correlated predicates, and many other factors that traditional methods struggle to capture. However, query-driven learned cardinality estimators are dependent on sample workloads, requiring vast amounts of labeled queries. Further, we show that state-of-the-art query-driven techniques can make significant and unpredictable errors on queries that are outside the distribution of their training set. We show that these out-of-distribution errors can be mitigated by incorporating the \\emph{domain knowledge} used in traditional query optimizers: \\emph{constraints} on values and cardinalities (e.g., based on key-foreign-key relationships, range predicates, and more generally on inclusion and functional dependencies). We develop methods for \\emph{semi-supervised} query-driven learned query optimization, based on constraints, and we experimentally demonstrate that such techniques can increase a learned query optimizer's accuracy in cardinality estimation, reduce the reliance on massive labeled queries, and improve the robustness of query end-to-end performance.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01025"
  },
  "2312.01024": {
    "title": "Hybrid Quantum Neural Network in High-dimensional Data Classification",
    "authors": [
      "Hao-Yuan Chen",
      "Yen-Jui Chang",
      "Shih-Wei Liao",
      "Ching-Ray Chang"
    ],
    "abstract": "The research explores the potential of quantum deep learning models to address challenging machine learning problems that classical deep learning models find difficult to tackle. We introduce a novel model architecture that combines classical convolutional layers with a quantum neural network, aiming to surpass state-of-the-art accuracy while maintaining a compact model size. The experiment is to classify high-dimensional audio data from the Bird-CLEF 2021 dataset. Our evaluation focuses on key metrics, including training duration, model accuracy, and total model size. This research demonstrates the promising potential of quantum machine learning in enhancing machine learning tasks and solving practical machine learning challenges available today.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01024"
  },
  "2312.01022": {
    "title": "Advanced Large Language Model (LLM)-Driven Verilog Development: Enhancing Power, Performance, and Area Optimization in Code Synthesis",
    "authors": [
      "Kiran Thorat",
      "Jiahui Zhao",
      "Yaotian Liu",
      "Hongwu Peng",
      "Xi Xie",
      "Bin Lei",
      "Jeff Zhang",
      "Caiwen Ding"
    ],
    "abstract": "The increasing use of Advanced Language Models (ALMs) in diverse sectors, particularly due to their impressive capability to generate top-tier content following linguistic instructions, forms the core of this investigation. This study probes into ALMs' deployment in electronic hardware design, with a specific emphasis on the synthesis and enhancement of Verilog programming. We introduce an innovative framework, crafted to assess and amplify ALMs' productivity in this niche. The methodology commences with the initial crafting of Verilog programming via ALMs, succeeded by a distinct dual-stage refinement protocol. The premier stage prioritizes augmenting the code's operational and linguistic precision, while the latter stage is dedicated to aligning the code with Power-Performance-Area (PPA) benchmarks, a pivotal component in proficient hardware design. This bifurcated strategy, merging error remediation with PPA enhancement, has yielded substantial upgrades in the caliber of ALM-created Verilog programming. Our framework achieves an 81.37% rate in linguistic accuracy and 62.0% in operational efficacy in programming synthesis, surpassing current leading-edge techniques, such as 73% in linguistic accuracy and 46% in operational efficacy. These findings illuminate ALMs' aptitude in tackling complex technical domains and signal a positive shift in the mechanization of hardware design operations.\n        \u25b3 Less",
    "submission_date": "9 January, 2024",
    "eprint_id": "2312.01022"
  },
  "2312.01021": {
    "title": "Data-Driven Autoencoder Numerical Solver with Uncertainty Quantification for Fast Physical Simulations",
    "authors": [
      "Christophe Bonneville",
      "Youngsoo Choi",
      "Debojyoti Ghosh",
      "Jonathan L. Belof"
    ],
    "abstract": "Traditional partial differential equation (PDE) solvers can be computationally expensive, which motivates the development of faster methods, such as reduced-order-models (ROMs). We present GPLaSDI, a hybrid deep-learning and Bayesian ROM. GPLaSDI trains an autoencoder on full-order-model (FOM) data and simultaneously learns simpler equations governing the latent space. These equations are interpolated with Gaussian Processes, allowing for uncertainty quantification and active learning, even with limited access to the FOM solver. Our framework is able to achieve up to 100,000 times speed-up and less than 7% relative error on fluid mechanics problems.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01021"
  },
  "2312.01020": {
    "title": "ResNLS: An Improved Model for Stock Price Forecasting",
    "authors": [
      "Yuanzhe Jia",
      "Ali Anaissi",
      "Basem Suleiman"
    ],
    "abstract": "Stock prices forecasting has always been a challenging task. Although many research projects adopt machine learning and deep learning algorithms to address the problem, few of them pay attention to the varying degrees of dependencies between stock prices. In this paper we introduce a hybrid model that improves stock price prediction by emphasizing the dependencies between adjacent stock prices. The proposed model, ResNLS, is mainly composed of two neural architectures, ResNet and LSTM. ResNet serves as a feature extractor to identify dependencies between stock prices across time windows, while LSTM analyses the initial time-series data with the combination of dependencies which considered as residuals. In predicting the SSE Composite Index, our experiment reveals that when the closing price data for the previous 5 consecutive trading days is used as the input, the performance of the model (ResNLS-5) is optimal compared to those with other inputs. Furthermore, ResNLS-5 outperforms vanilla CNN, RNN, LSTM, and BiLSTM models in terms of prediction accuracy. It also demonstrates at least a 20% improvement over the current state-of-the-art baselines. To verify whether ResNLS-5 can help clients effectively avoid risks and earn profits in the stock market, we construct a quantitative trading framework for back testing. The experimental results show that the trading strategy based on predictions from ResNLS-5 can successfully mitigate losses during declining stock prices and generate profits in the periods of rising stock prices.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01020"
  },
  "2312.01018": {
    "title": "Decentralized Finance: Protocols, Risks, and Governance",
    "authors": [
      "Agostino Capponi",
      "Garud Iyengar",
      "Jay Sethuraman"
    ],
    "abstract": "Financial markets are undergoing an unprecedented transformation. Technological advances have brought major improvements to the operations of financial services. While these advances promote improved accessibility and convenience, traditional finance shortcomings like lack of transparency and moral hazard frictions continue to plague centralized platforms, imposing societal costs. In this paper, we argue how these shortcomings and frictions are being mitigated by the decentralized finance (DeFi) ecosystem. We delve into the workings of smart contracts, the backbone of DeFi transactions, with an emphasis on those underpinning token exchange and lending services. We highlight the pros and cons of the novel form of decentralized governance introduced via the ownership of governance tokens. Despite its potential, the current DeFi infrastructure introduces operational risks to users, which we segment into five primary categories: consensus mechanisms, protocol, oracle, frontrunning, and systemic risks. We conclude by emphasizing the need for future research to focus on the scalability of existing blockchains, the improved design and interoperability of DeFi protocols, and the rigorous auditing of smart contracts.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01018"
  },
  "2312.01017": {
    "title": "Unveiling the Power of Audio-Visual Early Fusion Transformers with Dense Interactions through Masked Modeling",
    "authors": [
      "Shentong Mo",
      "Pedro Morgado"
    ],
    "abstract": "Humans possess a remarkable ability to integrate auditory and visual information, enabling a deeper understanding of the surrounding environment. This early fusion of audio and visual cues, demonstrated through cognitive psychology and neuroscience research, offers promising potential for developing multimodal perception models. However, training early fusion architectures poses significant challenges, as the increased model expressivity requires robust learning frameworks to harness their enhanced capabilities. In this paper, we address this challenge by leveraging the masked reconstruction framework, previously successful in unimodal settings, to train audio-visual encoders with early fusion. Additionally, we propose an attention-based fusion module that captures interactions between local audio and visual representations, enhancing the model's ability to capture fine-grained interactions. While effective, this procedure can become computationally intractable, as the number of local representations increases. Thus, to address the computational complexity, we propose an alternative procedure that factorizes the local representations before representing audio-visual interactions. Extensive evaluations on a variety of datasets demonstrate the superiority of our approach in audio-event classification, visual sound localization, sound separation, and audio-visual segmentation. These contributions enable the efficient training of deeply integrated audio-visual models and significantly advance the usefulness of early fusion architectures.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01017"
  },
  "2312.01015": {
    "title": "Aggressive Trajectory Tracking for Nano Quadrotors Using Embedded Nonlinear Model Predictive Control",
    "authors": [
      "Muhammad Kazim",
      "Hyunjae Sim",
      "Gihun Shin",
      "Hwancheol Hwang",
      "Kwang-Ki K. Kim"
    ],
    "abstract": "This paper presents an aggressive trajectory tracking method for a small lightweight nano-quadrotor using nonlinear model predictive control (NMPC) based on acados. Controlling a nano quadrotor for accurate trajectory tracking at high speed in dynamic environments is challenging due to complex aerodynamic forces that introduce significant disturbances and large positional tracking errors. These aerodynamic effects are difficult to be identified and require feedback control that compensates for them in real time. NMPC allows the nano-quadrotor to control its motion in real time based on onboard sensor measurements, making it well-suited for tasks such as aggressive maneuvers and navigation in complex and dynamic environments. The software package acados enables the implementation of the NMPC algorithm on embedded systems, which is particularly important for nano-quadrotor due to its limited computational resources. Our autonomous navigation system is developed based on an AI-deck that is a GAP8-based parallel ultra-low power computing platform with onboard sensors of a multi-ranger deck and a flow deck. The proposed method of NMPC-based trajectory tracking control is tested in simulation and the results demonstrate its effectiveness in trajectory tracking while considering the dynamic environments. It is also tested on a real nano quadrotor hardware, 27-g Crazyflie 2.1, with a customized MCU running embedded NMPC, in which accurate trajectory tracking results are achieved in dynamic real-world environments.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01015"
  },
  "2312.01007": {
    "title": "A Hypergraph-Based Approach to Recommend Online Resources in a Library",
    "authors": [
      "Debashish Roy",
      "Rajarshi Roy Chowdhury"
    ],
    "abstract": "When users in a digital library read or browse online resources, it generates an immense amount of data. If the underlying system can recommend items, such as books and journals, to the users, it will help them to find the related items. This research analyzes a digital library's usage data to recommend items to its users, and it uses different clustering algorithms to design the recommender system. We have used content-based clustering, including hierarchical, expectation maximization (EM), K-mean, FarthestFirst, and density-based clustering algorithms, and user access pattern-based clustering, which uses a hypergraph-based approach to generate the clusters. This research shows that the recommender system designed using the hypergraph algorithm generates the most accurate recommendation model compared to those designed using the content-based clustering approaches.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01007"
  },
  "2312.01006": {
    "title": "Dual-Teacher De-biasing Distillation Framework for Multi-domain Fake News Detection",
    "authors": [
      "Jiayang Li",
      "Xuan Feng",
      "Tianlong Gu",
      "Liang Chang"
    ],
    "abstract": "Multi-domain fake news detection aims to identify whether various news from different domains is real or fake and has become urgent and important. However, existing methods are dedicated to improving the overall performance of fake news detection, ignoring the fact that unbalanced data leads to disparate treatment for different domains, i.e., the domain bias problem. To solve this problem, we propose the Dual-Teacher De-biasing Distillation framework (DTDBD) to mitigate bias across different domains. Following the knowledge distillation methods, DTDBD adopts a teacher-student structure, where pre-trained large teachers instruct a student model. In particular, the DTDBD consists of an unbiased teacher and a clean teacher that jointly guide the student model in mitigating domain bias and maintaining performance. For the unbiased teacher, we introduce an adversarial de-biasing distillation loss to instruct the student model in learning unbiased domain knowledge. For the clean teacher, we design domain knowledge distillation loss, which effectively incentivizes the student model to focus on representing domain features while maintaining performance. Moreover, we present a momentum-based dynamic adjustment algorithm to trade off the effects of two teachers. Extensive experiments on Chinese and English datasets show that the proposed method substantially outperforms the state-of-the-art baseline methods in terms of bias metrics while guaranteeing competitive performance.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01006"
  },
  "2312.01005": {
    "title": "Generating Images of the M87* Black Hole Using GANs",
    "authors": [
      "Arya Mohan",
      "Pavlos Protopapas",
      "Keerthi Kunnumkai",
      "Cecilia Garraffo",
      "Lindy Blackburn",
      "Koushik Chatterjee",
      "Sheperd S. Doeleman",
      "Razieh Emami",
      "Christian M. Fromm",
      "Yosuke Mizuno",
      "Angelo Ricarte"
    ],
    "abstract": "In this paper, we introduce a novel data augmentation methodology based on Conditional Progressive Generative Adversarial Networks (CPGAN) to generate diverse black hole (BH) images, accounting for variations in spin and electron temperature prescriptions. These generated images are valuable resources for training deep learning algorithms to accurately estimate black hole parameters from observational data. Our model can generate BH images for any spin value within the range of [-1, 1], given an electron temperature distribution. To validate the effectiveness of our approach, we employ a convolutional neural network to predict the BH spin using both the GRMHD images and the images generated by our proposed model. Our results demonstrate a significant performance improvement when training is conducted with the augmented dataset while testing is performed using GRMHD simulated data, as indicated by the high R2 score. Consequently, we propose that GANs can be employed as cost effective models for black hole image generation and reliably augment training datasets for other parameterization algorithms.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.01005"
  },
  "2312.01003": {
    "title": "Self-Evolving Neural Radiance Fields",
    "authors": [
      "Jaewoo Jung",
      "Jisang Han",
      "Jiwon Kang",
      "Seongchan Kim",
      "Min-Seop Kwak",
      "Seungryong Kim"
    ],
    "abstract": "Recently, neural radiance field (NeRF) has shown remarkable performance in novel view synthesis and 3D reconstruction. However, it still requires abundant high-quality images, limiting its applicability in real-world scenarios. To overcome this limitation, recent works have focused on training NeRF only with sparse viewpoints by giving additional regularizations, often called few-shot NeRF. We observe that due to the under-constrained nature of the task, solely using additional regularization is not enough to prevent the model from overfitting to sparse viewpoints. In this paper, we propose a novel framework, dubbed Self-Evolving Neural Radiance Fields (SE-NeRF), that applies a self-training framework to NeRF to address these problems. We formulate few-shot NeRF into a teacher-student framework to guide the network to learn a more robust representation of the scene by training the student with additional pseudo labels generated from the teacher. By distilling ray-level pseudo labels using distinct distillation schemes for reliable and unreliable rays obtained with our novel reliability estimation method, we enable NeRF to learn a more accurate and robust geometry of the 3D scene. We show and evaluate that applying our self-training framework to existing models improves the quality of the rendered images and achieves state-of-the-art performance in multiple settings.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.01003"
  },
  "2312.00997": {
    "title": "Scaling Whole-Chip QAOA for Higher-Order Ising Spin Glass Models on Heavy-Hex Graphs",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Lukasz Cincio",
      "John Golden",
      "Stephan Eidenbenz"
    ],
    "abstract": "We show through numerical simulation that the Quantum Alternating Operator Ansatz (QAOA) for higher-order, random-coefficient, heavy-hex compatible spin glass Ising models has strong parameter concentration across problem sizes from $16$ up to $127$ qubits for $p=1$ up to $p=5$, which allows for straight-forward transfer learning of QAOA angles on instance sizes where exhaustive grid-search is prohibitive even for $p>1$. We use Matrix Product State (MPS) simulation at different bond dimensions to obtain confidence in these results, and we obtain the optimal solutions to these combinatorial optimization problems using CPLEX. In order to assess the ability of current noisy quantum hardware to exploit such parameter concentration, we execute short-depth QAOA circuits (with a CNOT depth of 6 per $p$, resulting in circuits which contain $1420$ two qubit gates for $127$ qubit $p=5$ QAOA) on $100$ higher-order (cubic term) Ising models on IBM quantum superconducting processors with $16, 27, 127$ qubits using QAOA angles learned from a single $16$-qubit instance. We show that (i) the best quantum processors generally find lower energy solutions up to $p=3$ for 27 qubit systems and up to $p=2$ for 127 qubit systems and are overcome by noise at higher values of $p$, (ii) the best quantum processors find mean energies that are about a factor of two off from the noise-free numerical simulation results. Additional insights from our experiments are that large performance differences exist among different quantum processors even of the same generation and that dynamical decoupling significantly improve performance for some, but decrease performance for other quantum processors. Lastly we show $p=1$ QAOA angle mean energy landscapes computed using up to a $414$ qubit quantum computer, showing that the mean QAOA energy landscapes remain very similar as the problem size changes.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00997"
  },
  "2312.00995": {
    "title": "Second-Order Uncertainty Quantification: A Distance-Based Approach",
    "authors": [
      "Yusuf Sale",
      "Viktor Bengs",
      "Michele Caprio",
      "Eyke H\u00fcllermeier"
    ],
    "abstract": "In the past couple of years, various approaches to representing and quantifying different types of predictive uncertainty in machine learning, notably in the setting of classification, have been proposed on the basis of second-order probability distributions, i.e., predictions in the form of distributions on probability distributions. A completely conclusive solution has not yet been found, however, as shown by recent criticisms of commonly used uncertainty measures associated with second-order distributions, identifying undesirable theoretical properties of these measures. In light of these criticisms, we propose a set of formal criteria that meaningful uncertainty measures for predictive uncertainty based on second-order distributions should obey. Moreover, we provide a general framework for developing uncertainty measures to account for these criteria, and offer an instantiation based on the Wasserstein distance, for which we prove that all criteria are satisfied.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00995"
  },
  "2312.00992": {
    "title": "Improving Normative Modeling for Multi-modal Neuroimaging Data using mixture-of-product-of-experts variational autoencoders",
    "authors": [
      "Sayantan Kumar",
      "Philip Payne",
      "Aristeidis Sotiras"
    ],
    "abstract": "Normative models in neuroimaging learn the brain patterns of healthy population distribution and estimate how disease subjects like Alzheimer's Disease (AD) deviate from the norm. Existing variational autoencoder (VAE)-based normative models using multimodal neuroimaging data aggregate information from multiple modalities by estimating product or averaging of unimodal latent posteriors. This can often lead to uninformative joint latent distributions which affects the estimation of subject-level deviations. In this work, we addressed the prior limitations by adopting the Mixture-of-Product-of-Experts (MoPoE) technique which allows better modelling of the joint latent posterior. Our model labelled subjects as outliers by calculating deviations from the multimodal latent space. Further, we identified which latent dimensions and brain regions were associated with abnormal deviations due to AD pathology.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00992"
  },
  "2312.00991": {
    "title": "Convergences for Minimax Optimization Problems over Infinite-Dimensional Spaces Towards Stability in Adversarial Training",
    "authors": [
      "Takashi Furuya",
      "Satoshi Okuda",
      "Kazuma Suetake",
      "Yoshihide Sawada"
    ],
    "abstract": "Training neural networks that require adversarial optimization, such as generative adversarial networks (GANs) and unsupervised domain adaptations (UDAs), suffers from instability. This instability problem comes from the difficulty of the minimax optimization, and there have been various approaches in GANs and UDAs to overcome this problem. In this study, we tackle this problem theoretically through a functional analysis. Specifically, we show the convergence property of the minimax problem by the gradient descent over the infinite-dimensional spaces of continuous functions and probability measures under certain conditions. Using this setting, we can discuss GANs and UDAs comprehensively, which have been studied independently. In addition, we show that the conditions necessary for the convergence property are interpreted as stabilization techniques of adversarial training such as the spectral normalization and the gradient penalty.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00991"
  },
  "2312.00989": {
    "title": "Scrappy: SeCure Rate Assuring Protocol with PrivacY",
    "authors": [
      "Kosei Akama",
      "Yoshimichi Nakatsuka",
      "Masaaki Sato",
      "Keisuke Uehara"
    ],
    "abstract": "Preventing abusive activities caused by adversaries accessing online services at a rate exceeding that expected by websites has become an ever-increasing problem. CAPTCHAs and SMS authentication are widely used to provide a solution by implementing rate limiting, although they are becoming less effective, and some are considered privacy-invasive. In light of this, many studies have proposed better rate-limiting systems that protect the privacy of legitimate users while blocking malicious actors. However, they suffer from one or more shortcomings: (1) assume trust in the underlying hardware and (2) are vulnerable to side-channel attacks. Motivated by the aforementioned issues, this paper proposes Scrappy: SeCure Rate Assuring Protocol with PrivacY. Scrappy allows clients to generate unforgeable yet unlinkable rate-assuring proofs, which provides the server with cryptographic guarantees that the client is not misbehaving. We design Scrappy using a combination of DAA and hardware security devices. Scrappy is implemented over three types of devices, including one that can immediately be deployed in the real world. Our baseline evaluation shows that the end-to-end latency of Scrappy is minimal, taking only 0.32 seconds, and uses only 679 bytes of bandwidth when transferring necessary data. We also conduct an extensive security evaluation, showing that the rate-limiting capability of Scrappy is unaffected even if the hardware security device is compromised.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00989"
  },
  "2312.00978": {
    "title": "Combining Kernelized Autoencoding and Centroid Prediction for Dynamic Multi-objective Optimization",
    "authors": [
      "Zhanglu Hou",
      "Juan Zou",
      "Gan Ruan",
      "Yuan Liu",
      "Yizhang Xia"
    ],
    "abstract": "Evolutionary algorithms face significant challenges when dealing with dynamic multi-objective optimization because Pareto optimal solutions and/or Pareto optimal fronts change. This paper proposes a unified paradigm, which combines the kernelized autoncoding evolutionary search and the centriod-based prediction (denoted by KAEP), for solving dynamic multi-objective optimization problems (DMOPs). Specifically, whenever a change is detected, KAEP reacts effectively to it by generating two subpopulations. The first subpoulation is generated by a simple centriod-based prediction strategy. For the second initial subpopulation, the kernel autoencoder is derived to predict the moving of the Pareto-optimal solutions based on the historical elite solutions. In this way, an initial population is predicted by the proposed combination strategies with good convergence and diversity, which can be effective for solving DMOPs. The performance of our proposed method is compared with five state-of-the-art algorithms on a number of complex benchmark problems. Empirical results fully demonstrate the superiority of our proposed method on most test instances.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00978"
  },
  "2312.00977": {
    "title": "Optimal Placement of Transmissive RIS in the Near Field for Capacity Maximization in THz Communications",
    "authors": [
      "Nithish Sharvirala",
      "Amine Mezghani",
      "Ekram Hossain"
    ],
    "abstract": "This study centers on Line-of-Sight (LoS) MIMO communication enabled by a Transmissive Reconfigurable Intelligent Surface (RIS) operating in the Terahertz (THz) frequency bands. The study demonstrates that the introduction of RIS can render the curvature of the wavefront apparent over the transmit and receive arrays, even when they are positioned in the far field from each other. This phenomenon contributes to an enhancement in spatial multiplexing. Notably, simulation results underline that the optimal placement of the RIS in the near-field is not solely contingent on proximity to the transmitter (Tx) or receiver (Rx) but relies on the inter-antenna spacing of the Tx and Rx.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00977"
  },
  "2312.00975": {
    "title": "Noisy probing dose facilitated dose prediction for pencil beam scanning proton therapy: physics enhances generalizability",
    "authors": [
      "Lian Zhang",
      "Jason M. Holmes",
      "Zhengliang Liu",
      "Hongying Feng",
      "Terence T. Sio",
      "Carlos E. Vargas",
      "Sameer R. Keole",
      "Kristin St\u00fctzer",
      "Sheng Li",
      "Tianming Liu",
      "Jiajian Shen",
      "William W. Wong",
      "Sujay A. Vora",
      "Wei Liu"
    ],
    "abstract": "Purpose: Prior AI-based dose prediction studies in photon and proton therapy often neglect underlying physics, limiting their generalizability to handle outlier clinical cases, especially for pencil beam scanning proton therapy (PBSPT). Our aim is to design a physics-aware and generalizable AI-based PBSPT dose prediction method that has the underlying physics considered to achieve high generalizability to properly handle the outlier clinical cases. Methods and Materials: This study analyzed PBSPT plans of 103 prostate and 78 lung cancer patients from our institution,with each case comprising CT images, structure sets, and plan doses from our Monte-Carlo dose engine (serving as the ground truth). Three methods were evaluated in the ablation study: the ROI-based method, the beam mask and sliding window method, and the noisy probing dose method. Twelve cases with uncommon beam angles or prescription doses tested the methods' generalizability to rare treatment planning scenarios. Performance evaluation used DVH indices, 3D Gamma passing rates (3%/2mm/10%), and dice coefficients for dose agreement. Results: The noisy probing dose method showed improved agreement of DVH indices, 3D Gamma passing rates, and dice coefficients compared to the conventional methods for the testing cases. The noisy probing dose method showed better generalizability in the 6 outlier cases than the ROI-based and beam mask-based methods with 3D Gamma passing rates (for prostate cancer, targets: 89.32%$\\pm$1.45% vs. 93.48%$\\pm$1.51% vs. 96.79%$\\pm$0.83%, OARs: 85.87%$\\pm$1.73% vs. 91.15%$\\pm$1.13% vs. 94.29%$\\pm$1.01%). The dose predictions were completed within 0.3 seconds. Conclusions: We've devised a novel noisy probing dose method for PBSPT dose prediction in prostate and lung cancer patients. With more physics included, it enhances the generalizability of dose prediction in handling outlier clinical cases.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00975"
  },
  "2312.00971": {
    "title": "Consistent Mesh Diffusion",
    "authors": [
      "Julian Knodt",
      "Xifeng Gao"
    ],
    "abstract": "Given a 3D mesh with a UV parameterization, we introduce a novel approach to generating textures from text prompts. While prior work uses optimization from Text-to-Image Diffusion models to generate textures and geometry, this is slow and requires significant compute resources. Alternatively, there are projection based approaches that use the same Text-to-Image models that paint images onto a mesh, but lack consistency at different viewing angles, we propose a method that uses a single Depth-to-Image diffusion network, and generates a single consistent texture when rendered on the 3D surface by first unifying multiple 2D image's diffusion paths, and hoisting that to 3D with MultiDiffusion~\\cite{multidiffusion}. We demonstrate our approach on a dataset containing 30 meshes, taking approximately 5 minutes per mesh. To evaluate the quality of our approach, we use CLIP-score~\\cite{clipscore} and Frechet Inception Distance (FID)~\\cite{frechet} to evaluate the quality of the rendering, and show our improvement over prior work.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00971"
  },
  "2312.00966": {
    "title": "Spectral Temporal Contrastive Learning",
    "authors": [
      "Sacha Morin",
      "Somjit Nath",
      "Samira Ebrahimi Kahou",
      "Guy Wolf"
    ],
    "abstract": "Learning useful data representations without requiring labels is a cornerstone of modern deep learning. Self-supervised learning methods, particularly contrastive learning (CL), have proven successful by leveraging data augmentations to define positive pairs. This success has prompted a number of theoretical studies to better understand CL and investigate theoretical bounds for downstream linear probing tasks. This work is concerned with the temporal contrastive learning (TCL) setting where the sequential structure of the data is used instead to define positive pairs, which is more commonly used in RL and robotics contexts. In this paper, we adapt recent work on Spectral CL to formulate Spectral Temporal Contrastive Learning (STCL). We discuss a population loss based on a state graph derived from a time-homogeneous reversible Markov chain with uniform stationary distribution. The STCL loss enables to connect the linear probing performance to the spectral properties of the graph, and can be estimated by considering previously observed data sequences as an ensemble of MCMC chains.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00966"
  },
  "2312.00963": {
    "title": "Spatiotemporal Transformer for Imputing Sparse Data: A Deep Learning Approach",
    "authors": [
      "Kehui Yao",
      "Jingyi Huang",
      "Jun Zhu"
    ],
    "abstract": "Effective management of environmental resources and agricultural sustainability heavily depends on accurate soil moisture data. However, datasets like the SMAP/Sentinel-1 soil moisture product often contain missing values across their spatiotemporal grid, which poses a significant challenge. This paper introduces a novel Spatiotemporal Transformer model (ST-Transformer) specifically designed to address the issue of missing values in sparse spatiotemporal datasets, particularly focusing on soil moisture data. The ST-Transformer employs multiple spatiotemporal attention layers to capture the complex spatiotemporal correlations in the data and can integrate additional spatiotemporal covariates during the imputation process, thereby enhancing its accuracy. The model is trained using a self-supervised approach, enabling it to autonomously predict missing values from observed data points. Our model's efficacy is demonstrated through its application to the SMAP 1km soil moisture data over a 36 x 36 km grid in Texas. It showcases superior accuracy compared to well-known imputation methods. Additionally, our simulation studies on other datasets highlight the model's broader applicability in various spatiotemporal imputation tasks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00963"
  },
  "2312.00962": {
    "title": "MBot: A Modular Ecosystem for Scalable Robotics Education",
    "authors": [
      "Peter Gaskell",
      "Jana Pavlasek",
      "Tom Gao",
      "Abhishek Narula",
      "Stanley Lewis",
      "Odest Chadwicke Jenkins"
    ],
    "abstract": "The Michigan Robotics MBot is a low-cost mobile robot platform that has been used to train over 1,400 students in autonomous navigation since 2014 at the University of Michigan and our collaborating colleges. The MBot platform was designed to meet the needs of teaching robotics at scale to match the growth of robotics as a field and an academic discipline. Transformative advancements in robot navigation over the past decades have led to a significant demand for skilled roboticists across industry and academia. This demand has sparked a need for robotics courses in higher education, spanning all levels of undergraduate and graduate experiences. Incorporating real robot platforms into such courses and curricula is effective for conveying the unique challenges of programming embodied agents in real-world environments and sparking student interest. However, teaching with real robots remains challenging due to the cost of hardware and the development effort involved in adapting existing hardware for a new course. In this paper, we describe the design and evolution of the MBot platform, and the underlying principals of scalability and flexibility which are keys to its success.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00962"
  },
  "2312.00961": {
    "title": "Biased Random-Key Genetic Algorithms: A Review",
    "authors": [
      "Mariana A. Londe",
      "Luciana S. Pessoa",
      "Carlos E. Andrade",
      "Mauricio G. C. Resende"
    ],
    "abstract": "This paper is a comprehensive literature review of Biased Random-Key Genetic Algorithms (BRKGA). BRKGA is a metaheuristic that employs random-key-based chromosomes with biased, uniform, and elitist mating strategies in a genetic algorithm framework. The review encompasses over 150 papers with a wide range of applications, including classical combinatorial optimization problems, real-world industrial use cases, and non-orthodox applications such as neural network hyperparameter tuning in machine learning. Scheduling is by far the most prevalent application area in this review, followed by network design and location problems. The most frequent hybridization method employed is local search, and new features aim to increase population diversity. Overall, this survey provides a comprehensive overview of the BRKGA metaheuristic and its applications and highlights important areas for future research.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.00961"
  },
  "2312.00960": {
    "title": "The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models",
    "authors": [
      "Satya Sai Srinath Namburi",
      "Makesh Sreedhar",
      "Srinath Srinivasan",
      "Frederic Sala"
    ],
    "abstract": "Compressing large language models (LLMs), often consisting of billions of parameters, provides faster inference, smaller memory footprints, and enables local deployment. Two standard compression techniques are pruning and quantization, with the former eliminating redundant connections in model layers and the latter representing model parameters with fewer bits. The key tradeoff is between the degree of compression and the impact on the quality of the compressed model. Existing research on LLM compression primarily focuses on performance in terms of general metrics like perplexity or downstream task accuracy. More fine-grained metrics, such as those measuring parametric knowledge, remain significantly underexplored. To help bridge this gap, we present a comprehensive analysis across multiple model families (ENCODER, ENCODER-DECODER, and DECODER) using the LAMA and LM-HARNESS benchmarks in order to systematically quantify the effect of commonly employed compression techniques on model performance. A particular focus is on tradeoffs involving parametric knowledge, with the goal of providing practitioners with practical insights to help make informed decisions on compression. We release our codebase1 to enable further research.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00960"
  },
  "2312.00950": {
    "title": "Improve Supervised Representation Learning with Masked Image Modeling",
    "authors": [
      "Kaifeng Chen",
      "Daniel Salz",
      "Huiwen Chang",
      "Kihyuk Sohn",
      "Dilip Krishnan",
      "Mojtaba Seyedhosseini"
    ],
    "abstract": "Training visual embeddings with labeled data supervision has been the de facto setup for representation learning in computer vision. Inspired by recent success of adopting masked image modeling (MIM) in self-supervised representation learning, we propose a simple yet effective setup that can easily integrate MIM into existing supervised training paradigms. In our design, in addition to the original classification task applied to a vision transformer image encoder, we add a shallow transformer-based decoder on top of the encoder and introduce an MIM task which tries to reconstruct image tokens based on masked image inputs. We show with minimal change in architecture and no overhead in inference that this setup is able to improve the quality of the learned representations for downstream tasks such as classification, image retrieval, and semantic segmentation. We conduct a comprehensive study and evaluation of our setup on public benchmarks. On ImageNet-1k, our ViT-B/14 model achieves 81.72% validation accuracy, 2.01% higher than the baseline model. On K-Nearest-Neighbor image retrieval evaluation with ImageNet-1k, the same model outperforms the baseline by 1.32%. We also show that this setup can be easily scaled to larger models and datasets. Code and checkpoints will be released.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00950"
  },
  "2312.00948": {
    "title": "A Review of Communicating Robot Learning during Human-Robot Interaction",
    "authors": [
      "Soheil Habibian",
      "Antonio Alvarez Valdivia",
      "Laura H. Blumenschein",
      "Dylan P. Losey"
    ],
    "abstract": "For robots to seamlessly interact with humans, we first need to make sure that humans and robots understand one another. Diverse algorithms have been developed to enable robots to learn from humans (i.e., transferring information from humans to robots). In parallel, visual, haptic, and auditory communication interfaces have been designed to convey the robot's internal state to the human (i.e., transferring information from robots to humans). Prior research often separates these two directions of information transfer, and focuses primarily on either learning algorithms or communication interfaces. By contrast, in this review we take an interdisciplinary approach to identify common themes and emerging trends that close the loop between learning and communication. Specifically, we survey state-of-the-art methods and outcomes for communicating a robot's learning back to the human teacher during human-robot interaction. This discussion connects human-in-the-loop learning methods and explainable robot learning with multi-modal feedback systems and measures of human-robot interaction. We find that -- when learning and communication are developed together -- the resulting closed-loop system can lead to improved human teaching, increased human trust, and human-robot co-adaptation. The paper includes a perspective on several of the interdisciplinary research themes and open questions that could advance how future robots communicate their learning to everyday operators. Finally, we implement a selection of the reviewed methods in a case study where participants kinesthetically teach a robot arm. This case study documents and tests an integrated approach for learning in ways that can be communicated, conveying this learning across multi-modal interfaces, and measuring the resulting changes in human and robot behavior. See videos of our case study here: https://youtu.be/EXfQctqFzWs\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00948"
  },
  "2312.00944": {
    "title": "Enhancing Diffusion Models with 3D Perspective Geometry Constraints",
    "authors": [
      "Rishi Upadhyay",
      "Howard Zhang",
      "Yunhao Ba",
      "Ethan Yang",
      "Blake Gella",
      "Sicheng Jiang",
      "Alex Wong",
      "Achuta Kadambi"
    ],
    "abstract": "While perspective is a well-studied topic in art, it is generally taken for granted in images. However, for the recent wave of high-quality image synthesis methods such as latent diffusion models, perspective accuracy is not an explicit requirement. Since these methods are capable of outputting a wide gamut of possible images, it is difficult for these synthesized images to adhere to the principles of linear perspective. We introduce a novel geometric constraint in the training process of generative models to enforce perspective accuracy. We show that outputs of models trained with this constraint both appear more realistic and improve performance of downstream models trained on generated images. Subjective human trials show that images generated with latent diffusion models trained with our constraint are preferred over images from the Stable Diffusion V2 model 70% of the time. SOTA monocular depth estimation models such as DPT and PixelFormer, fine-tuned on our images, outperform the original models trained on real images by up to 7.03% in RMSE and 19.3% in SqRel on the KITTI test set for zero-shot transfer.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00944"
  },
  "2312.00942": {
    "title": "Survey of Security Issues in Memristor-based Machine Learning Accelerators for RF Analysis",
    "authors": [
      "William Lillis",
      "Max Cohen Hoffing",
      "Wayne Burleson"
    ],
    "abstract": "We explore security aspects of a new computing paradigm that combines novel memristors and traditional Complimentary Metal Oxide Semiconductor (CMOS) to construct a highly efficient analog and/or digital fabric that is especially well-suited to Machine Learning (ML) inference processors for Radio Frequency (RF) signals. Memristors have different properties than traditional CMOS which can potentially be exploited by attackers. In addition, the mixed signal approximate computing model has different vulnerabilities than traditional digital implementations. However both the memristor and the ML computation can be leveraged to create security mechanisms and countermeasures ranging from lightweight cryptography, identifiers (e.g. Physically Unclonable Functions (PUFs), fingerprints, and watermarks), entropy sources, hardware obfuscation and leakage/attack detection methods. Three different threat models are proposed: 1) Supply Chain, 2) Physical Attacks, and 3) Remote Attacks. For each threat model, potential vulnerabilities and defenses are identified. This survey reviews a variety of recent work from the hardware and ML security literature and proposes open problems for both attack and defense. The survey emphasizes the growing area of RF signal analysis and identification in terms of the commercial space, as well as military applications and threat models. We differ from other other recent surveys that target ML in general, neglecting RF applications.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00942"
  },
  "2312.00937": {
    "title": "Zero-Shot Video Question Answering with Procedural Programs",
    "authors": [
      "Rohan Choudhury",
      "Koichiro Niinuma",
      "Kris M. Kitani",
      "L\u00e1szl\u00f3 A. Jeni"
    ],
    "abstract": "We propose to answer zero-shot questions about videos by generating short procedural programs that derive a final answer from solving a sequence of visual subtasks. We present Procedural Video Querying (ProViQ), which uses a large language model to generate such programs from an input question and an API of visual modules in the prompt, then executes them to obtain the output. Recent similar procedural approaches have proven successful for image question answering, but videos remain challenging: we provide ProViQ with modules intended for video understanding, allowing it to generalize to a wide variety of videos. This code generation framework additionally enables ProViQ to perform other video tasks in addition to question answering, such as multi-object tracking or basic video editing. ProViQ achieves state-of-the-art results on a diverse range of benchmarks, with improvements of up to 25% on short, long, open-ended, and multimodal video question-answering datasets. Our project page is at https://rccchoudhury.github.io/proviq2023.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00937"
  },
  "2312.00934": {
    "title": "SimPLoID: Harnessing probabilistic logic programming for infectious disease epidemiology",
    "authors": [
      "Felix Weitk\u00e4mper",
      "Ameen Almiftah",
      "Kailin Sun"
    ],
    "abstract": "High quality epidemiological modelling is essential in order to combat the spread of infectious diseases. In this contribution, we present SimPLoID, an epidemiological modelling framework based on the probabilistic logic programming language ProbLog. SimPLoiI combines concepts from compartmental modelling, such as the classic Susceptible-Infected-Recovered (SIR) model, with network-based modelling. As a proof of concept, SimPLoID showcases the potential of declarative probabilistic logic programming for a natural, flexible and compact expression of infectious disease dynamics. In particular, its modularity makes it easily extendable in the face of changing requirements. This application area benefits especially from the precisely specified semantics of the ProbLog language and from the well-maintained engines, which support a variety of query types from exact inference to Monte Carlo simulation. We also provide a domain-specific language designed for researchers not trained in programming, which is compiled to ProbLog clauses within an interactive Python application.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00934"
  },
  "2312.00933": {
    "title": "Privacy Preserving Event Detection",
    "authors": [
      "Xiaoshan Wang",
      "Tan F. Wong"
    ],
    "abstract": "This paper presents a privacy-preserving event detection scheme based on measurements made by a network of sensors. A diameter-like decision statistic made up of the marginal types of the measurements observed by the sensors is employed. The proposed detection scheme can achieve the best type-I error exponent as the type-II error rate is required to be negligible. Detection performance with finite-length observations is also demonstrated through a simulation example of spectrum sensing. Privacy protection is achieved by obfuscating the type data with random zero-modulo-sum numbers that are generated and distributed via the exchange of encrypted messages among the sensors. The privacy-preserving performance against ``honest but curious'' adversaries, including colluding sensors, the fusion center, and external eavesdroppers, is analyzed through a series of cryptographic games. It is shown that the probability that any probabilistic polynomial time adversary successfully estimates the sensors' measured types can not be much better than independent guessing, when there are at least two non-colluding sensors.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00933"
  },
  "2312.00928": {
    "title": "The Hat Guessing Number of Cactus Graphs and Cycles",
    "authors": [
      "Jeremy Chizewer",
      "I. M. J. McInnis",
      "Mehrdad Sohrabi",
      "Shriya Kaistha"
    ],
    "abstract": "We study the hat guessing game on graphs. In this game, a player is placed on each vertex $v$ of a graph $G$ and assigned a colored hat from $h(v)$ possible colors. Each player makes a deterministic guess on their hat color based on the colors assigned to the players on neighboring vertices, and the players win if at least one player correctly guesses his assigned color. If there exists a strategy that ensures at least one player guesses correctly for every possible assignment of colors, the game defined by $\\langle G,h\\rangle$ is called winning. The hat guessing number of $G$ is the largest integer $q$ so that if $h(v)=q$ for all $v\\in G$ then $\\langle G,h\\rangle$ is winning.\n  In this note, we determine whether $\\langle G,h\\rangle $ is winning for any $h$ whenever $G$ is a cycle, resolving a conjecture of Kokhas and Latyshev in the affirmative and extending it. We then use this result to determine the hat guessing number of every cactus graph, graphs in which every pair of cycles share at most one vertex.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00928"
  },
  "2312.00921": {
    "title": "Bitstream Organization for Parallel Entropy Coding on Neural Network-based Video Codecs",
    "authors": [
      "Amir Said",
      "Hoang Le",
      "Farzad Farhadzadeh"
    ],
    "abstract": "Video compression systems must support increasing bandwidth and data throughput at low cost and power, and can be limited by entropy coding bottlenecks. Efficiency can be greatly improved by parallelizing coding, which can be done at much larger scales with new neural-based codecs, but with some compression loss related to data organization. We analyze the bit rate overhead needed to support multiple bitstreams for concurrent decoding, and for its minimization propose a method for compressing parallel-decoding entry points, using bidirectional bitstream packing, and a new form of jointly optimizing arithmetic coding termination. It is shown that those techniques significantly lower the overhead, making it easier to reduce it to a small fraction of the average bitstream size, like, for example, less than 1% and 0.1% when the average number of bitstream bytes is respectively larger than 95 and 1,200 bytes.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00921"
  },
  "2312.00918": {
    "title": "PACE: A Program Analysis Framework for Continuous Performance Prediction",
    "authors": [
      "Chidera Biringa",
      "Gokhan Kul"
    ],
    "abstract": "Software development teams establish elaborate continuous integration pipelines containing automated test cases to accelerate the development process of software. Automated tests help to verify the correctness of code modifications decreasing the response time to changing requirements. However, when the software teams do not track the performance impact of pending modifications, they may need to spend considerable time refactoring existing code. This paper presents PACE, a program analysis framework that provides continuous feedback on the performance impact of pending code updates. We design performance microbenchmarks by mapping the execution time of functional test cases given a code update. We map microbenchmarks to code stylometry features and feed them to predictors for performance predictions. Our experiments achieved significant performance in predicting code performance, outperforming current state-of-the-art by 75% on neural-represented code stylometry features.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00918"
  },
  "2312.00914": {
    "title": "Optimizing Information Freshness over a Channel that Wears Out",
    "authors": [
      "George J. Stamatakis",
      "Osvaldo Simeone",
      "Nikolaos Pappas"
    ],
    "abstract": "A sensor samples and transmits status updates to a destination through a wireless channel that wears out over time and with every use. At each time slot, the sensor can decide to sample and transmit a fresh status update, restore the initial quality of the channel, or remain silent. The actions impose different costs on the operation of the system, and we study the problem of optimally selecting the actions at the transmitter so as to maximize the freshness of the information at the receiver, while minimizing the communication cost. Freshness is measured by the age of information (AoI). The problem is addressed using dynamic programming, and numerical results are presented to provide insights into the optimal transmission policy.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00914"
  },
  "2312.00912": {
    "title": "Quick Back-Translation for Unsupervised Machine Translation",
    "authors": [
      "Benjamin Brimacombe",
      "Jiawei Zhou"
    ],
    "abstract": "The field of unsupervised machine translation has seen significant advancement from the marriage of the Transformer and the back-translation algorithm. The Transformer is a powerful generative model, and back-translation leverages Transformer's high-quality translations for iterative self-improvement. However, the Transformer is encumbered by the run-time of autoregressive inference during back-translation, and back-translation is limited by a lack of synthetic data efficiency. We propose a two-for-one improvement to Transformer back-translation: Quick Back-Translation (QBT). QBT re-purposes the encoder as a generative model, and uses encoder-generated sequences to train the decoder in conjunction with the original autoregressive back-translation step, improving data throughput and utilization. Experiments on various WMT benchmarks demonstrate that a relatively small number of refining steps of QBT improve current unsupervised machine translation models, and that QBT dramatically outperforms standard back-translation only method in terms of training efficiency for comparable translation qualities.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00912"
  },
  "2312.00909": {
    "title": "LLM-TAKE: Theme Aware Keyword Extraction Using Large Language Models",
    "authors": [
      "Reza Yousefi Maragheh",
      "Chenhao Fang",
      "Charan Chand Irugu",
      "Parth Parikh",
      "Jason Cho",
      "Jianpeng Xu",
      "Saranyan Sukumar",
      "Malay Patel",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "abstract": "Keyword extraction is one of the core tasks in natural language processing. Classic extraction models are notorious for having a short attention span which make it hard for them to conclude relational connections among the words and sentences that are far from each other. This, in turn, makes their usage prohibitive for generating keywords that are inferred from the context of the whole text. In this paper, we explore using Large Language Models (LLMs) in generating keywords for items that are inferred from the items textual metadata. Our modeling framework includes several stages to fine grain the results by avoiding outputting keywords that are non informative or sensitive and reduce hallucinations common in LLM. We call our LLM-based framework Theme-Aware Keyword Extraction (LLM TAKE). We propose two variations of framework for generating extractive and abstractive themes for products in an E commerce setting. We perform an extensive set of experiments on three real data sets and show that our modeling framework can enhance accuracy based and diversity based metrics when compared with benchmark models.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00909"
  },
  "2312.00907": {
    "title": "Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence",
    "authors": [
      "Rambod Mojgani",
      "Daniel Waelchli",
      "Yifei Guan",
      "Petros Koumoutsakos",
      "Pedram Hassanzadeh"
    ],
    "abstract": "Global climate models (GCMs) are the main tools for understanding and predicting climate change. However, due to limited numerical resolutions, these models suffer from major structural uncertainties; e.g., they cannot resolve critical processes such as small-scale eddies in atmospheric and oceanic turbulence. Thus, such small-scale processes have to be represented as a function of the resolved scales via closures (parametrization). The accuracy of these closures is particularly important for capturing climate extremes. Traditionally, such closures are based on heuristics and simplifying assumptions about the unresolved physics. Recently, supervised-learned closures, trained offline on high-fidelity data, have been shown to outperform the classical physics-based closures. However, this approach requires a significant amount of high-fidelity training data and can also lead to instabilities. Reinforcement learning is emerging as a potent alternative for developing such closures as it requires only low-order statistics and leads to stable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL) computational elements serve a dual role of discretization points and learning agents. We leverage SMARL and fundamentals of turbulence physics to learn closures for prototypes of atmospheric and oceanic turbulence. The policy is trained using only the enstrophy spectrum, which is nearly invariant and can be estimated from a few high-fidelity samples (these few samples are far from enough for supervised/offline learning). We show that these closures lead to stable low-resolution simulations that, at a fraction of the cost, can reproduce the high-fidelity simulations' statistics, including the tails of the probability density functions. The results demonstrate the high potential of SMARL for closure modeling for GCMs, especially in the regime of scarce data and indirect observations.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00907"
  },
  "2312.00902": {
    "title": "Lennard Jones Token: a blockchain solution to scientific data curation",
    "authors": [
      "Brian H. Lee",
      "Alejandro Strachan"
    ],
    "abstract": "Data science and artificial intelligence have become an indispensable part of scientific research. While such methods rely on high-quality and large quantities of machine-readable scientific data, the current scientific data infrastructure faces significant challenges that limit effective data curation and sharing. These challenges include insufficient return on investment for researchers to share quality data, logistical difficulties in maintaining long-term data repositories, and the absence of standardized methods for evaluating the relative importance of various datasets. To address these issues, this paper presents the Lennard Jones Token, a blockchain-based proof-of-concept solution implemented on the Ethereum network. The token system incentivizes users to submit optimized structures of Lennard Jones particles by offering token rewards, while also charging for access to these valuable structures. Utilizing smart contracts, the system automates the evaluation of submitted data, ensuring that only structures with energies lower than those in the existing database for a given cluster size are rewarded. The paper explores the details of the Lennard Jones Token as a proof of concept and proposes future blockchain-based tokens aimed at enhancing the curation and sharing of scientific data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00902"
  },
  "2312.00885": {
    "title": "Divisible minimal codes",
    "authors": [
      "Sascha Kurz"
    ],
    "abstract": "Minimal codes are linear codes where all non-zero codewords are minimal, i.e., whose support is not properly contained in the support of another codeword. The minimum possible length of such a $k$-dimensional linear code over $\\mathbb{F}_q$ is denoted by $m(k,q)$. Here we determine $m(7,2)$, $m(8,2)$, and $m(9,2)$, as well as full classifications of all codes attaining $m(k,2)$ for $k\\le 7$ and those attaining $m(9,2)$. For $m(11,2)$ and $m(12,2)$ we give improved upper bounds. It turns out that in many cases attaining extremal codes have the property that the weights of all codewords are divisible by some constant $\u0394>1$. So, here we study the minimum lengths of minimal codes where we additionally assume that the weights of the codewords are divisible by $\u0394$.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00885"
  },
  "2312.00878": {
    "title": "Grounding Everything: Emerging Localization Properties in Vision-Language Transformers",
    "authors": [
      "Walid Bousselham",
      "Felix Petersen",
      "Vittorio Ferrari",
      "Hilde Kuehne"
    ],
    "abstract": "Vision-language foundation models have shown remarkable performance in various zero-shot settings such as image retrieval, classification, or captioning. But so far, those models seem to fall behind when it comes to zero-shot localization of referential expressions and objects in images. As a result, they need to be fine-tuned for this task. In this paper, we show that pretrained vision-language (VL) models allow for zero-shot open-vocabulary object localization without any fine-tuning. To leverage those capabilities, we propose a Grounding Everything Module (GEM) that generalizes the idea of value-value attention introduced by CLIPSurgery to a self-self attention path. We show that the concept of self-self attention corresponds to clustering, thus enforcing groups of tokens arising from the same object to be similar while preserving the alignment with the language space. To further guide the group formation, we propose a set of regularizations that allows the model to finally generalize across datasets and backbones. We evaluate the proposed GEM framework on various benchmark tasks and datasets for semantic segmentation. It shows that GEM not only outperforms other training-free open-vocabulary localization methods, but also achieves state-of-the-art results on the recently proposed OpenImagesV7 large-scale segmentation benchmark.\n        \u25b3 Less",
    "submission_date": "14 December, 2023",
    "eprint_id": "2312.00878"
  },
  "2312.00874": {
    "title": "Hi-ArG: Exploring the Integration of Hierarchical Argumentation Graphs in Language Pretraining",
    "authors": [
      "Jingcong Liang",
      "Rong Ye",
      "Meng Han",
      "Qi Zhang",
      "Ruofei Lai",
      "Xinyu Zhang",
      "Zhao Cao",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "abstract": "The knowledge graph is a structure to store and represent knowledge, and recent studies have discussed its capability to assist language models for various applications. Some variations of knowledge graphs aim to record arguments and their relations for computational argumentation tasks. However, many must simplify semantic types to fit specific schemas, thus losing flexibility and expression ability. In this paper, we propose the Hierarchical Argumentation Graph (Hi-ArG), a new structure to organize arguments. We also introduce two approaches to exploit Hi-ArG, including a text-graph multi-modal model GreaseArG and a new pre-training framework augmented with graph information. Experiments on two argumentation tasks have shown that after further pre-training and fine-tuning, GreaseArG supersedes same-scale language models on these tasks, while incorporating graph information during further pre-training can also improve the performance of vanilla language models. Code for this paper is available at https://github.com/ljcleo/Hi-ArG .\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00874"
  },
  "2312.00870": {
    "title": "3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing",
    "authors": [
      "Balamurugan Thambiraja",
      "Sadegh Aliakbarian",
      "Darren Cosker",
      "Justus Thies"
    ],
    "abstract": "We present 3DiFACE, a novel method for personalized speech-driven 3D facial animation and editing. While existing methods deterministically predict facial animations from speech, they overlook the inherent one-to-many relationship between speech and facial expressions, i.e., there are multiple reasonable facial expression animations matching an audio input. It is especially important in content creation to be able to modify generated motion or to specify keyframes. To enable stochasticity as well as motion editing, we propose a lightweight audio-conditioned diffusion model for 3D facial motion. This diffusion model can be trained on a small 3D motion dataset, maintaining expressive lip motion output. In addition, it can be finetuned for specific subjects, requiring only a short video of the person. Through quantitative and qualitative evaluations, we show that our method outperforms existing state-of-the-art techniques and yields speech-driven animations with greater fidelity and diversity.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00870"
  },
  "2312.00863": {
    "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything",
    "authors": [
      "Yunyang Xiong",
      "Bala Varadarajan",
      "Lemeng Wu",
      "Xiaoyu Xiang",
      "Fanyi Xiao",
      "Chenchen Zhu",
      "Xiaoliang Dai",
      "Dilin Wang",
      "Fei Sun",
      "Forrest Iandola",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra"
    ],
    "abstract": "Segment Anything Model (SAM) has emerged as a powerful tool for numerous vision applications. A key component that drives the impressive performance for zero-shot transfer and high versatility is a super large Transformer model trained on the extensive high-quality SA-1B dataset. While beneficial, the huge computation cost of SAM model has limited its applications to wider real-world applications. To address this limitation, we propose EfficientSAMs, light-weight SAM models that exhibits decent performance with largely reduced complexity. Our idea is based on leveraging masked image pretraining, SAMI, which learns to reconstruct features from SAM image encoder for effective visual representation learning. Further, we take SAMI-pretrained light-weight image encoders and mask decoder to build EfficientSAMs, and finetune the models on SA-1B for segment anything task. We perform evaluations on multiple vision tasks including image classification, object detection, instance segmentation, and semantic object detection, and find that our proposed pretraining method, SAMI, consistently outperforms other masked image pretraining methods. On segment anything task such as zero-shot instance segmentation, our EfficientSAMs with SAMI-pretrained lightweight image encoders perform favorably with a significant gain (e.g., ~4 AP on COCO/LVIS) over other fast SAM models.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00863"
  },
  "2312.00859": {
    "title": "Random Walks Performed by Topologically-Specific Agents on Complex Networks",
    "authors": [
      "Alexandre Benatti",
      "Luciano da F. Costa"
    ],
    "abstract": "Random walks by single-node agents have been systematically conducted on various types of complex networks in order to investigate how their topologies can affect the dynamics of the agents. However, by fitting any network node, these agents do not engage in topological interactions with the network. In the present work, we describe random walks on complex networks performed by agents that are actually small graphs. These agents can only occupy admissible portions of the network onto which they fit topologically, hence their name being taken as topologically-specific agents. These agents are also allowed to move to adjacent subgraphs in the network, which have each node adjacent to the original respective node of the agent. Two types of random walks are considered here: uniformly random and influenced by an external field. The performance of the random walks performed by three types of topologically-specific agents is studied respectively to the obtained coverage considering three types of complex networks (geometrical, Erd\u0151s-R\u00e9nyi, and Barab\u00e1si-Albert). The number of nodes displaced at each random walk step is also obtained and analyzed. Several interesting results are reported and discussed, including the fact that, despite its intrinsic node degree heterogeneity, Barab\u00e1si-Albert networks tend to allow relatively smooth and effective coverage by all the considered topologically-specific agents. Erd\u0151s-R\u00e9nyi networks were also found to yield large dispersions of node coverage. In addition, the triangle agent was found to allow more effective random walks respectively to any of the three considered networks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00859"
  },
  "2312.00858": {
    "title": "DeepCache: Accelerating Diffusion Models for Free",
    "authors": [
      "Xinyin Ma",
      "Gongfan Fang",
      "Xinchao Wang"
    ],
    "abstract": "Diffusion models have recently gained unprecedented attention in the field of image synthesis due to their remarkable generative capabilities. Notwithstanding their prowess, these models often incur substantial computational costs, primarily attributed to the sequential denoising process and cumbersome model size. Traditional methods for compressing diffusion models typically involve extensive retraining, presenting cost and feasibility challenges. In this paper, we introduce DeepCache, a novel training-free paradigm that accelerates diffusion models from the perspective of model architecture. DeepCache capitalizes on the inherent temporal redundancy observed in the sequential denoising steps of diffusion models, which caches and retrieves features across adjacent denoising stages, thereby curtailing redundant computations. Utilizing the property of the U-Net, we reuse the high-level features while updating the low-level features in a very cheap way. This innovative strategy, in turn, enables a speedup factor of 2.3$\\times$ for Stable Diffusion v1.5 with only a 0.05 decline in CLIP Score, and 4.1$\\times$ for LDM-4-G with a slight decrease of 0.22 in FID on ImageNet. Our experiments also demonstrate DeepCache's superiority over existing pruning and distillation methods that necessitate retraining and its compatibility with current sampling techniques. Furthermore, we find that under the same throughput, DeepCache effectively achieves comparable or even marginally improved results with DDIM or PLMS. The code is available at https://github.com/horseee/DeepCache\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00858"
  },
  "2312.00857": {
    "title": "Latent Space Explorer: Visual Analytics for Multimodal Latent Space Exploration",
    "authors": [
      "Bum Chul Kwon",
      "Samuel Friedman",
      "Kai Xu",
      "Steven A Lubitz",
      "Anthony Philippakis",
      "Puneet Batra",
      "Patrick T Ellinor",
      "Kenney Ng"
    ],
    "abstract": "Machine learning models built on training data with multiple modalities can reveal new insights that are not accessible through unimodal datasets. For example, cardiac magnetic resonance images (MRIs) and electrocardiograms (ECGs) are both known to capture useful information about subjects' cardiovascular health status. A multimodal machine learning model trained from large datasets can potentially predict the onset of heart-related diseases and provide novel medical insights about the cardiovascular system. Despite the potential benefits, it is difficult for medical experts to explore multimodal representation models without visual aids and to test the predictive performance of the models on various subpopulations. To address the challenges, we developed a visual analytics system called Latent Space Explorer. Latent Space Explorer provides interactive visualizations that enable users to explore the multimodal representation of subjects, define subgroups of interest, interactively decode data with different modalities with the selected subjects, and inspect the accuracy of the embedding in downstream prediction tasks. A user study was conducted with medical experts and their feedback provided useful insights into how Latent Space Explorer can help their analysis and possible new direction for further development in the medical domain.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00857"
  },
  "2312.00856": {
    "title": "QAFE-Net: Quality Assessment of Facial Expressions with Landmark Heatmaps",
    "authors": [
      "Shuchao Duan",
      "Amirhossein Dadashzadeh",
      "Alan Whone",
      "Majid Mirmehdi"
    ],
    "abstract": "Facial expression recognition (FER) methods have made great inroads in categorising moods and feelings in humans. Beyond FER, pain estimation methods assess levels of intensity in pain expressions, however assessing the quality of all facial expressions is of critical value in health-related applications. In this work, we address the quality of five different facial expressions in patients affected by Parkinson's disease. We propose a novel landmark-guided approach, QAFE-Net, that combines temporal landmark heatmaps with RGB data to capture small facial muscle movements that are encoded and mapped to severity scores. The proposed approach is evaluated on a new Parkinson's Disease Facial Expression dataset (PFED5), as well as on the pain estimation benchmark, the UNBC-McMaster Shoulder Pain Expression Archive Database. Our comparative experiments demonstrate that the proposed method outperforms SOTA action quality assessment works on PFED5 and achieves lower mean absolute error than the SOTA pain estimation methods on UNBC-McMaster. Our code and the new PFED5 dataset are available at https://github.com/shuchaoduan/QAFE-Net.\n        \u25b3 Less",
    "submission_date": "12 December, 2023",
    "eprint_id": "2312.00856"
  },
  "2312.00854": {
    "title": "A Probabilistic Neural Twin for Treatment Planning in Peripheral Pulmonary Artery Stenosis",
    "authors": [
      "John D. Lee",
      "Jakob Richter",
      "Martin R. Pfaller",
      "Jason M. Szafron",
      "Karthik Menon",
      "Andrea Zanoni",
      "Michael R. Ma",
      "Jeffrey A. Feinstein",
      "Jacqueline Kreutzer",
      "Alison L. Marsden",
      "Daniele E. Schiavazzi"
    ],
    "abstract": "The substantial computational cost of high-fidelity models in numerical hemodynamics has, so far, relegated their use mainly to offline treatment planning. New breakthroughs in data-driven architectures and optimization techniques for fast surrogate modeling provide an exciting opportunity to overcome these limitations, enabling the use of such technology for time-critical decisions. We discuss an application to the repair of multiple stenosis in peripheral pulmonary artery disease through either transcatheter pulmonary artery rehabilitation or surgery, where it is of interest to achieve desired pressures and flows at specific locations in the pulmonary artery tree, while minimizing the risk for the patient. Since different degrees of success can be achieved in practice during treatment, we formulate the problem in probability, and solve it through a sample-based approach. We propose a new offline-online pipeline for probabilsitic real-time treatment planning which combines offline assimilation of boundary conditions, model reduction, and training dataset generation with online estimation of marginal probabilities, possibly conditioned on the degree of augmentation observed in already repaired lesions. Moreover, we propose a new approach for the parametrization of arbitrarily shaped vascular repairs through iterative corrections of a zero-dimensional approximant. We demonstrate this pipeline for a diseased model of the pulmonary artery tree available through the Vascular Model Repository.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00854"
  },
  "2312.00852": {
    "title": "Beyond First-Order Tweedie: Solving Inverse Problems using Latent Diffusion",
    "authors": [
      "Litu Rout",
      "Yujia Chen",
      "Abhishek Kumar",
      "Constantine Caramanis",
      "Sanjay Shakkottai",
      "Wen-Sheng Chu"
    ],
    "abstract": "Sampling from the posterior distribution poses a major computational challenge in solving inverse problems using latent diffusion models. Common methods rely on Tweedie's first-order moments, which are known to induce a quality-limiting bias. Existing second-order approximations are impractical due to prohibitive computational costs, making standard reverse diffusion processes intractable for posterior sampling. This paper introduces Second-order Tweedie sampler from Surrogate Loss (STSL), a novel sampler that offers efficiency comparable to first-order Tweedie with a tractable reverse process using second-order approximation. Our theoretical results reveal that the second-order approximation is lower bounded by our surrogate loss that only requires $O(1)$ compute using the trace of the Hessian, and by the lower bound we derive a new drift term to make the reverse process tractable. Our method surpasses SoTA solvers PSLD and P2L, achieving 4X and 8X reduction in neural function evaluations, respectively, while notably enhancing sampling quality on FFHQ, ImageNet, and COCO benchmarks. In addition, we show STSL extends to text-guided image editing and addresses residual distortions present from corrupted images in leading text-guided image editing methods. To our best knowledge, this is the first work to offer an efficient second-order approximation in solving inverse problems using latent diffusion and editing real-world images with corruptions.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00852"
  },
  "2312.00846": {
    "title": "NeuSG: Neural Implicit Surface Reconstruction with 3D Gaussian Splatting Guidance",
    "authors": [
      "Hanlin Chen",
      "Chen Li",
      "Gim Hee Lee"
    ],
    "abstract": "Existing neural implicit surface reconstruction methods have achieved impressive performance in multi-view 3D reconstruction by leveraging explicit geometry priors such as depth maps or point clouds as regularization. However, the reconstruction results still lack fine details because of the over-smoothed depth map or sparse point cloud. In this work, we propose a neural implicit surface reconstruction pipeline with guidance from 3D Gaussian Splatting to recover highly detailed surfaces. The advantage of 3D Gaussian Splatting is that it can generate dense point clouds with detailed structure. Nonetheless, a naive adoption of 3D Gaussian Splatting can fail since the generated points are the centers of 3D Gaussians that do not necessarily lie on the surface. We thus introduce a scale regularizer to pull the centers close to the surface by enforcing the 3D Gaussians to be extremely thin. Moreover, we propose to refine the point cloud from 3D Gaussians Splatting with the normal priors from the surface predicted by neural implicit models instead of using a fixed set of points as guidance. Consequently, the quality of surface reconstruction improves from the guidance of the more accurate 3D Gaussian splatting. By jointly optimizing the 3D Gaussian Splatting and the neural implicit model, our approach benefits from both representations and generates complete surfaces with intricate details. Experiments on Tanks and Temples verify the effectiveness of our proposed method.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00846"
  },
  "2312.00845": {
    "title": "VMC: Video Motion Customization using Temporal Attention Adaption for Text-to-Video Diffusion Models",
    "authors": [
      "Hyeonho Jeong",
      "Geon Yeong Park",
      "Jong Chul Ye"
    ],
    "abstract": "Text-to-video diffusion models have advanced video generation significantly. However, customizing these models to generate videos with tailored motions presents a substantial challenge. In specific, they encounter hurdles in (a) accurately reproducing motion from a target video, and (b) creating diverse visual variations. For example, straightforward extensions of static image customization methods to video often lead to intricate entanglements of appearance and motion data. To tackle this, here we present the Video Motion Customization (VMC) framework, a novel one-shot tuning approach crafted to adapt temporal attention layers within video diffusion models. Our approach introduces a novel motion distillation objective using residual vectors between consecutive frames as a motion reference. The diffusion process then preserves low-frequency motion trajectories while mitigating high-frequency motion-unrelated noise in image space. We validate our method against state-of-the-art video generative models across diverse real-world motions and contexts. Our codes, data and the project demo can be found at https://video-motion-customization.github.io\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00845"
  },
  "2312.00843": {
    "title": "Exploring the Robustness of Decentralized Training for Large Language Models",
    "authors": [
      "Lin Lu",
      "Chenxi Dai",
      "Wangcheng Tao",
      "Binhang Yuan",
      "Yanan Sun",
      "Pan Zhou"
    ],
    "abstract": "Decentralized training of large language models has emerged as an effective way to democratize this technology. However, the potential threats associated with this approach have not been carefully discussed, which would hinder the development of decentralized training infrastructures. This paper aims to initiate discussion towards this end by exploring the robustness of decentralized training from three main perspectives. First, we demonstrate the vulnerabilities inherent in decentralized training frameworks in terms of hardware, data, and models. Second, we highlight the fundamental difference between decentralized foundation model training and vanilla federated learning, where the security techniques employed in federated learning cannot be applied directly. Third, we discuss the essential components required for a robust and efficient decentralized training framework and present a case study by modeling a concrete threat model. Our objective in this vision paper is to emphasize the importance of addressing security concerns in the context of decentralized training for large language models.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00843"
  },
  "2312.00842": {
    "title": "ESM-NBR: fast and accurate nucleic acid-binding residue prediction via protein language model feature representation and multi-task learning",
    "authors": [
      "Wenwu Zeng",
      "Dafeng Lv",
      "Wenjuan Liu",
      "Shaoliang Peng"
    ],
    "abstract": "Protein-nucleic acid interactions play a very important role in a variety of biological activities. Accurate identification of nucleic acid-binding residues is a critical step in understanding the interaction mechanisms. Although many computationally based methods have been developed to predict nucleic acid-binding residues, challenges remain. In this study, a fast and accurate sequence-based method, called ESM-NBR, is proposed. In ESM-NBR, we first use the large protein language model ESM2 to extract discriminative biological properties feature representation from protein primary sequences; then, a multi-task deep learning model composed of stacked bidirectional long short-term memory (BiLSTM) and multi-layer perceptron (MLP) networks is employed to explore common and private information of DNA- and RNA-binding residues with ESM2 feature as input. Experimental results on benchmark data sets demonstrate that the prediction performance of ESM2 feature representation comprehensively outperforms evolutionary information-based hidden Markov model (HMM) features. Meanwhile, the ESM-NBR obtains the MCC values for DNA-binding residues prediction of 0.427 and 0.391 on two independent test sets, which are 18.61 and 10.45% higher than those of the second-best methods, respectively. Moreover, by completely discarding the time-cost multiple sequence alignment process, the prediction speed of ESM-NBR far exceeds that of existing methods (5.52s for a protein sequence of length 500, which is about 16 times faster than the second-fastest method). A user-friendly standalone package and the data of ESM-NBR are freely available for academic use at: https://github.com/wwzll123/ESM-NBR.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00842"
  },
  "2312.00840": {
    "title": "Towards Redundancy-Free Sub-networks in Continual Learning",
    "authors": [
      "Cheng Chen",
      "Jingkuan Song",
      "LianLi Gao",
      "Heng Tao Shen"
    ],
    "abstract": "Catastrophic Forgetting (CF) is a prominent issue in continual learning. Parameter isolation addresses this challenge by masking a sub-network for each task to mitigate interference with old tasks. However, these sub-networks are constructed relying on weight magnitude, which does not necessarily correspond to the importance of weights, resulting in maintaining unimportant weights and constructing redundant sub-networks. To overcome this limitation, inspired by information bottleneck, which removes redundancy between adjacent network layers, we propose \\textbf{\\underline{I}nformation \\underline{B}ottleneck \\underline{M}asked sub-network (IBM)} to eliminate redundancy within sub-networks. Specifically, IBM accumulates valuable information into essential weights to construct redundancy-free sub-networks, not only effectively mitigating CF by freezing the sub-networks but also facilitating new tasks training through the transfer of valuable knowledge. Additionally, IBM decomposes hidden representations to automate the construction process and make it flexible. Extensive experiments demonstrate that IBM consistently outperforms state-of-the-art methods. Notably, IBM surpasses the state-of-the-art parameter isolation method with a 70\\% reduction in the number of parameters within sub-networks and an 80\\% decrease in training time.\n        \u25b3 Less",
    "submission_date": "11 January, 2024",
    "eprint_id": "2312.00840"
  },
  "2312.00839": {
    "title": "PipeOptim: Ensuring Effective 1F1B Schedule with Optimizer-Dependent Weight Prediction",
    "authors": [
      "Lei Guan",
      "Dongsheng Li",
      "Jiye Liang",
      "Wenjian Wang",
      "Xicheng Lu"
    ],
    "abstract": "Asynchronous pipeline model parallelism with a \"1F1B\" (one forward, one backward) schedule generates little bubble overhead and always provides quite a high throughput. However, the \"1F1B\" schedule inevitably leads to weight inconsistency and weight staleness issues due to the cross-training of different mini-batches across GPUs. To simultaneously address these two problems, in this paper, we propose an optimizer-dependent weight prediction strategy (a.k.a PipeOptim) for asynchronous pipeline training. The key insight of our proposal is that we employ a weight prediction strategy in the forward pass to ensure that each mini-batch uses consistent and staleness-free weights to compute the forward pass. To be concrete, we first construct the weight prediction scheme based on the update rule of the used optimizer when training the deep neural network models. Then throughout the \"1F1B\" pipelined training, each mini-batch is mandated to execute weight prediction ahead of the forward pass, subsequently employing the predicted weights to perform the forward pass. As a result, PipeOptim 1) inherits the advantage of the \"1F1B\" schedule and generates pretty high throughput, and 2) can ensure effective parameter learning regardless of the type of the used optimizer. To verify the effectiveness of our proposal, we conducted extensive experimental evaluations using eight different deep-learning models spanning three machine-learning tasks including image classification, sentiment analysis, and machine translation. The experiment results demonstrate that PipeOptim outperforms the popular pipelined approaches including GPipe, PipeDream, PipeDream-2BW, and SpecTrain. The code of PipeOptim can be accessible at https://github.com/guanleics/PipeOptim.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.00839"
  },
  "2312.00833": {
    "title": "Lasagna: Layered Score Distillation for Disentangled Object Relighting",
    "authors": [
      "Dina Bashkirova",
      "Arijit Ray",
      "Rupayan Mallick",
      "Sarah Adel Bargal",
      "Jianming Zhang",
      "Ranjay Krishna",
      "Kate Saenko"
    ],
    "abstract": "Professional artists, photographers, and other visual content creators use object relighting to establish their photo's desired effect. Unfortunately, manual tools that allow relighting have a steep learning curve and are difficult to master. Although generative editing methods now enable some forms of image editing, relighting is still beyond today's capabilities; existing methods struggle to keep other aspects of the image -- colors, shapes, and textures -- consistent after the edit. We propose Lasagna, a method that enables intuitive text-guided relighting control. Lasagna learns a lighting prior by using score distillation sampling to distill the prior of a diffusion model, which has been finetuned on synthetic relighting data. To train Lasagna, we curate a new synthetic dataset ReLiT, which contains 3D object assets re-lit from multiple light source locations. Despite training on synthetic images, quantitative results show that Lasagna relights real-world images while preserving other aspects of the input image, outperforming state-of-the-art text-guided image editing methods. Lasagna enables realistic and controlled results on natural images and digital art pieces and is preferred by humans over other methods in over 91% of cases. Finally, we demonstrate the versatility of our learning objective by extending it to allow colorization, another form of image editing.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00833"
  },
  "2312.00827": {
    "title": "A Unified Framework for Connecting Noise Modeling to Boost Noise Detection",
    "authors": [
      "Siqi Wang",
      "Chau Pham",
      "Bryan A. Plummer"
    ],
    "abstract": "Noisy labels can impair model performance, making the study of learning with noisy labels an important topic. Two conventional approaches are noise modeling and noise detection. However, these two methods are typically studied independently, and there has been limited work on their collaboration. In this work, we explore the integration of these two approaches, proposing an interconnected structure with three crucial blocks: noise modeling, source knowledge identification, and enhanced noise detection using noise source-knowledge-integration methods. This collaboration structure offers advantages such as discriminating hard negatives and preserving genuinely clean labels that might be suspiciously noisy. Our experiments on four datasets, featuring three types of noise and different combinations of each block, demonstrate the efficacy of these components' collaboration. Our collaborative structure methods achieve up to a 10% increase in top-1 classification accuracy in synthesized noise datasets and 3-5% in real-world noisy datasets. The results also suggest that these components make distinct contributions to overall performance across various noise scenarios. These findings provide valuable insights for designing noisy label learning methods customized for specific noise scenarios in the future. Our code is accessible to the public.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00827"
  },
  "2312.00823": {
    "title": "Adaptive Multi-Modality Prompt Learning",
    "authors": [
      "Zongqian Wu",
      "Yujing Liu",
      "Mengmeng Zhan",
      "Jialie Shen",
      "Ping Hu",
      "Xiaofeng Zhu"
    ],
    "abstract": "Although current prompt learning methods have successfully been designed to effectively reuse the large pre-trained models without fine-tuning their large number of parameters, they still have limitations to be addressed, i.e., without considering the adverse impact of meaningless patches in every image and without simultaneously considering in-sample generalization and out-of-sample generalization. In this paper, we propose an adaptive multi-modality prompt learning to address the above issues. To do this, we employ previous text prompt learning and propose a new image prompt learning. The image prompt learning achieves in-sample and out-of-sample generalization, by first masking meaningless patches and then padding them with the learnable parameters and the information from texts. Moreover, each of the prompts provides auxiliary information to each other, further strengthening these two kinds of generalization. Experimental results on real datasets demonstrate that our method outperforms SOTA methods, in terms of different downstream tasks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00823"
  },
  "2312.00820": {
    "title": "Non-Cross Diffusion for Semantic Consistency",
    "authors": [
      "Ziyang Zheng",
      "Ruiyuan Gao",
      "Qiang Xu"
    ],
    "abstract": "In diffusion models, deviations from a straight generative flow are a common issue, resulting in semantic inconsistencies and suboptimal generations. To address this challenge, we introduce `Non-Cross Diffusion', an innovative approach in generative modeling for learning ordinary differential equation (ODE) models. Our methodology strategically incorporates an ascending dimension of input to effectively connect points sampled from two distributions with uncrossed paths. This design is pivotal in ensuring enhanced semantic consistency throughout the inference process, which is especially critical for applications reliant on consistent generative flows, including various distillation methods and deterministic sampling, which are fundamental in image editing and interpolation tasks. Our empirical results demonstrate the effectiveness of Non-Cross Diffusion, showing a substantial reduction in semantic inconsistencies at different inference steps and a notable enhancement in the overall performance of diffusion models.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00820"
  },
  "2312.00819": {
    "title": "Large Language Models for Travel Behavior Prediction",
    "authors": [
      "Baichuan Mo",
      "Hanyong Xu",
      "Dingyi Zhuang",
      "Ruoyun Ma",
      "Xiaotong Guo",
      "Jinhua Zhao"
    ],
    "abstract": "Travel behavior prediction is a fundamental task in transportation demand management. The conventional methods for travel behavior prediction rely on numerical data to construct mathematical models and calibrate model parameters to represent human preferences. Recent advancement in large language models (LLMs) has shown great reasoning abilities to solve complex problems. In this study, we propose to use LLMs to predict travel behavior with prompt engineering without data-based parameter learning. Specifically, we carefully design our prompts that include 1) task description, 2) travel characteristics, 3) individual attributes, and 4) guides of thinking with domain knowledge, and ask the LLMs to predict an individual's travel behavior and explain the results. We select the travel mode choice task as a case study. Results show that, though no training samples are provided, LLM-based predictions have competitive accuracy and F1-score as canonical supervised learning methods such as multinomial logit, random forest, and neural networks. LLMs can also output reasons that support their prediction. However, though in most of the cases, the output explanations are reasonable, we still observe cases that violate logic or with hallucinations.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00819"
  },
  "2312.00818": {
    "title": "The perpetual motion machine of AI-generated data and the distraction of ChatGPT-as-scientist",
    "authors": [
      "Jennifer Listgarten"
    ],
    "abstract": "Since ChatGPT works so well, are we on the cusp of solving science with AI? Is not AlphaFold2 suggestive that the potential of LLMs in biology and the sciences more broadly is limitless? Can we use AI itself to bridge the lack of data in the sciences in order to then train an AI? Herein we present a discussion of these topics.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00818"
  },
  "2312.00811": {
    "title": "Seizure detection from Electroencephalogram signals via Wavelets and Graph Theory metrics",
    "authors": [
      "Paul Grant",
      "Md Zahidul Islam"
    ],
    "abstract": "Epilepsy is one of the most prevalent neurological conditions, where an epileptic seizure is a transient occurrence due to abnormal, excessive and synchronous activity in the brain. Electroencephalogram signals emanating from the brain may be captured, analysed and then play a significant role in detection and prediction of epileptic seizures. In this work we enhance upon a previous approach that relied on the differing properties of the wavelet transform. Here we apply the Maximum Overlap Discrete Wavelet Transform to both reduce signal \\textit{noise} and use signal variance exhibited at differing inherent frequency levels to develop various metrics of connection between the electrodes placed upon the scalp. %The properties of both the noise reduced signal and the interconnected electrodes differ significantly during the different brain states.\n  Using short duration epochs, to approximate close to real time monitoring, together with simple statistical parameters derived from the reconstructed noise reduced signals we initiate seizure detection. To further improve performance we utilise graph theoretic indicators from derived electrode connectivity. From there we build the attribute space. We utilise open-source software and publicly available data to highlight the superior Recall/Sensitivity performance of our approach, when compared to existing published methods.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.00811"
  },
  "2312.00808": {
    "title": "Transforming organic chemistry research paradigms: moving from manual efforts to the intersection of automation and artificial intelligence",
    "authors": [
      "Chengchun Liu",
      "Yuntian Chen",
      "Fanyang Mo"
    ],
    "abstract": "Organic chemistry is undergoing a major paradigm shift, moving from a labor-intensive approach to a new era dominated by automation and artificial intelligence (AI). This transformative shift is being driven by technological advances, the ever-increasing demand for greater research efficiency and accuracy, and the burgeoning growth of interdisciplinary research. AI models, supported by computational power and algorithms, are drastically reshaping synthetic planning and introducing groundbreaking ways to tackle complex molecular synthesis. In addition, autonomous robotic systems are rapidly accelerating the pace of discovery by performing tedious tasks with unprecedented speed and precision. This article examines the multiple opportunities and challenges presented by this paradigm shift and explores its far-reaching implications. It provides valuable insights into the future trajectory of organic chemistry research, which is increasingly defined by the synergistic interaction of automation and AI.\n        \u25b3 Less",
    "submission_date": "26 November, 2023",
    "eprint_id": "2312.00808"
  },
  "2312.00805": {
    "title": "Gender inference: can chatGPT outperform common commercial tools?",
    "authors": [
      "Michelle Alexopoulos",
      "Kelly Lyons",
      "Kaushar Mahetaji",
      "Marcus Emmanuel Barnes",
      "Rogan Gutwillinger"
    ],
    "abstract": "An increasing number of studies use gender information to understand phenomena such as gender bias, inequity in access and participation, or the impact of the Covid pandemic response. Unfortunately, most datasets do not include self-reported gender information, making it necessary for researchers to infer gender from other information, such as names or names and country information. An important limitation of these tools is that they fail to appropriately capture the fact that gender exists on a non-binary scale, however, it remains important to evaluate and compare how well these tools perform in a variety of contexts. In this paper, we compare the performance of a generative Artificial Intelligence (AI) tool ChatGPT with three commercially available list-based and machine learning-based gender inference tools (Namsor, Gender-API, and genderize.io) on a unique dataset. Specifically, we use a large Olympic athlete dataset and report how variations in the input (e.g., first name and first and last name, with and without country information) impact the accuracy of their predictions. We report results for the full set, as well as for the subsets: medal versus non-medal winners, athletes from the largest English-speaking countries, and athletes from East Asia. On these sets, we find that Namsor is the best traditional commercially available tool. However, ChatGPT performs at least as well as Namsor and often outperforms it, especially for the female sample when country and/or last name information is available. All tools perform better on medalists versus non-medalists and on names from English-speaking countries. Although not designed for this purpose, ChatGPT may be a cost-effective tool for gender prediction. In the future, it might even be possible for ChatGPT or other large scale language models to better identify self-reported gender rather than report gender on a binary scale.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2312.00805"
  },
  "2312.00804": {
    "title": "Automatic detection of problem-gambling signs from online texts using large language models",
    "authors": [
      "Elke Smith",
      "Nils Reiter",
      "Jan Peters"
    ],
    "abstract": "Problem gambling is a major public health concern and is associated with profound psychological distress and economic problems. There are numerous gambling communities on the internet where users exchange information about games, gambling tactics, as well as gambling-related problems. Individuals exhibiting higher levels of problem gambling engage more in such communities. Online gambling communities may provide insights into problem-gambling behaviour. Using data scraped from a major German gambling discussion board, we fine-tuned a large language model, specifically a Bidirectional Encoder Representations from Transformers (BERT) model, to predict signs of problem-gambling from forum posts. Training data were generated by manual annotation and by taking into account diagnostic criteria and gambling-related cognitive distortions. Using k-fold cross-validation, our models achieved a precision of 0.95 and F1 score of 0.71, demonstrating that satisfactory classification performance can be achieved by generating high-quality training material through manual annotation based on diagnostic criteria. The current study confirms that a BERT-based model can be reliably used on small data sets and to detect signatures of problem gambling in online communication data. Such computational approaches may have potential for the detection of changes in problem-gambling prevalence among online users.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2312.00804"
  },
  "2312.00803": {
    "title": "InceptionCaps: A Performant Glaucoma Classification Model for Data-scarce Environment",
    "authors": [
      "Gyanendar Manohar",
      "Ruairi O'Reilly"
    ],
    "abstract": "Glaucoma is an irreversible ocular disease and is the second leading cause of visual disability worldwide. Slow vision loss and the asymptomatic nature of the disease make its diagnosis challenging. Early detection is crucial for preventing irreversible blindness. Ophthalmologists primarily use retinal fundus images as a non-invasive screening method. Convolutional neural networks (CNN) have demonstrated high accuracy in the classification of medical images. Nevertheless, CNN's translation-invariant nature and inability to handle the part-whole relationship between objects make its direct application unsuitable for glaucomatous fundus image classification, as it requires a large number of labelled images for training. This work reviews existing state of the art models and proposes InceptionCaps, a novel capsule network (CapsNet) based deep learning model having pre-trained InceptionV3 as its convolution base, for automatic glaucoma classification. InceptionCaps achieved an accuracy of 0.956, specificity of 0.96, and AUC of 0.9556, which surpasses several state-of-the-art deep learning model performances on the RIM-ONE v2 dataset. The obtained result demonstrates the robustness of the proposed deep learning model.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2312.00803"
  },
  "2312.00802": {
    "title": "Continuous Authentication Using Mouse Clickstream Data Analysis",
    "authors": [
      "Sultan Almalki",
      "Prosenjit Chatterjee",
      "Kaushik Roy"
    ],
    "abstract": "Biometrics is used to authenticate an individual based on physiological or behavioral traits. Mouse dynamics is an example of a behavioral biometric that can be used to perform continuous authentication as protection against security breaches. Recent research on mouse dynamics has shown promising results in identifying users; however, it has not yet reached an acceptable level of accuracy. In this paper, an empirical evaluation of different classification techniques is conducted on a mouse dynamics dataset, the Balabit Mouse Challenge dataset. User identification is carried out using three mouse actions: mouse move, point and click, and drag and drop. Verification and authentication methods are conducted using three machine-learning classifiers: the Decision Tree classifier, the K-Nearest Neighbors classifier, and the Random Forest classifier. The results show that the three classifiers can distinguish between a genuine user and an impostor with a relatively high degree of accuracy. In the verification mode, all the classifiers achieve a perfect accuracy of 100%. In authentication mode, all three classifiers achieved the highest accuracy (ACC) and Area Under Curve (AUC) from scenario B using the point and click action data: (Decision Tree ACC:87.6%, AUC:90.3%), (K-Nearest Neighbors ACC:99.3%, AUC:99.9%), and (Random Forest ACC:89.9%, AUC:92.5%).\n        \u25b3 Less",
    "submission_date": "23 November, 2023",
    "eprint_id": "2312.00802"
  },
  "2312.00799": {
    "title": "hvEEGNet: exploiting hierarchical VAEs on EEG data for neuroscience applications",
    "authors": [
      "Giulia Cisotto",
      "Alberto Zancanaro",
      "Italo F. Zoppis",
      "Sara L. Manzoni"
    ],
    "abstract": "With the recent success of artificial intelligence in neuroscience, a number of deep learning (DL) models were proposed for classification, anomaly detection, and pattern recognition tasks in electroencephalography (EEG). EEG is a multi-channel time-series that provides information about the individual brain activity for diagnostics, neuro-rehabilitation, and other applications (including emotions recognition). Two main issues challenge the existing DL-based modeling methods for EEG: the high variability between subjects and the low signal-to-noise ratio making it difficult to ensure a good quality in the EEG data. In this paper, we propose two variational autoencoder models, namely vEEGNet-ver3 and hvEEGNet, to target the problem of high-fidelity EEG reconstruction. We properly designed their architectures using the blocks of the well-known EEGNet as the encoder, and proposed a loss function based on dynamic time warping. We tested the models on the public Dataset 2a - BCI Competition IV, where EEG was collected from 9 subjects and 22 channels. hvEEGNet was found to reconstruct the EEG data with very high-fidelity, outperforming most previous solutions (including our vEEGNet-ver3 ). Furthermore, this was consistent across all subjects. Interestingly, hvEEGNet made it possible to discover that this popular dataset includes a number of corrupted EEG recordings that might have influenced previous literature results. We also investigated the training behaviour of our models and related it with the quality and the size of the input EEG dataset, aiming at opening a new research debate on this relationship. In the future, hvEEGNet could be used as anomaly (e.g., artefact) detector in large EEG datasets to support the domain experts, but also the latent representations it provides could be used in other classification problems and EEG data generation.\n        \u25b3 Less",
    "submission_date": "20 November, 2023",
    "eprint_id": "2312.00799"
  },
  "2312.00798": {
    "title": "A Turing Test: Are AI Chatbots Behaviorally Similar to Humans?",
    "authors": [
      "Qiaozhu Mei",
      "Yutong Xie",
      "Walter Yuan",
      "Matthew O. Jackson"
    ],
    "abstract": "We administer a Turing Test to AI Chatbots. We examine how Chatbots behave in a suite of classic behavioral games that are designed to elicit characteristics such as trust, fairness, risk-aversion, cooperation, \\textit{etc.}, as well as how they respond to a traditional Big-5 psychological survey that measures personality traits. ChatGPT-4 exhibits behavioral and personality traits that are statistically indistinguishable from a random human from tens of thousands of human subjects from more than 50 countries. Chatbots also modify their behavior based on previous experience and contexts ``as if'' they were learning from the interactions, and change their behavior in response to different framings of the same strategic situation. Their behaviors are often distinct from average and modal human behaviors, in which case they tend to behave on the more altruistic and cooperative end of the distribution. We estimate that they act as if they are maximizing an average of their own and partner's payoffs.\n        \u25b3 Less",
    "submission_date": "1 January, 2024",
    "eprint_id": "2312.00798"
  },
  "2312.00797": {
    "title": "Multi-mode OAM Convergent Transmission with Co-divergent Angle Tailored by Airy Wavefront",
    "authors": [
      "Yufei Zhao",
      "Ziyang Wang",
      "Yilong Lu",
      "Yong Liang Guan"
    ],
    "abstract": "Wireless backhaul offers a more cost-effective, time-efficient, and reconfigurable solution than wired backhaul to connect the edge-computing cells to the core network. As the amount of transmitted data increases, the low-rank characteristic of Line-of-Sight (LoS) channel severely limits the growth of channel capacity in the point-to-point backhaul transmission scenario. Orbital Angular Momentum (OAM), also known as vortex beam, is considered a potentially effective solution for high-capacity LoS wireless transmission. However, due to the shortcomings of its energy divergence and the specificity of multi-mode divergence angles, OAM beams have been difficult to apply in practical communication systems for a long time. In this work, a novel multi-mode convergent transmission with co-scale reception scheme is proposed. OAM beams of different modes can be transmitted with the same beam divergent angle, while the wavefronts are tailored by the ring-shaped Airy compensation lens during propagation, so that the energy will converge to the same spatial area for receiving. Based on this scheme, not only is the Signal-to-Noise Ratio (SNR) greatly improved, but it is also possible to simultaneously receive and demodulate OAM channels multiplexed with different modes in a limited space area. Through prototype experiments, we demonstrated that 3 kinds of OAM modes are tunable, and different channels can be separated simultaneously with receiving power increasing. The measurement isolations between channels are over 11 dB, which ensures a reliable 16-QAM multiplexing wireless transmission demo system. This work may explore the potential applications of OAM-based multi-mode convergent transmission in LoS wireless communications.\n        \u25b3 Less",
    "submission_date": "18 November, 2023",
    "eprint_id": "2312.00797"
  },
  "2312.00796": {
    "title": "Multiple Protein Profiler 1.0 (MPP): A webserver for predicting and visualizing physiochemical properties of proteins at the proteome level",
    "authors": [
      "Gustavo Sganzerla Martinez",
      "Mansi Dutt",
      "Anuj Kumar",
      "David J Kelvin"
    ],
    "abstract": "Determining the physicochemical properties of a protein can reveal important insights in their structure, biological functions, stability, and interactions with other molecules. Although tools for computing properties of proteins already existed, we could not find a comprehensive tool that enables the calculations of multiple properties for multiple input proteins on the proteome level at once. Facing this limitation, we have developed Multiple Protein Profiler (MPP) 1.0 as an integrated tool that allows the profiling of 12 individual properties of multiple proteins in a significant manner. MPP provides a tabular and graphic visualization of properties of multiple proteins. The tool is freely accessible at https://mproteinprofiler.microbiologyandimmunology.dal.ca/\n        \u25b3 Less",
    "submission_date": "17 November, 2023",
    "eprint_id": "2312.00796"
  },
  "2312.00795": {
    "title": "Talent-Interview: Web-Client Cheating Detection for Online Exams",
    "authors": [
      "Mert Ege",
      "Mustafa Ceyhan"
    ],
    "abstract": "Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Online exams are more attractive after the Covid-19 pandemic. Furthermore, during recruitment, online exams are used. However, there are more cheating possibilities for online exams. Assigning a proctor for each exam increases cost. At this point, automatic proctor systems detect possible cheating status. This article proposes an end-to-end system and submodules to get better results for online proctoring. Object detection, face recognition, human voice detection, and segmentation are used in our system. Furthermore, our proposed model works on the PCs of users, meaning a client-based system. So, server cost is eliminated. As far as we know, it is the first time the client-based online proctoring system has been used for recruitment. Furthermore, this cheating system works at https://www.talent-interview.com/tr/.\n        \u25b3 Less",
    "submission_date": "17 November, 2023",
    "eprint_id": "2312.00795"
  },
  "2312.00794": {
    "title": "Informative Priors Improve the Reliability of Multimodal Clinical Data Classification",
    "authors": [
      "L. Julian Lechuga Lopez",
      "Tim G. J. Rudner",
      "Farah E. Shamout"
    ],
    "abstract": "Machine learning-aided clinical decision support has the potential to significantly improve patient care. However, existing efforts in this domain for principled quantification of uncertainty have largely been limited to applications of ad-hoc solutions that do not consistently improve reliability. In this work, we consider stochastic neural networks and design a tailor-made multimodal data-driven (M2D2) prior distribution over network parameters. We use simple and scalable Gaussian mean-field variational inference to train a Bayesian neural network using the M2D2 prior. We train and evaluate the proposed approach using clinical time-series data in MIMIC-IV and corresponding chest X-ray images in MIMIC-CXR for the classification of acute care conditions. Our empirical results show that the proposed method produces a more reliable predictive model compared to deterministic and Bayesian neural network baselines.\n        \u25b3 Less",
    "submission_date": "16 November, 2023",
    "eprint_id": "2312.00794"
  },
  "2312.00793": {
    "title": "Variants of Tagged Sentential Decision Diagrams",
    "authors": [
      "Deyuan Zhong",
      "Mingwei Zhang",
      "Quanlong Guan",
      "Liangda Fang",
      "Zhaorong Lai",
      "Yong Lai"
    ],
    "abstract": "A recently proposed canonical form of Boolean functions, namely tagged sentential decision diagrams (TSDDs), exploits both the standard and zero-suppressed trimming rules. The standard ones minimize the size of sentential decision diagrams (SDDs) while the zero-suppressed trimming rules have the same objective as the standard ones but for zero-suppressed sentential decision diagrams (ZSDDs). The original TSDDs, which we call zero-suppressed TSDDs (ZTSDDs), firstly fully utilize the zero-suppressed trimming rules, and then the standard ones. In this paper, we present a variant of TSDDs which we call standard TSDDs (STSDDs) by reversing the order of trimming rules. We then prove the canonicity of STSDDs and present the algorithms for binary operations on TSDDs. In addition, we offer two kinds of implementations of STSDDs and ZTSDDs and acquire three variations of the original TSDDs. Experimental evaluations demonstrate that the four versions of TSDDs have the size advantage over SDDs and ZSDDs.\n        \u25b3 Less",
    "submission_date": "16 November, 2023",
    "eprint_id": "2312.00793"
  },
  "2312.00789": {
    "title": "Do androids dream of fictional references? A bibliographic dialogue with ChatGPT3.5",
    "authors": [
      "Olivier Las Vergnas"
    ],
    "abstract": "This article focuses on bibliographic references generated by the ChatGPT3.5 tool. Using this tool based on the trained GPT generation model ChatGPT3.5, developed by the company OpenAI, we explored six different themes and analyzed a sample of references generated by the model, in French and English. The results revealed high percentages of fictitious references in several fields, underlining the importance of carefully checking these references before using them in research work. An improvement in results was nevertheless noted between May and July with regard to English references for themes on which ChatGPR3.5 has been particularly trained, but the situation remains unsatisfactory in French, for example. It should also be pointed out that much of the text in this article was generated by ChatGPT in a joint effort with the human author.\n        \u25b3 Less",
    "submission_date": "4 September, 2023",
    "eprint_id": "2312.00789"
  },
  "2312.00785": {
    "title": "Sequential Modeling Enables Scalable Learning for Large Vision Models",
    "authors": [
      "Yutong Bai",
      "Xinyang Geng",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Alan Yuille",
      "Trevor Darrell",
      "Jitendra Malik",
      "Alexei A Efros"
    ],
    "abstract": "We introduce a novel sequential modeling approach which enables learning a Large Vision Model (LVM) without making use of any linguistic data. To do this, we define a common format, \"visual sentences\", in which we can represent raw images and videos as well as annotated data sources such as semantic segmentations and depth reconstructions without needing any meta-knowledge beyond the pixels. Once this wide variety of visual data (comprising 420 billion tokens) is represented as sequences, the model can be trained to minimize a cross-entropy loss for next token prediction. By training across various scales of model architecture and data diversity, we provide empirical evidence that our models scale effectively. Many different vision tasks can be solved by designing suitable visual prompts at test time.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00785"
  },
  "2312.00777": {
    "title": "VideoBooth: Diffusion-based Video Generation with Image Prompts",
    "authors": [
      "Yuming Jiang",
      "Tianxing Wu",
      "Shuai Yang",
      "Chenyang Si",
      "Dahua Lin",
      "Yu Qiao",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "abstract": "Text-driven video generation witnesses rapid progress. However, merely using text prompts is not enough to depict the desired subject appearance that accurately aligns with users' intents, especially for customized content creation. In this paper, we study the task of video generation with image prompts, which provide more accurate and direct content control beyond the text prompts. Specifically, we propose a feed-forward framework VideoBooth, with two dedicated designs: 1) We propose to embed image prompts in a coarse-to-fine manner. Coarse visual embeddings from image encoder provide high-level encodings of image prompts, while fine visual embeddings from the proposed attention injection module provide multi-scale and detailed encoding of image prompts. These two complementary embeddings can faithfully capture the desired appearance. 2) In the attention injection module at fine level, multi-scale image prompts are fed into different cross-frame attention layers as additional keys and values. This extra spatial information refines the details in the first frame and then it is propagated to the remaining frames, which maintains temporal consistency. Extensive experiments demonstrate that VideoBooth achieves state-of-the-art performance in generating customized high-quality videos with subjects specified in image prompts. Notably, VideoBooth is a generalizable framework where a single model works for a wide range of image prompts with feed-forward pass.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00777"
  },
  "2312.00775": {
    "title": "Towards Generalizable Zero-Shot Manipulation via Translating Human Interaction Plans",
    "authors": [
      "Homanga Bharadhwaj",
      "Abhinav Gupta",
      "Vikash Kumar",
      "Shubham Tulsiani"
    ],
    "abstract": "We pursue the goal of developing robots that can interact zero-shot with generic unseen objects via a diverse repertoire of manipulation skills and show how passive human videos can serve as a rich source of data for learning such generalist robots. Unlike typical robot learning approaches which directly learn how a robot should act from interaction data, we adopt a factorized approach that can leverage large-scale human videos to learn how a human would accomplish a desired task (a human plan), followed by translating this plan to the robots embodiment. Specifically, we learn a human plan predictor that, given a current image of a scene and a goal image, predicts the future hand and object configurations. We combine this with a translation module that learns a plan-conditioned robot manipulation policy, and allows following humans plans for generic manipulation tasks in a zero-shot manner with no deployment-time training. Importantly, while the plan predictor can leverage large-scale human videos for learning, the translation module only requires a small amount of in-domain data, and can generalize to tasks not seen during training. We show that our learned system can perform over 16 manipulation skills that generalize to 40 objects, encompassing 100 real-world tasks for table-top manipulation and diverse in-the-wild manipulation. https://homangab.github.io/hopman/\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00775"
  },
  "2312.00774": {
    "title": "Context Retrieval via Normalized Contextual Latent Interaction for Conversational Agent",
    "authors": [
      "Junfeng Liu",
      "Zhuocheng Mei",
      "Kewen Peng",
      "Ranga Raju Vatsavai"
    ],
    "abstract": "Conversational agents leveraging AI, particularly deep learning, are emerging in both academic research and real-world applications. However, these applications still face challenges, including disrespecting knowledge and facts, not personalizing to user preferences, and enormous demand for computational resources during training and inference. Recent research efforts have been focused on addressing these challenges from various aspects, including supplementing various types of auxiliary information to the conversational agents. However, existing methods are still not able to effectively and efficiently exploit relevant information from these auxiliary supplements to further unleash the power of the conversational agents and the language models they use. In this paper, we present a novel method, PK-NCLI, that is able to accurately and efficiently identify relevant auxiliary information to improve the quality of conversational responses by learning the relevance among persona, chat history, and knowledge background through low-level normalized contextual latent interaction. Our experimental results indicate that PK-NCLI outperforms the state-of-the-art method, PK-FoCus, by 47.80%/30.61%/24.14% in terms of perplexity, knowledge grounding, and training efficiency, respectively, and maintained the same level of persona grounding performance. We also provide a detailed analysis of how different factors, including language model choices and trade-offs on training weights, would affect the performance of PK-NCLI.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00774"
  },
  "2312.00766": {
    "title": "Automated Material Properties Extraction For Enhanced Beauty Product Discovery and Makeup Virtual Try-on",
    "authors": [
      "Fatemeh Taheri Dezaki",
      "Himanshu Arora",
      "Rahul Suresh",
      "Amin Banitalebi-Dehkordi"
    ],
    "abstract": "The multitude of makeup products available can make it challenging to find the ideal match for desired attributes. An intelligent approach for product discovery is required to enhance the makeup shopping experience to make it more convenient and satisfying. However, enabling accurate and efficient product discovery requires extracting detailed attributes like color and finish type. Our work introduces an automated pipeline that utilizes multiple customized machine learning models to extract essential material attributes from makeup product images. Our pipeline is versatile and capable of handling various makeup products. To showcase the efficacy of our pipeline, we conduct extensive experiments on eyeshadow products (both single and multi-shade ones), a challenging makeup product known for its diverse range of shapes, colors, and finish types. Furthermore, we demonstrate the applicability of our approach by successfully extending it to other makeup categories like lipstick and foundation, showcasing its adaptability and effectiveness across different beauty products. Additionally, we conduct ablation experiments to demonstrate the superiority of our machine learning pipeline over human labeling methods in terms of reliability. Our proposed method showcases its effectiveness in cross-category product discovery, specifically in recommending makeup products that perfectly match a specified outfit. Lastly, we also demonstrate the application of these material attributes in enabling virtual-try-on experiences which makes makeup shopping experience significantly more engaging.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00766"
  },
  "2312.00765": {
    "title": "Explaining Knock-on Effects of Bias Mitigation",
    "authors": [
      "Svetoslav Nizhnichenkov",
      "Rahul Nair",
      "Elizabeth Daly",
      "Brian Mac Namee"
    ],
    "abstract": "In machine learning systems, bias mitigation approaches aim to make outcomes fairer across privileged and unprivileged groups. Bias mitigation methods work in different ways and have known \"waterfall\" effects, e.g., mitigating bias at one place may manifest bias elsewhere. In this paper, we aim to characterise impacted cohorts when mitigation interventions are applied. To do so, we treat intervention effects as a classification task and learn an explainable meta-classifier to identify cohorts that have altered outcomes. We examine a range of bias mitigation strategies that work at various stages of the model life cycle. We empirically demonstrate that our meta-classifier is able to uncover impacted cohorts. Further, we show that all tested mitigation strategies negatively impact a non-trivial fraction of cases, i.e., people who receive unfavourable outcomes solely on account of mitigation efforts. This is despite improvement in fairness metrics. We use these results as a basis to argue for more careful audits of static mitigation interventions that go beyond aggregate metrics.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00765"
  },
  "2312.00763": {
    "title": "Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses",
    "authors": [
      "Xiao Ma",
      "Swaroop Mishra",
      "Ariel Liu",
      "Sophie Su",
      "Jilin Chen",
      "Chinmay Kulkarni",
      "Heng-Tze Cheng",
      "Quoc Le",
      "Ed Chi"
    ],
    "abstract": "Large language model (LLM) powered chatbots are primarily text-based today, and impose a large interactional cognitive load, especially for exploratory or sensemaking tasks such as planning a trip or learning about a new city. Because the interaction is textual, users have little scaffolding in the way of structure, informational \"scent\", or ability to specify high-level preferences or goals. We introduce ExploreLLM that allows users to structure thoughts, help explore different options, navigate through the choices and recommendations, and to more easily steer models to generate more personalized responses. We conduct a user study and show that users find it helpful to use ExploreLLM for exploratory or planning tasks, because it provides a useful schema-like structure to the task, and guides users in planning. The study also suggests that users can more easily personalize responses with high-level preferences with ExploreLLM. Together, ExploreLLM points to a future where users interact with LLMs beyond the form of chatbots, and instead designed to support complex user tasks with a tighter integration between natural language and graphical user interfaces.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00763"
  },
  "2312.00760": {
    "title": "${L}^{\\infty}$-norm computation for linear time-invariant systems depending on parameters",
    "authors": [
      "Alban Quadrat",
      "Fabrice Rouillier",
      "Grace Younes"
    ],
    "abstract": "This paper focuses on representing the $L^{\\infty}$-norm of finite-dimensional linear time-invariant systems with parameter-dependent coefficients. Previous studies tackled the problem in a non-parametric scenario by simplifying it to finding the maximum $y$-projection of real solutions $(x, y)$ of a system of the form $\u03a3=\\{P=0, \\, \\partial P/\\partial x=0\\}$, where $P \\in \\Z[x, y]$. To solve this problem, standard computer algebra methods were employed and analyzed \\cite{bouzidi2021computation}.\n  In this paper, we extend our approach to address the parametric case. We aim to represent the \"maximal\" $y$-projection of real solutions of $\u03a3$ as a function of the given parameters. %a set of parameters $\u03b1$. To accomplish this, we utilize cylindrical algebraic decomposition. This method allows us to determine the desired value as a function of the parameters within specific regions of parameter space.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.00760"
  },
  "2312.00751": {
    "title": "Mitigating Over-smoothing in Transformers via Regularized Nonlocal Functionals",
    "authors": [
      "Tam Nguyen",
      "Tan M. Nguyen",
      "Richard G. Baraniuk"
    ],
    "abstract": "Transformers have achieved remarkable success in a wide range of natural language processing and computer vision applications. However, the representation capacity of a deep transformer model is degraded due to the over-smoothing issue in which the token representations become identical when the model's depth grows. In this work, we show that self-attention layers in transformers minimize a functional which promotes smoothness, thereby causing token uniformity. We then propose a novel regularizer that penalizes the norm of the difference between the smooth output tokens from self-attention and the input tokens to preserve the fidelity of the tokens. Minimizing the resulting regularized energy functional, we derive the Neural Transformer with a Regularized Nonlocal Functional (NeuTRENO), a novel class of transformer models that can mitigate the over-smoothing issue. We empirically demonstrate the advantages of NeuTRENO over the baseline transformers and state-of-the-art methods in reducing the over-smoothing of token representations on various practical tasks, including object classification, image segmentation, and language modeling.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00751"
  },
  "2312.00747": {
    "title": "Reduction from sparse LPN to LPN, Dual Attack 3.0",
    "authors": [
      "K\u00e9vin Carrier",
      "Thomas Debris-Alazard",
      "Charles Meyer-Hilfiger",
      "Jean-Pierre Tillich"
    ],
    "abstract": "The security of code-based cryptography relies primarily on the hardness of decoding generic linear codes. Until very recently, all the best algorithms for solving the decoding problem were information set decoders (ISD). However, recently a new algorithm called RLPN-decoding which relies on a completely different approach was introduced and it has been shown that RLPN outperforms significantly ISD decoders for a rather large range of rates. This RLPN decoder relies on two ingredients, first reducing decoding to some underlying LPN problem, and then computing efficiently many parity-checks of small weight when restricted to some positions. We revisit RLPN-decoding by noticing that, in this algorithm, decoding is in fact reduced to a sparse-LPN problem, namely with a secret whose Hamming weight is small. Our new approach consists this time in making an additional reduction from sparse-LPN to plain-LPN with a coding approach inspired by coded-BKW. It outperforms significantly the ISD's and RLPN for code rates smaller than 0.42. This algorithm can be viewed as the code-based cryptography cousin of recent dual attacks in lattice-based cryptography. We depart completely from the traditional analysis of this kind of algorithm which uses a certain number of independence assumptions that have been strongly questioned recently in the latter domain. We give instead a formula for the LPNs noise relying on duality which allows to analyze the behavior of the algorithm by relying only on the analysis of a certain weight distribution. By using only a minimal assumption whose validity has been verified experimentally we are able to justify the correctness of our algorithm. This key tool, namely the duality formula, can be readily adapted to the lattice setting and is shown to give a simple explanation for some phenomena observed on dual attacks in lattices in [DP23].\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00747"
  },
  "2312.00742": {
    "title": "Scalable Meta-Learning with Gaussian Processes",
    "authors": [
      "Petru Tighineanu",
      "Lukas Grossberger",
      "Paul Baireuther",
      "Kathrin Skubch",
      "Stefan Falkner",
      "Julia Vinogradska",
      "Felix Berkenkamp"
    ],
    "abstract": "Meta-learning is a powerful approach that exploits historical data to quickly solve new tasks from the same distribution. In the low-data regime, methods based on the closed-form posterior of Gaussian processes (GP) together with Bayesian optimization have achieved high performance. However, these methods are either computationally expensive or introduce assumptions that hinder a principled propagation of uncertainty between task models. This may disrupt the balance between exploration and exploitation during optimization. In this paper, we develop ScaML-GP, a modular GP model for meta-learning that is scalable in the number of tasks. Our core contribution is a carefully designed multi-task kernel that enables hierarchical training and task scalability. Conditioning ScaML-GP on the meta-data exposes its modular nature yielding a test-task prior that combines the posteriors of meta-task GPs. In synthetic and real-world meta-learning experiments, we demonstrate that ScaML-GP can learn efficiently both with few and many meta-tasks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00742"
  },
  "2312.00741": {
    "title": "Crystal: Enhancing Blockchain Mining Transparency with Quorum Certificate",
    "authors": [
      "Jianyu Niu",
      "Fangyu Gai",
      "Runchao Han",
      "Ren Zhang",
      "Yinqian Zhang",
      "Chen Feng"
    ],
    "abstract": "Researchers have discovered a series of theoretical attacks against Bitcoin's Nakamoto consensus; the most damaging ones are selfish mining, double-spending, and consistency delay attacks. These attacks have one common cause: block withholding. This paper proposes Crystal, which leverages quorum certificates to resist block withholding misbehavior. Crystal continuously elects committees from miners and requires each block to have a quorum certificate, i.e., a set of signatures issued by members of its committee. Consequently, an attacker has to publish its blocks to obtain quorum certificates, rendering block withholding impossible. To build Crystal, we design a novel two-round committee election in a Sybil-resistant, unpredictable and non-interactive way, and a reward mechanism to incentivize miners to follow the protocol. Our analysis and evaluations show that Crystal can significantly mitigate selfish mining and double-spending attacks. For example, in Bitcoin, an attacker with 30% of the total computation power will succeed in double-spending attacks with a probability of 15.6% to break the 6-confirmation rule; however, in Crystal, the success probability for the same attacker falls to 0.62%. We provide formal end-to-end safety proofs for Crystal, ensuring no unknown attacks will be introduced. To the best of our knowledge, Crystal is the first protocol that prevents selfish mining and double-spending attacks while providing safety proof.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00741"
  },
  "2312.00740": {
    "title": "Computing Networks Enabled Semantic Communications",
    "authors": [
      "Zhijin Qin",
      "Jingkai Ying",
      "Dingxi Yang",
      "Hengjiang Wang",
      "Xiaoming Tao"
    ],
    "abstract": "Semantic communication has shown great potential in boosting the effectiveness and reliability of communications. However, its systems to date are mostly enabled by deep learning, which requires demanding computing resources. This article proposes a framework for the computing networks enabled semantic communication system, aiming to offer sufficient computing resources for semantic processing and transmission. Key techniques including semantic sampling and reconstruction, semantic-channel coding, semantic-aware resource allocation and optimization are introduced based on the cloud-edge-end computing coordination. Two use cases are demonstrated to show advantages of the proposed framework. The article concludes with several future research directions.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00740"
  },
  "2312.00733": {
    "title": "Provable bounds for noise-free expectation values computed from noisy samples",
    "authors": [
      "Samantha V. Barron",
      "Daniel J. Egger",
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz",
      "Matthis Lehmkuehler",
      "Stefan Woerner"
    ],
    "abstract": "In this paper, we explore the impact of noise on quantum computing, particularly focusing on the challenges when sampling bit strings from noisy quantum computers as well as the implications for optimization and machine learning applications. We formally quantify the sampling overhead to extract good samples from noisy quantum computers and relate it to the layer fidelity, a metric to determine the performance of noisy quantum processors. Further, we show how this allows us to use the Conditional Value at Risk of noisy samples to determine provable bounds on noise-free expectation values. We discuss how to leverage these bounds for different algorithms and demonstrate our findings through experiments on a real quantum computer involving up to 127 qubits. The results show a strong alignment with theoretical predictions.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00733"
  },
  "2312.00727": {
    "title": "Safe Reinforcement Learning in Tensor Reproducing Kernel Hilbert Space",
    "authors": [
      "Xiaoyuan Cheng",
      "Boli Chen",
      "Liz Varga",
      "Yukun Hu"
    ],
    "abstract": "This paper delves into the problem of safe reinforcement learning (RL) in a partially observable environment with the aim of achieving safe-reachability objectives. In traditional partially observable Markov decision processes (POMDP), ensuring safety typically involves estimating the belief in latent states. However, accurately estimating an optimal Bayesian filter in POMDP to infer latent states from observations in a continuous state space poses a significant challenge, largely due to the intractable likelihood. To tackle this issue, we propose a stochastic model-based approach that guarantees RL safety almost surely in the face of unknown system dynamics and partial observation environments. We leveraged the Predictive State Representation (PSR) and Reproducing Kernel Hilbert Space (RKHS) to represent future multi-step observations analytically, and the results in this context are provable. Furthermore, we derived essential operators from the kernel Bayes' rule, enabling the recursive estimation of future observations using various operators. Under the assumption of \\textit{undercompleness}, a polynomial sample complexity is established for the RL algorithm for the infinite size of observation and action spaces, ensuring an $\u03b5-$suboptimal safe policy guarantee.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00727"
  },
  "2312.00720": {
    "title": "Efficiently Processing Large Relational Joins on GPUs",
    "authors": [
      "Bowen Wu",
      "Dimitrios Koutsoukos",
      "Gustavo Alonso"
    ],
    "abstract": "With the growing interest in Machine Learning (ML), Graphic Processing Units (GPUs) have become key elements of any computing infrastructure. Their widespread deployment in data centers and the cloud raises the question of how to use them beyond ML use cases, with growing interest in employing them in a database context. In this paper, we explore and analyze the implementation of relational joins on GPUs from an end-to-end perspective, meaning that we take result materialization into account. We conduct a comprehensive performance study of state-of-the-art GPU-based join algorithms over diverse synthetic workloads and TPC-H/TPC-DS benchmarks. Without being restricted to the conventional setting where each input relation has only one key and one non-key with all attributes being 4-bytes long, we investigate the effect of various factors (e.g., input sizes, number of non-key columns, skewness, data types, match ratios, and number of joins) on the end-to-end throughput. Furthermore, we propose a technique called \"Gather-from-Transformed-Relations\" (GFTR) to reduce the long-ignored yet high materialization cost in GPU-based joins. The experimental evaluation shows significant performance improvements from GFTR, with throughput gains of up to 2.3 times over previous work. The insights gained from the performance study not only advance the understanding of GPU-based joins but also introduce a structured approach to selecting the most efficient GPU join algorithm based on the input relation characteristics.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00720"
  },
  "2312.00718": {
    "title": "Removing Biases from Molecular Representations via Information Maximization",
    "authors": [
      "Chenyu Wang",
      "Sharut Gupta",
      "Caroline Uhler",
      "Tommi Jaakkola"
    ],
    "abstract": "High-throughput drug screening -- using cell imaging or gene expression measurements as readouts of drug effect -- is a critical tool in biotechnology to assess and understand the relationship between the chemical structure and biological activity of a drug. Since large-scale screens have to be divided into multiple experiments, a key difficulty is dealing with batch effects, which can introduce systematic errors and non-biological associations in the data. We propose InfoCORE, an Information maximization approach for COnfounder REmoval, to effectively deal with batch effects and obtain refined molecular representations. InfoCORE establishes a variational lower bound on the conditional mutual information of the latent representations given a batch identifier. It adaptively reweighs samples to equalize their implied batch distribution. Extensive experiments on drug screening data reveal InfoCORE's superior performance in a multitude of tasks including molecular property prediction and molecule-phenotype retrieval. Additionally, we show results for how InfoCORE offers a versatile framework and resolves general distribution shifts and issues of data fairness by minimizing correlation with spurious features or removing sensitive attributes. The code is available at https://github.com/uhlerlab/InfoCORE.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00718"
  },
  "2312.00714": {
    "title": "Zipr: A High-Impact, Robust, Open-source, Multi-platform, Static Binary Rewriter",
    "authors": [
      "Jason D. Hiser",
      "Anh Nguyen-Tuong",
      "Jack W. Davidson"
    ],
    "abstract": "Zipr is a tool for static binary rewriting, first published in 2016. Zipr was engineered to support arbitrary program modification with an emphasis on low overhead, robustness, and flexibility to perform security enhancements and instrumentation. Originally targeted to Linux x86-32 binaries, Zipr now supports 32- and 64-bit binaries for X86, ARM, and MIPS architectures, as well as preliminary support for Windows programs.\n  These features have helped Zipr make a dramatic impact on research. It was first used in the DARPA Cyber Grand Challenge to take second place overall, with the best security score of any participant, Zipr has now been used in a variety of research areas by both the original authors as well as third parties. Zipr has also led to publications in artificial diversity, program instrumentation, program repair, fuzzing, autonomous vehicle security, research computing security, as well as directly contributing to two student dissertations. The open-source repository has accepted accepted patches from several external authors, demonstrating the impact of Zipr beyond the original authors.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00714"
  },
  "2312.00710": {
    "title": "SpaCE: The Spatial Confounding Environment",
    "authors": [
      "Mauricio Tec",
      "Ana Trisovic",
      "Michelle Audirac",
      "Sophie Woodward",
      "Jie Kate Hu",
      "Naeem Khoshnevis",
      "Francesca Dominici"
    ],
    "abstract": "Spatial confounding poses a significant challenge in scientific studies involving spatial data, where unobserved spatial variables can influence both treatment and outcome, possibly leading to spurious associations. To address this problem, we introduce SpaCE: The Spatial Confounding Environment, the first toolkit to provide realistic benchmark datasets and tools for systematically evaluating causal inference methods designed to alleviate spatial confounding. Each dataset includes training data, true counterfactuals, a spatial graph with coordinates, and smoothness and confounding scores characterizing the effect of a missing spatial confounder. It also includes realistic semi-synthetic outcomes and counterfactuals, generated using state-of-the-art machine learning ensembles, following best practices for causal inference benchmarks. The datasets cover real treatment and covariates from diverse domains, including climate, health and social sciences. SpaCE facilitates an automated end-to-end pipeline, simplifying data loading, experimental setup, and evaluating machine learning and causal inference models. The SpaCE project provides several dozens of datasets of diverse sizes and spatial complexity. It is publicly available as a Python package, encouraging community feedback and contributions.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.00710"
  },
  "2312.00702": {
    "title": "A Holistic Approach for Trustworthy Distributed Systems with WebAssembly and TEEs",
    "authors": [
      "J\u00e4mes M\u00e9n\u00e9trey",
      "Aeneas Gr\u00fcter",
      "Peterson Yuhala",
      "Julius Oeftiger",
      "Pascal Felber",
      "Marcelo Pasin",
      "Valerio Schiavoni"
    ],
    "abstract": "Publish/subscribe systems play a key role in enabling communication between numerous devices in distributed and large-scale architectures. While widely adopted, securing such systems often trades portability for additional integrity and attestation guarantees. Trusted Execution Environments (TEEs) offer a potential solution with enclaves to enhance security and trust. However, application development for TEEs is complex, and many existing solutions are tied to specific TEE architectures, limiting adaptability. Current communication protocols also inadequately manage attestation proofs or expose essential attestation information. This paper introduces a novel approach using WebAssembly to address these issues, a key enabling technology nowadays capturing academia and industry attention. We present the design of a portable and fully attested publish/subscribe middleware system as a holistic approach for trustworthy and distributed communication between various systems. Based on this proposal, we have implemented and evaluated in-depth a fully-fledged publish/subscribe broker running within Intel SGX, compiled in WebAssembly, and built on top of industry-battled frameworks and standards, i.e., MQTT and TLS protocols. Our extended TLS protocol preserves the privacy of attestation information, among other benefits. Our experimental results showcase most overheads, revealing a 1.55x decrease in message throughput when using a trusted broker. We open-source the contributions of this work to the research community to facilitate experimental reproducibility.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00702"
  },
  "2312.00699": {
    "title": "Rethinking Detection Based Table Structure Recognition for Visually Rich Document Images",
    "authors": [
      "Bin Xiao",
      "Murat Simsek",
      "Burak Kantarci",
      "Ala Abu Alkheir"
    ],
    "abstract": "Table Structure Recognition (TSR) is a widely discussed task aiming at transforming unstructured table images into structured formats, such as HTML sequences, to make text-only models, such as ChatGPT, that can further process these tables. One type of solution is using detection models to detect table components, such as columns and rows, then applying a rule-based post-processing method to convert detection results into HTML sequences. However, existing detection-based models usually cannot perform as well as other types of solutions regarding cell-level TSR metrics, such as TEDS, and the underlying reasons limiting the performance of these models on the TSR task are also not well-explored. Therefore, we revisit existing detection-based models comprehensively and explore the underlying reasons hindering these models' performance, including the improper problem definition, the mismatch issue of detection and TSR metrics, the characteristics of detection models, and the impact of local and long-range features extraction. Based on our analysis and findings, we apply simple methods to tailor a typical two-stage detection model, Cascade R-CNN, for the TSR task. The experimental results show that the tailored Cascade R-CNN based model can improve the base Cascade R-CNN model by 16.35\\% on the FinTabNet dataset regarding the structure-only TEDS, outperforming other types of state-of-the-art methods, demonstrating that our findings can be a guideline for improving detection-based TSR models and that a purely detection-based solution is competitive with other types of solutions, such as graph-based and image-to-sequence solutions.\n        \u25b3 Less",
    "submission_date": "10 January, 2024",
    "eprint_id": "2312.00699"
  },
  "2312.00694": {
    "title": "Object Detector Differences when using Synthetic and Real Training Data",
    "authors": [
      "Martin Georg Ljungqvist",
      "Otto Nordander",
      "Markus Skans",
      "Arvid Mildner",
      "Tony Liu",
      "Pierre Nugues"
    ],
    "abstract": "To train well-performing generalizing neural networks, sufficiently large and diverse datasets are needed. Collecting data while adhering to privacy legislation becomes increasingly difficult and annotating these large datasets is both a resource-heavy and time-consuming task. An approach to overcome these difficulties is to use synthetic data since it is inherently scalable and can be automatically annotated. However, how training on synthetic data affects the layers of a neural network is still unclear. In this paper, we train the YOLOv3 object detector on real and synthetic images from city environments. We perform a similarity analysis using Centered Kernel Alignment (CKA) to explore the effects of training on synthetic data on a layer-wise basis. The analysis captures the architecture of the detector while showing both different and similar patterns between different models. With this similarity analysis we want to give insights on how training synthetic data affects each layer and to give a better understanding of the inner workings of complex neural networks. The results show that the largest similarity between a detector trained on real data and a detector trained on synthetic data was in the early layers, and the largest difference was in the head part. The results also show that no major difference in performance or similarity could be seen between frozen and unfrozen backbone.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00694"
  },
  "2312.00692": {
    "title": "VisionaryVR: An Optical Simulation Tool for Evaluating and Optimizing Vision Correction Solutions in Virtual Reality",
    "authors": [
      "Benedikt W. Hosp",
      "Martin Dechant",
      "Yannick Sauer",
      "Rajat Agarwala",
      "Siegfried Wahl"
    ],
    "abstract": "Developing and evaluating vision science methods require robust and efficient tools for assessing their performance in various real-world scenarios. This study presents a novel virtual reality (VR) simulation tool that simulates real-world optical methods while giving high experimental control to the experiment. The tool incorporates an experiment controller, to smoothly and easily handle multiple conditions, a generic eye-tracking controller, that works with most common VR eye-trackers, a configurable defocus simulator, and a generic VR questionnaire loader to assess participants' behavior in virtual reality. This VR-based simulation tool bridges the gap between theoretical and applied research on new optical methods, corrections, and therapies. It enables vision scientists to increase their research tools with a robust, realistic, and fast research environment.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00692"
  },
  "2312.00689": {
    "title": "Infrared Image Super-Resolution via GAN",
    "authors": [
      "Yongsong Huang",
      "Shinichiro Omachi"
    ],
    "abstract": "The ability of generative models to accurately fit data distributions has resulted in their widespread adoption and success in fields such as computer vision and natural language processing. In this chapter, we provide a brief overview of the application of generative models in the domain of infrared (IR) image super-resolution, including a discussion of the various challenges and adversarial training methods employed. We propose potential areas for further investigation and advancement in the application of generative models for IR image super-resolution.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00689"
  },
  "2312.00688": {
    "title": "Towards Transparency in Coreference Resolution: A Quantum-Inspired Approach",
    "authors": [
      "Hadi Wazni",
      "Mehrnoosh Sadrzadeh"
    ],
    "abstract": "Guided by grammatical structure, words compose to form sentences, and guided by discourse structure, sentences compose to form dialogues and documents. The compositional aspect of sentence and discourse units is often overlooked by machine learning algorithms. A recent initiative called Quantum Natural Language Processing (QNLP) learns word meanings as points in a Hilbert space and acts on them via a translation of grammatical structure into Parametrised Quantum Circuits (PQCs). Previous work extended the QNLP translation to discourse structure using points in a closure of Hilbert spaces. In this paper, we evaluate this translation on a Winograd-style pronoun resolution task. We train a Variational Quantum Classifier (VQC) for binary classification and implement an end-to-end pronoun resolution system. The simulations executed on IBMQ software converged with an F1 score of 87.20%. The model outperformed two out of three classical coreference resolution systems and neared state-of-the-art SpanBERT. A mixed quantum-classical model yet improved these results with an F1 score increase of around 6%.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00688"
  },
  "2312.00686": {
    "title": "Classification of cyber attacks on IoT and ubiquitous computing devices",
    "authors": [
      "Monika Freunek",
      "Alexandra Rombos"
    ],
    "abstract": "As the Internet of Things (IoT) has become truly ubiquitous, so has the surrounding threat landscape. However, while the security of classical computing systems has significantly matured in the last decades, IoT cybersecurity is still typically low or fully neglected. This paper provides a classification of IoT malware. Major targets and used exploits for attacks are identified and referred to the specific malware. The lack of standard definitions of IoT devices and, therefore, security goals has been identified during this research as a profound barrier in advancing IoT cybersecurity. Furthermore, standardized reporting of IoT malware by trustworthy sources is required in the field. The majority of current IoT attacks continue to be of comparably low effort and level of sophistication and could be mitigated by existing technical measures.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00686"
  },
  "2312.00685": {
    "title": "How to Tune Autofocals: A Comparative Study of Advanced Tuning Methods",
    "authors": [
      "Benedikt W. Hosp",
      "Yannick Sauer",
      "Bj\u00f6rn Severitt",
      "Rajat Agarwala",
      "Siegfried Wahl"
    ],
    "abstract": "This study comprehensively evaluates tuning methods for autofocal glasses using virtual reality (VR), addressing the challenge of presbyopia. With aging, presbyopia diminishes the eye's ability to focus on nearby objects, impacting the quality of life for billions. Autofocals, employing focus-tunable lenses, dynamically adjust optical power for each fixation, promising a more natural visual experience than traditional bifocal or multifocal lenses. Our research contrasts the most common tuning methods - manual, gaze-based, and vergence - within a VR setup to mimic real-world scenarios. Utilizing the XTAL VR headset equipped with eye-tracking, the study replicated autofocal scenarios, measuring performance and usability through psychophysical tasks and NASA TLX surveys. Results show varying strengths and weaknesses across methods, with gaze control excelling in precision but not necessarily comfort and manual control providing stability and predictability. The findings guide the selection of tuning methods based on task requirements and user preferences, highlighting a balance between precision and ease of use.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00685"
  },
  "2312.00681": {
    "title": "Applicability of Blockchain Technology in Avionics Systems",
    "authors": [
      "Harun Celik",
      "Aysenur Sayil"
    ],
    "abstract": "Blockchain technology, within its fast widespread and superiority demonstrated by recent studies, can be also used as an informatic tool for solving various aviation problems. Aviation electronics (avionics) systems stand out as the application area of informatics methods in solving aviation problems or providing different capabilities to aircrafts. Avionics systems are electronic systems used in air and space vehicles for many purposes such as surveillance, navigation and communication. In this study, the applicability of blockchain technology as a new approach in the development of avionics systems is discussed, and in this regard, a method inspired by the previously implemented applications in electronic flight systems is proposed to help evaluate the applicability of this technology in new avionics system designs. The potential of blockchain for solving the problems especially in basic services, communication, navigation and flight management systems; the problem structures for which application of this technology would be a reliable solution; and the superiority and inferiority of its use in avionic systems are explained. A guiding paper is proposed for aviation engineers/experts to make a decision on applying blockchain into avionics systems.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00681"
  },
  "2312.00680": {
    "title": "Contextualized word senses: from attention to compositionality",
    "authors": [
      "Pablo Gamallo"
    ],
    "abstract": "The neural architectures of language models are becoming increasingly complex, especially that of Transformers, based on the attention mechanism. Although their application to numerous natural language processing tasks has proven to be very fruitful, they continue to be models with little or no interpretability and explainability. One of the tasks for which they are best suited is the encoding of the contextual sense of words using contextualized embeddings. In this paper we propose a transparent, interpretable, and linguistically motivated strategy for encoding the contextual sense of words by modeling semantic compositionality. Particular attention is given to dependency relations and semantic notions such as selection preferences and paradigmatic classes. A partial implementation of the proposed model is carried out and compared with Transformer-based architectures for a given semantic task, namely the similarity calculation of word senses in context. The results obtained show that it is possible to be competitive with linguistically motivated models instead of using the black boxes underlying complex neural architectures.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00680"
  },
  "2312.00677": {
    "title": "Unsupervised Adaptive Implicit Neural Representation Learning for Scan-Specific MRI Reconstruction",
    "authors": [
      "Junwei Yang",
      "Pietro Li\u00f2"
    ],
    "abstract": "In recent studies on MRI reconstruction, advances have shown significant promise for further accelerating the MRI acquisition. Most state-of-the-art methods require a large amount of fully-sampled data to optimise reconstruction models, which is impractical and expensive under certain clinical settings. On the other hand, for unsupervised scan-specific reconstruction methods, overfitting is likely to happen due to insufficient supervision, while restrictions on acceleration rates and under-sampling patterns further limit their applicability. To this end, we propose an unsupervised, adaptive coarse-to-fine framework that enhances reconstruction quality without being constrained by the sparsity levels or patterns in under-sampling. The framework employs an implicit neural representation for scan-specific MRI reconstruction, learning a mapping from multi-dimensional coordinates to their corresponding signal intensities. Moreover, we integrate a novel learning strategy that progressively refines the use of acquired k-space signals for self-supervision. This approach effectively adjusts the proportion of supervising signals from unevenly distributed information across different frequency bands, thus mitigating the issue of overfitting while improving the overall reconstruction. Comprehensive evaluation on a public dataset, including both 2D and 3D data, has shown that our method outperforms current state-of-the-art scan-specific MRI reconstruction techniques, for up to 8-fold under-sampling.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00677"
  },
  "2312.00674": {
    "title": "LightCLIP: Learning Multi-Level Interaction for Lightweight Vision-Language Models",
    "authors": [
      "Ying Nie",
      "Wei He",
      "Kai Han",
      "Yehui Tang",
      "Tianyu Guo",
      "Fanyi Du",
      "Yunhe Wang"
    ],
    "abstract": "Vision-language pre-training like CLIP has shown promising performance on various downstream tasks such as zero-shot image classification and image-text retrieval. Most of the existing CLIP-alike works usually adopt relatively large image encoders like ResNet50 and ViT, while the lightweight counterparts are rarely discussed. In this paper, we propose a multi-level interaction paradigm for training lightweight CLIP models. Firstly, to mitigate the problem that some image-text pairs are not strictly one-to-one correspondence, we improve the conventional global instance-level alignment objective by softening the label of negative samples progressively. Secondly, a relaxed bipartite matching based token-level alignment objective is introduced for finer-grained alignment between image patches and textual words. Moreover, based on the observation that the accuracy of CLIP model does not increase correspondingly as the parameters of text encoder increase, an extra objective of masked language modeling (MLM) is leveraged for maximizing the potential of the shortened text encoder. In practice, an auxiliary fusion module injecting unmasked image embedding into masked text embedding at different network stages is proposed for enhancing the MLM. Extensive experiments show that without introducing additional computational cost during inference, the proposed method achieves a higher performance on multiple downstream tasks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00674"
  },
  "2312.00671": {
    "title": "CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous Cell Populations",
    "authors": [
      "Mehdi Naouar",
      "Gabriel Kalweit",
      "Anusha Klett",
      "Yannick Vogt",
      "Paula Silvestrini",
      "Diana Laura Infante Ramirez",
      "Roland Mertelsmann",
      "Joschka Boedecker",
      "Maria Kalweit"
    ],
    "abstract": "In recent years, several unsupervised cell segmentation methods have been presented, trying to omit the requirement of laborious pixel-level annotations for the training of a cell segmentation model. Most if not all of these methods handle the instance segmentation task by focusing on the detection of different cell instances ignoring their type. While such models prove adequate for certain tasks, like cell counting, other applications require the identification of each cell's type. In this paper, we present CellMixer, an innovative annotation-free approach for the semantic segmentation of heterogeneous cell populations. Our augmentation-based method enables the training of a segmentation model from image-level labels of homogeneous cell populations. Our results show that CellMixer can achieve competitive segmentation performance across multiple cell types and imaging modalities, demonstrating the method's scalability and potential for broader applications in medical imaging, cellular biology, and diagnostics.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00671"
  },
  "2312.00663": {
    "title": "Generalized Label-Efficient 3D Scene Parsing via Hierarchical Feature Aligned Pre-Training and Region-Aware Fine-tuning",
    "authors": [
      "Kangcheng Liu",
      "Yong-Jin Liu",
      "Kai Tang",
      "Ming Liu",
      "Baoquan Chen"
    ],
    "abstract": "Deep neural network models have achieved remarkable progress in 3D scene understanding while trained in the closed-set setting and with full labels. However, the major bottleneck for current 3D recognition approaches is that they do not have the capacity to recognize any unseen novel classes beyond the training categories in diverse kinds of real-world applications. In the meantime, current state-of-the-art 3D scene understanding approaches primarily require high-quality labels to train neural networks, which merely perform well in a fully supervised manner. This work presents a generalized and simple framework for dealing with 3D scene understanding when the labeled scenes are quite limited. To extract knowledge for novel categories from the pre-trained vision-language models, we propose a hierarchical feature-aligned pre-training and knowledge distillation strategy to extract and distill meaningful information from large-scale vision-language models, which helps benefit the open-vocabulary scene understanding tasks. To leverage the boundary information, we propose a novel energy-based loss with boundary awareness benefiting from the region-level boundary predictions. To encourage latent instance discrimination and to guarantee efficiency, we propose the unsupervised region-level semantic contrastive learning scheme for point clouds, using confident predictions of the neural network to discriminate the intermediate feature embeddings at multiple stages. Extensive experiments with both indoor and outdoor scenes demonstrated the effectiveness of our approach in both data-efficient learning and open-world few-shot learning. All codes, models, and data are made publicly available at: https://drive.google.com/drive/folders/1M58V-PtR8DBEwD296zJkNg_m2qq-MTAP?usp=sharing.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00663"
  },
  "2312.00662": {
    "title": "Nonparametric Variational Regularisation of Pretrained Transformers",
    "authors": [
      "Fabio Fehr",
      "James Henderson"
    ],
    "abstract": "The current paradigm of large-scale pre-training and fine-tuning Transformer large language models has lead to significant improvements across the board in natural language processing. However, such large models are susceptible to overfitting to their training data, and as a result the models perform poorly when the domain changes. Also, due to the model's scale, the cost of fine-tuning the model to the new domain is large. Nonparametric Variational Information Bottleneck (NVIB) has been proposed as a regulariser for training cross-attention in Transformers, potentially addressing the overfitting problem. We extend the NVIB framework to replace all types of attention functions in Transformers, and show that existing pretrained Transformers can be reinterpreted as Nonparametric Variational (NV) models using a proposed identity initialisation. We then show that changing the initialisation introduces a novel, information-theoretic post-training regularisation in the attention mechanism, which improves out-of-domain generalisation without any training. This success supports the hypothesis that pretrained Transformers are implicitly NV Bayesian models.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00662"
  },
  "2312.00661": {
    "title": "Dual-Domain Multi-Contrast MRI Reconstruction with Synthesis-based Fusion Network",
    "authors": [
      "Junwei Yang",
      "Pietro Li\u00f2"
    ],
    "abstract": "Purpose: To develop an efficient dual-domain reconstruction framework for multi-contrast MRI, with the focus on minimising cross-contrast misalignment in both the image and the frequency domains to enhance optimisation. Theory and Methods: Our proposed framework, based on deep learning, facilitates the optimisation for under-sampled target contrast using fully-sampled reference contrast that is quicker to acquire. The method consists of three key steps: 1) Learning to synthesise data resembling the target contrast from the reference contrast; 2) Registering the multi-contrast data to reduce inter-scan motion; and 3) Utilising the registered data for reconstructing the target contrast. These steps involve learning in both domains with regularisation applied to ensure their consistency. We also compare the reconstruction performance with existing deep learning-based methods using a dataset of brain MRI scans. Results: Extensive experiments demonstrate the superiority of our proposed framework, for up to an 8-fold acceleration rate, compared to state-of-the-art algorithms. Comprehensive analysis and ablation studies further present the effectiveness of the proposed components. Conclusion:Our dual-domain framework offers a promising approach to multi-contrast MRI reconstruction. It can also be integrated with existing methods to further enhance the reconstruction.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00661"
  },
  "2312.00660": {
    "title": "Resource-constrained knowledge diffusion processes inspired by human peer learning",
    "authors": [
      "Ehsan Beikihassan",
      "Amy K. Hoover",
      "Ioannis Koutis",
      "Ali Parviz",
      "Niloofar Aghaieabiane"
    ],
    "abstract": "We consider a setting where a population of artificial learners is given, and the objective is to optimize aggregate measures of performance, under constraints on training resources. The problem is motivated by the study of peer learning in human educational systems. In this context, we study natural knowledge diffusion processes in networks of interacting artificial learners. By `natural', we mean processes that reflect human peer learning where the students' internal state and learning process is mostly opaque, and the main degree of freedom lies in the formation of peer learning groups by a coordinator who can potentially evaluate the learners before assigning them to peer groups. Among else, we empirically show that such processes indeed make effective use of the training resources, and enable the design of modular neural models that have the capacity to generalize without being prone to overfitting noisy labels.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00660"
  },
  "2312.00656": {
    "title": "Simple Transferability Estimation for Regression Tasks",
    "authors": [
      "Cuong N. Nguyen",
      "Phong Tran",
      "Lam Si Tung Ho",
      "Vu Dinh",
      "Anh T. Tran",
      "Tal Hassner",
      "Cuong V. Nguyen"
    ],
    "abstract": "We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 12% to 36% better results on average while being at least 27% faster than previous state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.00656"
  },
  "2312.00655": {
    "title": "Machine Learning for Health symposium 2023 -- Findings track",
    "authors": [
      "Stefan Hegselmann",
      "Antonio Parziale",
      "Divya Shanmugam",
      "Shengpu Tang",
      "Mercy Nyamewaa Asiedu",
      "Serina Chang",
      "Thomas Hartvigsen",
      "Harvineet Singh"
    ],
    "abstract": "A collection of the accepted Findings papers that were presented at the 3rd Machine Learning for Health symposium (ML4H 2023), which was held on December 10, 2023, in New Orleans, Louisiana, USA. ML4H 2023 invited high-quality submissions on relevant problems in a variety of health-related disciplines including healthcare, biomedicine, and public health. Two submission tracks were offered: the archival Proceedings track, and the non-archival Findings track. Proceedings were targeted at mature work with strong technical sophistication and a high impact to health. The Findings track looked for new ideas that could spark insightful discussion, serve as valuable resources for the community, or could enable new collaborations. Submissions to the Proceedings track, if not accepted, were automatically considered for the Findings track. All the manuscripts submitted to ML4H Symposium underwent a double-blind peer-review process.\n        \u25b3 Less",
    "submission_date": "15 December, 2023",
    "eprint_id": "2312.00655"
  },
  "2312.00647": {
    "title": "MaxMem: Colocation and Performance for Big Data Applications on Tiered Main Memory Servers",
    "authors": [
      "Amanda Raybuck",
      "Wei Zhang",
      "Kayvan Mansoorshahi",
      "Aditya K. Kamath",
      "Mattan Erez",
      "Simon Peter"
    ],
    "abstract": "We present MaxMem, a tiered main memory management system that aims to maximize Big Data application colocation and performance. MaxMem uses an application-agnostic and lightweight memory occupancy control mechanism based on fast memory miss ratios to provide application QoS under increasing colocation. By relying on memory access sampling and binning to quickly identify per-process memory heat gradients, MaxMem maximizes performance for many applications sharing tiered main memory simultaneously. MaxMem is designed as a user-space memory manager to be easily modifiable and extensible, without complex kernel code development. On a system with tiered main memory consisting of DRAM and Intel Optane persistent memory modules, our evaluation confirms that MaxMem provides 11% and 38% better throughput and up to 80% and an order of magnitude lower 99th percentile latency than HeMem and Linux AutoNUMA, respectively, with a Big Data key-value store in dynamic colocation scenarios.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00647"
  },
  "2312.00645": {
    "title": "Hashmarks: Privacy-Preserving Benchmarks for High-Stakes AI Evaluation",
    "authors": [
      "Paul Bricman"
    ],
    "abstract": "There is a growing need to gain insight into language model capabilities that relate to sensitive topics, such as bioterrorism or cyberwarfare. However, traditional open source benchmarks are not fit for the task, due to the associated practice of publishing the correct answers in human-readable form. At the same time, enforcing mandatory closed-quarters evaluations might stifle development and erode trust. In this context, we propose hashmarking, a protocol for evaluating language models in the open without having to disclose the correct answers. In its simplest form, a hashmark is a benchmark whose reference solutions have been cryptographically hashed prior to publication. Following an overview of the proposed evaluation protocol, we go on to assess its resilience against traditional attack vectors (e.g. rainbow table attacks), as well as against failure modes unique to increasingly capable generative models.\n        \u25b3 Less",
    "submission_date": "25 December, 2023",
    "eprint_id": "2312.00645"
  },
  "2312.00640": {
    "title": "One to beat them all: \"RYU'' -- a unifying framework for the construction of safe balls",
    "authors": [
      "Thu-Le Tran",
      "Cl\u00e9ment Elvira",
      "Hong-Phuong Dang",
      "C\u00e9dric Herzet"
    ],
    "abstract": "In this paper, we put forth a novel framework (named ``RYU'') for the construction of ``safe'' balls, i.e. regions that provably contain the dual solution of a target optimization problem. We concentrate on the standard setup where the cost function is the sum of two terms: a closed, proper, convex Lipschitz-smooth function and a closed, proper, convex function. The RYU framework is shown to generalize or improve upon all the results proposed in the last decade for the considered family of optimization problems.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00640"
  },
  "2312.00638": {
    "title": "What if an SQL Statement Returned a Database?",
    "authors": [
      "Joris Nix",
      "Jens Dittrich"
    ],
    "abstract": "Every SQL statement is limited to return a single, possibly denormalized, table. This design decision has far reaching consequences. (1.) for databases users in terms of slow query performance, long query result transfer times, usability-issues of SQL in web applications and object-relational mappers. In addition, (2.) for database architects it has consequences when designing query optimizers leading to logical (algebraic) join enumeration effort, memory consumption for intermediate result materialization, and physical operator selection effort. So basically, the entire query optimization stack is shaped by that design decision. In this paper, we argue that the single-table limitation should be dropped. We extend the SELECT-clause of SQL by a keyword 'RESULTDB' to support returning a result database. Our approach has clear semantics, i.e. our extended SQL returns subsets of all tables with only those tuples that would be part of the traditional (single-table) query result set, however without performing any denormalization through joins. Our SQL-extension is downward compatible. Moreover, we discuss the surprisingly long list of benefits of our approach. First, for database users: far simpler and more readable application code, better query performance, smaller query results, better query result transfer times. Second, for database architects, we present how to leverage existing closed source systems as well as change open source database systems to support our feature. We propose a couple of algorithms to integrate our feature into both closed-source as well as open source database systems. We present an initial experimental study with promising results.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00638"
  },
  "2312.00634": {
    "title": "A Recent Survey of Vision Transformers for Medical Image Segmentation",
    "authors": [
      "Asifullah Khan",
      "Zunaira Rauf",
      "Abdul Rehman Khan",
      "Saima Rathore",
      "Saddam Hussain Khan",
      "Najmus Saher Shah",
      "Umair Farooq",
      "Hifsa Asif",
      "Aqsa Asif",
      "Umme Zahoora",
      "Rafi Ullah Khalil",
      "Suleman Qamar",
      "Umme Hani Asif",
      "Faiza Babar Khan",
      "Abdul Majid",
      "Jeonghwan Gwak"
    ],
    "abstract": "Medical image segmentation plays a crucial role in various healthcare applications, enabling accurate diagnosis, treatment planning, and disease monitoring. Traditionally, convolutional neural networks (CNNs) dominated this domain, excelling at local feature extraction. However, their limitations in capturing long-range dependencies across image regions pose challenges for segmenting complex, interconnected structures often encountered in medical data. In recent years, Vision Transformers (ViTs) have emerged as a promising technique for addressing the challenges in medical image segmentation. Their multi-scale attention mechanism enables effective modeling of long-range dependencies between distant structures, crucial for segmenting organs or lesions spanning the image. Additionally, ViTs' ability to discern subtle pattern heterogeneity allows for the precise delineation of intricate boundaries and edges, a critical aspect of accurate medical image segmentation. However, they do lack image-related inductive bias and translational invariance, potentially impacting their performance. Recently, researchers have come up with various ViT-based approaches that incorporate CNNs in their architectures, known as Hybrid Vision Transformers (HVTs) to capture local correlation in addition to the global information in the images. This survey paper provides a detailed review of the recent advancements in ViTs and HVTs for medical image segmentation. Along with the categorization of ViT and HVT-based medical image segmentation approaches, we also present a detailed overview of their real-time applications in several medical image modalities. This survey may serve as a valuable resource for researchers, healthcare practitioners, and students in understanding the state-of-the-art approaches for ViT-based medical image segmentation.\n        \u25b3 Less",
    "submission_date": "18 December, 2023",
    "eprint_id": "2312.00634"
  },
  "2312.00633": {
    "title": "Towards Efficient 3D Object Detection in Bird's-Eye-View Space for Autonomous Driving: A Convolutional-Only Approach",
    "authors": [
      "Yuxin Li",
      "Qiang Han",
      "Mengying Yu",
      "Yuxin Jiang",
      "Chaikiat Yeo",
      "Yiheng Li",
      "Zihang Huang",
      "Nini Liu",
      "Hsuanhan Chen",
      "Xiaojun Wu"
    ],
    "abstract": "3D object detection in Bird's-Eye-View (BEV) space has recently emerged as a prevalent approach in the field of autonomous driving. Despite the demonstrated improvements in accuracy and velocity estimation compared to perspective view methods, the deployment of BEV-based techniques in real-world autonomous vehicles remains challenging. This is primarily due to their reliance on vision-transformer (ViT) based architectures, which introduce quadratic complexity with respect to the input resolution. To address this issue, we propose an efficient BEV-based 3D detection framework called BEVENet, which leverages a convolutional-only architectural design to circumvent the limitations of ViT models while maintaining the effectiveness of BEV-based methods. Our experiments show that BEVENet is 3$\\times$ faster than contemporary state-of-the-art (SOTA) approaches on the NuScenes challenge, achieving a mean average precision (mAP) of 0.456 and a nuScenes detection score (NDS) of 0.555 on the NuScenes validation dataset, with an inference speed of 47.6 frames per second. To the best of our knowledge, this study stands as the first to achieve such significant efficiency improvements for BEV-based methods, highlighting their enhanced feasibility for real-world autonomous driving applications.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00633"
  },
  "2312.00629": {
    "title": "The Ecosystem of Trust (EoT): Enabling effective deployment of autonomous systems through collaborative and trusted ecosystems",
    "authors": [
      "Jon Arne Glomsrud",
      "Tita Alissa Bach"
    ],
    "abstract": "Ecosystems are ubiquitous but trust within them is not guaranteed. Trust is paramount because stakeholders within an ecosystem must collaborate to achieve their objectives. With the twin transitions, digital transformation to go in parallel with green transition, accelerating the deployment of autonomous systems, trust has become even more critical to ensure that the deployed technology creates value. To address this need, we propose an ecosystem of trust approach to support deployment of technology by enabling trust among and between stakeholders, technologies and infrastructures, institutions and governance, and the artificial and natural environments in an ecosystem. The approach can help the stakeholders in the ecosystem to create, deliver, and receive value by addressing their concerns and aligning their objectives. We present an autonomous, zero emission ferry as a real world use case to demonstrate the approach from a stakeholder perspective. We argue that assurance, defined as grounds for justified confidence originated from evidence and knowledge, is a prerequisite to enable the approach. Assurance provides evidence and knowledge that are collected, analysed, and communicated in a systematic, targeted, and meaningful way. Assurance can enable the approach to help successfully deploy technology by ensuring that risk is managed, trust is shared, and value is created.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00629"
  },
  "2312.00627": {
    "title": "Rethinking the Domain Gap in Near-infrared Face Recognition",
    "authors": [
      "Michail Tarasiou",
      "Jiankang Deng",
      "Stefanos Zafeiriou"
    ],
    "abstract": "Heterogeneous face recognition (HFR) involves the intricate task of matching face images across the visual domains of visible (VIS) and near-infrared (NIR). While much of the existing literature on HFR identifies the domain gap as a primary challenge and directs efforts towards bridging it at either the input or feature level, our work deviates from this trend. We observe that large neural networks, unlike their smaller counterparts, when pre-trained on large scale homogeneous VIS data, demonstrate exceptional zero-shot performance in HFR, suggesting that the domain gap might be less pronounced than previously believed. By approaching the HFR problem as one of low-data fine-tuning, we introduce a straightforward framework: comprehensive pre-training, succeeded by a regularized fine-tuning strategy, that matches or surpasses the current state-of-the-art on four publicly available benchmarks. Corresponding codes can be found at https://github.com/michaeltrs/RethinkNIRVIS.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00627"
  },
  "2312.00626": {
    "title": "Forecasting Trends in Food Security: a Reservoir Computing Approach",
    "authors": [
      "Joschka Herteux",
      "Christoph R\u00e4th",
      "Amine Baha",
      "Giulia Martini",
      "Duccio Piovani"
    ],
    "abstract": "Early warning systems are an essential tool for effective humanitarian action. Advance warnings on impending disasters facilitate timely and targeted response which help save lives, livelihoods, and scarce financial resources. In this work we present a new quantitative methodology to forecast levels of food consumption for 60 consecutive days, at the sub-national level, in four countries: Mali, Nigeria, Syria, and Yemen. The methodology is built on publicly available data from the World Food Programme's integrated global hunger monitoring system which collects, processes, and displays daily updates on key food security metrics, conflict, weather events, and other drivers of food insecurity across 90 countries (https://hungermap.wfp.org/). In this study, we assessed the performance of various models including ARIMA, XGBoost, LSTMs, CNNs, and Reservoir Computing (RC), by comparing their Root Mean Squared Error (RMSE) metrics. This comprehensive analysis spanned classical statistical, machine learning, and deep learning approaches. Our findings highlight Reservoir Computing as a particularly well-suited model in the field of food security given both its notable resistance to over-fitting on limited data samples and its efficient training capabilities. The methodology we introduce establishes the groundwork for a global, data-driven early warning system designed to anticipate and detect food insecurity.\n        \u25b3 Less",
    "submission_date": "20 December, 2023",
    "eprint_id": "2312.00626"
  },
  "2312.00622": {
    "title": "Practical Path-based Bayesian Optimization",
    "authors": [
      "Jose Pablo Folch",
      "James Odgers",
      "Shiqiang Zhang",
      "Robert M Lee",
      "Behrang Shafei",
      "David Walz",
      "Calvin Tsay",
      "Mark van der Wilk",
      "Ruth Misener"
    ],
    "abstract": "There has been a surge in interest in data-driven experimental design with applications to chemical engineering and drug manufacturing. Bayesian optimization (BO) has proven to be adaptable to such cases, since we can model the reactions of interest as expensive black-box functions. Sometimes, the cost of this black-box functions can be separated into two parts: (a) the cost of the experiment itself, and (b) the cost of changing the input parameters. In this short paper, we extend the SnAKe algorithm to deal with both types of costs simultaneously. We further propose extensions to the case of a maximum allowable input change, as well as to the multi-objective setting.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00622"
  },
  "2312.00621": {
    "title": "Weighted Riesz Particles",
    "authors": [
      "Xiongming Dai",
      "Gerald Baumgartner"
    ],
    "abstract": "Markov chain Monte Carlo (MCMC) methods are simulated by local exploration of complex statistical distributions, and while bypassing the cumbersome requirement of a specific analytical expression for the target, this stochastic exploration of an uncertain parameter space comes at the expense of a large number of samples, and this computational complexity increases with parameter dimensionality. Although at the exploration level, some methods are proposed to accelerate the convergence of the algorithm, such as tempering, Hamiltonian Monte Carlo, Rao-redwellization, and scalable methods for better performance, it cannot avoid the stochastic nature of this exploration. We consider the target distribution as a mapping where the infinite-dimensional Eulerian space of the parameters consists of a number of deterministic submanifolds and propose a generalized energy metric, termed weighted Riesz energy, where a number of points is generated through pairwise interactions, to discretize rectifiable submanifolds. We study the properties of the point, called Riesz particle, and embed it into sequential MCMC, and we find that there will be higher acceptance rates with fewer evaluations, we validate it through experimental comparative analysis from a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility model with real-world data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00621"
  },
  "2312.00616": {
    "title": "Investigating a domain adaptation approach for integrating different measurement instruments in a longitudinal clinical registry",
    "authors": [
      "Maren Hackenberg",
      "Michelle Pfaffenlehner",
      "Max Behrens",
      "Astrid Pechmann",
      "Janbernd Kirschner",
      "Harald Binder"
    ],
    "abstract": "In a longitudinal clinical registry, different measurement instruments might have been used for assessing individuals at different time points. To combine them, we investigate deep learning techniques for obtaining a joint latent representation, to which the items of different measurement instruments are mapped. This corresponds to domain adaptation, an established concept in computer science for image data. Using the proposed approach as an example, we evaluate the potential of domain adaptation in a longitudinal cohort setting with a rather small number of time points, motivated by an application with different motor function measurement instruments in a registry of spinal muscular atrophy (SMA) patients. There, we model trajectories in the latent representation by ordinary differential equations (ODEs), where person-specific ODE parameters are inferred from baseline characteristics. The goodness of fit and complexity of the ODE solutions then allows to judge the measurement instrument mappings. We subsequently explore how alignment can be improved by incorporating corresponding penalty terms into model fitting. To systematically investigate the effect of differences between measurement instruments, we consider several scenarios based on modified SMA data, including scenarios where a mapping should be feasible in principle and scenarios where no perfect mapping is available. While misalignment increases in more complex scenarios, some structure is still recovered, even if the availability of measurement instruments depends on patient state. A reasonable mapping is feasible also in the more complex real SMA dataset. These results indicate that domain adaptation might be more generally useful in statistical modeling for longitudinal registry data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00616"
  },
  "2312.00601": {
    "title": "Online Graph Coloring with Predictions",
    "authors": [
      "Antonios Antoniadis",
      "Hajo Broersma",
      "Yang Meng"
    ],
    "abstract": "We introduce learning augmented algorithms to the online graph coloring problem. Although the simple greedy algorithm FirstFit is known to perform poorly in the worst case, we are able to establish a relationship between the structure of any input graph $G$ that is revealed online and the number of colors that FirstFit uses for $G$. Based on this relationship, we propose an online coloring algorithm FirstFitPredictions that extends FirstFit while making use of machine learned predictions. We show that FirstFitPredictions is both \\emph{consistent} and \\emph{smooth}. Moreover, we develop a novel framework for combining online algorithms at runtime specifically for the online graph coloring problem. Finally, we show how this framework can be used to robustify by combining it with any classical online coloring algorithm (that disregards the predictions).\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00601"
  },
  "2312.00596": {
    "title": "BCN: Batch Channel Normalization for Image Classification",
    "authors": [
      "Afifa Khaled",
      "Chao Li",
      "Jia Ning",
      "Kun He"
    ],
    "abstract": "Normalization techniques have been widely used in the field of deep learning due to their capability of enabling higher learning rates and are less careful in initialization. However, the effectiveness of popular normalization technologies is typically limited to specific areas. Unlike the standard Batch Normalization (BN) and Layer Normalization (LN), where BN computes the mean and variance along the (N,H,W) dimensions and LN computes the mean and variance along the (C,H,W) dimensions (N, C, H and W are the batch, channel, spatial height and width dimension, respectively), this paper presents a novel normalization technique called Batch Channel Normalization (BCN). To exploit both the channel and batch dependence and adaptively and combine the advantages of BN and LN based on specific datasets or tasks, BCN separately normalizes inputs along the (N, H, W) and (C, H, W) axes, then combines the normalized outputs based on adaptive parameters. As a basic block, BCN can be easily integrated into existing models for various applications in the field of computer vision. Empirical results show that the proposed technique can be seamlessly applied to various versions of CNN or Vision Transformer architecture. The code is publicly available at https://github.com/AfifaKhaled/BatchChannel-Normalization\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00596"
  },
  "2312.00593": {
    "title": "Event Recognition in Laparoscopic Gynecology Videos with Hybrid Transformers",
    "authors": [
      "Sahar Nasirihaghighi",
      "Negin Ghamsarian",
      "Heinrich Husslein",
      "Klaus Schoeffmann"
    ],
    "abstract": "Analyzing laparoscopic surgery videos presents a complex and multifaceted challenge, with applications including surgical training, intra-operative surgical complication prediction, and post-operative surgical assessment. Identifying crucial events within these videos is a significant prerequisite in a majority of these applications. In this paper, we introduce a comprehensive dataset tailored for relevant event recognition in laparoscopic gynecology videos. Our dataset includes annotations for critical events associated with major intra-operative challenges and post-operative complications. To validate the precision of our annotations, we assess event recognition performance using several CNN-RNN architectures. Furthermore, we introduce and evaluate a hybrid transformer architecture coupled with a customized training-inference framework to recognize four specific events in laparoscopic surgery videos. Leveraging the Transformer networks, our proposed architecture harnesses inter-frame dependencies to counteract the adverse effects of relevant content occlusion, motion blur, and surgical scene variation, thus significantly enhancing event recognition accuracy. Moreover, we present a frame sampling strategy designed to manage variations in surgical scenes and the surgeons' skill level, resulting in event recognition with high temporal resolution. We empirically demonstrate the superiority of our proposed methodology in event recognition compared to conventional CNN-RNN architectures through a series of extensive experiments.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00593"
  },
  "2312.00591": {
    "title": "Less is More: Learning Reference Knowledge Using No-Reference Image Quality Assessment",
    "authors": [
      "Xudong Li",
      "Jingyuan Zheng",
      "Xiawu Zheng",
      "Runze Hu",
      "Enwei Zhang",
      "Yuting Gao",
      "Yunhang Shen",
      "Ke Li",
      "Yutao Liu",
      "Pingyang Dai",
      "Yan Zhang",
      "Rongrong Ji"
    ],
    "abstract": "Image Quality Assessment (IQA) with reference images have achieved great success by imitating the human vision system, in which the image quality is effectively assessed by comparing the query image with its pristine reference image. However, for the images in the wild, it is quite difficult to access accurate reference images. We argue that it is possible to learn reference knowledge under the No-Reference Image Quality Assessment (NR-IQA) setting, which is effective and efficient empirically. Concretely, by innovatively introducing a novel feature distillation method in IQA, we propose a new framework to learn comparative knowledge from non-aligned reference images. And then, to achieve fast convergence and avoid overfitting, we further propose an inductive bias regularization. Such a framework not only solves the congenital defects of NR-IQA but also improves the feature extraction framework, enabling it to express more abundant quality information. Surprisingly, our method utilizes less input while obtaining a more significant improvement compared to the teacher models. Extensive experiments on eight standard NR-IQA datasets demonstrate the superior performance to the state-of-the-art NR-IQA methods, i.e., achieving the PLCC values of 0.917 (vs. 0.884 in LIVEC) and 0.686 (vs. 0.661 in LIVEFB).\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00591"
  },
  "2312.00587": {
    "title": "Efficient and Secure Energy Trading with Electric Vehicles and Distributed Ledger Technology",
    "authors": [
      "Conor Mullaney",
      "Adnan Aijaz",
      "Rasheed Hussain"
    ],
    "abstract": "Efficient energy management of Distributed Renewable Energy Resources (DRER) enables a more sustainable and efficient energy ecosystem. Therefore, we propose a holistic Energy Management System (EMS), utilising the computational and energy storage capabilities of nearby Electric Vehicles (EVs), providing a low-latency and efficient management platform for DRER. Through leveraging the inherent, immutable features of Distributed Ledger Technology (DLT) and smart contracts, we create a secure management environment, facilitating interactions between multiple EVs and energy resources. Using a privacy-preserving load forecasting method powered by Vehicular Fog Computing (VFC), we integrate the computational resources of the EVs. Using DLT and our forecasting framework, we accommodate efficient management algorithms in a secure and low-latency manner enabling greater utilisation of the energy storage resources. Finally, we assess our proposed EMS in terms of monetary and energy utility metrics, establishing the increased benefits of multiple interacting EVs and load forecasting. Through the proposed system, we have established the potential of our framework to create a more sustainable and efficient energy ecosystem whilst providing measurable benefits to participating agents.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00587"
  },
  "2312.00586": {
    "title": "Explainable Fraud Detection with Deep Symbolic Classification",
    "authors": [
      "Samantha Visbeek",
      "Erman Acar",
      "Floris den Hengst"
    ],
    "abstract": "There is a growing demand for explainable, transparent, and data-driven models within the domain of fraud detection. Decisions made by fraud detection models need to be explainable in the event of a customer dispute. Additionally, the decision-making process in the model must be transparent to win the trust of regulators and business stakeholders. At the same time, fraud detection solutions can benefit from data due to the noisy, dynamic nature of fraud and the availability of large historical data sets. Finally, fraud detection is notorious for its class imbalance: there are typically several orders of magnitude more legitimate transactions than fraudulent ones. In this paper, we present Deep Symbolic Classification (DSC), an extension of the Deep Symbolic Regression framework to classification problems. DSC casts classification as a search problem in the space of all analytic functions composed of a vocabulary of variables, constants, and operations and optimizes for an arbitrary evaluation metric directly. The search is guided by a deep neural network trained with reinforcement learning. Because the functions are mathematical expressions that are in closed-form and concise, the model is inherently explainable both at the level of a single classification decision and the model's decision process. Furthermore, the class imbalance problem is successfully addressed by optimizing for metrics that are robust to class imbalance such as the F1 score. This eliminates the need for oversampling and undersampling techniques that plague traditional approaches. Finally, the model allows to explicitly balance between the prediction accuracy and the explainability. An evaluation on the PaySim data set demonstrates competitive predictive performance with state-of-the-art models, while surpassing them in terms of explainability. This establishes DSC as a promising model for fraud detection systems.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00586"
  },
  "2312.00584": {
    "title": "The Ethics of Automating Legal Actors",
    "authors": [
      "Josef Valvoda",
      "Alec Thompson",
      "Ryan Cotterell",
      "Simone Teufel"
    ],
    "abstract": "The introduction of large public legal datasets has brought about a renaissance in legal NLP. Many of these datasets are comprised of legal judgements - the product of judges deciding cases. This fact, together with the way machine learning works, means that several legal NLP models are models of judges. While some have argued for the automation of judges, in this position piece, we argue that automating the role of the judge raises difficult ethical challenges, in particular for common law legal systems. Our argument follows from the social role of the judge in actively shaping the law, rather than merely applying it. Since current NLP models come nowhere close to having the facilities necessary for this task, they should not be used to automate judges. Furthermore, even in the case the models could achieve human-level capabilities, there would still be remaining ethical concerns inherent in the automation of the legal process.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00584"
  },
  "2312.00582": {
    "title": "Design Patterns for Machine Learning Based Systems with Human-in-the-Loop",
    "authors": [
      "Jakob Smedegaard Andersen",
      "Walid Maalej"
    ],
    "abstract": "The development and deployment of systems using supervised machine learning (ML) remain challenging: mainly due to the limited reliability of prediction models and the lack of knowledge on how to effectively integrate human intelligence into automated decision-making. Humans involvement in the ML process is a promising and powerful paradigm to overcome the limitations of pure automated predictions and improve the applicability of ML in practice. We compile a catalog of design patterns to guide developers select and implement suitable human-in-the-loop (HiL) solutions. Our catalog takes into consideration key requirements as the cost of human involvement and model retraining. It includes four training patterns, four deployment patterns, and two orthogonal cooperation patterns.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00582"
  },
  "2312.00581": {
    "title": "Pathway to a fully data-driven geotechnics: lessons from materials informatics",
    "authors": [
      "Stephen Wu",
      "Yu Otake",
      "Yosuke Higo",
      "Ikumasa Yoshida"
    ],
    "abstract": "This paper elucidates the challenges and opportunities inherent in integrating data-driven methodologies into geotechnics, drawing inspiration from the success of materials informatics. Highlighting the intricacies of soil complexity, heterogeneity, and the lack of comprehensive data, the discussion underscores the pressing need for community-driven database initiatives and open science movements. By leveraging the transformative power of deep learning, particularly in feature extraction from high-dimensional data and the potential of transfer learning, we envision a paradigm shift towards a more collaborative and innovative geotechnics field. The paper concludes with a forward-looking stance, emphasizing the revolutionary potential brought about by advanced computational tools like large language models in reshaping geotechnics informatics.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00581"
  },
  "2312.00580": {
    "title": "Using Honeybuckets to Characterize Cloud Storage Scanning in the Wild",
    "authors": [
      "Katherine Izhikevich",
      "Geoff Voelker",
      "Stefan Savage",
      "Liz Izhikevich"
    ],
    "abstract": "In this work, we analyze to what extent actors target poorly-secured cloud storage buckets for attack. We deployed hundreds of AWS S3 honeybuckets with different names and content to lure and measure different scanning strategies. Actors exhibited clear preferences for scanning buckets that appeared to belong to organizations, especially commercial entities in the technology sector with a vulnerability disclosure program. Actors continuously engaged with the content of buckets by downloading, uploading, and deleting files. Most alarmingly, we recorded multiple instances in which malicious actors downloaded, read, and understood a document from our honeybucket, leading them to attempt to gain unauthorized server access.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00580"
  },
  "2312.00570": {
    "title": "Generative models for visualising abstract social processes: Guiding streetview image synthesis of StyleGAN2 with indices of deprivation",
    "authors": [
      "Aleksi Knuutila"
    ],
    "abstract": "This paper presents a novel application of Generative Adverserial Networks (GANs) to study visual aspects of social processes. I train a a StyleGAN2-model on a custom dataset of 14,564 images of London, sourced from Google Streetview taken in London. After training, I invert the images in the training set, finding points in the model's latent space that correspond to them, and compare results from three inversion techniques. I connect each data point with metadata from the Indices of Multiple Deprivation, describing income, health and environmental quality in the area where the photographs were taken. It is then possible to map which parts of the model's latent space encode visual features that are distinctive for health, income and environmental quality, and condition the synthesis of new images based on these factors. The synthetic images created reflect visual features of social processes that were previously unknown and difficult to study, describing recurring visual differences between deprived and privileged areas in London. GANs are known for their capability to produce a continuous range of images that exhibit visual differences. The paper tests how to exploit this ability through visual comparisons in still images as well as through an interactive website where users can guide image synthesis with sliders. Though conditioned synthesis has its limitations and the results are difficult to validate, the paper points to the potential for generative models to be repurposed to be parts of social scientific methods.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00570"
  },
  "2312.00567": {
    "title": "Explanatory Argument Extraction of Correct Answers in Resident Medical Exams",
    "authors": [
      "Iakes Goenaga",
      "Aitziber Atutxa",
      "Koldo Gojenola",
      "Maite Oronoz",
      "Rodrigo Agerri"
    ],
    "abstract": "Developing the required technology to assist medical experts in their everyday activities is currently a hot topic in the Artificial Intelligence research field. Thus, a number of large language models (LLMs) and automated benchmarks have recently been proposed with the aim of facilitating information extraction in Evidence-Based Medicine (EBM) using natural language as a tool for mediating in human-AI interaction. The most representative benchmarks are limited to either multiple-choice or long-form answers and are available only in English. In order to address these shortcomings, in this paper we present a new dataset which, unlike previous work: (i) includes not only explanatory arguments for the correct answer, but also arguments to reason why the incorrect answers are not correct; (ii) the explanations are written originally by medical doctors to answer questions from the Spanish Residency Medical Exams. Furthermore, this new benchmark allows us to setup a novel extractive task which consists of identifying the explanation of the correct answer written by medical doctors. An additional benefit of our setting is that we can leverage the extractive QA paradigm to automatically evaluate performance of LLMs without resorting to costly manual evaluation by medical experts. Comprehensive experimentation with language models for Spanish shows that sometimes multilingual models fare better than monolingual ones, even outperforming models which have been adapted to the medical domain. Furthermore, results across the monolingual models are mixed, with supposedly smaller and inferior models performing competitively. In any case, the obtained results show that our novel dataset and approach can be an effective technique to help medical practitioners in identifying relevant evidence-based explanations for medical questions.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00567"
  },
  "2312.00564": {
    "title": "The Discontinuous Strain Method: accurately representing fatigue and failure",
    "authors": [
      "Leon Herrmann",
      "Alireza Daneshyar",
      "Stefan Kollmannsberger"
    ],
    "abstract": "Fatigue simulation requires accurate modeling of unloading and reloading. However, classical ductile damage models treat deformations after complete failure as irrecoverable -- which leads to unphysical behavior during unloading. This unphysical behavior stems from the continued accumulation of plastic strains after failure, resulting in an incorrect stress state at crack closure. As a remedy, we introduce a discontinuity strain in the additive elasto-plastic strain decomposition, which absorbs the excess strain after failure. This allows representing pre- and post-cracking regimes in a fully continuous setting, wherein the transition from the elasto-plastic response to cracking can be triggered at any arbitrary stage in a completely smooth manner. Moreover, the presented methodology does not exhibit the spurious energy release observed in hybrid approaches. In addition, our approach guarantees mesh-independent results by relying on a characteristic length scale -- based on the discretization's resolution. We name this new methodology the discontinuous strain method. The proposed approach requires only minor modifications of conventional plastic-damage routines. To convey the method in a didactic manner, the algorithmic modifications are first discussed for one- and subsequently for two-/three-dimensional implementations. Using a simple ductile constitutive model, the discontinuous strain method is validated against established two-dimensional benchmarks. The method is, however, independent of the employed constitutive model. Elastic, plastic, and damage models may thus be chosen arbitrarily. Furthermore, computational efforts associated with the method are minimal, rendering it advantageous for accurately representing low-cycle fatigue but potentially also for other scenarios requiring a discontinuity representation within a plastic-damage framework.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.00564"
  },
  "2312.00555": {
    "title": "Dense, irregular, yet always graphic $3$-uniform hypergraph degree sequences",
    "authors": [
      "Runze Li",
      "Istvan Miklos"
    ],
    "abstract": "A $3$-uniform hypergraph is a generalization of simple graphs where each hyperedge is a subset of vertices of size $3$. The degree of a vertex in a hypergraph is the number of hyperedges incident with it. The degree sequence of a hypergraph is the sequence of the degrees of its vertices. The degree sequence problem for $3$-uniform hypergraphs is to decide if a $3$-uniform hypergraph exists with a prescribed degree sequence. Such a hypergraph is called a realization. Recently, Deza \\emph{et al.} proved that the degree sequence problem for $3$-uniform hypergraphs is NP-complete. Some special cases are easy; however, polynomial algorithms have been known so far only for some very restricted degree sequences. The main result of our research is the following. If all degrees are between $\\frac{2n^2}{63}+O(n)$ and $\\frac{5n^2}{63}-O(n)$ in a degree sequence $D$, further, the number of vertices is at least $45$, and the degree sum can be divided by $3$, then $D$ has a $3$-uniform hypergraph realization. Our proof is constructive and in fact, it constructs a hypergraph realization in polynomial time for any degree sequence satisfying the properties mentioned above. To our knowledge, this is the first polynomial running time algorithm to construct a $3$-uniform hypergraph realization of a highly irregular and dense degree sequence.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00555"
  },
  "2312.00554": {
    "title": "Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?",
    "authors": [
      "Aniket Deroy",
      "Subhankar Maity"
    ],
    "abstract": "The evolution of legal datasets and the advent of large language models (LLMs) have significantly transformed the legal field, particularly in the generation of case judgment summaries. However, a critical concern arises regarding the potential biases embedded within these summaries. This study scrutinizes the biases present in case judgment summaries produced by legal datasets and large language models. The research aims to analyze the impact of biases on legal decision making. By interrogating the accuracy, fairness, and implications of biases in these summaries, this study contributes to a better understanding of the role of technology in legal contexts and the implications for justice systems worldwide. In this study, we investigate biases wrt Gender-related keywords, Race-related keywords, Keywords related to crime against women, Country names and religious keywords. The study shows interesting evidences of biases in the outputs generated by the large language models and pre-trained abstractive summarization models. The reasoning behind these biases needs further studies.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00554"
  },
  "2312.00553": {
    "title": "A Spatio-Temporal Graph Convolutional Network for Gesture Recognition from High-Density Electromyography",
    "authors": [
      "Wenjuan Zhong",
      "Yuyang Zhang",
      "Peiwen Fu",
      "Wenxuan Xiong",
      "Mingming Zhang"
    ],
    "abstract": "Accurate hand gesture prediction is crucial for effective upper-limb prosthetic limbs control. As the high flexibility and multiple degrees of freedom exhibited by human hands, there has been a growing interest in integrating deep networks with high-density surface electromyography (HD-sEMG) grids to enhance gesture recognition capabilities. However, many existing methods fall short in fully exploit the specific spatial topology and temporal dependencies present in HD-sEMG data. Additionally, these studies are often limited number of gestures and lack generality. Hence, this study introduces a novel gesture recognition method, named STGCN-GR, which leverages spatio-temporal graph convolution networks for HD-sEMG-based human-machine interfaces. Firstly, we construct muscle networks based on functional connectivity between channels, creating a graph representation of HD-sEMG recordings. Subsequently, a temporal convolution module is applied to capture the temporal dependences in the HD-sEMG series and a spatial graph convolution module is employed to effectively learn the intrinsic spatial topology information among distinct HD-sEMG channels. We evaluate our proposed model on a public HD-sEMG dataset comprising a substantial number of gestures (i.e., 65). Our results demonstrate the remarkable capability of the STGCN-GR method, achieving an impressive accuracy of 91.07% in predicting gestures, which surpasses state-of-the-art deep learning methods applied to the same dataset.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00553"
  },
  "2312.00552": {
    "title": "Improving Unsupervised Relation Extraction by Augmenting Diverse Sentence Pairs",
    "authors": [
      "Qing Wang",
      "Kang Zhou",
      "Qiao Qiao",
      "Yuepei Li",
      "Qi Li"
    ],
    "abstract": "Unsupervised relation extraction (URE) aims to extract relations between named entities from raw text without requiring manual annotations or pre-existing knowledge bases. In recent studies of URE, researchers put a notable emphasis on contrastive learning strategies for acquiring relation representations. However, these studies often overlook two important aspects: the inclusion of diverse positive pairs for contrastive learning and the exploration of appropriate loss functions. In this paper, we propose AugURE with both within-sentence pairs augmentation and augmentation through cross-sentence pairs extraction to increase the diversity of positive pairs and strengthen the discriminative power of contrastive learning. We also identify the limitation of noise-contrastive estimation (NCE) loss for relation representation learning and propose to apply margin loss for sentence pairs. Experiments on NYT-FB and TACRED datasets demonstrate that the proposed relation representation learning and a simple K-Means clustering achieves state-of-the-art performance.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00552"
  },
  "2312.00548": {
    "title": "Domain Adaptive Imitation Learning with Visual Observation",
    "authors": [
      "Sungho Choi",
      "Seungyul Han",
      "Woojun Kim",
      "Jongseong Chae",
      "Whiyoung Jung",
      "Youngchul Sung"
    ],
    "abstract": "In this paper, we consider domain-adaptive imitation learning with visual observation, where an agent in a target domain learns to perform a task by observing expert demonstrations in a source domain. Domain adaptive imitation learning arises in practical scenarios where a robot, receiving visual sensory data, needs to mimic movements by visually observing other robots from different angles or observing robots of different shapes. To overcome the domain shift in cross-domain imitation learning with visual observation, we propose a novel framework for extracting domain-independent behavioral features from input observations that can be used to train the learner, based on dual feature extraction and image reconstruction. Empirical results demonstrate that our approach outperforms previous algorithms for imitation learning from visual observation with domain shift.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00548"
  },
  "2312.00545": {
    "title": "Hiding in text/plain sight: Security defences of Tor Onion Services",
    "authors": [
      "Q Misell"
    ],
    "abstract": "Tor Onion Services are a way to host websites and other internet services anonymously. Onion Services are often used to bypass internet censorship and provide information services to users in oppressive regimes. This paper presents an analysis of the security defences deployed on these Onion Services. Onion Services tend to have better security policy than sites on the clear web. However they lag behind in the deployment of HTTPS, a key defence to ensuring the security of users of such services.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00545"
  },
  "2312.00540": {
    "title": "Target-agnostic Source-free Domain Adaptation for Regression Tasks",
    "authors": [
      "Tianlang He",
      "Zhiqiu Xia",
      "Jierun Chen",
      "Haoliang Li",
      "S. -H. Gary Chan"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) seeks to bridge the domain gap between the target and source using unlabeled target data. Source-free UDA removes the requirement for labeled source data at the target to preserve data privacy and storage. However, work on source-free UDA assumes knowledge of domain gap distribution, and hence is limited to either target-aware or classification task. To overcome it, we propose TASFAR, a novel target-agnostic source-free domain adaptation approach for regression tasks. Using prediction confidence, TASFAR estimates a label density map as the target label distribution, which is then used to calibrate the source model on the target domain. We have conducted extensive experiments on four regression tasks with various domain gaps, namely, pedestrian dead reckoning for different users, image-based people counting in different scenes, housing-price prediction at different districts, and taxi-trip duration prediction from different departure points. TASFAR is shown to substantially outperform the state-of-the-art source-free UDA approaches by averagely reducing 22% errors for the four tasks and achieve notably comparable accuracy as source-based UDA without using source data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00540"
  },
  "2312.00538": {
    "title": "A Preconditioned Interior Point Method for Support Vector Machines Using an ANOVA-Decomposition and NFFT-Based Matrix-Vector Products",
    "authors": [
      "Theresa Wagner",
      "John W. Pearson",
      "Martin Stoll"
    ],
    "abstract": "In this paper we consider the numerical solution to the soft-margin support vector machine optimization problem. This problem is typically solved using the SMO algorithm, given the high computational complexity of traditional optimization algorithms when dealing with large-scale kernel matrices. In this work, we propose employing an NFFT-accelerated matrix-vector product using an ANOVA decomposition for the feature space that is used within an interior point method for the overall optimization problem. As this method requires the solution of a linear system of saddle point form we suggest a preconditioning approach that is based on low-rank approximations of the kernel matrix together with a Krylov subspace solver. We compare the accuracy of the ANOVA-based kernel with the default LIBSVM implementation. We investigate the performance of the different preconditioners as well as the accuracy of the ANOVA kernel on several large-scale datasets.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00538"
  },
  "2312.00536": {
    "title": "Trained MT Metrics Learn to Cope with Machine-translated References",
    "authors": [
      "Jannis Vamvas",
      "Tobias Domhan",
      "Sony Trenous",
      "Rico Sennrich",
      "Eva Hasler"
    ],
    "abstract": "Neural metrics trained on human evaluations of MT tend to correlate well with human judgments, but their behavior is not fully understood. In this paper, we perform a controlled experiment and compare a baseline metric that has not been trained on human evaluations (Prism) to a trained version of the same metric (Prism+FT). Surprisingly, we find that Prism+FT becomes more robust to machine-translated references, which are a notorious problem in MT evaluation. This suggests that the effects of metric training go beyond the intended effect of improving overall correlation with human judgments.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00536"
  },
  "2312.00535": {
    "title": "RIS-Based On-the-Air Semantic Communications -- a Diffractional Deep Neural Network Approach",
    "authors": [
      "Shuyi Chen",
      "Yingzhe Hui",
      "Yifan Qin",
      "Yueyi Yuan",
      "Weixiao Meng",
      "Xuewen Luo",
      "Hsiao-Hwa Chen"
    ],
    "abstract": "Semantic communication has gained significant attention recently due to its advantages in achieving higher transmission efficiency by focusing on semantic information instead of bit-level information. However, current AI-based semantic communication methods require digital hardware for implementation. With the rapid advancement on reconfigurable intelligence surfaces (RISs), a new approach called on-the-air diffractional deep neural networks (D$^2$NN) can be utilized to enable semantic communications on the wave domain. This paper proposes a new paradigm of RIS-based on-the-air semantic communications, where the computational process occurs inherently as wireless signals pass through RISs. We present the system model and discuss the data and control flows of this scheme, followed by a performance analysis using image transmission as an example. In comparison to traditional hardware-based approaches, RIS-based semantic communications offer appealing features, such as light-speed computation, low computational power requirements, and the ability to handle multiple tasks simultaneously.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00535"
  },
  "2312.00534": {
    "title": "LiDAR-based curb detection for ground truth annotation in automated driving validation",
    "authors": [
      "Jose Luis Apell\u00e1niz",
      "Mikel Garc\u00eda",
      "Nerea Aranjuelo",
      "Javier Barandiar\u00e1n",
      "Marcos Nieto"
    ],
    "abstract": "Curb detection is essential for environmental awareness in Automated Driving (AD), as it typically limits drivable and non-drivable areas. Annotated data are necessary for developing and validating an AD function. However, the number of public datasets with annotated point cloud curbs is scarce. This paper presents a method for detecting 3D curbs in a sequence of point clouds captured from a LiDAR sensor, which consists of two main steps. First, our approach detects the curbs at each scan using a segmentation deep neural network. Then, a sequence-level processing step estimates the 3D curbs in the reconstructed point cloud using the odometry of the vehicle. From these 3D points of the curb, we obtain polylines structured following ASAM OpenLABEL standard. These detections can be used as pre-annotations in labelling pipelines to efficiently generate curb-related ground truth data. We validate our approach through an experiment in which different human annotators were required to annotate curbs in a group of LiDAR-based sequences with and without our automatically generated pre-annotations. The results show that the manual annotation time is reduced by 50.99% thanks to our detections, keeping the data quality level.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.00534"
  },
  "2312.00532": {
    "title": "DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality",
    "authors": [
      "Christina Gsaxner",
      "Shohei Mori",
      "Dieter Schmalstieg",
      "Jan Egger",
      "Gerhard Paar",
      "Werner Bailer",
      "Denis Kalkofen"
    ],
    "abstract": "Diminished reality (DR) refers to the removal of real objects from the environment by virtually replacing them with their background. Modern DR frameworks use inpainting to hallucinate unobserved regions. While recent deep learning-based inpainting is promising, the DR use case is complicated by the need to generate coherent structure and 3D geometry (i.e., depth), in particular for advanced applications, such as 3D scene editing. In this paper, we propose DeepDR, a first RGB-D inpainting framework fulfilling all requirements of DR: Plausible image and geometry inpainting with coherent structure, running at real-time frame rates, with minimal temporal artifacts. Our structure-aware generative network allows us to explicitly condition color and depth outputs on the scene semantics, overcoming the difficulty of reconstructing sharp and consistent boundaries in regions with complex backgrounds. Experimental results show that the proposed framework can outperform related work qualitatively and quantitatively.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00532"
  },
  "2312.00529": {
    "title": "Algorithm-based diagnostic application for diabetic retinopathy detection",
    "authors": [
      "Agnieszka Cisek",
      "Karolina Korycinska",
      "Leszek Pyziak",
      "Marzena Malicka",
      "Tomasz Wiecek",
      "Grzegorz Gruzel",
      "Kamil Szmuc",
      "Jozef Cebulski",
      "Mariusz Spyra"
    ],
    "abstract": "Diabetic retinopathy (DR) is a growing health problem worldwide and is a leading cause of visual impairment and blindness, especially among working people aged 20-65. Its incidence is increasing along with the number of diabetes cases, and it is more common in developed countries than in developing countries. Recent research in the field of diabetic retinopathy diagnosis is using advanced technologies, such as analysis of images obtained by ophthalmoscopy. Automatic methods for analyzing eye images based on neural networks, deep learning and image analysis algorithms can improve the efficiency of diagnosis. This paper describes an automatic DR diagnosis method that includes processing and analysis of ophthalmoscopic images of the eye. It uses morphological algorithms to identify the optic disc and lesions characteristic of DR, such as microaneurysms, hemorrhages and exudates. Automated DR diagnosis has the potential to improve the efficiency of early detection of this disease and contribute to reducing the number of cases of diabetes-related visual impairment. The final step was to create an application with a graphical user interface that allowed retinal images taken at cooperating ophthalmology offices to be uploaded to the server. These images were then analyzed using a developed algorithm to make a diagnosis.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00529"
  },
  "2312.00525": {
    "title": "SurreyAI 2023 Submission for the Quality Estimation Shared Task",
    "authors": [
      "Archchana Sindhujan",
      "Diptesh Kanojia",
      "Constantin Orasan",
      "Tharindu Ranasinghe"
    ],
    "abstract": "Quality Estimation (QE) systems are important in situations where it is necessary to assess the quality of translations, but there is no reference available. This paper describes the approach adopted by the SurreyAI team for addressing the Sentence-Level Direct Assessment shared task in WMT23. The proposed approach builds upon the TransQuest framework, exploring various autoencoder pre-trained language models within the MonoTransQuest architecture using single and ensemble settings. The autoencoder pre-trained language models employed in the proposed systems are XLMV, InfoXLM-large, and XLMR-large. The evaluation utilizes Spearman and Pearson correlation coefficients, assessing the relationship between machine-predicted quality scores and human judgments for 5 language pairs (English-Gujarati, English-Hindi, English-Marathi, English-Tamil and English-Telugu). The MonoTQ-InfoXLM-large approach emerges as a robust strategy, surpassing all other individual models proposed in this study by significantly improving over the baseline for the majority of the language pairs.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00525"
  },
  "2312.00522": {
    "title": "No Ascending Auction can find Equilibrium for SubModular valuations",
    "authors": [
      "Oren Ben-Zwi",
      "Ilan Newman"
    ],
    "abstract": "We show that no efficient ascending auction can guarantee to find even a minimal envy-free price vector if all valuations are submodular, assuming a basic complexity theory's assumption.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00522"
  },
  "2312.00518": {
    "title": "Preprocess your Paths -- Speeding up Linear Programming-based Optimization for Segment Routing Traffic Engineering",
    "authors": [
      "Alexander Brundiers",
      "Timmy Sch\u00fcller",
      "Nils Aschenbruck"
    ],
    "abstract": "Many state-of-the-art Segment Routing (SR) Traffic Engineering (TE) algorithms rely on Linear Program (LP)-based optimization. However, the poor scalability of the latter and the resulting high computation times impose severe restrictions on the practical usability of such approaches for many use cases. To tackle this problem, a variety of preprocessing approaches have been proposed that aim to reduce computational complexity by preemtively limiting the number of SR paths to consider during optimization. In this paper, we provide the first extensive literature review of existing preprocessing approaches for SR. Based on this, we conduct a large scale comparative study using various real-world topologies, including recent data from a Tier-1 Internet Service Provider (ISP) backbone. Based on the insights obtained from this evaluation, we finally propose a combination of multiple preprocessing approaches and show that this can reliably reduce computation times by around a factor of 10 or more, without resulting in relevant deterioration of the solution quality. This is a major improvement over the current state-of-the-art and facilitates the reliable usability of LP-based optimization for large segment-routed networks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00518"
  },
  "2312.00513": {
    "title": "Summarization-based Data Augmentation for Document Classification",
    "authors": [
      "Yueguan Wang",
      "Naoki Yoshinaga"
    ],
    "abstract": "Despite the prevalence of pretrained language models in natural language understanding tasks, understanding lengthy text such as document is still challenging due to the data sparseness problem. Inspired by that humans develop their ability of understanding lengthy text from reading shorter text, we propose a simple yet effective summarization-based data augmentation, SUMMaug, for document classification. We first obtain easy-to-learn examples for the target document classification task by summarizing the input of the original training examples, while optionally merging the original labels to conform to the summarized input. We then use the generated pseudo examples to perform curriculum learning. Experimental results on two datasets confirmed the advantage of our method compared to existing baseline methods in terms of robustness and accuracy. We release our code and data at https://github.com/etsurin/summaug.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00513"
  },
  "2312.00512": {
    "title": "Attack Detection Using Item Vector Shift in Matrix Factorisation Recommenders",
    "authors": [
      "Sulthana Shams",
      "Douglas Leith"
    ],
    "abstract": "This paper proposes a novel method for detecting shilling attacks in Matrix Factorization (MF)-based Recommender Systems (RS), in which attackers use false user-item feedback to promote a specific item. Unlike existing methods that use either use supervised learning to distinguish between attack and genuine profiles or analyse target item rating distributions to detect false ratings, our method uses an unsupervised technique to detect false ratings by examining shifts in item preference vectors that exploit rating deviations and user characteristics, making it a promising new direction. The experimental results demonstrate the effectiveness of our approach in various attack scenarios, including those involving obfuscation techniques.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00512"
  },
  "2312.00509": {
    "title": "Bayesian causal discovery from unknown general interventions",
    "authors": [
      "Alessandro Mascaro",
      "Federico Castelletti"
    ],
    "abstract": "We consider the problem of learning causal Directed Acyclic Graphs (DAGs) using combinations of observational and interventional experimental data. Current methods tailored to this setting assume that interventions either destroy parent-child relations of the intervened (target) nodes or only alter such relations without modifying the parent sets, even when the intervention targets are unknown. We relax this assumption by proposing a Bayesian method for causal discovery from general interventions, which allow for modifications of the parent sets of the unknown targets. Even in this framework, DAGs and general interventions may be identifiable only up to some equivalence classes. We provide graphical characterizations of such interventional Markov equivalence and devise compatible priors for Bayesian inference that guarantee score equivalence of indistinguishable structures. We then develop a Markov Chain Monte Carlo (MCMC) scheme to approximate the posterior distribution over DAGs, intervention targets and induced parent sets. Finally, we evaluate the proposed methodology on both simulated and real protein expression data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00509"
  },
  "2312.00508": {
    "title": "PyraTrans: Attention-Enriched Pyramid Transformer for Malicious URL Detection",
    "authors": [
      "Ruitong Liu",
      "Yanbin Wang",
      "Zhenhao Guo",
      "Haitao Xu",
      "Zhan Qin",
      "Wenrui Ma",
      "Fan Zhang"
    ],
    "abstract": "Although advancements in machine learning have driven the development of malicious URL detection technology, current techniques still face significant challenges in their capacity to generalize and their resilience against evolving threats. In this paper, we propose PyraTrans, a novel method that integrates pretrained Transformers with pyramid feature learning to detect malicious URL. PyraTrans utilizes a pretrained CharBERT as its foundation and is augmented with three interconnected feature modules: 1) Encoder Feature Extraction, extracting multi-order feature matrices from each CharBERT encoder layer; 2) Multi-Scale Feature Learning, capturing local contextual insights at various scales and aggregating information across encoder layers; and 3) Spatial Pyramid Attention, focusing on regional-level attention to emphasize areas rich in expressive information. The proposed approach addresses the limitations of the Transformer in local feature learning and regional relational awareness, which are vital for capturing URL-specific word patterns, character combinations, or structural anomalies. In several challenging experimental scenarios, the proposed method has shown significant improvements in accuracy, generalization, and robustness in malicious URL detection. For instance, it achieved a peak F1-score improvement of 40% in class-imbalanced scenarios, and exceeded the best baseline result by 14.13% in accuracy in adversarial attack scenarios. Additionally, we conduct a case study where our method accurately identifies all 30 active malicious web pages, whereas two pior SOTA methods miss 4 and 7 malicious web pages respectively. Codes and data are available at:https://github.com/Alixyvtte/PyraTrans.\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.00508"
  },
  "2312.00500": {
    "title": "Global Localization: Utilizing Relative Spatio-Temporal Geometric Constraints from Adjacent and Distant Cameras",
    "authors": [
      "Mohammad Altillawi",
      "Zador Pataki",
      "Shile Li",
      "Ziyuan Liu"
    ],
    "abstract": "Re-localizing a camera from a single image in a previously mapped area is vital for many computer vision applications in robotics and augmented/virtual reality. In this work, we address the problem of estimating the 6 DoF camera pose relative to a global frame from a single image. We propose to leverage a novel network of relative spatial and temporal geometric constraints to guide the training of a Deep Network for localization. We employ simultaneously spatial and temporal relative pose constraints that are obtained not only from adjacent camera frames but also from camera frames that are distant in the spatio-temporal space of the scene. We show that our method, through these constraints, is capable of learning to localize when little or very sparse ground-truth 3D coordinates are available. In our experiments, this is less than 1% of available ground-truth data. We evaluate our method on 3 common visual localization datasets and show that it outperforms other direct pose estimation methods.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00500"
  },
  "2312.00499": {
    "title": "Unveiling the Landscape of Smart Contract Vulnerabilities: A Detailed Examination and Codification of Vulnerabilities in Prominent Blockchains",
    "authors": [
      "Oualid Zaazaa",
      "Hanan El Bakkali"
    ],
    "abstract": "With the rise in using immature smart contract programming languages to build a decentralized application, more vulnerabilities have been introduced to the Blockchain and were the main reasons behind critical financial losses. Moreover, the immutability of Blockchain technology makes deployed smart contracts unfixable for the whole life of the Blockchain itself. The lack of complete and up-to-date resources that explain those vulnerabilities in detail has also contributed to increasing the number of vulnerabilities in Blockchain. In addition, the lack of a standardized nomination of the existing vulnerabilities has made redundant research and made developers more confused. Therefore, in this paper, we propose the most complete list of smart contract vulnerabilities that exist in the most popular Blockchains with a detailed explanation of each one of them. In addition, we propose a new codification system that facilitates the communication of those vulnerabilities between developers and researchers. This codification, help identify the most uncovered vulnerabilities to focus on in future research. Moreover, the discussed list of vulnerabilities covers multiple Blockchain and could be used for even future built Blockchains.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00499"
  },
  "2312.00491": {
    "title": "Slotted Aloha for Optical Wireless Communications in Internet of Underwater Things",
    "authors": [
      "Milica Petkovic",
      "Sotiris A. Tegos",
      "Panagiotis D. Diamantoulakis",
      "Dejan Vukobratovic",
      "Erdal Panayirci",
      "Cedomir Stefanovic",
      "George K. Karagiannidis"
    ],
    "abstract": "In this work, we design and analyse a Slotted ALOHA (SA) solution for Optical Wireless Communication (OWC)-based Internet of Underwater Things (IoUT). In the proposed system, user devices exchange data with an access point (AP) which exploits the capture effect. The space spanned by the IoUT nodes is three-dimensional, i.e., users are located in half-sphere centered at the AP placed at the bottom of a floating object at the water surface level. The analytical expressions for the system throughput and reliability expressed in terms of the outage probability are derived. Based on the simulated signal-to-noise-and-interference-ratio statistics and derived analytical expressions, we present numerical results that investigate the trade-off between the system performance and the IoUT system parameters, such as the number of users, activation probability and type of water medium. The presented conclusions provide valuable insights into the design of an SA-based solution for IoUT communications.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00491"
  },
  "2312.00487": {
    "title": "Explainable AI in Diagnosing and Anticipating Leukemia Using Transfer Learning Method",
    "authors": [
      "Wahidul Hasan Abir",
      "Md. Fahim Uddin",
      "Faria Rahman Khanam",
      "Mohammad Monirujjaman Khan"
    ],
    "abstract": "This research paper focuses on Acute Lymphoblastic Leukemia (ALL), a form of blood cancer prevalent in children and teenagers, characterized by the rapid proliferation of immature white blood cells (WBCs). These atypical cells can overwhelm healthy cells, leading to severe health consequences. Early and accurate detection of ALL is vital for effective treatment and improving survival rates. Traditional diagnostic methods are time-consuming, costly, and prone to errors. The paper proposes an automated detection approach using computer-aided diagnostic (CAD) models, leveraging deep learning techniques to enhance the accuracy and efficiency of leukemia diagnosis. The study utilizes various transfer learning models like ResNet101V2, VGG19, InceptionV3, and InceptionResNetV2 for classifying ALL. The methodology includes using the Local Interpretable Model-Agnostic Explanations (LIME) for ensuring the validity and reliability of the AI system's predictions. This approach is critical for overcoming the \"black box\" nature of AI, where decisions made by models are often opaque and unaccountable. The paper highlights that the proposed method using the InceptionV3 model achieved an impressive 98.38% accuracy, outperforming other tested models. The results, verified by the LIME algorithm, showcase the potential of this method in accurately identifying ALL, providing a valuable tool for medical practitioners. The research underscores the impact of explainable artificial intelligence (XAI) in medical diagnostics, paving the way for more transparent and trustworthy AI applications in healthcare.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00487"
  },
  "2312.00486": {
    "title": "REDUCR: Robust Data Downsampling Using Class Priority Reweighting",
    "authors": [
      "William Bankes",
      "George Hughes",
      "Ilija Bogunovic",
      "Zi Wang"
    ],
    "abstract": "Modern machine learning models are becoming increasingly expensive to train for real-world image and text classification tasks, where massive web-scale data is collected in a streaming fashion. To reduce the training cost, online batch selection techniques have been developed to choose the most informative datapoints. However, these techniques can suffer from poor worst-class generalization performance due to class imbalance and distributional shifts. This work introduces REDUCR, a robust and efficient data downsampling method that uses class priority reweighting. REDUCR reduces the training data while preserving worst-class generalization performance. REDUCR assigns priority weights to datapoints in a class-aware manner using an online learning algorithm. We demonstrate the data efficiency and robust performance of REDUCR on vision and text classification tasks. On web-scraped datasets with imbalanced class distributions, REDUCR significantly improves worst-class test accuracy (and average accuracy), surpassing state-of-the-art methods by around 15%.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00486"
  },
  "2312.00485": {
    "title": "Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic Forecasting",
    "authors": [
      "Junkai Mao",
      "Yuexing Han",
      "Gouhei Tanaka",
      "Bing Wang"
    ],
    "abstract": "Accurate epidemic forecasting is a critical task in controlling disease transmission. Many deep learning-based models focus only on static or dynamic graphs when constructing spatial information, ignoring their relationship. Additionally, these models often rely on recurrent structures, which can lead to error accumulation and computational time consumption. To address the aforementioned problems, we propose a novel model called Backbone-based Dynamic Graph Spatio-Temporal Network (BDGSTN). Intuitively, the continuous and smooth changes in graph structure, make adjacent graph structures share a basic pattern. To capture this property, we use adaptive methods to generate static backbone graphs containing the primary information and temporal models to generate dynamic temporal graphs of epidemic data, fusing them to generate a backbone-based dynamic graph. To overcome potential limitations associated with recurrent structures, we introduce a linear model DLinear to handle temporal dependencies and combine it with dynamic graph convolution for epidemic forecasting. Extensive experiments on two datasets demonstrate that BDGSTN outperforms baseline models and ablation comparison further verifies the effectiveness of model components. Furthermore, we analyze and measure the significance of backbone and temporal graphs by using information metrics from different aspects. Finally, we compare model parameter volume and training time to confirm the superior complexity and efficiency of BDGSTN.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00485"
  },
  "2312.00484": {
    "title": "MultiView Independent Component Analysis with Delays",
    "authors": [
      "Ambroise Heurtebise",
      "Pierre Ablin",
      "Alexandre Gramfort"
    ],
    "abstract": "Linear Independent Component Analysis (ICA) is a blind source separation technique that has been used in various domains to identify independent latent sources from observed signals. In order to obtain a higher signal-to-noise ratio, the presence of multiple views of the same sources can be used. In this work, we present MultiView Independent Component Analysis with Delays (MVICAD). This algorithm builds on the MultiView ICA model by allowing sources to be delayed versions of some shared sources: sources are shared across views up to some unknown latencies that are view- and source-specific. Using simulations, we demonstrate that MVICAD leads to better unmixing of the sources. Moreover, as ICA is often used in neuroscience, we show that latencies are age-related when applied to Cam-CAN, a large-scale magnetoencephalography (MEG) dataset. These results demonstrate that the MVICAD model can reveal rich effects on neural signals without human supervision.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00484"
  },
  "2312.00483": {
    "title": "MalDicom: A Memory Forensic Framework for Detecting Malicious Payload in DICOM Files",
    "authors": [
      "Ayushi Mishra",
      "Priyanka Bagade"
    ],
    "abstract": "Digital Imaging and Communication System (DICOM) is widely used throughout the public health sector for portability in medical imaging. However, these DICOM files have vulnerabilities present in the preamble section. Successful exploitation of these vulnerabilities can allow attackers to embed executable codes in the 128-Byte preamble of DICOM files. Embedding the malicious executable will not interfere with the readability or functionality of DICOM imagery. However, it will affect the underline system silently upon viewing these files. This paper shows the infiltration of Windows malware executables into DICOM files. On viewing the files, the malicious DICOM will get executed and eventually infect the entire hospital network through the radiologist's workstation. The code injection process of executing malware in DICOM files affects the hospital networks and workstations' memory. Memory forensics for the infected radiologist's workstation is crucial as it can detect which malware disrupts the hospital environment, and future detection methods can be deployed. In this paper, we consider the machine learning (ML) algorithms to conduct memory forensics on three memory dump categories: Trojan, Spyware, and Ransomware, taken from the CIC-MalMem-2022 dataset. We obtain the highest accuracy of 75% with the Random Forest model. For estimating the feature importance for ML model prediction, we leveraged the concept of Shapley values.\n        \u25b3 Less",
    "submission_date": "8 December, 2023",
    "eprint_id": "2312.00483"
  },
  "2312.00475": {
    "title": "Pathologists light level preferences using the microscope -- a study to guide digital pathology display use",
    "authors": [
      "Charlotte Jennings",
      "Darren Treanor",
      "David Brettle"
    ],
    "abstract": "There is a paucity of guidelines relating to displays in digital pathology making procurement decisions, and display configuration challenging. Experience suggests pathologists have personal preferences for brightness when using a microscope which we hypothesised could be used as a predictor for display setup. We conducted an online survey across 6 NHS hospitals to capture brightness adjustment habits on both microscopes and screens. A subsample of respondents took part in a practical task to determine microscope brightness and display luminance preferences.\n  The survey indicates 81% of respondents adjust the brightness on their microscope, compared with 11% adjusting their digital display. Display adjustments are more likely for visual comfort and ambient light compensation rather than for tissue factors, common for microscope adjustments. Twenty consultants took part in the practical brightness assessment. Light preferences on the microscope showed no correlation with screen preferences, except where a pathologist has a markedly brighter microscope preference. All of the preferences in this cohort were for a display luminance of less than 500cd/m$^2$, with 90% preferring 350cd/m$^2$ or less. There was no correlation between these preferences and the ambient lighting in the room.\n  We conclude that microscope preferences can only be used to predict screen luminance requirements where the microscope is being used at very high brightness levels. A display capable of a brightness of 500cd/m$^2$ should be suitable for almost all pathologists with 300cd/m$^2$ suitable for the majority. The ability to adjust display luminance was felt to be important by the majority of respondents. Further work needs to be undertaken to establish the relationship between diagnostic performance, preferences and ambient lighting levels.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.00475"
  },
  "2312.00471": {
    "title": "A Bayesian approach for prompt optimization in pre-trained language models",
    "authors": [
      "Antonio Sabbatella",
      "Andrea Ponti",
      "Antonio Candelieri",
      "Ilaria Giordani",
      "Francesco Archetti"
    ],
    "abstract": "A prompt is a sequence of symbol or tokens, selected from a vocabulary according to some rule, which is prepended/concatenated to a textual query. A key problem is how to select the sequence of tokens: in this paper we formulate it as a combinatorial optimization problem. The high dimensionality of the token space com-pounded by the length of the prompt sequence requires a very efficient solution. In this paper we propose a Bayesian optimization method, executed in a continuous em-bedding of the combinatorial space. In this paper we focus on hard prompt tuning (HPT) which directly searches for discrete tokens to be added to the text input with-out requiring access to the large language model (LLM) and can be used also when LLM is available only as a black-box. This is critically important if LLMs are made available in the Model as a Service (MaaS) manner as in GPT-4. The current manu-script is focused on the optimization of discrete prompts for classification tasks. The discrete prompts give rise to difficult combinatorial optimization problem which easily become intractable given the dimension of the token space in realistic applications. The optimization method considered in this paper is Bayesian optimization (BO) which has become the dominant approach in black-box optimization for its sample efficiency along with its modular structure and versatility. In this paper we use BoTorch, a library for Bayesian optimization research built on top of pyTorch. Albeit preliminary and obtained using a 'vanilla' version of BO, the experiments on RoB-ERTa on six benchmarks, show a good performance across a variety of tasks and enable an analysis of the tradeoff between size of the search space, accuracy and wall clock time.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00471"
  },
  "2312.00467": {
    "title": "Unfolder: Fast localization and image rectification of a document with a crease from folding in half",
    "authors": [
      "A. M. Ershov",
      "D. V. Tropin",
      "E. E. Limonova",
      "D. P. Nikolaev",
      "V. V. Arlazarov"
    ],
    "abstract": "Presentation of folded documents is not an uncommon case in modern society. Digitizing such documents by capturing them with a smartphone camera can be tricky since a crease can divide the document contents into separate planes. To unfold the document, one could hold the edges potentially obscuring it in a captured image. While there are many geometrical rectification methods, they were usually developed for arbitrary bends and folds. We consider such algorithms and propose a novel approach Unfolder developed specifically for images of documents with a crease from folding in half. Unfolder is robust to projective distortions of the document image and does not fragment the image in the vicinity of a crease after rectification. A new Folded Document Images dataset was created to investigate the rectification accuracy of folded (2, 3, 4, and 8 folds) documents. The dataset includes 1600 images captured when document placed on a table and when held in hand. The Unfolder algorithm allowed for a recognition error rate of 0.33, which is better than the advanced neural network methods DocTr (0.44) and DewarpNet (0.57). The average runtime for Unfolder was only 0.25 s/image on an iPhone XR.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00467"
  },
  "2312.00462": {
    "title": "Learning Unorthogonalized Matrices for Rotation Estimation",
    "authors": [
      "Kerui Gu",
      "Zhihao Li",
      "Shiyong Liu",
      "Jianzhuang Liu",
      "Songcen Xu",
      "Youliang Yan",
      "Michael Bi Mi",
      "Kenji Kawaguchi",
      "Angela Yao"
    ],
    "abstract": "Estimating 3D rotations is a common procedure for 3D computer vision. The accuracy depends heavily on the rotation representation. One form of representation -- rotation matrices -- is popular due to its continuity, especially for pose estimation tasks. The learning process usually incorporates orthogonalization to ensure orthonormal matrices. Our work reveals, through gradient analysis, that common orthogonalization procedures based on the Gram-Schmidt process and singular value decomposition will slow down training efficiency. To this end, we advocate removing orthogonalization from the learning process and learning unorthogonalized `Pseudo' Rotation Matrices (PRoM). An optimization analysis shows that PRoM converges faster and to a better solution. By replacing the orthogonalization incorporated representation with our proposed PRoM in various rotation-related tasks, we achieve state-of-the-art results on large-scale benchmarks for human pose estimation.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00462"
  },
  "2312.00458": {
    "title": "Semantics of Attack-Defense Trees for Dynamic Countermeasures and a New Hierarchy of Star-free Languages",
    "authors": [
      "Thomas Brihaye",
      "Sophie Pinchinat",
      "Alexandre Terefenko"
    ],
    "abstract": "We present a mathematical setting for attack-defense trees, a classic graphical model to specify attacks and countermeasures. We equip attack-defense trees with (trace) language semantics allowing to have an original dynamic interpretation of countermeasures. Interestingly, the expressiveness of attack-defense trees coincides with star-free languages, and the nested countermeasures impact the expressiveness of attack-defense trees. With an adequate notion of countermeasure-depth, we exhibit a strict hierarchy of the star-free languages that does not coincides with the classic one. Additionally, driven by the use of attack-defense trees in practice, we address the decision problems of trace membership and of non-emptiness, and study their computational complexities parameterized by the countermeasure-depth.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00458"
  },
  "2312.00456": {
    "title": "Auto-encoding GPS data to reveal individual and collective behaviour",
    "authors": [
      "Saint-Clair Chabert-Liddell",
      "Nicolas Bez",
      "Pierre Gloaguen",
      "Sophie Donnet",
      "St\u00e9phanie Mah\u00e9vas"
    ],
    "abstract": "We propose an innovative and generic methodology to analyse individual and collective behaviour through individual trajectory data. The work is motivated by the analysis of GPS trajectories of fishing vessels collected from regulatory tracking data in the context of marine biodiversity conservation and ecosystem-based fisheries management. We build a low-dimensional latent representation of trajectories using convolutional neural networks as non-linear mapping. This is done by training a conditional variational auto-encoder taking into account covariates. The posterior distributions of the latent representations can be linked to the characteristics of the actual trajectories. The latent distributions of the trajectories are compared with the Bhattacharyya coefficient, which is well-suited for comparing distributions. Using this coefficient, we analyse the variation of the individual behaviour of each vessel during time. For collective behaviour analysis, we build proximity graphs and use an extension of the stochastic block model for multiple networks. This model results in a clustering of the individuals based on their set of trajectories. The application to French fishing vessels enables us to obtain groups of vessels whose individual and collective behaviours exhibit spatio-temporal patterns over the period 2014-2018.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00456"
  },
  "2312.00455": {
    "title": "Meta-Diversity Search in Complex Systems, A Recipe for Artificial Open-Endedness ?",
    "authors": [
      "Mayalen Etcheverry",
      "Bert Wang-Chak Chan",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "abstract": "Can we build an artificial system that would be able to generate endless surprises if ran \"forever\" in Minecraft? While there is not a single path toward solving that grand challenge, this article presents what we believe to be some working ingredients for the endless generation of novel increasingly complex artifacts in Minecraft. Our framework for an open-ended system includes two components: a complex system used to recursively grow and complexify artifacts over time, and a discovery algorithm that leverages the concept of meta-diversity search. Since complex systems have shown to enable the emergence of considerable complexity from set of simple rules, we believe them to be great candidates to generate all sort of artifacts in Minecraft. Yet, the space of possible artifacts that can be generated by these systems is often unknown, challenging to characterize and explore. Therefore automating the long-term discovery of novel and increasingly complex artifacts in these systems is an exciting research field. To approach these challenges, we formulate the problem of meta-diversity search where an artificial \"discovery assistant\" incrementally learns a diverse set of representations to characterize behaviors and searches to discover diverse patterns within each of them. A successful discovery assistant should continuously seek for novel sources of diversities while being able to quickly specialize the search toward a new unknown type of diversity. To implement those ideas in the Minecraft environment, we simulate an artificial \"chemistry\" system based on Lenia continuous cellular automaton for generating artifacts, as well as an artificial \"discovery assistant\" (called Holmes) for the artifact-discovery process. Holmes incrementally learns a hierarchy of modular representations to characterize divergent sources of diversity and uses a goal-based intrinsically-motivated exploration as the diversity search strategy.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00455"
  },
  "2312.00454": {
    "title": "An Encoding Framework for Binarized Images using HyperDimensional Computing",
    "authors": [
      "Laura Smets",
      "Werner Van Leekwijck",
      "Ing Jyh Tsang",
      "Steven Latr\u00e9"
    ],
    "abstract": "Hyperdimensional Computing (HDC) is a brain-inspired and light-weight machine learning method. It has received significant attention in the literature as a candidate to be applied in the wearable internet of things, near-sensor artificial intelligence applications and on-device processing. HDC is computationally less complex than traditional deep learning algorithms and typically achieves moderate to good classification performance. A key aspect that determines the performance of HDC is the encoding of the input data to the hyperdimensional (HD) space. This article proposes a novel light-weight approach relying only on native HD arithmetic vector operations to encode binarized images that preserves similarity of patterns at nearby locations by using point of interest selection and local linear mapping. The method reaches an accuracy of 97.35% on the test set for the MNIST data set and 84.12% for the Fashion-MNIST data set. These results outperform other studies using baseline HDC with different encoding approaches and are on par with more complex hybrid HDC models. The proposed encoding approach also demonstrates a higher robustness to noise and blur compared to the baseline encoding.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00454"
  },
  "2312.00452": {
    "title": "Towards Generalizable Referring Image Segmentation via Target Prompt and Visual Coherence",
    "authors": [
      "Yajie Liu",
      "Pu Ge",
      "Haoxiang Ma",
      "Shichao Fan",
      "Qingjie Liu",
      "Di Huang",
      "Yunhong Wang"
    ],
    "abstract": "Referring image segmentation (RIS) aims to segment objects in an image conditioning on free-from text descriptions. Despite the overwhelming progress, it still remains challenging for current approaches to perform well on cases with various text expressions or with unseen visual entities, limiting its further application. In this paper, we present a novel RIS approach, which substantially improves the generalization ability by addressing the two dilemmas mentioned above. Specially, to deal with unconstrained texts, we propose to boost a given expression with an explicit and crucial prompt, which complements the expression in a unified context, facilitating target capturing in the presence of linguistic style changes. Furthermore, we introduce a multi-modal fusion aggregation module with visual guidance from a powerful pretrained model to leverage spatial relations and pixel coherences to handle the incomplete target masks and false positive irregular clumps which often appear on unseen visual entities. Extensive experiments are conducted in the zero-shot cross-dataset settings and the proposed approach achieves consistent gains compared to the state-of-the-art, e.g., 4.15\\%, 5.45\\%, and 4.64\\% mIoU increase on RefCOCO, RefCOCO+ and ReferIt respectively, demonstrating its effectiveness. Additionally, the results on GraspNet-RIS show that our approach also generalizes well to new scenarios with large domain shifts.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00452"
  },
  "2312.00438": {
    "title": "Dolphins: Multimodal Language Model for Driving",
    "authors": [
      "Yingzi Ma",
      "Yulong Cao",
      "Jiachen Sun",
      "Marco Pavone",
      "Chaowei Xiao"
    ],
    "abstract": "The quest for fully autonomous vehicles (AVs) capable of navigating complex real-world scenarios with human-like understanding and responsiveness. In this paper, we introduce Dolphins, a novel vision-language model architected to imbibe human-like abilities as a conversational driving assistant. Dolphins is adept at processing multimodal inputs comprising video (or image) data, text instructions, and historical control signals to generate informed outputs corresponding to the provided instructions. Building upon the open-sourced pretrained Vision-Language Model, OpenFlamingo, we first enhance Dolphins's reasoning capabilities through an innovative Grounded Chain of Thought (GCoT) process. Then we tailored Dolphins to the driving domain by constructing driving-specific instruction data and conducting instruction tuning. Through the utilization of the BDD-X dataset, we designed and consolidated four distinct AV tasks into Dolphins to foster a holistic understanding of intricate driving scenarios. As a result, the distinctive features of Dolphins are characterized into two dimensions: (1) the ability to provide a comprehensive understanding of complex and long-tailed open-world driving scenarios and solve a spectrum of AV tasks, and (2) the emergence of human-like capabilities including gradient-free instant adaptation via in-context learning and error recovery via reflection.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00438"
  },
  "2312.00436": {
    "title": "Consensus group decision making under model uncertainty with a view towards environmental policy making",
    "authors": [
      "Phoebe Koundouri",
      "Georgios I. Papayiannis",
      "Electra V. Petracou",
      "Athanasios N. Yannacopoulos"
    ],
    "abstract": "In this paper we propose a consensus group decision making scheme under model uncertainty consisting of an iterative two-stage procedure and based on the concept of Fr\u00e9chet barycenter. Each step consists of two stages: the agents first update their position in the opinion metric space by a local barycenter characterized by the agents' immediate interactions and then a moderator makes a proposal in terms of a global barycenter, checking for consensus at each step. In cases of large heterogeneous groups the procedure can be complemented by an auxiliary initial homogenization step, consisting of a clustering procedure in opinion space, leading to large homogeneous groups for which the aforementioned procedure will be applied.\n  The scheme is illustrated in examples motivated from environmental economics.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00436"
  },
  "2312.00435": {
    "title": "Enhancing Image Captioning with Neural Models",
    "authors": [
      "Pooja Bhatnagar",
      "Sai Mrunaal",
      "Sachin Kamnure"
    ],
    "abstract": "This research explores the realm of neural image captioning using deep learning models. The study investigates the performance of different neural architecture configurations, focusing on the inject architecture, and proposes a novel quality metric for evaluating caption generation. Through extensive experimentation and analysis, this work sheds light on the challenges and opportunities in image captioning, providing insights into model behavior and overfitting. The results reveal that while the merge models exhibit a larger vocabulary and higher ROUGE scores, the inject architecture generates relevant and concise image captions. The study also highlights the importance of refining training data and optimizing hyperparameters for improved model performance. This research contributes to the growing body of knowledge in neural image captioning and encourages further exploration in the field, emphasizing the democratization of artificial intelligence.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00435"
  },
  "2312.00434": {
    "title": "PEFTDebias : Capturing debiasing information using PEFTs",
    "authors": [
      "Sumit Agarwal",
      "Aditya Srikanth Veerubhotla",
      "Srijan Bansal"
    ],
    "abstract": "The increasing use of foundation models highlights the urgent need to address and eliminate implicit biases present in them that arise during pretraining. In this paper, we introduce PEFTDebias, a novel approach that employs parameter-efficient fine-tuning (PEFT) to mitigate the biases within foundation models. PEFTDebias consists of two main phases: an upstream phase for acquiring debiasing parameters along a specific bias axis, and a downstream phase where these parameters are incorporated into the model and frozen during the fine-tuning process. By evaluating on four datasets across two bias axes namely gender and race, we find that downstream biases can be effectively reduced with PEFTs. In addition, we show that these parameters possess axis-specific debiasing characteristics, enabling their effective transferability in mitigating biases in various downstream tasks. To ensure reproducibility, we release the code to do our experiments.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00434"
  },
  "2312.00429": {
    "title": "Polygraphs: From Rewriting to Higher Categories",
    "authors": [
      "Dimitri Ara",
      "Albert Burroni",
      "Yves Guiraud",
      "Philippe Malbos",
      "Fran\u00e7ois M\u00e9tayer",
      "Samuel Mimram"
    ],
    "abstract": "Polygraphs are a higher-dimensional generalization of the notion of directed graph. Based on those as unifying concept, this monograph on polygraphs revisits the theory of rewriting in the context of strict higher categories, adopting the abstract point of view offered by homotopical algebra. The first half explores the theory of polygraphs in low dimensions and its applications to the computation of the coherence of algebraic structures. It is meant to be progressive, with little requirements on the background of the reader, apart from basic category theory, and is illustrated with algorithmic computations on algebraic structures. The second half introduces and studies the general notion of n-polygraph, dealing with the homotopy theory of those. It constructs the folk model structure on the category of strict higher categories and exhibits polygraphs as cofibrant objects. This allows extending to higher dimensional structures the coherence results developed in the first half.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00429"
  },
  "2312.00427": {
    "title": "From Mutual Information to Expected Dynamics: New Generalization Bounds for Heavy-Tailed SGD",
    "authors": [
      "Benjamin Dupuis",
      "Paul Viallard"
    ],
    "abstract": "Understanding the generalization abilities of modern machine learning algorithms has been a major research topic over the past decades. In recent years, the learning dynamics of Stochastic Gradient Descent (SGD) have been related to heavy-tailed dynamics. This has been successfully applied to generalization theory by exploiting the fractal properties of those dynamics. However, the derived bounds depend on mutual information (decoupling) terms that are beyond the reach of computability. In this work, we prove generalization bounds over the trajectory of a class of heavy-tailed dynamics, without those mutual information terms. Instead, we introduce a geometric decoupling term by comparing the learning dynamics (depending on the empirical risk) with an expected one (depending on the population risk). We further upper-bound this geometric term, by using techniques from the heavy-tailed and the fractal literature, making it fully computable. Moreover, as an attempt to tighten the bounds, we propose a PAC-Bayesian setting based on perturbed dynamics, in which the same geometric term plays a crucial role and can still be bounded using the techniques described above.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00427"
  },
  "2312.00421": {
    "title": "A Semi-Tensor Product based Circuit Simulation for SAT-sweeping",
    "authors": [
      "Hongyang Pan",
      "Ruibing Zhang",
      "Yinshui Xia",
      "Lunyao Wang",
      "Fan Yang",
      "Xuan Zeng",
      "Zhufei Chu"
    ],
    "abstract": "In recent years, circuit simulators and Boolean satisfiability (SAT) solvers have been tightly integrated to provide efficient logic synthesis and verification. Circuit simulation can generate highly expressive simulation patterns that can either enumerate or filter out most candidates for synthesis. Subsequently, SAT solvers are employed to check those that remain, thereby making the logic synthesis process more efficient. This paper introduces a novel circuit simulator of k-input lookup table (k-LUT) networks, based on semi-tensor product (STP). STP-based simulators use computation of logic matrices, the primitives of logic networks, as opposed to relying on bitwise logic operations for simulation of k-LUT networks. Experimental results show that our STP-based simulator reduces the runtime by an average of 7.2x. Furthermore, we integrate this proposed simulator into a SAT-sweeping engine known as SAT sweeper. Through a combination of structural hashing, simulation, and SAT queries, SAT sweeper simplifies logic networks by systematically merging graph vertices from input to output. To enhance the efficiency, we used STP-based exhaustive simulation, which significantly reduces the number of false equivalence class candidates, thereby improving the computational efficiency by reducing the number of SAT calls required. When compared to the SOTA SAT sweeper, our method demonstrates an average 35% runtime reduction.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00421"
  },
  "2312.00416": {
    "title": "Towards Explaining Satellite Based Poverty Predictions with Convolutional Neural Networks",
    "authors": [
      "Hamid Sarmadi",
      "Thorsteinn R\u00f6gnvaldsson",
      "Nils Roger Carlsson",
      "Mattias Ohlsson",
      "Ibrahim Wahab",
      "Ola Hall"
    ],
    "abstract": "Deep convolutional neural networks (CNNs) have been shown to predict poverty and development indicators from satellite images with surprising accuracy. This paper presents a first attempt at analyzing the CNNs responses in detail and explaining the basis for the predictions. The CNN model, while trained on relatively low resolution day- and night-time satellite images, is able to outperform human subjects who look at high-resolution images in ranking the Wealth Index categories. Multiple explainability experiments performed on the model indicate the importance of the sizes of the objects, pixel colors in the image, and provide a visualization of the importance of different structures in input images. A visualization is also provided of type images that maximize the network prediction of Wealth Index, which provides clues on what the CNN prediction is based on.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00416"
  },
  "2312.00413": {
    "title": "Abstract Syntax Tree for Programming Language Understanding and Representation: How Far Are We?",
    "authors": [
      "Weisong Sun",
      "Chunrong Fang",
      "Yun Miao",
      "Yudu You",
      "Mengzhe Yuan",
      "Yuchen Chen",
      "Quanjun Zhang",
      "An Guo",
      "Xiang Chen",
      "Yang Liu",
      "Zhenyu Chen"
    ],
    "abstract": "Programming language understanding and representation (a.k.a code representation learning) has always been a hot and challenging task in software engineering. It aims to apply deep learning techniques to produce numerical representations of the source code features while preserving its semantics. These representations can be used for facilitating subsequent code-related tasks. The abstract syntax tree (AST), a fundamental code feature, illustrates the syntactic information of the source code and has been widely used in code representation learning. However, there is still a lack of systematic and quantitative evaluation of how well AST-based code representation facilitates subsequent code-related tasks. In this paper, we first conduct a comprehensive empirical study to explore the effectiveness of the AST-based code representation in facilitating follow-up code-related tasks. To do so, we compare the performance of models trained with code token sequence (Token for short) based code representation and AST-based code representation on three popular types of code-related tasks. Surprisingly, the overall quantitative statistical results demonstrate that models trained with AST-based code representation consistently perform worse across all three tasks compared to models trained with Token-based code representation. Our further quantitative analysis reveals that models trained with AST-based code representation outperform models trained with Token-based code representation in certain subsets of samples across all three tasks. We also conduct comprehensive experiments to evaluate and reveal the impact of the choice of AST parsing/preprocessing/encoding methods on AST-based code representation and subsequent code-related tasks. Our study provides future researchers with detailed guidance on how to select solutions at each stage to fully exploit AST.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00413"
  },
  "2312.00411": {
    "title": "A framework for mining lifestyle profiles through multi-dimensional and high-order mobility feature clustering",
    "authors": [
      "Yeshuo Shu",
      "Gangcheng Zhang",
      "Keyi Liu",
      "Jintong Tang",
      "Liyan Xu"
    ],
    "abstract": "Human mobility demonstrates a high degree of regularity, which facilitates the discovery of lifestyle profiles. Existing research has yet to fully utilize the regularities embedded in high-order features extracted from human mobility records in such profiling. This study proposes a progressive feature extraction strategy that mines high-order mobility features from users' moving trajectory records from the spatial, temporal, and semantic dimensions. Specific features are extracted such as travel motifs, rhythms decomposed by discrete Fourier transform (DFT) of mobility time series, and vectorized place semantics by word2vec, respectively to the three dimensions, and they are further clustered to reveal the users' lifestyle characteristics. An experiment using a trajectory dataset of over 500k users in Shenzhen, China yields seven user clusters with different lifestyle profiles that can be well interpreted by common sense. The results suggest the possibility of fine-grained user profiling through cross-order trajectory feature engineering and clustering.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00411"
  },
  "2312.00408": {
    "title": "Beyond the Screen: Reshaping the Workplace with Virtual and Augmented Reality",
    "authors": [
      "Nuno Verdelho Trindade",
      "Alfredo Ferreira",
      "Jo\u00e3o Madeiras Pereira"
    ],
    "abstract": "Although extended reality technologies have enjoyed an explosion in popularity in recent years, few applications are effectively used outside the entertainment or academic contexts. This work consists of a literature review regarding the effective integration of such technologies in the workplace. It aims to provide an updated view of how they are being used in that context. First, we examine existing research concerning virtual, augmented, and mixed-reality applications. We also analyze which have made their way to the workflows of companies and institutions. Furthermore, we circumscribe the aspects of extended reality technologies that determined this applicability.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00408"
  },
  "2312.00407": {
    "title": "CoLLiE: Collaborative Training of Large Language Models in an Efficient Way",
    "authors": [
      "Kai Lv",
      "Shuo Zhang",
      "Tianle Gu",
      "Shuhao Xing",
      "Jiawei Hong",
      "Keyu Chen",
      "Xiaoran Liu",
      "Yuqing Yang",
      "Honglin Guo",
      "Tengxiao Liu",
      "Yu Sun",
      "Qipeng Guo",
      "Hang Yan",
      "Xipeng Qiu"
    ],
    "abstract": "Large language models (LLMs) are increasingly pivotal in a wide range of natural language processing tasks. Access to pre-trained models, courtesy of the open-source community, has made it possible to adapt these models to specific applications for enhanced performance. However, the substantial resources required for training these models necessitate efficient solutions. This paper introduces CoLLiE, an efficient library that facilitates collaborative training of large language models using 3D parallelism, parameter-efficient fine-tuning (PEFT) methods, and optimizers such as Lion, Adan, Sophia, LOMO and AdaLomo. With its modular design and comprehensive functionality, CoLLiE offers a balanced blend of efficiency, ease of use, and customization. CoLLiE has proven superior training efficiency in comparison with prevalent solutions in pre-training and fine-tuning scenarios. Furthermore, we provide an empirical evaluation of the correlation between model size and GPU memory consumption under different optimization methods, as well as an analysis of the throughput. Lastly, we carry out a comprehensive comparison of various optimizers and PEFT methods within the instruction-tuning context. CoLLiE is available at https://github.com/OpenLMLab/collie.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00407"
  },
  "2312.00404": {
    "title": "A Causality-Aware Pattern Mining Scheme for Group Activity Recognition in a Pervasive Sensor Space",
    "authors": [
      "Hyunju Kim",
      "Heesuk Son",
      "Dongman Lee"
    ],
    "abstract": "Human activity recognition (HAR) is a key challenge in pervasive computing and its solutions have been presented based on various disciplines. Specifically, for HAR in a smart space without privacy and accessibility issues, data streams generated by deployed pervasive sensors are leveraged. In this paper, we focus on a group activity by which a group of users perform a collaborative task without user identification and propose an efficient group activity recognition scheme which extracts causality patterns from pervasive sensor event sequences generated by a group of users to support as good recognition accuracy as the state-of-the-art graphical model. To filter out irrelevant noise events from a given data stream, a set of rules is leveraged to highlight causally related events. Then, a pattern-tree algorithm extracts frequent causal patterns by means of a growing tree structure. Based on the extracted patterns, a weighted sum-based pattern matching algorithm computes the likelihoods of stored group activities to the given test event sequence by means of matched event pattern counts for group activity recognition. We evaluate the proposed scheme using the data collected from our testbed and CASAS datasets where users perform their tasks on a daily basis and validate its effectiveness in a real environment. Experiment results show that the proposed scheme performs higher recognition accuracy and with a small amount of runtime overhead than the existing schemes.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00404"
  },
  "2312.00401": {
    "title": "VIoTGPT: Learning to Schedule Vision Tools towards Intelligent Video Internet of Things",
    "authors": [
      "Yaoyao Zhong",
      "Mengshi Qi",
      "Rui Wang",
      "Yuhan Qiu",
      "Yang Zhang",
      "Huadong Ma"
    ],
    "abstract": "Video Internet of Things (VIoT) has shown full potential in collecting an unprecedented volume of video data. Learning to schedule perceiving models and analyzing the collected videos intelligently will be potential sparks for VIoT. In this paper, to address the challenges posed by the fine-grained and interrelated vision tool usage of VIoT, we build VIoTGPT, the framework based on LLMs to correctly interact with humans, query knowledge videos, and invoke vision models to accomplish complicated tasks. To support VIoTGPT and related future works, we meticulously crafted the training dataset and established benchmarks involving 11 representative vision models across three categories based on semi-automatic annotations. To guide LLM to act as the intelligent agent towards intelligent VIoT, we resort to ReAct instruction tuning based on the collected VIoT dataset to learn the tool capability. Quantitative and qualitative experimental results and analyses demonstrate the effectiveness of VIoTGPT.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00401"
  },
  "2312.00396": {
    "title": "GFN-SR: Symbolic Regression with Generative Flow Networks",
    "authors": [
      "Sida Li",
      "Ioana Marinescu",
      "Sebastian Musslick"
    ],
    "abstract": "Symbolic regression (SR) is an area of interpretable machine learning that aims to identify mathematical expressions, often composed of simple functions, that best fit in a given set of covariates $X$ and response $y$. In recent years, deep symbolic regression (DSR) has emerged as a popular method in the field by leveraging deep reinforcement learning to solve the complicated combinatorial search problem. In this work, we propose an alternative framework (GFN-SR) to approach SR with deep learning. We model the construction of an expression tree as traversing through a directed acyclic graph (DAG) so that GFlowNet can learn a stochastic policy to generate such trees sequentially. Enhanced with an adaptive reward baseline, our method is capable of generating a diverse set of best-fitting expressions. Notably, we observe that GFN-SR outperforms other SR algorithms in noisy data regimes, owing to its ability to learn a distribution of rewards over a space of candidate solutions.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00396"
  },
  "2312.00392": {
    "title": "Study and Survey on Gesture Recognition Systems",
    "authors": [
      "Kshitij Deshpande",
      "Varad Mashalkar",
      "Kaustubh Mhaisekar",
      "Amaan Naikwadi",
      "Archana Ghotkar"
    ],
    "abstract": "In recent years, there has been a considerable amount of research in the Gesture Recognition domain, mainly owing to the technological advancements in Computer Vision. Various new applications have been conceptualised and developed in this field. This paper discusses the implementation of gesture recognition systems in multiple sectors such as gaming, healthcare, home appliances, industrial robots, and virtual reality. Different methodologies for capturing gestures are compared and contrasted throughout this survey. Various data sources and data acquisition techniques have been discussed. The role of gestures in sign language has been studied and existing approaches have been reviewed. Common challenges faced while building gesture recognition systems have also been explored.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00392"
  },
  "2312.00388": {
    "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
    "authors": [
      "Junchen Zhao",
      "Yurun Song",
      "Simeng Liu",
      "Ian G. Harris",
      "Sangeetha Abdu Jyothi"
    ],
    "abstract": "Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of $1.11\\times$ to $1.61\\times$ in single-threaded settings, $1.73\\times$ to $2.65\\times$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of $1.29\\times$ to $1.32\\times$.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00388"
  },
  "2312.00387": {
    "title": "Partition-based K-space Synthesis for Multi-contrast Parallel Imaging",
    "authors": [
      "Yuxia Huang",
      "Zhonghui Wu",
      "Xiaoling Xu",
      "Minghui Zhang",
      "Shanshan Wang",
      "Qiegen Liu"
    ],
    "abstract": "Multi-contrast magnetic resonance imaging is a significant and essential medical imaging technique.However, multi-contrast imaging has longer acquisition time and is easy to cause motion artifacts. In particular, the acquisition time for a T2-weighted image is prolonged due to its longer repetition time (TR). On the contrary, T1-weighted image has a shorter TR. Therefore,utilizing complementary information across T1 and T2-weighted image is a way to decrease the overall imaging time. Previous T1-assisted T2 reconstruction methods have mostly focused on image domain using whole-based image fusion approaches. The image domain reconstruction method has the defects of high computational complexity and limited flexibility. To address this issue, we propose a novel multi-contrast imaging method called partition-based k-space synthesis (PKS) which can achieve super reconstruction quality of T2-weighted image by feature fusion. Concretely, we first decompose fully-sampled T1 k-space data and under-sampled T2 k-space data into two sub-data, separately. Then two new objects are constructed by combining the two sub-T1/T2 data. After that, the two new objects as the whole data to realize the reconstruction of T2-weighted image. Finally, the objective T2 is synthesized by extracting the sub-T2 data of each part. Experimental results showed that our combined technique can achieve comparable or better results than using traditional k-space parallel imaging(SAKE) that processes each contrast independently.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00387"
  },
  "2312.00386": {
    "title": "Local monotone operator learning using non-monotone operators: MnM-MOL",
    "authors": [
      "Maneesh John",
      "Jyothi Rikhab Chand",
      "Mathews Jacob"
    ],
    "abstract": "The recovery of magnetic resonance (MR) images from undersampled measurements is a key problem that has seen extensive research in recent years. Unrolled approaches, which rely on end-to-end training of convolutional neural network (CNN) blocks within iterative reconstruction algorithms, offer state-of-the-art performance. These algorithms require a large amount of memory during training, making them difficult to employ in high-dimensional applications. Deep equilibrium (DEQ) models and the recent monotone operator learning (MOL) approach were introduced to eliminate the need for unrolling, thus reducing the memory demand during training. Both approaches require a Lipschitz constraint on the network to ensure that the forward and backpropagation iterations converge. Unfortunately, the constraint often results in reduced performance compared to unrolled methods. The main focus of this work is to relax the constraint on the CNN block in two different ways. Inspired by convex-non-convex regularization strategies, we now impose the monotone constraint on the sum of the gradient of the data term and the CNN block, rather than constrain the CNN itself to be a monotone operator. This approach enables the CNN to learn possibly non-monotone score functions, which can translate to improved performance. In addition, we only restrict the operator to be monotone in a local neighborhood around the image manifold. Our theoretical results show that the proposed algorithm is guaranteed to converge to the fixed point and that the solution is robust to input perturbations, provided that it is initialized close to the true solution. Our empirical results show that the relaxed constraints translate to improved performance and that the approach enjoys robustness to input perturbations similar to MOL.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00386"
  },
  "2312.00380": {
    "title": "Enhancing Explainability in Mobility Data Science through a combination of methods",
    "authors": [
      "Georgios Makridis",
      "Vasileios Koukos",
      "Georgios Fatouros",
      "Dimosthenis Kyriazis"
    ],
    "abstract": "In the domain of Mobility Data Science, the intricate task of interpreting models trained on trajectory data, and elucidating the spatio-temporal movement of entities, has persistently posed significant challenges. Conventional XAI techniques, although brimming with potential, frequently overlook the distinct structure and nuances inherent within trajectory data. Observing this deficiency, we introduced a comprehensive framework that harmonizes pivotal XAI techniques: LIME (Local Interpretable Model-agnostic Explanations), SHAP (SHapley Additive exPlanations), Saliency maps, attention mechanisms, direct trajectory visualization, and Permutation Feature Importance (PFI). Unlike conventional strategies that deploy these methods singularly, our unified approach capitalizes on the collective efficacy of these techniques, yielding deeper and more granular insights for models reliant on trajectory data. In crafting this synthesis, we effectively address the multifaceted essence of trajectories, achieving not only amplified interpretability but also a nuanced, contextually rich comprehension of model decisions. To validate and enhance our framework, we undertook a survey to gauge preferences and reception among various user demographics. Our findings underscored a dichotomy: professionals with academic orientations, particularly those in roles like Data Scientist, IT Expert, and ML Engineer, showcased a profound, technical understanding and often exhibited a predilection for amalgamated methods for interpretability. Conversely, end-users or individuals less acquainted with AI and Data Science showcased simpler inclinations, such as bar plots indicating timestep significance or visual depictions pinpointing pivotal segments of a vessel's trajectory.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00380"
  },
  "2312.00379": {
    "title": "Optimal Sample Complexity of Contrastive Learning",
    "authors": [
      "Noga Alon",
      "Dmitrii Avdiukhin",
      "Dor Elboim",
      "Orr Fischer",
      "Grigory Yaroslavtsev"
    ],
    "abstract": "Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions, both general $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$ we show that $\\tilde \u0398(\\min(nd,n^2))$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00379"
  },
  "2312.00375": {
    "title": "Text-Guided 3D Face Synthesis -- From Generation to Editing",
    "authors": [
      "Yunjie Wu",
      "Yapeng Meng",
      "Zhipeng Hu",
      "Lincheng Li",
      "Haoqian Wu",
      "Kun Zhou",
      "Weiwei Xu",
      "Xin Yu"
    ],
    "abstract": "Text-guided 3D face synthesis has achieved remarkable results by leveraging text-to-image (T2I) diffusion models. However, most existing works focus solely on the direct generation, ignoring the editing, restricting them from synthesizing customized 3D faces through iterative adjustments. In this paper, we propose a unified text-guided framework from face generation to editing. In the generation stage, we propose a geometry-texture decoupled generation to mitigate the loss of geometric details caused by coupling. Besides, decoupling enables us to utilize the generated geometry as a condition for texture generation, yielding highly geometry-texture aligned results. We further employ a fine-tuned texture diffusion model to enhance texture quality in both RGB and YUV space. In the editing stage, we first employ a pre-trained diffusion model to update facial geometry or texture based on the texts. To enable sequential editing, we introduce a UV domain consistency preservation regularization, preventing unintentional changes to irrelevant facial attributes. Besides, we propose a self-guided consistency weight strategy to improve editing efficacy while preserving consistency. Through comprehensive experiments, we showcase our method's superiority in face synthesis. Project page: https://faceg2e.github.io/.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00375"
  },
  "2312.00373": {
    "title": "Streaming Bayesian Modeling for predicting Fat-Tailed Customer Lifetime Value",
    "authors": [
      "Alexey V. Calabourdin",
      "Konstantin A. Aksenov"
    ],
    "abstract": "We develop an online learning MCMC approach applicable for hierarchical bayesian models and GLMS. We also develop a fat-tailed LTV model that generalizes over several kinds of fat and thin tails. We demonstrate both developments on commercial LTV data from a large mobile app.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00373"
  },
  "2312.00372": {
    "title": "Event-driven Real-time Retrieval in Web Search",
    "authors": [
      "Nan Yang",
      "Shusen Zhang",
      "Yannan Zhang",
      "Xiaoling Bai",
      "Hualong Deng",
      "Tianhua Zhou",
      "Jin Ma"
    ],
    "abstract": "Information retrieval in real-time search presents unique challenges distinct from those encountered in classical web search. These challenges are particularly pronounced due to the rapid change of user search intent, which is influenced by the occurrence and evolution of breaking news events, such as earthquakes, elections, and wars. Previous dense retrieval methods, which primarily focused on static semantic representation, lack the capacity to capture immediate search intent, leading to inferior performance in retrieving the most recent event-related documents in time-sensitive scenarios. To address this issue, this paper expands the query with event information that represents real-time search intent. The Event information is then integrated with the query through a cross-attention mechanism, resulting in a time-context query representation. We further enhance the model's capacity for event representation through multi-task training. Since publicly available datasets such as MS-MARCO do not contain any event information on the query side and have few time-sensitive queries, we design an automatic data collection and annotation pipeline to address this issue, which includes ModelZoo-based Coarse Annotation and LLM-driven Fine Annotation processes. In addition, we share the training tricks such as two-stage training and hard negative sampling. Finally, we conduct a set of offline experiments on a million-scale production dataset to evaluate our approach and deploy an A/B testing in a real online system to verify the performance. Extensive experimental results demonstrate that our proposed approach significantly outperforms existing state-of-the-art baseline methods.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.00372"
  },
  "2312.00366": {
    "title": "Unbounded Donoho-Stark-Elad-Bruckstein-Ricaud-Torr\u00e9sani Uncertainty Principles",
    "authors": [
      "K. Mahesh Krishna"
    ],
    "abstract": "Let $(\u03a9, \u03bc)$, $(\u0394, \u03bd)$ be measure spaces and $p=1$ or $p=\\infty$. Let $(\\{f_\u03b1\\}_{\u03b1\\in \u03a9}, \\{\u03c4_\u03b1\\}_{\u03b1\\in \u03a9})$ and $(\\{g_\u03b2\\}_{\u03b2\\in \u0394}, \\{\u03c9_\u03b2\\}_{\u03b2\\in \u0394})$ be unbounded continuous p-Schauder frames for a Banach space $\\mathcal{X}$. Then for every $x \\in ( \\mathcal{D}(\u03b8_f) \\cap\\mathcal{D}(\u03b8_g))\\setminus\\{0\\}$, we show that \\begin{align}\\label{UB}\n  (1) \\quad \\quad \\quad \\quad \u03bc(\\operatorname{supp}(\u03b8_f x))\u03bd(\\operatorname{supp}(\u03b8_g x)) \\geq \\frac{1}{\\left(\\displaystyle\\sup_{\u03b1\\in \u03a9, \u03b2\\in \u0394}|f_\u03b1(\u03c9_\u03b2)|\\right)\\left(\\displaystyle\\sup_{\u03b1\\in \u03a9, \u03b2\\in \u0394}|g_\u03b2(\u03c4_\u03b1)|\\right)}, \\end{align} where \\begin{align*} &\u03b8_f:\\mathcal{D}(\u03b8_f) \\ni x \\mapsto \u03b8_fx \\in \\mathcal{L}^p(\u03a9, \u03bc); \\quad \u03b8_fx: \u03a9\\ni \u03b1\\mapsto (\u03b8_fx) (\u03b1):= f_\u03b1(x) \\in \\mathbb{K},\\\\ &\u03b8_g: \\mathcal{D}(\u03b8_g) \\ni x \\mapsto \u03b8_gx \\in \\mathcal{L}^p(\u0394, \u03bd); \\quad \u03b8_gx: \u0394\\ni \u03b2\\mapsto (\u03b8_gx) (\u03b2):= g_\u03b2(x) \\in \\mathbb{K}. \\end{align*} We call Inequality (1) as \\textbf{Unbounded Donoho-Stark-Elad-Bruckstein-Ricaud-Torr\u00e9sani Uncertainty Principle}. Along with recent \\textbf{Functional Continuous Uncertainty Principle} [arXiv:2308.00312], Inequality (1) also improves Ricaud-Torr\u00e9sani uncertainty principle [IEEE Trans. Inform. Theory, 2013]. In particular, it improves Elad-Bruckstein uncertainty principle [IEEE Trans. Inform. Theory, 2002] and Donoho-Stark uncertainty principle [SIAM J. Appl. Math., 1989].\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00366"
  },
  "2312.00364": {
    "title": "Benchmarking Multi-Domain Active Learning on Image Classification",
    "authors": [
      "Jiayi Li",
      "Rohan Taori",
      "Tatsunori B. Hashimoto"
    ],
    "abstract": "Active learning aims to enhance model performance by strategically labeling informative data points. While extensively studied, its effectiveness on large-scale, real-world datasets remains underexplored. Existing research primarily focuses on single-source data, ignoring the multi-domain nature of real-world data. We introduce a multi-domain active learning benchmark to bridge this gap. Our benchmark demonstrates that traditional single-domain active learning strategies are often less effective than random selection in multi-domain scenarios. We also introduce CLIP-GeoYFCC, a novel large-scale image dataset built around geographical domains, in contrast to existing genre-based domain datasets. Analysis on our benchmark shows that all multi-domain strategies exhibit significant tradeoffs, with no strategy outperforming across all datasets or all metrics, emphasizing the need for future research.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00364"
  },
  "2312.00360": {
    "title": "Efficient Multimodal Semantic Segmentation via Dual-Prompt Learning",
    "authors": [
      "Shaohua Dong",
      "Yunhe Feng",
      "Qing Yang",
      "Yan Huang",
      "Dongfang Liu",
      "Heng Fan"
    ],
    "abstract": "Multimodal (e.g., RGB-Depth/RGB-Thermal) fusion has shown great potential for improving semantic segmentation in complex scenes (e.g., indoor/low-light conditions). Existing approaches often fully fine-tune a dual-branch encoder-decoder framework with a complicated feature fusion strategy for achieving multimodal semantic segmentation, which is training-costly due to the massive parameter updates in feature extraction and fusion. To address this issue, we propose a surprisingly simple yet effective dual-prompt learning network (dubbed DPLNet) for training-efficient multimodal (e.g., RGB-D/T) semantic segmentation. The core of DPLNet is to directly adapt a frozen pre-trained RGB model to multimodal semantic segmentation, reducing parameter updates. For this purpose, we present two prompt learning modules, comprising multimodal prompt generator (MPG) and multimodal feature adapter (MFA). MPG works to fuse the features from different modalities in a compact manner and is inserted from shadow to deep stages to generate the multi-level multimodal prompts that are injected into the frozen backbone, while MPG adapts prompted multimodal features in the frozen backbone for better multimodal semantic segmentation. Since both the MPG and MFA are lightweight, only a few trainable parameters (3.88M, 4.4% of the pre-trained backbone parameters) are introduced for multimodal feature fusion and learning. Using a simple decoder (3.27M parameters), DPLNet achieves new state-of-the-art performance or is on a par with other complex approaches on four RGB-D/T semantic segmentation datasets while satisfying parameter efficiency. Moreover, we show that DPLNet is general and applicable to other multimodal tasks such as salient object detection and video semantic segmentation. Without special design, DPLNet outperforms many complicated models. Our code will be available at github.com/ShaohuaDong2021/DPLNet.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.00360"
  },
  "2312.00359": {
    "title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training",
    "authors": [
      "Yefan Zhou",
      "Tianyu Pang",
      "Keqin Liu",
      "Charles H. Martin",
      "Michael W. Mahoney",
      "Yaoqing Yang"
    ],
    "abstract": "Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs, and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00359"
  },
  "2312.00358": {
    "title": "Impact of Data Augmentation on QCNNs",
    "authors": [
      "Leting Zhouli",
      "Peiyong Wang",
      "Udaya Parampalli"
    ],
    "abstract": "In recent years, Classical Convolutional Neural Networks (CNNs) have been applied for image recognition successfully. Quantum Convolutional Neural Networks (QCNNs) are proposed as a novel generalization to CNNs by using quantum mechanisms. The quantum mechanisms lead to an efficient training process in QCNNs by reducing the size of input from $N$ to $log_2N$. This paper implements and compares both CNNs and QCNNs by testing losses and prediction accuracy on three commonly used datasets. The datasets include the MNIST hand-written digits, Fashion MNIST and cat/dog face images. Additionally, data augmentation (DA), a technique commonly used in CNNs to improve the performance of classification by generating similar images based on original inputs, is also implemented in QCNNs. Surprisingly, the results showed that data augmentation didn't improve QCNNs performance. The reasons and logic behind this result are discussed, hoping to expand our understanding of Quantum machine learning theory.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00358"
  },
  "2312.00357": {
    "title": "A Generalizable Deep Learning System for Cardiac MRI",
    "authors": [
      "Rohan Shad",
      "Cyril Zakka",
      "Dhamanpreet Kaur",
      "Robyn Fong",
      "Ross Warren Filice",
      "John Mongan",
      "Kimberly Kalianos",
      "Nishith Khandwala",
      "David Eng",
      "Matthew Leipzig",
      "Walter Witschey",
      "Alejandro de Feria",
      "Victor Ferrari",
      "Euan Ashley",
      "Michael A. Acker",
      "Curtis Langlotz",
      "William Hiesinger"
    ],
    "abstract": "Cardiac MRI allows for a comprehensive assessment of myocardial structure, function, and tissue characteristics. Here we describe a foundational vision system for cardiac MRI, capable of representing the breadth of human cardiovascular disease and health. Our deep learning model is trained via self-supervised contrastive learning, by which visual concepts in cine-sequence cardiac MRI scans are learned from the raw text of the accompanying radiology reports. We train and evaluate our model on data from four large academic clinical institutions in the United States. We additionally showcase the performance of our models on the UK BioBank, and two additional publicly available external datasets. We explore emergent zero-shot capabilities of our system, and demonstrate remarkable performance across a range of tasks; including the problem of left ventricular ejection fraction regression, and the diagnosis of 35 different conditions such as cardiac amyloidosis and hypertrophic cardiomyopathy. We show that our deep learning system is capable of not only understanding the staggering complexity of human cardiovascular disease, but can be directed towards clinical problems of interest yielding impressive, clinical grade diagnostic accuracy with a fraction of the training data typically required for such tasks.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00357"
  },
  "2312.00356": {
    "title": "Transfer learning for predicting source terms of principal component transport in chemically reactive flow",
    "authors": [
      "Ki Sung Jung",
      "Tarek Echekki",
      "Jacqueline H. Chen",
      "Mohammad Khalil"
    ],
    "abstract": "The objective of this study is to evaluate whether the number of requisite training samples can be reduced with the use of various transfer learning models for predicting, for example, the chemical source terms of the data-driven reduced-order model that represents the homogeneous ignition process of a hydrogen/air mixture. Principal component analysis is applied to reduce the dimensionality of the hydrogen/air mixture in composition space. Artificial neural networks (ANNs) are used to tabulate the reaction rates of principal components, and subsequently, a system of ordinary differential equations is solved. As the number of training samples decreases at the target task (i.e.,for T0 > 1000 K and various phi), the reduced-order model fails to predict the ignition evolution of a hydrogen/air mixture. Three transfer learning strategies are then applied to the training of the ANN model with a sparse dataset. The performance of the reduced-order model with a sparse dataset is found to be remarkably enhanced if the training of the ANN model is restricted by a regularization term that controls the degree of knowledge transfer from source to target tasks. To this end, a novel transfer learning method is introduced, parameter control via partial initialization and regularization (PaPIR), whereby the amount of knowledge transferred is systemically adjusted for the initialization and regularization of the ANN model in the target task. It is found that an additional performance gain can be achieved by changing the initialization scheme of the ANN model in the target task when the task similarity between source and target tasks is relatively low.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00356"
  },
  "2312.00353": {
    "title": "On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs",
    "authors": [
      "Pei-Chi Lo",
      "Yi-Hang Tsai",
      "Ee-Peng Lim",
      "San-Yih Hwang"
    ],
    "abstract": "This paper examines the capacity of LLMs to reason with knowledge graphs using their internal knowledge graph, i.e., the knowledge graph they learned during pre-training. Two research questions are formulated to investigate the accuracy of LLMs in recalling information from pre-training knowledge graphs and their ability to infer knowledge graph relations from context. To address these questions, we employ LLMs to perform four distinct knowledge graph reasoning tasks. Furthermore, we identify two types of hallucinations that may occur during knowledge reasoning with LLMs: content and ontology hallucination. Our experimental results demonstrate that LLMs can successfully tackle both simple and complex knowledge graph reasoning tasks from their own memory, as well as infer from input context.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00353"
  },
  "2312.00352": {
    "title": "Quantum Kernel t-Distributed Stochastic Neighbor Embedding",
    "authors": [
      "Yoshiaki Kawase",
      "Kosuke Mitarai",
      "Keisuke Fujii"
    ],
    "abstract": "Data visualization is important in understanding the characteristics of data that are difficult to see directly. It is used to visualize loss landscapes and optimization trajectories to analyze optimization performance. Popular optimization analysis is performed by visualizing a loss landscape around the reached local or global minimum using principal component analysis. However, this visualization depends on the variational parameters of a quantum circuit rather than quantum states, which makes it difficult to understand the mechanism of optimization process through the property of quantum states. Here, we propose a quantum data visualization method using quantum kernels, which enables us to offer fast and highly accurate visualization of quantum states. In our numerical experiments, we visualize hand-written digits dataset and apply $k$-nearest neighbor algorithm to the low-dimensional data to quantitatively evaluate our proposed method compared with a classical kernel method. As a result, our proposed method achieves comparable accuracy to the state-of-the-art classical kernel method, meaning that the proposed visualization method based on quantum machine learning does not degrade the separability of the input higher dimensional data. Furthermore, we visualize the optimization trajectories of finding the ground states of transverse field Ising model and successfully find the trajectory characteristics. Since quantum states are higher dimensional objects that can only be seen via observables, our visualization method, which inherits the similarity of quantum data, would be useful in understanding the behavior of quantum circuits and algorithms.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2312.00352"
  },
  "2312.00351": {
    "title": "Manipulating the Label Space for In-Context Classification",
    "authors": [
      "Haokun Chen",
      "Xu Yang",
      "Yuhang Huang",
      "Zihan Wu",
      "Jing Wang",
      "Xin Geng"
    ],
    "abstract": "After pre-training by generating the next word conditional on previous words, the Language Model (LM) acquires the ability of In-Context Learning (ICL) that can learn a new task conditional on the context of the given in-context examples (ICEs). Similarly, visually-conditioned Language Modelling is also used to train Vision-Language Models (VLMs) with ICL ability. However, such VLMs typically exhibit weaker classification abilities compared to contrastive learning-based models like CLIP, since the Language Modelling objective does not directly contrast whether an object is paired with a text. To improve the ICL of classification, using more ICEs to provide more knowledge is a straightforward way. However, this may largely increase the selection time, and more importantly, the inclusion of additional in-context images tends to extend the length of the in-context sequence beyond the processing capacity of a VLM. To alleviate these limitations, we propose to manipulate the label space of each ICE to increase its knowledge density, allowing for fewer ICEs to convey as much information as a larger set would. Specifically, we propose two strategies which are Label Distribution Enhancement and Visual Descriptions Enhancement to improve In-context classification performance on diverse datasets, including the classic ImageNet and more fine-grained datasets like CUB-200. Specifically, using our approach on ImageNet, we increase accuracy from 74.70\\% in a 4-shot setting to 76.21\\% with just 2 shots. surpassing CLIP by 0.67\\%. On CUB-200, our method raises 1-shot accuracy from 48.86\\% to 69.05\\%, 12.15\\% higher than CLIP. The code is given in https://anonymous.4open.science/r/MLS_ICC.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2312.00351"
  },
  "2312.00349": {
    "title": "The Case for Scalable, Data-Driven Theory: A Paradigm for Scientific Progress in NLP",
    "authors": [
      "Julian Michael"
    ],
    "abstract": "I propose a paradigm for scientific progress in NLP centered around developing scalable, data-driven theories of linguistic structure. The idea is to collect data in tightly scoped, carefully defined ways which allow for exhaustive annotation of behavioral phenomena of interest, and then use machine learning to construct explanatory theories of these phenomena which can form building blocks for intelligible AI systems. After laying some conceptual groundwork, I describe several investigations into data-driven theories of shallow semantic structure using Question-Answer driven Semantic Role Labeling (QA-SRL), a schema for annotating verbal predicate-argument relations using highly constrained question-answer pairs. While this only scratches the surface of the complex language behaviors of interest in AI, I outline principles for data collection and theoretical modeling which can inform future scientific progress. This note summarizes and draws heavily on my PhD thesis.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00349"
  },
  "2312.00348": {
    "title": "Student Activity Recognition in Classroom Environments using Transfer Learning",
    "authors": [
      "Anagha Deshpande",
      "Vedant Deshpande"
    ],
    "abstract": "The recent advances in artificial intelligence and deep learning facilitate automation in various applications including home automation, smart surveillance systems, and healthcare among others. Human Activity Recognition is one of its emerging applications, which can be implemented in a classroom environment to enhance safety, efficiency, and overall educational quality. This paper proposes a system for detecting and recognizing the activities of students in a classroom environment. The dataset has been structured and recorded by the authors since a standard dataset for this task was not available at the time of this study. Transfer learning, a widely adopted method within the field of deep learning, has proven to be helpful in complex tasks like image and video processing. Pretrained models including VGG-16, ResNet-50, InceptionV3, and Xception are used for feature extraction and classification tasks. Xception achieved an accuracy of 93%, on the novel classroom dataset, outperforming the other three models in consideration. The system proposed in this study aims to introduce a safer and more productive learning environment for students and educators.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00348"
  },
  "2312.00347": {
    "title": "RTQ: Rethinking Video-language Understanding Based on Image-text Model",
    "authors": [
      "Xiao Wang",
      "Yaoyu Li",
      "Tian Gan",
      "Zheng Zhang",
      "Jingjing Lv",
      "Liqiang Nie"
    ],
    "abstract": "Recent advancements in video-language understanding have been established on the foundation of image-text models, resulting in promising outcomes due to the shared knowledge between images and videos. However, video-language understanding presents unique challenges due to the inclusion of highly complex semantic details, which result in information redundancy, temporal dependency, and scene complexity. Current techniques have only partially tackled these issues, and our quantitative analysis indicates that some of these methods are complementary. In light of this, we propose a novel framework called RTQ (Refine, Temporal model, and Query), which addresses these challenges simultaneously. The approach involves refining redundant information within frames, modeling temporal relations among frames, and querying task-specific information from the videos. Remarkably, our model demonstrates outstanding performance even in the absence of video-language pre-training, and the results are comparable with or superior to those achieved by state-of-the-art pre-training methods. Code is available at https://github.com/SCZwangxiao/RTQ-MM2023.\n        \u25b3 Less",
    "submission_date": "17 December, 2023",
    "eprint_id": "2312.00347"
  },
  "2312.00344": {
    "title": "TRC: Trust Region Conditional Value at Risk for Safe Reinforcement Learning",
    "authors": [
      "Dohyeong Kim",
      "Songhwai Oh"
    ],
    "abstract": "As safety is of paramount importance in robotics, reinforcement learning that reflects safety, called safe RL, has been studied extensively. In safe RL, we aim to find a policy which maximizes the desired return while satisfying the defined safety constraints. There are various types of constraints, among which constraints on conditional value at risk (CVaR) effectively lower the probability of failures caused by high costs since CVaR is a conditional expectation obtained above a certain percentile. In this paper, we propose a trust region-based safe RL method with CVaR constraints, called TRC. We first derive the upper bound on CVaR and then approximate the upper bound in a differentiable form in a trust region. Using this approximation, a subproblem to get policy gradients is formulated, and policies are trained by iteratively solving the subproblem. TRC is evaluated through safe navigation tasks in simulations with various robots and a sim-to-real environment with a Jackal robot from Clearpath. Compared to other safe RL methods, the performance is improved by 1.93 times while the constraints are satisfied in all experiments.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00344"
  },
  "2312.00342": {
    "title": "Efficient Off-Policy Safe Reinforcement Learning Using Trust Region Conditional Value at Risk",
    "authors": [
      "Dohyeong Kim",
      "Songhwai Oh"
    ],
    "abstract": "This paper aims to solve a safe reinforcement learning (RL) problem with risk measure-based constraints. As risk measures, such as conditional value at risk (CVaR), focus on the tail distribution of cost signals, constraining risk measures can effectively prevent a failure in the worst case. An on-policy safe RL method, called TRC, deals with a CVaR-constrained RL problem using a trust region method and can generate policies with almost zero constraint violations with high returns. However, to achieve outstanding performance in complex environments and satisfy safety constraints quickly, RL methods are required to be sample efficient. To this end, we propose an off-policy safe RL method with CVaR constraints, called off-policy TRC. If off-policy data from replay buffers is directly used to train TRC, the estimation error caused by the distributional shift results in performance degradation. To resolve this issue, we propose novel surrogate functions, in which the effect of the distributional shift can be reduced, and introduce an adaptive trust-region constraint to ensure a policy not to deviate far from replay buffers. The proposed method has been evaluated in simulation and real-world environments and satisfied safety constraints within a few steps while achieving high returns even in complex robotic tasks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00342"
  },
  "2312.00339": {
    "title": "Propagation of chaos in path spaces via information theory",
    "authors": [
      "Lei Li",
      "Yuelin Wang",
      "Yuliang Wang"
    ],
    "abstract": "We study the mean-field limit of the stochastic interacting particle systems via tools from information theory. The key in our method is that, after applying the data processing inequality, one only needs to handle independent copies of solutions to the mean-field McKean stochastic differential equations, which then allows one to apply the law of large numbers. Our result on the propagation of chaos in path space is valid for both first and second order interacting particle systems; in particular, for the latter one our convergence rate is independent of the particle mass and also only linear in time. Our framework is different from current approaches in literature and could provide new insight for the study of interacting particle systems.\n        \u25b3 Less",
    "submission_date": "21 January, 2024",
    "eprint_id": "2312.00339"
  },
  "2312.00337": {
    "title": "Dynamic Matrix of Extremisms and Terrorism (DMET): A Continuum Approach Towards Identifying Different Degrees of Extremisms",
    "authors": [
      "Marten Risius",
      "Kevin M. Blasiak",
      "Susilo Wibisono",
      "Rita Jabri-Markwell",
      "Winnifred Louis"
    ],
    "abstract": "We propose to extend the current binary understanding of terrorism (versus non-terrorism) with a Dynamic Matrix of Extremisms and Terrorism (DMET). DMET considers the whole ecosystem of content and actors that can contribute to a continuum of extremism (e.g., right-wing, left-wing, religious, separatist, single-issue). It organizes levels of extremisms by varying degrees of ideological engagement and the presence of violence identified (e.g., partisan, fringe, violent extremism, terrorism) based on cognitive and behavioral cues and group dynamics. DMET is globally applicable due to its comprehensive conceptualization of the levels of extremisms. It is also dynamic, enabling iterative mapping with the region- and time-specific classifications of extremist actors. Once global actors recognize DMET types and their distinct characteristics, they can comprehensively analyze the profiles of extremist actors (e.g., individuals, groups, movements), track these respective actors and their activities (e.g., social media content) over time, and launch targeted counter activities (e.g. de-platforming, content moderation, or redirects to targeted CVE narratives).\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00337"
  },
  "2312.00336": {
    "title": "Hypergraph Node Representation Learning with One-Stage Message Passing",
    "authors": [
      "Shilin Qu",
      "Weiqing Wang",
      "Yuan-Fang Li",
      "Xin Zhou",
      "Fajie Yuan"
    ],
    "abstract": "Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node -> hyperedge -> node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node -> node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52% and 6.70%. Our code and datasets are available.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00336"
  },
  "2312.00334": {
    "title": "UAV-Aided Lifelong Learning for AoI and Energy Optimization in Non-Stationary IoT Networks",
    "authors": [
      "Zhenzhen Gong",
      "Omar Hashash",
      "Yingze Wang",
      "Qimei Cui",
      "Wei Ni",
      "Walid Saad",
      "Kei Sakaguchi"
    ],
    "abstract": "In this paper, a novel joint energy and age of information (AoI) optimization framework for IoT devices in a non-stationary environment is presented. In particular, IoT devices that are distributed in the real-world are required to efficiently utilize their computing resources so as to balance the freshness of their data and their energy consumption. To optimize the performance of IoT devices in such a dynamic setting, a novel lifelong reinforcement learning (RL) solution that enables IoT devices to continuously adapt their policies to each newly encountered environment is proposed. Given that IoT devices have limited energy and computing resources, an unmanned aerial vehicle (UAV) is leveraged to visit the IoT devices and update the policy of each device sequentially. As such, the UAV is exploited as a mobile learning agent that can learn a shared knowledge base with a feature base in its training phase, and feature sets of a zero-shot learning method in its testing phase, to generalize between the environments. To optimize the trajectory and flying velocity of the UAV, an actor-critic network is leveraged so as to minimize the UAV energy consumption. Simulation results show that the proposed lifelong RL solution can outperform the state-of-art benchmarks by enhancing the balanced cost of IoT devices by $8.3\\%$ when incorporating warm-start policies for unseen environments. In addition, our solution achieves up to $49.38\\%$ reduction in terms of energy consumption by the UAV in comparison to the random flying strategy.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00334"
  },
  "2312.00332": {
    "title": "Matching Weak Informative Ontologies",
    "authors": [
      "Peng Wang"
    ],
    "abstract": "Most existing ontology matching methods utilize the literal information to discover alignments. However, some literal information in ontologies may be opaque and some ontologies may not have sufficient literal information. In this paper, these ontologies are named as weak informative ontologies (WIOs) and it is challenging for existing methods to matching WIOs. On one hand, string-based and linguistic-based matching methods cannot work well for WIOs. On the other hand, some matching methods use external resources to improve their performance, but collecting and processing external resources is still time-consuming. To address this issue, this paper proposes a practical method for matching WIOs by employing the ontology structure information to discover alignments. First, the semantic subgraphs are extracted from the ontology graph to capture the precise meanings of ontology elements. Then, a new similarity propagation model is designed for matching WIOs. Meanwhile, in order to avoid meaningless propagation, the similarity propagation is constrained by semantic subgraphs and other conditions. Consequently, the similarity propagation model ensures a balance between efficiency and quality during matching. Finally, the similarity propagation model uses a few credible alignments as seeds to find more alignments, and some useful strategies are adopted to improve the performance. This matching method for WIOs has been implemented in the ontology matching system Lily. Experimental results on public OAEI benchmark datasets demonstrate that Lily significantly outperforms most of the state-of-the-art works in both WIO matching tasks and general ontology matching tasks. In particular, Lily increases the recall by a large margin, while it still obtains high precision of matching results.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00332"
  },
  "2312.00324": {
    "title": "Machine Learning for Actionable Warning Identification: A Comprehensive Survey",
    "authors": [
      "Xiuting Ge",
      "Chunrong Fang",
      "Xuanye Li",
      "Weisong Sun",
      "Daoyuan Wu",
      "Juan Zhai",
      "Shangwei Lin",
      "Zhihong Zhao",
      "Yang Liu",
      "Zhenyu Chen"
    ],
    "abstract": "Actionable Warning Identification (AWI) plays a crucial role in improving the usability of static code analyzers. With recent advances in Machine Learning (ML), various approaches have been proposed to incorporate ML techniques into AWI. These ML-based AWI approaches, benefiting from ML's strong ability to learn subtle and previously unseen patterns from historical data, have demonstrated superior performance. However, a comprehensive overview of these approaches is missing, which could hinder researchers/practitioners from understanding the current process and discovering potential for future improvement in the ML-based AWI community. In this paper, we systematically review the state-of-the-art ML-based AWI approaches. First, we employ a meticulous survey methodology and gather 50 primary studies from 2000/01/01 to 2023/09/01. Then, we outline the typical ML-based AWI workflow, including warning dataset preparation, preprocessing, AWI model construction, and evaluation stages. In such a workflow, we categorize ML-based AWI approaches based on the warning output format. Besides, we analyze the techniques used in each stage, along with their strengths, weaknesses, and distribution. Finally, we provide practical research directions for future ML-based AWI approaches, focusing on aspects like data improvement (e.g., enhancing the warning labeling strategy) and model exploration (e.g., exploring large language models for AWI).\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00324"
  },
  "2312.00320": {
    "title": "On Multi-step Fuzzy Inference in Goedel Logic",
    "authors": [
      "Dusan Guller"
    ],
    "abstract": "This paper addresses the logical and computational foundations of multi-step fuzzy inference using the Mamdani-Assilian type of fuzzy rules by implementing such inference in Goedel logic with truth constants. We apply the results achieved in the development of a hyperresolution calculus for this logic. We pose three fundamental problems: reachability, stability, the existence of a k-cycle in multi-step fuzzy inference and reduce them to certain deduction and unsatisfiability problems. The corresponding unsatisfiability problems may be solved using hyperresolution.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00320"
  },
  "2312.00316": {
    "title": "Improving Efficiency of DNN-based Relocalization Module for Autonomous Driving with Server-side Computing",
    "authors": [
      "Dengbo Li",
      "Jieren Cheng",
      "Boyi Liu"
    ],
    "abstract": "In this work, we present a novel framework for camera relocation in autonomous vehicles, leveraging deep neural networks (DNN). While existing literature offers various DNN-based camera relocation methods, their deployment is hindered by their high computational demands during inference. In contrast, our approach addresses this challenge through edge cloud collaboration. Specifically, we strategically offload certain modules of the neural network to the server and evaluate the inference time of data frames under different network segmentation schemes to guide our offloading decisions. Our findings highlight the vital role of server-side offloading in DNN-based camera relocation for autonomous vehicles, and we also discuss the results of data fusion. Finally, we validate the effectiveness of our proposed framework through experimental evaluation.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00316"
  },
  "2312.00314": {
    "title": "A bilevel optimal motion planning (BOMP) model with application to autonomous parking",
    "authors": [
      "Shenglei Shi",
      "Youlun Xiong",
      "Jiankui Chen",
      "Caihua Xiong"
    ],
    "abstract": "In this paper, we present a bilevel optimal motion planning (BOMP) model for autonomous parking. The BOMP model treats motion planning as an optimal control problem, in which the upper level is designed for vehicle nonlinear dynamics, and the lower level is for geometry collision-free constraints. The significant feature of the BOMP model is that the lower level is a linear programming problem that serves as a constraint for the upper-level problem. That is, an optimal control problem contains an embedded optimization problem as constraints. Traditional optimal control methods cannot solve the BOMP problem directly. Therefore, the modified approximate Karush-Kuhn-Tucker theory is applied to generate a general nonlinear optimal control problem. Then the pseudospectral optimal control method solves the converted problem. Particularly, the lower level is the $J_2$-function that acts as a distance function between convex polyhedron objects. Polyhedrons can approximate vehicles in higher precision than spheres or ellipsoids. Besides, the modified $J_2$-function (MJ) and the active-points based modified $J_2$-function (APMJ) are proposed to reduce the variables number and time complexity. As a result, an iteirative two-stage BOMP algorithm for autonomous parking concerning dynamical feasibility and collision-free property is proposed. The MJ function is used in the initial stage to find an initial collision-free approximate optimal trajectory and the active points, then the APMJ function in the final stage finds out the optimal trajectory. Simulation results and experiment on Turtlebot3 validate the BOMP model, and demonstrate that the computation speed increases almost two orders of magnitude compared with the area criterion based collision avoidance method.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00314"
  },
  "2312.00313": {
    "title": "Improving Normalization with the James-Stein Estimator",
    "authors": [
      "Seyedalireza Khoshsirat",
      "Chandra Kambhamettu"
    ],
    "abstract": "Stein's paradox holds considerable sway in high-dimensional statistics, highlighting that the sample mean, traditionally considered the de facto estimator, might not be the most efficacious in higher dimensions. To address this, the James-Stein estimator proposes an enhancement by steering the sample means toward a more centralized mean vector. In this paper, first, we establish that normalization layers in deep learning use inadmissible estimators for mean and variance. Next, we introduce a novel method to employ the James-Stein estimator to improve the estimation of mean and variance within normalization layers. We evaluate our method on different computer vision tasks: image classification, semantic segmentation, and 3D object classification. Through these evaluations, it is evident that our improved normalization layers consistently yield superior accuracy across all tasks without extra computational burden. Moreover, recognizing that a plethora of shrinkage estimators surpass the traditional estimator in performance, we study two other prominent shrinkage estimators: Ridge and LASSO. Additionally, we provide visual representations to intuitively demonstrate the impact of shrinkage on the estimated layer statistics. Finally, we study the effect of regularization and batch size on our modified batch normalization. The studies show that our method is less sensitive to batch size and regularization, improving accuracy under various setups.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00313"
  },
  "2312.00312": {
    "title": "Segment Anything Model-guided Collaborative Learning Network for Scribble-supervised Polyp Segmentation",
    "authors": [
      "Yiming Zhao",
      "Tao Zhou",
      "Yunqi Gu",
      "Yi Zhou",
      "Yizhe Zhang",
      "Ye Wu",
      "Huazhu Fu"
    ],
    "abstract": "Polyp segmentation plays a vital role in accurately locating polyps at an early stage, which holds significant clinical importance for the prevention of colorectal cancer. Various polyp segmentation methods have been developed using fully-supervised deep learning techniques. However, pixel-wise annotation for polyp images by physicians during the diagnosis is both time-consuming and expensive. Moreover, visual foundation models such as the Segment Anything Model (SAM) have shown remarkable performance. Nevertheless, directly applying SAM to medical segmentation may not produce satisfactory results due to the inherent absence of medical knowledge. In this paper, we propose a novel SAM-guided Collaborative Learning Network (SAM-CLNet) for scribble-supervised polyp segmentation, enabling a collaborative learning process between our segmentation network and SAM to boost the model performance. Specifically, we first propose a Cross-level Enhancement and Aggregation Network (CEA-Net) for weakly-supervised polyp segmentation. Within CEA-Net, we propose a Cross-level Enhancement Module (CEM) that integrates the adjacent features to enhance the representation capabilities of different resolution features. Additionally, a Feature Aggregation Module (FAM) is employed to capture richer features across multiple levels. Moreover, we present a box-augmentation strategy that combines the segmentation maps generated by CEA-Net with scribble annotations to create more precise prompts. These prompts are then fed into SAM, generating segmentation SAM-guided masks, which can provide additional supervision to train CEA-Net effectively. Furthermore, we present an Image-level Filtering Mechanism to filter out unreliable SAM-guided masks. Extensive experimental results show that our SAM-CLNet outperforms state-of-the-art weakly-supervised segmentation methods.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00312"
  },
  "2312.00308": {
    "title": "A knowledge-based data-driven (KBDD) framework for all-day identification of cloud types using satellite remote sensing",
    "authors": [
      "Longfeng Nie",
      "Yuntian Chen",
      "Mengge Du",
      "Changqi Sun",
      "Dongxiao Zhang"
    ],
    "abstract": "Cloud types, as a type of meteorological data, are of particular significance for evaluating changes in rainfall, heatwaves, water resources, floods and droughts, food security and vegetation cover, as well as land use. In order to effectively utilize high-resolution geostationary observations, a knowledge-based data-driven (KBDD) framework for all-day identification of cloud types based on spectral information from Himawari-8/9 satellite sensors is designed. And a novel, simple and efficient network, named CldNet, is proposed. Compared with widely used semantic segmentation networks, including SegNet, PSPNet, DeepLabV3+, UNet, and ResUnet, our proposed model CldNet with an accuracy of 80.89+-2.18% is state-of-the-art in identifying cloud types and has increased by 32%, 46%, 22%, 2%, and 39%, respectively. With the assistance of auxiliary information (e.g., satellite zenith/azimuth angle, solar zenith/azimuth angle), the accuracy of CldNet-W using visible and near-infrared bands and CldNet-O not using visible and near-infrared bands on the test dataset is 82.23+-2.14% and 73.21+-2.02%, respectively. Meanwhile, the total parameters of CldNet are only 0.46M, making it easy for edge deployment. More importantly, the trained CldNet without any fine-tuning can predict cloud types with higher spatial resolution using satellite spectral data with spatial resolution 0.02\u00b0*0.02\u00b0, which indicates that CldNet possesses a strong generalization ability. In aggregate, the KBDD framework using CldNet is a highly effective cloud-type identification system capable of providing a high-fidelity, all-day, spatiotemporal cloud-type database for many climate assessment fields.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00308"
  },
  "2312.00306": {
    "title": "RadioGalaxyNET: Dataset and Novel Computer Vision Algorithms for the Detection of Extended Radio Galaxies and Infrared Hosts",
    "authors": [
      "Nikhel Gupta",
      "Zeeshan Hayder",
      "Ray P. Norris",
      "Minh Huynh",
      "Lars Petersson"
    ],
    "abstract": "Creating radio galaxy catalogues from next-generation deep surveys requires automated identification of associated components of extended sources and their corresponding infrared hosts. In this paper, we introduce RadioGalaxyNET, a multimodal dataset, and a suite of novel computer vision algorithms designed to automate the detection and localization of multi-component extended radio galaxies and their corresponding infrared hosts. The dataset comprises 4,155 instances of galaxies in 2,800 images with both radio and infrared channels. Each instance provides information about the extended radio galaxy class, its corresponding bounding box encompassing all components, the pixel-level segmentation mask, and the keypoint position of its corresponding infrared host galaxy. RadioGalaxyNET is the first dataset to include images from the highly sensitive Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope, corresponding infrared images, and instance-level annotations for galaxy detection. We benchmark several object detection algorithms on the dataset and propose a novel multimodal approach to simultaneously detect radio galaxies and the positions of infrared hosts.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00306"
  },
  "2312.00305": {
    "title": "Multiple Testing of Linear Forms for Noisy Matrix Completion",
    "authors": [
      "Wanteng Ma",
      "Lilun Du",
      "Dong Xia",
      "Ming Yuan"
    ],
    "abstract": "Many important tasks of large-scale recommender systems can be naturally cast as testing multiple linear forms for noisy matrix completion. These problems, however, present unique challenges because of the subtle bias-and-variance tradeoff of and an intricate dependence among the estimated entries induced by the low-rank structure. In this paper, we develop a general approach to overcome these difficulties by introducing new statistics for individual tests with sharp asymptotics both marginally and jointly, and utilizing them to control the false discovery rate (FDR) via a data splitting and symmetric aggregation scheme. We show that valid FDR control can be achieved with guaranteed power under nearly optimal sample size requirements using the proposed methodology. Extensive numerical simulations and real data examples are also presented to further illustrate its practical merits.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00305"
  },
  "2312.00304": {
    "title": "Developmental Pretraining (DPT) for Image Classification Networks",
    "authors": [
      "Niranjan Rajesh",
      "Debayan Gupta"
    ],
    "abstract": "In the backdrop of increasing data requirements of Deep Neural Networks for object recognition that is growing more untenable by the day, we present Developmental PreTraining (DPT) as a possible solution. DPT is designed as a curriculum-based pre-training approach designed to rival traditional pre-training techniques that are data-hungry. These training approaches also introduce unnecessary features that could be misleading when the network is employed in a downstream classification task where the data is sufficiently different from the pre-training data and is scarce. We design the curriculum for DPT by drawing inspiration from human infant visual development. DPT employs a phased approach where carefully-selected primitive and universal features like edges and shapes are taught to the network participating in our pre-training regime. A model that underwent the DPT regime is tested against models with randomised weights to evaluate the viability of DPT.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00304"
  },
  "2312.00303": {
    "title": "A Review of the In-Network Computing and Its Role in the Edge-Cloud Continuum",
    "authors": [
      "Manel Gherari",
      "Fatemeh Aghaali Akbari",
      "Sama Habibi",
      "Soukaina Ouledsidi Ali",
      "Zakaria Ait Hmitti",
      "Youcef Kardjadja",
      "Muhammad Saqib",
      "Adyson Magalhaes Maia",
      "Marsa Rayani",
      "Ece Gelal Soyak",
      "Halima Elbiaze",
      "Ozgur Ercetin",
      "Yacine Ghamri-Doudane",
      "Roch Glitho",
      "Wessam Ajib"
    ],
    "abstract": "Future networks are anticipated to enable exciting applications and industrial services ranging from Multisensory Extended Reality to Holographic and Haptic communication. These services are accompanied by high bandwidth requirements and/or require low latency and low reliability, which leads to the need for scarce and expensive resources. Cloud and edge computing offer different functionalities to these applications that require communication, computing, and caching (3C) resources working collectively. Hence, a paradigm shift is necessary to enable the joint management of the 3Cs in the edge-cloud continuum. We argue that In-Network Computing (INC) is the missing element that completes the edge-cloud continuum. This paper provides a detailed analysis of the driving use-cases, explores the synergy between INC and 3C, and emphasizes the crucial role of INC. A discussion on the opportunities and challenges posed by INC is held from various perspectives, including hardware implementation, architectural design, and regulatory and commercial aspects.\n        \u25b3 Less",
    "submission_date": "4 August, 2023",
    "eprint_id": "2312.00303"
  },
  "2312.00299": {
    "title": "QIENet: Quantitative irradiance estimation network using recurrent neural network based on satellite remote sensing data",
    "authors": [
      "Longfeng Nie",
      "Yuntian Chen",
      "Dongxiao Zhang",
      "Xinyue Liu",
      "Wentian Yuan"
    ],
    "abstract": "Global horizontal irradiance (GHI) plays a vital role in estimating solar energy resources, which are used to generate sustainable green energy. In order to estimate GHI with high spatial resolution, a quantitative irradiance estimation network, named QIENet, is proposed. Specifically, the temporal and spatial characteristics of remote sensing data of the satellite Himawari-8 are extracted and fused by recurrent neural network (RNN) and convolution operation, respectively. Not only remote sensing data, but also GHI-related time information (hour, day, and month) and geographical information (altitude, longitude, and latitude), are used as the inputs of QIENet. The satellite spectral channels B07 and B11 - B15 and time are recommended as model inputs for QIENet according to the spatial distributions of annual solar energy. Meanwhile, QIENet is able to capture the impact of various clouds on hourly GHI estimates. More importantly, QIENet does not overestimate ground observations and can also reduce RMSE by 27.51%/18.00%, increase R2 by 20.17%/9.42%, and increase r by 8.69%/3.54% compared with ERA5/NSRDB. Furthermore, QIENet is capable of providing a high-fidelity hourly GHI database with spatial resolution 0.02\u00b0 * 0.02\u00b0(approximately 2km * 2km) for many applied energy fields.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00299"
  },
  "2312.00296": {
    "title": "Towards Aligned Canonical Correlation Analysis: Preliminary Formulation and Proof-of-Concept Results",
    "authors": [
      "Biqian Cheng",
      "Evangelos E. Papalexakis",
      "Jia Chen"
    ],
    "abstract": "Canonical Correlation Analysis (CCA) has been widely applied to jointly embed multiple views of data in a maximally correlated latent space. However, the alignment between various data perspectives, which is required by traditional approaches, is unclear in many practical cases. In this work we propose a new framework Aligned Canonical Correlation Analysis (ACCA), to address this challenge by iteratively solving the alignment and multi-view embedding.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00296"
  },
  "2312.00293": {
    "title": "PsyAttention: Psychological Attention Model for Personality Detection",
    "authors": [
      "Baohua Zhang",
      "Yongyi Huang",
      "Wenyao Cui",
      "Huaping Zhang",
      "Jianyun Shang"
    ],
    "abstract": "Work on personality detection has tended to incorporate psychological features from different personality models, such as BigFive and MBTI. There are more than 900 psychological features, each of which is helpful for personality detection. However, when used in combination, the application of different calculation standards among these features may result in interference between features calculated using distinct systems, thereby introducing noise and reducing performance. This paper adapts different psychological models in the proposed PsyAttention for personality detection, which can effectively encode psychological features, reducing their number by 85%. In experiments on the BigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and 86.30%, respectively, outperforming state-of-the-art methods, indicating that it is effective at encoding psychological features.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00293"
  },
  "2312.00292": {
    "title": "SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection",
    "authors": [
      "Anku Rani",
      "Dwip Dalal",
      "Shreya Gautam",
      "Pankaj Gupta",
      "Vinija Jain",
      "Aman Chadha",
      "Amit Sheth",
      "Amitava Das"
    ],
    "abstract": "Deception is the intentional practice of twisting information. It is a nuanced societal practice deeply intertwined with human societal evolution, characterized by a multitude of facets. This research explores the problem of deception through the lens of psychology, employing a framework that categorizes deception into three forms: lies of omission, lies of commission, and lies of influence. The primary focus of this study is specifically on investigating only lies of omission. We propose a novel framework for deception detection leveraging NLP techniques. We curated an annotated dataset of 876,784 samples by amalgamating a popular large-scale fake news dataset and scraped news headlines from the Twitter handle of Times of India, a well-known Indian news media house. Each sample has been labeled with four layers, namely: (i) the type of omission (speculation, bias, distortion, sounds factual, and opinion), (ii) colors of lies(black, white, etc), and (iii) the intention of such lies (to influence, etc) (iv) topic of lies (political, educational, religious, etc). We present a novel multi-task learning pipeline that leverages the dataless merging of fine-tuned language models to address the deception detection task mentioned earlier. Our proposed model achieved an F1 score of 0.87, demonstrating strong performance across all layers including the type, color, intent, and topic aspects of deceptive content. Finally, our research explores the relationship between lies of omission and propaganda techniques. To accomplish this, we conducted an in-depth analysis, uncovering compelling findings. For instance, our analysis revealed a significant correlation between loaded language and opinion, shedding light on their interconnectedness. To encourage further research in this field, we will be making the models and dataset available with the MIT License, making it favorable for open-source research.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00292"
  },
  "2312.00290": {
    "title": "Learning to forecast diagnostic parameters using pre-trained weather embedding",
    "authors": [
      "Peetak P. Mitra",
      "Vivek Ramavajjala"
    ],
    "abstract": "Data-driven weather prediction (DDWP) models are increasingly becoming popular for weather forecasting. However, while operational weather forecasts predict a wide variety of weather variables, DDWPs currently forecast a specific set of key prognostic variables. Non-prognostic (\"diagnostic\") variables are sometimes modeled separately as dependent variables of the prognostic variables (c.f. FourCastNet), or by including the diagnostic variable as a target in the DDWP. However, the cost of training and deploying bespoke models for each diagnostic variable can increase dramatically with more diagnostic variables, and limit the operational use of such models. Likewise, retraining an entire DDWP each time a new diagnostic variable is added is also cost-prohibitive. We present an two-stage approach that allows new diagnostic variables to be added to an end-to-end DDWP model without the expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen and \"downstream\" models are trained to predict diagnostic variables using only the latent representations of prognostic variables as input. Our experiments indicate that models trained using the two-stage approach offer accuracy comparable to training bespoke models, while leading to significant reduction in resource utilization during training and inference. This approach allows for new \"downstream\" models to be developed as needed, without affecting existing models and thus reducing the friction in operationalizing new models.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00290"
  },
  "2312.00289": {
    "title": "Robust Generalized Proportional Integral Control for Trajectory Tracking of Soft Actuators in a Pediatric Wearable Assistive Device",
    "authors": [
      "Caio Mucchiani",
      "Zhichao Liu",
      "Ipsita Sahin",
      "Elena Kokkoni",
      "Konstantinos Karydis"
    ],
    "abstract": "Soft robotics hold promise in the development of safe yet powered assistive wearable devices for infants. Key to this is the development of closed-loop controllers that can help regulate pneumatic pressure in the device's actuators in an effort to induce controlled motion at the user's limbs and be able to track different types of trajectories. This work develops a controller for soft pneumatic actuators aimed to power a pediatric soft wearable robotic device prototype for upper extremity motion assistance. The controller tracks desired trajectories for a system of soft pneumatic actuators supporting two-degree-of-freedom shoulder joint motion on an infant-sized engineered mannequin. The degrees of freedom assisted by the actuators are equivalent to shoulder motion (abduction/adduction and flexion/extension). Embedded inertial measurement unit sensors provide real-time joint feedback. Experimental data from performing reaching tasks using the engineered mannequin are obtained and compared against ground truth to evaluate the performance of the developed controller. Results reveal the proposed controller leads to accurate trajectory tracking performance across a variety of shoulder joint motions.\n        \u25b3 Less",
    "submission_date": "1 August, 2023",
    "eprint_id": "2312.00289"
  },
  "2312.00286": {
    "title": "Complexity-theoretic foundations of BosonSampling with a linear number of modes",
    "authors": [
      "Adam Bouland",
      "Daniel Brod",
      "Ishaun Datta",
      "Bill Fefferman",
      "Daniel Grier",
      "Felipe Hernandez",
      "Michal Oszmaniec"
    ],
    "abstract": "BosonSampling is the leading candidate for demonstrating quantum computational advantage in photonic systems. While we have recently seen many impressive experimental demonstrations, there is still a formidable distance between the complexity-theoretic hardness arguments and current experiments. One of the largest gaps involves the ratio of photons to modes: all current hardness evidence assumes a \"high-mode\" regime in which the number of linear optical modes scales at least quadratically in the number of photons. By contrast, current experiments operate in a \"low-mode\" regime with a linear number of modes. In this paper we bridge this gap, bringing the hardness evidence for the low-mode experiments to the same level as had been previously established for the high-mode regime. This involves proving a new worst-to-average-case reduction for computing the Permanent that is robust to large numbers of row repetitions and also to distributions over matrices with correlated entries.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00286"
  },
  "2312.00281": {
    "title": "A Scale-out Decentralized Blockchain Ledger System for Web3.0",
    "authors": [
      "Lide Xue",
      "Wei Yang",
      "Wei Li"
    ],
    "abstract": "The development of underlying technologies in blockchain mostly revolves around a difficult problem: how to enhance the performance of the system and reduce various costs of nodes (such as communication, storage and verification) without compromising the system's security and decentralization. Various layer-1 and layer-2 protocols have provided excellent solutions for this challenge. However, they cannot yet be considered as a ``silver bullet\". This paper proposes EZchain -- a novel decentralized ``scale-out\" ledger system designed for web3.0, aiming to enable blockchain technology to truly support ledger applications in large-scale fully decentralized networks. Without compromising security and decentralization, EZchain successfully accomplishes the following milestones: 1) Scalability: The theoretical throughput of EZchain can be infinitely expanded, nearly unaffected by bandwidth and other resource constraints. 2) Consumer-Grade Hardware Compatibility: EZchain is designed to be compatible with consumer-grade hardware, supporting storage, computation, and verification requirements. 3) Efficient Transaction Confirmation: EZchain strives to maintain transaction confirmation delays within one minute. Our prototype experiment demonstrates that under typical daily bandwidth network conditions, EZchain's performance in all aspects approaches that of the accounts in centralized payment systems. This provides a solid infrastructure for realizing mobile payments in web3.0.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00281"
  },
  "2312.00277": {
    "title": "Text Attribute Control via Closed-Loop Disentanglement",
    "authors": [
      "Lei Sha",
      "Thomas Lukasiewicz"
    ],
    "abstract": "Changing an attribute of a text without changing the content usually requires to first disentangle the text into irrelevant attributes and content representations. After that, in the inference phase, the representation of one attribute is tuned to a different value, expecting that the corresponding attribute of the text can also be changed accordingly. The usual way of disentanglement is to add some constraints on the latent space of an encoder-decoder architecture, including adversarial-based constraints and mutual-information-based constraints. However, the previous semi-supervised processes of attribute change are usually not enough to guarantee the success of attribute change and content preservation. In this paper, we propose a novel approach to achieve a robust control of attributes while enhancing content preservation. In this approach, we use a semi-supervised contrastive learning method to encourage the disentanglement of attributes in latent spaces. Differently from previous works, we re-disentangle the reconstructed sentence and compare the re-disentangled latent space with the original latent space, which makes a closed-loop disentanglement process. This also helps content preservation. In addition, the contrastive learning method is also able to replace the role of minimizing mutual information and adversarial training in the disentanglement process, which alleviates the computation cost. We conducted experiments on three text datasets, including the Yelp Service review dataset, the Amazon Product review dataset, and the GoEmotions dataset. The experimental results show the effectiveness of our model.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00277"
  },
  "2312.00273": {
    "title": "Mark My Words: Analyzing and Evaluating Language Model Watermarks",
    "authors": [
      "Julien Piet",
      "Chawin Sitawarin",
      "Vivian Fang",
      "Norman Mu",
      "David Wagner"
    ],
    "abstract": "The capabilities of large language models have grown significantly in recent years and so too have concerns about their misuse. In this context, the ability to distinguish machine-generated text from human-authored content becomes important. Prior works have proposed numerous schemes to watermark text, which would benefit from a systematic evaluation framework. This work focuses on text watermarking techniques - as opposed to image watermarks - and proposes MARKMYWORDS, a comprehensive benchmark for them under different tasks as well as practical attacks. We focus on three main metrics: quality, size (e.g. the number of tokens needed to detect a watermark), and tamper-resistance. Current watermarking techniques are good enough to be deployed: Kirchenbauer et al. [1] can watermark Llama2-7B-chat with no perceivable loss in quality, the watermark can be detected with fewer than 100 tokens, and the scheme offers good tamper-resistance to simple attacks. We argue that watermark indistinguishability, a criteria emphasized in some prior works, is too strong a requirement: schemes that slightly modify logit distributions outperform their indistinguishable counterparts with no noticeable loss in generation quality. We publicly release our benchmark (https://github.com/wagner-group/MarkMyWords)\n        \u25b3 Less",
    "submission_date": "6 December, 2023",
    "eprint_id": "2312.00273"
  },
  "2312.00271": {
    "title": "Towards Clinical Prediction with Transparency: An Explainable AI Approach to Survival Modelling in Residential Aged Care",
    "authors": [
      "Teo Susnjak",
      "Elise Griffin"
    ],
    "abstract": "Background: Accurate survival time estimates aid end-of-life medical decision-making. Objectives: Develop an interpretable survival model for elderly residential aged care residents using advanced machine learning. Setting: A major Australasian residential aged care provider. Participants: Residents aged 65+ admitted for long-term care from July 2017 to August 2023. Sample size: 11,944 residents across 40 facilities. Predictors: Factors include age, gender, health status, co-morbidities, cognitive function, mood, nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome: Probability of survival post-admission, specifically calibrated for 6-month survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB, and RF models in 20 experiments with a 90/10 train/test split. Evaluated accuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month predictions using Platt scaling. Employed SHAP values to analyze predictor impacts. Results: GB, XGB, and RF models showed the highest C-Index values (0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors include age, male gender, mobility, health status, pressure ulcer risk, and appetite. Conclusions: The study successfully applies machine learning to create a survival model for aged care, aligning with clinical insights on mortality risk factors and enhancing model interpretability and clinical utility through explainable AI.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00271"
  },
  "2312.00269": {
    "title": "Adaptability of Computer Vision at the Tactical Edge: Addressing Environmental Uncertainty",
    "authors": [
      "Hayden Moore"
    ],
    "abstract": "Computer Vision (CV) systems are increasingly being adopted into Command and Control (C2) systems to improve intelligence analysis on the battlefield, the tactical edge. CV systems leverage Artificial Intelligence (AI) algorithms to help visualize and interpret the environment, enhancing situational awareness. However, the adaptability of CV systems at the tactical edge remains challenging due to rapidly changing environments and objects which can confuse the deployed models. A CV model leveraged in this environment can become uncertain in its predictions, as the environment and the objects existing in the environment begin to change. Additionally, mission objectives can rapidly change leading to adjustments in technology, camera angles, and image resolutions. All of which can negatively affect the performance of and potentially introduce uncertainty into the system. When the training environment and/or technology differs from the deployment environment, CV models can perform unexpectedly. Unfortunately, most scenarios at the tactical edge do not incorporate Uncertainty Quantification (UQ) into their deployed C2 and CV systems. This concept paper explores the idea of synchronizing robust data operations and model fine-tuning driven by UQ all at the tactical edge. Specifically, curating datasets and training child models based on the residuals of predictions, using these child models to calculate prediction intervals (PI), and then using these PI to calibrate the deployed models. By incorporating UQ into the core operations surrounding C2 and CV systems at the tactical edge, we can help drive purposeful adaptability on the battlefield.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00269"
  },
  "2312.00268": {
    "title": "Academic competitions",
    "authors": [
      "Hugo Jair Escalante",
      "Aleksandra Kruchinina"
    ],
    "abstract": "Academic challenges comprise effective means for (i) advancing the state of the art, (ii) putting in the spotlight of a scientific community specific topics and problems, as well as (iii) closing the gap for under represented communities in terms of accessing and participating in the shaping of research fields. Competitions can be traced back for centuries and their achievements have had great influence in our modern world. Recently, they (re)gained popularity, with the overwhelming amounts of data that is being generated in different domains, as well as the need of pushing the barriers of existing methods, and available tools to handle such data. This chapter provides a survey of academic challenges in the context of machine learning and related fields. We review the most influential competitions in the last few years and analyze challenges per area of knowledge. The aims of scientific challenges, their goals, major achievements and expectations for the next few years are reviewed.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00268"
  },
  "2312.00267": {
    "title": "Sample Efficient Reinforcement Learning from Human Feedback via Active Exploration",
    "authors": [
      "Viraj Mehta",
      "Vikramjeet Das",
      "Ojash Neopane",
      "Yijia Dai",
      "Ilija Bogunovic",
      "Jeff Schneider",
      "Willie Neiswanger"
    ],
    "abstract": "Preference-based feedback is important for many applications in reinforcement learning where direct evaluation of a reward function is not feasible. A notable recent example arises in reinforcement learning from human feedback (RLHF) on large language models. For many applications of RLHF, the cost of acquiring the human feedback can be substantial. In this work, we take advantage of the fact that one can often choose contexts at which to obtain human feedback in order to most efficiently identify a good policy, and formalize this as an offline contextual dueling bandit problem. We give an upper-confidence-bound style algorithm for this problem and prove a polynomial worst-case regret bound. We then provide empirical confirmation in a synthetic setting that our approach outperforms existing methods. After, we extend the setting and methodology for practical use in RLHF training of large language models. Here, our method is able to reach better performance with fewer samples of human preferences than multiple baselines on three real-world datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00267"
  },
  "2312.00265": {
    "title": "RoboSync: Efficient Real-Time Operating System for Social Robots with Customizable Behaviour",
    "authors": [
      "Cheng Tang",
      "Yijing Feng",
      "Yue Hu"
    ],
    "abstract": "Traditional robotic systems require complex implementations that are not always accessible or easy to use for Human-Robot Interaction (HRI) application developers. With the aim of simplifying the implementation of HRI applications, this paper introduces a novel real-time operating system (RTOS) designed for customizable HRI - RoboSync. By creating multi-level abstraction layers, the system enables users to define complex emotional and behavioral models without needing deep technical expertise. The system's modular architecture comprises a behavior modeling layer, a machine learning plugin configuration layer, a sensor checks customization layer, a scheduler that fits the need of HRI, and a communication and synchronization layer. This approach not only promotes ease of use without highly specialized skills but also ensures real-time responsiveness and adaptability. The primary functionality of the RTOS has been implemented for proof of concept and was tested on a CortexM4 microcontroller, demonstrating its potential for a wide range of lightweight simple-to-implement social robotics applications.\n        \u25b3 Less",
    "submission_date": "13 December, 2023",
    "eprint_id": "2312.00265"
  },
  "2312.00264": {
    "title": "Skipper: Improving the Reach and Fidelity of Quantum Annealers by Skipping Long Chains",
    "authors": [
      "Ramin Ayanzadeh",
      "Moinuddin Qureshi"
    ],
    "abstract": "Quantum Annealers (QAs) operate as single-instruction machines, lacking a SWAP operation to overcome limited qubit connectivity. Consequently, multiple physical qubits are chained to form a program qubit with higher connectivity, resulting in a drastically diminished effective QA capacity by up to 33x. We observe that in QAs: (a) chain lengths exhibit a power-law distribution, a few dominant chains holding substantially more qubits than others; and (b) about 25% of physical qubits remain unused, getting isolated between these chains. We propose Skipper, a software technique that enhances the capacity and fidelity of QAs by skipping dominant chains and substituting their program qubit with two readout results. Using a 5761-qubit QA, we demonstrate that Skipper can tackle up to 59% (Avg. 28%) larger problems when eleven chains are skipped. Additionally, Skipper can improve QA fidelity by up to 44% (Avg. 33%) when cutting five chains (32 runs). Users can specify up to eleven chain cuts in Skipper, necessitating about 2,000 distinct quantum executable runs. To mitigate this, we introduce Skipper-G, a greedy scheme that skips sub-problems less likely to hold the global optimum, executing a maximum of 23 quantum executables with eleven chain trims. Skipper-G can boost QA fidelity by up to 41% (Avg. 29%) when cutting five chains (11 runs).\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00264"
  },
  "2312.00262": {
    "title": "Augmented Kinesthetic Teaching: Enhancing Task Execution Efficiency through Intuitive Human Instructions",
    "authors": [
      "Cheng Tang",
      "Jiaming Zhong",
      "Yue Hu"
    ],
    "abstract": "In this paper, we present a complete and efficient implementation of a knowledge-sharing augmented kinesthetic teaching approach for efficient task execution in robotics. Our augmented kinesthetic teaching method integrates intuitive human feedback, including verbal, gesture, gaze, and physical guidance, to facilitate the extraction of multiple layers of task information including control type, attention direction, input and output type, action state change trigger, etc., enhancing the adaptability and autonomy of robots during task execution. We propose an efficient Programming by Demonstration (PbD) framework for users with limited technical experience to teach the robot in an intuitive manner. The proposed framework provides an interface for such users to teach customized tasks using high-level commands, with the goal of achieving a smoother teaching experience and task execution. This is demonstrated with the sample task of pouring water.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00262"
  },
  "2312.00259": {
    "title": "Scalable Cellular V2X Solutions: Large-Scale Deployment Challenges of Connected Vehicle Safety Networks",
    "authors": [
      "Ghayoor Shah",
      "Mahdi Zaman",
      "Md Saifuddin",
      "Behrad Toghi",
      "Yaser Fallah"
    ],
    "abstract": "Vehicle-to-Everything (V2X) communication is expected to accomplish a long-standing goal of the Connected and Autonomous Vehicle (CAV) community to bring connected vehicles to roads on a large scale. A major challenge, and perhaps the biggest hurdle on the path towards this goal is the scalability issues associated with it, especially when vehicular safety is concerned. As a major stakeholder, 3rd Generation Partnership Project (3GPP) based Cellular V2X (C-V2X) community has long been trying to research on whether vehicular networks are able to support the safety-critical applications in high-density vehicular scenarios. This paper attempts to answer this by first presenting an overview on the scalability challenges faced by 3GPP Release 14 Long Term Evolution C-V2X (LTE-V2X) using the PC5 sidelink interface for low and heavy-density traffic scenarios. Next, it demonstrates a series of solutions that address network congestion, packet losses and other scalability issues associated with LTE-V2X to enable this communication technology for commercial deployment. In addition, a brief survey is provided into 3GPP Release 16 5G New Radio V2X (NR-V2X) that utilizes the NR sidelink interface and works as an evolution of C-V2X towards better performance for V2X communications including new enhanced V2X (eV2X) scenarios that possess ultra-low-latency and high-reliability requirements.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00259"
  },
  "2312.00258": {
    "title": "Precipitation Nowcasting With Spatial And Temporal Transfer Learning Using Swin-UNETR",
    "authors": [
      "Ajitabh Kumar"
    ],
    "abstract": "Climate change has led to an increase in frequency of extreme weather events. Early warning systems can prevent disasters and loss of life. Managing such events remain a challenge for both public and private institutions. Precipitation nowcasting can help relevant institutions to better prepare for such events. Numerical weather prediction (NWP) has traditionally been used to make physics based forecasting, and recently deep learning based approaches have been used to reduce turn-around time for nowcasting. In this work, recently proposed Swin-UNETR (Swin UNEt TRansformer) is used for precipitation nowcasting for ten different regions of Europe. Swin-UNETR utilizes a U-shaped network within which a swin transformer-based encoder extracts multi-scale features from multiple input channels of satellite image, while CNN-based decoder makes the prediction. Trained model is capable of nowcasting not only for the regions for which data is available, but can also be used for new regions for which data is not available.\n        \u25b3 Less",
    "submission_date": "11 December, 2023",
    "eprint_id": "2312.00258"
  },
  "2312.00252": {
    "title": "PyNeRF: Pyramidal Neural Radiance Fields",
    "authors": [
      "Haithem Turki",
      "Michael Zollh\u00f6fer",
      "Christian Richardt",
      "Deva Ramanan"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples but such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20-90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00252"
  },
  "2312.00250": {
    "title": "Advancements and Trends in Ultra-High-Resolution Image Processing: An Overview",
    "authors": [
      "Zhuoran Zheng",
      "Boxue Xiao"
    ],
    "abstract": "Currently, to further improve visual enjoyment, Ultra-High-Definition (UHD) images are catching wide attention. Here, UHD images are usually referred to as having a resolution greater than or equal to $3840 \\times 2160$. However, since the imaging equipment is subject to environmental noise or equipment jitter, UHD images are prone to contrast degradation, blurring, low dynamic range, etc. To address these issues, a large number of algorithms for UHD image enhancement have been proposed. In this paper, we introduce the current state of UHD image enhancement from two perspectives, one is the application field and the other is the technology. In addition, we briefly explore its trends.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00250"
  },
  "2312.00245": {
    "title": "SPAM: Secure & Private Aircraft Management",
    "authors": [
      "Yaman Jandali",
      "Nojan Sheybani",
      "Farinaz Koushanfar"
    ],
    "abstract": "With the rising use of aircrafts for operations ranging from disaster-relief to warfare, there is a growing risk of adversarial attacks. Malicious entities often only require the location of the aircraft for these attacks. Current satellite-aircraft communication and tracking protocols put aircrafts at risk if the satellite is compromised, due to computation being done in plaintext. In this work, we present \\texttt{SPAM}, a private, secure, and accurate system that allows satellites to efficiently manage and maintain tracking angles for aircraft fleets without learning aircrafts' locations. \\texttt{SPAM} is built upon multi-party computation and zero-knowledge proofs to guarantee privacy and high efficiency. While catered towards aircrafts, \\texttt{SPAM}'s zero-knowledge fleet management can be easily extended to the IoT, with very little overhead.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00245"
  },
  "2312.00238": {
    "title": "Self-similarity of Communities of the ABCD Model",
    "authors": [
      "Jordan Barrett",
      "Bogumil Kaminski",
      "Pawel Pralat",
      "Francois Theberge"
    ],
    "abstract": "The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster and can be investigated analytically.\n  In this paper, we show that the ABCD model exhibits some interesting self-similar behaviour, namely, the degree distribution of ground-truth communities is asymptotically the same as the degree distribution of the whole graph (appropriately normalized based on their sizes). As a result, we can not only estimate the number of edges induced by each community but also the number of self-loops and multi-edges generated during the process. Understanding these quantities is important as (a) rewiring self-loops and multi-edges to keep the graph simple is an expensive part of the algorithm, and (b) every rewiring causes the underlying configuration models to deviate slightly from uniform simple graphs on their corresponding degree sequences.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00238"
  },
  "2312.00237": {
    "title": "Negotiated Representations to Prevent Forgetting in Machine Learning Applications",
    "authors": [
      "Nuri Korhan",
      "Ceren \u00d6ner"
    ],
    "abstract": "Catastrophic forgetting is a significant challenge in the field of machine learning, particularly in neural networks. When a neural network learns to perform well on a new task, it often forgets its previously acquired knowledge or experiences. This phenomenon occurs because the network adjusts its weights and connections to minimize the loss on the new task, which can inadvertently overwrite or disrupt the representations that were crucial for the previous tasks. As a result, the the performance of the network on earlier tasks deteriorates, limiting its ability to learn and adapt to a sequence of tasks. In this paper, we propose a novel method for preventing catastrophic forgetting in machine learning applications, specifically focusing on neural networks. Our approach aims to preserve the knowledge of the network across multiple tasks while still allowing it to learn new information effectively. We demonstrate the effectiveness of our method by conducting experiments on various benchmark datasets, including Split MNIST, Split CIFAR10, Split Fashion MNIST, and Split CIFAR100. These datasets are created by dividing the original datasets into separate, non overlapping tasks, simulating a continual learning scenario where the model needs to learn multiple tasks sequentially without forgetting the previous ones. Our proposed method tackles the catastrophic forgetting problem by incorporating negotiated representations into the learning process, which allows the model to maintain a balance between retaining past experiences and adapting to new tasks. By evaluating our method on these challenging datasets, we aim to showcase its potential for addressing catastrophic forgetting and improving the performance of neural networks in continual learning settings.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00237"
  },
  "2312.00234": {
    "title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs",
    "authors": [
      "Tanya Marwah",
      "Ashwini Pokle",
      "J. Zico Kolter",
      "Zachary C. Lipton",
      "Jianfeng Lu",
      "Andrej Risteski"
    ],
    "abstract": "Data-driven machine learning approaches are being increasingly used to solve partial differential equations (PDEs). They have shown particularly striking successes when training an operator, which takes as input a PDE in some family, and outputs its solution. However, the architectural design space, especially given structural knowledge of the PDE family of interest, is still poorly understood. We seek to remedy this gap by studying the benefits of weight-tied neural network architectures for steady-state PDEs. To achieve this, we first demonstrate that the solution of most steady-state PDEs can be expressed as a fixed point of a non-linear operator. Motivated by this observation, we propose FNO-DEQ, a deep equilibrium variant of the FNO architecture that directly solves for the solution of a steady-state PDE as the infinite-depth fixed point of an implicit operator layer using a black-box root solver and differentiates analytically through this fixed point resulting in $\\mathcal{O}(1)$ training memory. Our experiments indicate that FNO-DEQ-based architectures outperform FNO-based baselines with $4\\times$ the number of parameters in predicting the solution to steady-state PDEs such as Darcy Flow and steady-state incompressible Navier-Stokes. Finally, we show FNO-DEQ is more robust when trained with datasets with more noisy observations than the FNO-based baselines, demonstrating the benefits of using appropriate inductive biases in architectural design for different neural network based PDE solvers. Further, we show a universal approximation result that demonstrates that FNO-DEQ can approximate the solution to any steady-state PDE that can be written as a fixed point equation.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00234"
  },
  "2312.00232": {
    "title": "Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks",
    "authors": [
      "Alexander M\u00f6llers",
      "Alexander Immer",
      "Elvin Isufi",
      "Vincent Fortuin"
    ],
    "abstract": "Graph contrastive learning has shown great promise when labeled data is scarce, but large unlabeled datasets are available. However, it often does not take uncertainty estimation into account. We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance on semi-supervised node-classification tasks. Moreover, we propose a new measure of uncertainty for contrastive learning, that is based on the disagreement in likelihood due to different positive samples.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00232"
  },
  "2312.00224": {
    "title": "Unsupervised textile defect detection using convolutional neural networks",
    "authors": [
      "Imane Koulali",
      "M. Taner Eskil"
    ],
    "abstract": "In this study, we propose a novel motif-based approach for unsupervised textile anomaly detection that combines the benefits of traditional convolutional neural networks with those of an unsupervised learning paradigm. It consists of five main steps: preprocessing, automatic pattern period extraction, patch extraction, features selection and anomaly detection. This proposed approach uses a new dynamic and heuristic method for feature selection which avoids the drawbacks of initialization of the number of filters (neurons) and their weights, and those of the backpropagation mechanism such as the vanishing gradients, which are common practice in the state-of-the-art methods. The design and training of the network are performed in a dynamic and input domain-based manner and, thus, no ad-hoc configurations are required. Before building the model, only the number of layers and the stride are defined. We do not initialize the weights randomly nor do we define the filter size or number of filters as conventionally done in CNN-based approaches. This reduces effort and time spent on hyperparameter initialization and fine-tuning. Only one defect-free sample is required for training and no further labeled data is needed. The trained network is then used to detect anomalies on defective fabric samples. We demonstrate the effectiveness of our approach on the Patterned Fabrics benchmark dataset. Our algorithm yields reliable and competitive results (on recall, precision, accuracy and f1- measure) compared to state-of-the-art unsupervised approaches, in less time, with efficient training in a single epoch and a lower computational cost.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00224"
  },
  "2312.00223": {
    "title": "Convolutional Neural Networks for Segmentation of Malignant Pleural Mesothelioma: Analysis of Probability Map Thresholds (CALGB 30901, Alliance)",
    "authors": [
      "Mena Shenouda",
      "Eyj\u00f3lfur Gudmundsson",
      "Feng Li",
      "Christopher M. Straus",
      "Hedy L. Kindler",
      "Arkadiusz Z. Dudek",
      "Thomas Stinchcombe",
      "Xiaofei Wang",
      "Adam Starkey",
      "Samuel G. Armato III"
    ],
    "abstract": "Malignant pleural mesothelioma (MPM) is the most common form of mesothelioma. To assess response to treatment, tumor measurements are acquired and evaluated based on a patient's longitudinal computed tomography (CT) scans. Tumor volume, however, is the more accurate metric for assessing tumor burden and response. Automated segmentation methods using deep learning can be employed to acquire volume, which otherwise is a tedious task performed manually. The deep learning-based tumor volume and contours can then be compared with a standard reference to assess the robustness of the automated segmentations. The purpose of this study was to evaluate the impact of probability map threshold on MPM tumor delineations generated using a convolutional neural network (CNN). Eighty-eight CT scans from 21 MPM patients were segmented by a VGG16/U-Net CNN. A radiologist modified the contours generated at a 0.5 probability threshold. Percent difference of tumor volume and overlap using the Dice Similarity Coefficient (DSC) were compared between the standard reference provided by the radiologist and CNN outputs for thresholds ranging from 0.001 to 0.9. CNN annotations consistently yielded smaller tumor volumes than radiologist contours. Reducing the probability threshold from 0.5 to 0.1 decreased the absolute percent volume difference, on average, from 43.96% to 24.18%. Median and mean DSC ranged from 0.58 to 0.60, with a peak at a threshold of 0.5; no distinct threshold was found for percent volume difference. No single output threshold in the CNN probability maps was optimal for both tumor volume and DSC. This work underscores the need to assess tumor volume and spatial overlap when evaluating CNN performance. While automated segmentations may yield comparable tumor volumes to that of the reference standard, the spatial region delineated by the CNN at a specific threshold is equally important.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00223"
  },
  "2312.00220": {
    "title": "Multi-Modal Video Topic Segmentation with Dual-Contrastive Domain Adaptation",
    "authors": [
      "Linzi Xing",
      "Quan Tran",
      "Fabian Caba",
      "Franck Dernoncourt",
      "Seunghyun Yoon",
      "Zhaowen Wang",
      "Trung Bui",
      "Giuseppe Carenini"
    ],
    "abstract": "Video topic segmentation unveils the coarse-grained semantic structure underlying videos and is essential for other video understanding tasks. Given the recent surge in multi-modal, relying solely on a single modality is arguably insufficient. On the other hand, prior solutions for similar tasks like video scene/shot segmentation cater to short videos with clear visual shifts but falter for long videos with subtle changes, such as livestreams. In this paper, we introduce a multi-modal video topic segmenter that utilizes both video transcripts and frames, bolstered by a cross-modal attention mechanism. Furthermore, we propose a dual-contrastive learning framework adhering to the unsupervised domain adaptation paradigm, enhancing our model's adaptability to longer, more semantically complex videos. Experiments on short and long video corpora demonstrate that our proposed solution, significantly surpasses baseline methods in terms of both accuracy and transferability, in both intra- and cross-domain settings.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00220"
  },
  "2312.00218": {
    "title": "Cascaded Channel Decoupling Based Solution for RIS Regulation Matrix",
    "authors": [
      "Yajun Zhao"
    ],
    "abstract": "This article presents a novel solution for reconfigurable intelligent surfaces (RISs) based on cascaded channel decoupling. The proposed mechanism simplifies the RIS regulation matrix, by decomposing the electromagnetic wave regulation process into two sub-processes: virtual receiving response and virtual regular transmission, which leads to the decoupling of the RIS cascaded channel. This article further discusses the concrete implementation of the proposed channel decoupling mechanism in two scenarios of single-user access and multi-user access, and gives the corresponding detailed scheme. The numerical simulation results demonstrate that the proposed channel decoupling scheme is a low-complexity and effective solution for resolving the RIS regulation matrix.\n        \u25b3 Less",
    "submission_date": "26 July, 2023",
    "eprint_id": "2312.00218"
  },
  "2312.00216": {
    "title": "Medication abortion via digital health in the United States: a systematic scoping review",
    "authors": [
      "Fekede Asefa Kumsa",
      "Rameshwari Prasad",
      "Arash Shaban-Nejad"
    ],
    "abstract": "Digital health, including telemedicine, has increased access to abortion care. The convenience, flexibility of appointment times, and ensured privacy to abortion users may make abortion services via telemedicine preferable. This scoping review systematically mapped studies conducted on abortion services via telemedicine, including their effectiveness and acceptability for abortion users and providers. All published papers included abortion services via telemedicine in the United States were considered. Articles were searched in PubMed, CINAHL, and Google Scholar databases in September 2022. The findings were synthesized narratively, and the PRISMA-ScR guidelines were used to report this study. Out of 757 retrieved articles, 33 articles were selected based on the inclusion criteria. These studies were published between 2011 and 2022, with 24 published in the last 3 years. The study found that telemedicine increased access to abortion care in the United States, especially for people in remote areas or those worried about stigma from in-person visits. The effectiveness of abortion services via telemedicine was comparable to in-clinic visits, with 6% or fewer abortions requiring surgical intervention. Both care providers and abortion seekers expressed positive perceptions of telemedicine-based abortion services. However, abortion users reported mixed emotions, with some preferring in-person visits. The most common reasons for choosing telemedicine included the distance to the abortion clinic, convenience, privacy, cost, flexibility of appointment times, and state laws imposing waiting periods or restrictive policies. Telemedicine offered a preferable option for abortion seekers and providers. The feasibility of accessing abortion services via telemedicine in low-resource settings needs further investigation.\n        \u25b3 Less",
    "submission_date": "18 July, 2023",
    "eprint_id": "2312.00216"
  },
  "2312.00215": {
    "title": "Learning active tactile perception through belief-space control",
    "authors": [
      "Jean-Fran\u00e7ois Tremblay",
      "David Meger",
      "Francois Hogan",
      "Gregory Dudek"
    ],
    "abstract": "Robots operating in an open world will encounter novel objects with unknown physical properties, such as mass, friction, or size. These robots will need to sense these properties through interaction prior to performing downstream tasks with the objects. We propose a method that autonomously learns tactile exploration policies by developing a generative world model that is leveraged to 1) estimate the object's physical parameters using a differentiable Bayesian filtering algorithm and 2) develop an exploration policy using an information-gathering model predictive controller. We evaluate our method on three simulated tasks where the goal is to estimate a desired object property (mass, height or toppling height) through physical interaction. We find that our method is able to discover policies that efficiently gather information about the desired property in an intuitive manner. Finally, we validate our method on a real robot system for the height estimation task, where our method is able to successfully learn and execute an information-gathering policy from scratch.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00215"
  },
  "2312.00214": {
    "title": "Relevance-guided Neural Machine Translation",
    "authors": [
      "Isidora Chara Tourni",
      "Derry Wijaya"
    ],
    "abstract": "With the advent of the Transformer architecture, Neural Machine Translation (NMT) results have shown great improvement lately. However, results in low-resource conditions still lag behind in both bilingual and multilingual setups, due to the limited amount of available monolingual and/or parallel data; hence, the need for methods addressing data scarcity in an efficient, and explainable way, is eminent. We propose an explainability-based training approach for NMT, applied in Unsupervised and Supervised model training, for translation of three languages of varying resources, French, Gujarati, Kazakh, to and from English. Our results show our method can be promising, particularly when training in low-resource conditions, outperforming simple training baselines; though the improvement is marginal, it sets the ground for further exploration of the approach and the parameters, and its extension to other languages.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00214"
  },
  "2312.00209": {
    "title": "On the Interplay Between Stepsize Tuning and Progressive Sharpening",
    "authors": [
      "Vincent Roulet",
      "Atish Agarwala",
      "Fabian Pedregosa"
    ],
    "abstract": "Recent empirical work has revealed an intriguing property of deep learning models by which the sharpness (largest eigenvalue of the Hessian) increases throughout optimization until it stabilizes around a critical value at which the optimizer operates at the edge of stability, given a fixed stepsize (Cohen et al, 2022). We investigate empirically how the sharpness evolves when using stepsize-tuners, the Armijo linesearch and Polyak stepsizes, that adapt the stepsize along the iterations to local quantities such as, implicitly, the sharpness itself. We find that the surprisingly poor performance of a classical Armijo linesearch in the deterministic setting may be well explained by its tendency to ever-increase the sharpness of the objective. On the other hand, we observe that Polyak stepsizes operate generally at the edge of stability or even slightly beyond, outperforming its Armijo and constant stepsizes counterparts in the deterministic setting. We conclude with an analysis that suggests unlocking stepsize tuners requires an understanding of the joint dynamics of the step size and the sharpness.\n        \u25b3 Less",
    "submission_date": "29 December, 2023",
    "eprint_id": "2312.00209"
  },
  "2312.00207": {
    "title": "EpiTESTER: Testing Autonomous Vehicles with Epigenetic Algorithm and Attention Mechanism",
    "authors": [
      "Chengjie Lu",
      "Shaukat Ali",
      "Tao Yue"
    ],
    "abstract": "Testing autonomous vehicles (AVs) under various environmental scenarios that lead the vehicles to unsafe situations is known to be challenging. Given the infinite possible environmental scenarios, it is essential to find critical scenarios efficiently. To this end, we propose a novel testing method, named EpiTESTER, by taking inspiration from epigenetics, which enables species to adapt to sudden environmental changes. In particular, EpiTESTER adopts gene silencing as its epigenetic mechanism, which regulates gene expression to prevent the expression of a certain gene, and the probability of gene expression is dynamically computed as the environment changes. Given different data modalities (e.g., images, lidar point clouds) in the context of AV, EpiTESTER benefits from a multi-model fusion transformer to extract high-level feature representations from environmental factors and then calculates probabilities based on these features with the attention mechanism. To assess the cost-effectiveness of EpiTESTER, we compare it with a classical genetic algorithm (GA) (i.e., without any epigenetic mechanism implemented) and EpiTESTER with equal probability for each gene. We evaluate EpiTESTER with four initial environments from CARLA, an open-source simulator for autonomous driving research, and an end-to-end AV controller, Interfuser. Our results show that EpiTESTER achieved a promising performance in identifying critical scenarios compared to the baselines, showing that applying epigenetic mechanisms is a good option for solving practical problems.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00207"
  },
  "2312.00204": {
    "title": "DNS SLAM: Dense Neural Semantic-Informed SLAM",
    "authors": [
      "Kunyi Li",
      "Michael Niemeyer",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "abstract": "In recent years, coordinate-based neural implicit representations have shown promising results for the task of Simultaneous Localization and Mapping (SLAM). While achieving impressive performance on small synthetic scenes, these methods often suffer from oversmoothed reconstructions, especially for complex real-world scenes. In this work, we introduce DNS SLAM, a novel neural RGB-D semantic SLAM approach featuring a hybrid representation. Relying only on 2D semantic priors, we propose the first semantic neural SLAM method that trains class-wise scene representations while providing stable camera tracking at the same time. Our method integrates multi-view geometry constraints with image-based feature extraction to improve appearance details and to output color, density, and semantic class information, enabling many downstream applications. To further enable real-time tracking, we introduce a lightweight coarse scene representation which is trained in a self-supervised manner in latent space. Our experimental results achieve state-of-the-art performance on both synthetic data and real-world data tracking while maintaining a commendable operational speed on off-the-shelf hardware. Further, our method outputs class-wise decomposed reconstructions with better texture capturing appearance and geometric details.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00204"
  },
  "2312.00201": {
    "title": "An integrated framework for developing and evaluating an automated lecture style assessment system",
    "authors": [
      "Eleni Dimitriadou",
      "Andreas Lanitis"
    ],
    "abstract": "The aim of the work presented in this paper is to develop and evaluate an integrated system that provides automated lecture style evaluation, allowing teachers to get instant feedback related to the goodness of their lecturing style. The proposed system aims to promote improvement of lecture quality, that could upgrade the overall student learning experience. The proposed application utilizes specific measurable biometric characteristics, such as facial expressions, body activity, speech rate and intonation, hand movement, and facial pose, extracted from a video showing the lecturer from the audience point of view. Measurable biometric features extracted during a lecture are combined to provide teachers with a score reflecting lecture style quality both at frame rate and by providing lecture quality metrics for the whole lecture. The acceptance of the proposed lecture style evaluation system was evaluated by chief education officers, teachers and students regarding the functionality, usefulness of the application, and possible improvements. The results indicate that participants found the application novel and useful in providing automated feedback regarding lecture quality. Furthermore, the performance evaluation of the proposed system was compared with the performance of humans in the task of lecture style evaluation. Results indicate that the proposed system not only achieves similar performance to human observers, but in some cases, it outperforms them.\n        \u25b3 Less",
    "submission_date": "28 December, 2023",
    "eprint_id": "2312.00201"
  },
  "2312.00200": {
    "title": "Performance Analysis of Multi-Angle QAOA for p > 1",
    "authors": [
      "Igor Gaidai",
      "Rebekah Herrman"
    ],
    "abstract": "In this paper we consider the scalability of Multi-Angle QAOA with respect to the number of QAOA layers. We found that MA-QAOA is able to significantly reduce the depth of QAOA circuits, by a factor of up to 4 for the considered data sets. However, MA-QAOA is not optimal for minimization of the total QPU time. Different optimization initialization strategies are considered and compared for both QAOA and MA-QAOA. Among them, a new initialization strategy is suggested for MA-QAOA that is able to consistently and significantly outperform random initialization used in the previous studies.\n        \u25b3 Less",
    "submission_date": "21 December, 2023",
    "eprint_id": "2312.00200"
  },
  "2312.00194": {
    "title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Nicholas Monath",
      "Avinava Dubey",
      "Amr Ahmed",
      "Snigdha Chaturvedi"
    ],
    "abstract": "Distributed representations provide a vector space that captures meaningful relationships between data instances. The distributed nature of these representations, however, entangles together multiple attributes or concepts of data instances (e.g., the topic or sentiment of a text, characteristics of the author (age, gender, etc), etc). Recent work has proposed the task of concept erasure, in which rather than making a concept predictable, the goal is to remove an attribute from distributed representations while retaining other information from the original representation space as much as possible. In this paper, we propose a new distance metric learning-based objective, the Kernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure. KRaM fits a transformation of representations to match a specified distance measure (defined by a labeled concept to erase) using a modified rate-distortion function. Specifically, KRaM's objective function aims to make instances with similar concept labels dissimilar in the learned representation space while retaining other information. We find that optimizing KRaM effectively erases various types of concepts: categorical, continuous, and vector-valued variables from data representations across diverse domains. We also provide a theoretical analysis of several properties of KRaM's objective. To assess the quality of the learned representations, we propose an alignment score to evaluate their similarity with the original representation space. Additionally, we conduct experiments to showcase KRaM's efficacy in various settings, from erasing binary gender variables in word embeddings to vector-valued variables in GPT-3 representations.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00194"
  },
  "2312.00193": {
    "title": "SISO Decoding of Z4 Linear Kerdock and Preparata Codes",
    "authors": [
      "Aleksandar Minja",
      "Vojin \u0160enk"
    ],
    "abstract": "Some nonlinear codes, such as Kerdock and Preparata codes, can be represented as binary images under the Gray map of linear codes over rings. This paper introduces MAP decoding of Kerdock and Preparata codes by working with their quaternary representation (linear codes over Z4 ) with the complexity of O(N2log2N), where N is the code length in Z4. A sub-optimal bitwise APP decoder with good error-correcting performance and complexity of O(Nlog2N) that is constructed using the decoder lifting technique is also introduced. This APP decoder extends upon the original lifting decoder by working with likelihoods instead of hard decisions and is not limited to Kerdock and Preparata code families. Simulations show that our novel decoders significantly outperform several popular decoders in terms of error rate.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00193"
  },
  "2312.00192": {
    "title": "Benchmarking and Enhancing Disentanglement in Concept-Residual Models",
    "authors": [
      "Renos Zabounidis",
      "Ini Oguntola",
      "Konghao Zhao",
      "Joseph Campbell",
      "Simon Stepputtis",
      "Katia Sycara"
    ],
    "abstract": "Concept bottleneck models (CBMs) are interpretable models that first predict a set of semantically meaningful features, i.e., concepts, from observations that are subsequently used to condition a downstream task. However, the model's performance strongly depends on the engineered features and can severely suffer from incomplete sets of concepts. Prior works have proposed a side channel -- a residual -- that allows for unconstrained information flow to the downstream task, thus improving model performance but simultaneously introducing information leakage, which is undesirable for interpretability. This work proposes three novel approaches to mitigate information leakage by disentangling concepts and residuals, investigating the critical balance between model performance and interpretability. Through extensive empirical analysis on the CUB, OAI, and CIFAR 100 datasets, we assess the performance of each disentanglement method and provide insights into when they work best. Further, we show how each method impacts the ability to intervene over the concepts and their subsequent impact on task performance.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00192"
  },
  "2312.00191": {
    "title": "Enhancing Ligand Pose Sampling for Molecular Docking",
    "authors": [
      "Patricia Suriana",
      "Ron O. Dror"
    ],
    "abstract": "Deep learning promises to dramatically improve scoring functions for molecular docking, leading to substantial advances in binding pose prediction and virtual screening. To train scoring functions-and to perform molecular docking-one must generate a set of candidate ligand binding poses. Unfortunately, the sampling protocols currently used to generate candidate poses frequently fail to produce any poses close to the correct, experimentally determined pose, unless information about the correct pose is provided. This limits the accuracy of learned scoring functions and molecular docking. Here, we describe two improved protocols for pose sampling: GLOW (auGmented sampLing with sOftened vdW potential) and a novel technique named IVES (IteratiVe Ensemble Sampling). Our benchmarking results demonstrate the effectiveness of our methods in improving the likelihood of sampling accurate poses, especially for binding pockets whose shape changes substantially when different ligands bind. This improvement is observed across both experimentally determined and AlphaFold-generated protein structures. Additionally, we present datasets of candidate ligand poses generated using our methods for each of around 5,000 protein-ligand cross-docking pairs, for training and testing scoring functions. To benefit the research community, we provide these cross-docking datasets and an open-source Python implementation of GLOW and IVES at https://github.com/drorlab/GLOW_IVES .\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00191"
  },
  "2312.00189": {
    "title": "HeTriNet: Heterogeneous Graph Triplet Attention Network for Drug-Target-Disease Interaction",
    "authors": [
      "Farhan Tanvir",
      "Khaled Mohammed Saifuddin",
      "Tanvir Hossain",
      "Arunkumar Bagavathi",
      "Esra Akbas"
    ],
    "abstract": "Modeling the interactions between drugs, targets, and diseases is paramount in drug discovery and has significant implications for precision medicine and personalized treatments. Current approaches frequently consider drug-target or drug-disease interactions individually, ignoring the interdependencies among all three entities. Within human metabolic systems, drugs interact with protein targets in cells, influencing target activities and subsequently impacting biological pathways to promote healthy functions and treat diseases. Moving beyond binary relationships and exploring tighter triple relationships is essential to understanding drugs' mechanism of action (MoAs). Moreover, identifying the heterogeneity of drugs, targets, and diseases, along with their distinct characteristics, is critical to model these complex interactions appropriately. To address these challenges, we effectively model the interconnectedness of all entities in a heterogeneous graph and develop a novel Heterogeneous Graph Triplet Attention Network (\\texttt{HeTriNet}). \\texttt{HeTriNet} introduces a novel triplet attention mechanism within this heterogeneous graph structure. Beyond pairwise attention as the importance of an entity for the other one, we define triplet attention to model the importance of pairs for entities in the drug-target-disease triplet prediction problem. Experimental results on real-world datasets show that \\texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable proficiency in uncovering novel drug-target-disease relationships.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00189"
  },
  "2312.00188": {
    "title": "REACT: Recognize Every Action Everywhere All At Once",
    "authors": [
      "Naga VS Raviteja Chappa",
      "Pha Nguyen",
      "Page Daniel Dobbs",
      "Khoa Luu"
    ],
    "abstract": "Group Activity Recognition (GAR) is a fundamental problem in computer vision, with diverse applications in sports video analysis, video surveillance, and social scene understanding. Unlike conventional action recognition, GAR aims to classify the actions of a group of individuals as a whole, requiring a deep understanding of their interactions and spatiotemporal relationships. To address the challenges in GAR, we present REACT (\\textbf{R}ecognize \\textbf{E}very \\textbf{Act}ion Everywhere All At Once), a novel architecture inspired by the transformer encoder-decoder model explicitly designed to model complex contextual relationships within videos, including multi-modality and spatio-temporal features. Our architecture features a cutting-edge Vision-Language Encoder block for integrated temporal, spatial, and multi-modal interaction modeling. This component efficiently encodes spatiotemporal interactions, even with sparsely sampled frames, and recovers essential local information. Our Action Decoder Block refines the joint understanding of text and video data, allowing us to precisely retrieve bounding boxes, enhancing the link between semantics and visual reality. At the core, our Actor Fusion Block orchestrates a fusion of actor-specific data and textual features, striking a balance between specificity and context. Our method outperforms state-of-the-art GAR approaches in extensive experiments, demonstrating superior accuracy in recognizing and understanding group activities. Our architecture's potential extends to diverse real-world applications, offering empirical evidence of its performance gains. This work significantly advances the field of group activity recognition, providing a robust framework for nuanced scene comprehension.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.00188"
  },
  "2312.00186": {
    "title": "Planning Reliability Assurance Tests for Autonomous Vehicles",
    "authors": [
      "Simin Zheng",
      "Lu Lu",
      "Yili Hong",
      "Jian Liu"
    ],
    "abstract": "Artificial intelligence (AI) technology has become increasingly prevalent and transforms our everyday life. One important application of AI technology is the development of autonomous vehicles (AV). However, the reliability of an AV needs to be carefully demonstrated via an assurance test so that the product can be used with confidence in the field. To plan for an assurance test, one needs to determine how many AVs need to be tested for how many miles and the standard for passing the test. Existing research has made great efforts in developing reliability demonstration tests in the other fields of applications for product development and assessment. However, statistical methods have not been utilized in AV test planning. This paper aims to fill in this gap by developing statistical methods for planning AV reliability assurance tests based on recurrent events data. We explore the relationship between multiple criteria of interest in the context of planning AV reliability assurance tests. Specifically, we develop two test planning strategies based on homogeneous and non-homogeneous Poisson processes while balancing multiple objectives with the Pareto front approach. We also offer recommendations for practical use. The disengagement events data from the California Department of Motor Vehicles AV testing program is used to illustrate the proposed assurance test planning methods.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00186"
  },
  "2312.00184": {
    "title": "Galaxy Classification: A machine learning approach for classifying shapes using numerical data",
    "authors": [
      "Anusha Guruprasad"
    ],
    "abstract": "The classification of galaxies as spirals or ellipticals is a crucial task in understanding their formation and evolution. With the arrival of large-scale astronomical surveys, such as the Sloan Digital Sky Survey (SDSS), astronomers now have access to images of a vast number of galaxies. However, the visual inspection of these images is an impossible task for humans due to the sheer number of galaxies to be analyzed. To solve this problem, the Galaxy Zoo project was created to engage thousands of citizen scientists to classify the galaxies based on their visual features. In this paper, we present a machine learning model for galaxy classification using numerical data from the Galaxy Zoo[5] project. Our model utilizes a convolutional neural network architecture to extract features from galaxy images and classify them into spirals or ellipticals. We demonstrate the effectiveness of our model by comparing its performance with that of human classifiers using a subset of the Galaxy Zoo dataset. Our results show that our model achieves high accuracy in classifying galaxies and has the potential to significantly enhance our understanding of the formation and evolution of galaxies.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00184"
  },
  "2312.00183": {
    "title": "RNA-KG: An ontology-based knowledge graph for representing interactions involving RNA molecules",
    "authors": [
      "Emanuele Cavalleri",
      "Alberto Cabri",
      "Mauricio Soto-Gomez",
      "Sara Bonfitto",
      "Paolo Perlasca",
      "Jessica Gliozzo",
      "Tiffany J. Callahan",
      "Justin Reese",
      "Peter N Robinson",
      "Elena Casiraghi",
      "Giorgio Valentini",
      "Marco Mesiti"
    ],
    "abstract": "The \"RNA world\" represents a novel frontier for the study of fundamental biological processes and human diseases and is paving the way for the development of new drugs tailored to the patient's biomolecular characteristics. Although scientific data about coding and non-coding RNA molecules are continuously produced and available from public repositories, they are scattered across different databases and a centralized, uniform, and semantically consistent representation of the \"RNA world\" is still lacking. We propose RNA-KG, a knowledge graph encompassing biological knowledge about RNAs gathered from more than 50 public databases, integrating functional relationships with genes, proteins, and chemicals and ontologically grounded biomedical concepts. To develop RNA-KG, we first identified, pre-processed, and characterized each data source; next, we built a meta-graph that provides an ontological description of the KG by representing all the bio-molecular entities and medical concepts of interest in this domain, as well as the types of interactions connecting them. Finally, we leveraged an instance-based semantically abstracted knowledge model to specify the ontological alignment according to which RNA-KG was generated. RNA-KG can be downloaded in different formats and also queried by a SPARQL endpoint. A thorough topological analysis of the resulting heterogeneous graph provides further insights into the characteristics of the \"RNA world\". RNA-KG can be both directly explored and visualized, and/or analyzed by applying computational methods to infer bio-medical knowledge from its heterogeneous nodes and edges. The resource can be easily updated with new experimental data, and specific views of the overall KG can be extracted according to the bio-medical problem to be studied.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00183"
  },
  "2312.00176": {
    "title": "Ellora: Exploring Low-Power OFDM-based Radar Processors using Approximate Computing",
    "authors": [
      "Rajat Bhattacharjya",
      "Alish Kanani",
      "A Anil Kumar",
      "Manoj Nambiar",
      "M Girish Chandra",
      "Rekha Singhal"
    ],
    "abstract": "In recent times, orthogonal frequency-division multiplexing (OFDM)-based radar has gained wide acceptance given its applicability in joint radar-communication systems. However, realizing such a system on hardware poses a huge area and power bottleneck given its complexity. Therefore it has become ever-important to explore low-power OFDM-based radar processors in order to realize energy-efficient joint radar-communication systems targeting edge devices. This paper aims to address the aforementioned challenges by exploiting approximations on hardware for early design space exploration (DSE) of trade-offs between accuracy, area and power. We present Ellora, a DSE framework for incorporating approximations in an OFDM radar processing pipeline. Ellora uses pairs of approximate adders and multipliers to explore design points realizing energy-efficient radar processors. Particularly, we incorporate approximations into the block involving periodogram based estimation and report area, power and accuracy levels. Experimental results show that at an average accuracy loss of 0.063% in the positive SNR region, we save 22.9% of on-chip area and 26.2% of power. Towards achieving the area and power statistics, we design a fully parallel Inverse Fast Fourier Transform (IFFT) core which acts as a part of periodogram based estimation and approximate the addition and multiplication operations in it. The aforementioned results show that Ellora can be used in an integrated way with various other optimization methods for generating low-power and energy-efficient radar processors.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00176"
  },
  "2312.00175": {
    "title": "Advances in soft grasping in agriculture",
    "authors": [
      "Ali Leylavi Shoushtari"
    ],
    "abstract": "Agricultural robotics and automation are facing some challenges rooted in the high variability 9 of products, task complexity, crop quality requirement, and dense vegetation. Such a set of 10 challenges demands a more versatile and safe robotic system. Soft robotics is a young yet 11 promising field of research aimed to enhance these aspects of current rigid robots which 12 makes it a good candidate solution for that challenge. In general, it aimed to provide robots 13 and machines with adaptive locomotion (Ansari et al., 2015), safe and adaptive manipulation 14 (Arleo et al., 2020) and versatile grasping (Langowski et al., 2020). But in agriculture, soft 15 robots have been mainly used in harvesting tasks and more specifically in grasping. In this 16 chapter, we review a candidate group of soft grippers that were used for handling and 17 harvesting crops regarding agricultural challenges i.e. safety in handling and adaptability to 18 the high variation of crops. The review is aimed to show why and to what extent soft grippers 19 have been successful in handling agricultural tasks. The analysis carried out on the results 20 provides future directions for the systematic design of soft robots in agricultural tasks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00175"
  },
  "2312.00174": {
    "title": "Compression of end-to-end non-autoregressive image-to-speech system for low-resourced devices",
    "authors": [
      "Gokul Srinivasagan",
      "Michael Deisher",
      "Munir Georges"
    ],
    "abstract": "People with visual impairments have difficulty accessing touchscreen-enabled personal computing devices like mobile phones and laptops. The image-to-speech (ITS) systems can assist them in mitigating this problem, but their huge model size makes it extremely hard to be deployed on low-resourced embedded devices. In this paper, we aim to overcome this challenge by developing an efficient endto-end neural architecture for generating audio from tiny segments of display content on low-resource devices. We introduced a vision transformers-based image encoder and utilized knowledge distillation to compress the model from 6.1 million to 2.46 million parameters. Human and automatic evaluation results show that our approach leads to a very minimal drop in performance and can speed up the inference time by 22%.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00174"
  },
  "2312.00173": {
    "title": "Fool the Hydra: Adversarial Attacks against Multi-view Object Detection Systems",
    "authors": [
      "Bilel Tarchoun",
      "Quazi Mishkatul Alam",
      "Nael Abu-Ghazaleh",
      "Ihsen Alouani"
    ],
    "abstract": "Adversarial patches exemplify the tangible manifestation of the threat posed by adversarial attacks on Machine Learning (ML) models in real-world scenarios. Robustness against these attacks is of the utmost importance when designing computer vision applications, especially for safety-critical domains such as CCTV systems. In most practical situations, monitoring open spaces requires multi-view systems to overcome acquisition challenges such as occlusion handling. Multiview object systems are able to combine data from multiple views, and reach reliable detection results even in difficult environments. Despite its importance in real-world vision applications, the vulnerability of multiview systems to adversarial patches is not sufficiently investigated. In this paper, we raise the following question: Does the increased performance and information sharing across views offer as a by-product robustness to adversarial patches? We first conduct a preliminary analysis showing promising robustness against off-the-shelf adversarial patches, even in an extreme setting where we consider patches applied to all views by all persons in Wildtrack benchmark. However, we challenged this observation by proposing two new attacks: (i) In the first attack, targeting a multiview CNN, we maximize the global loss by proposing gradient projection to the different views and aggregating the obtained local gradients. (ii) In the second attack, we focus on a Transformer-based multiview framework. In addition to the focal loss, we also maximize the transformer-specific loss by dissipating its attention blocks. Our results show a large degradation in the detection performance of victim multiview systems with our first patch attack reaching an attack success rate of 73% , while our second proposed attack reduced the performance of its target detector by 62%\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00173"
  },
  "2312.00171": {
    "title": "Extending Rely-Guarantee thinking to handle Real-Time Scheduling",
    "authors": [
      "Cliff B. Jones",
      "Alan Burns"
    ],
    "abstract": "The reference point for developing any artefact is its specification; to develop software formally, a formal specification is required. For sequential programs, pre and post conditions (together with abstract objects) suffice; rely and guarantee conditions extend the scope of formal development approaches to tackle concurrency. In addition, real-time systems need ways of both requiring progress and relating that progress to some notion of time. This paper extends rely-guarantee ideas to cope with specifications of -- and assumptions about -- real-time schedulers. Furthermore it shows how the approach helps identify and specify fault-tolerance aspects of such schedulers by systematically challenging the assumptions.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00171"
  },
  "2312.00169": {
    "title": "Integration of Swin UNETR and statistical shape modeling for a semi-automated segmentation of the knee and biomechanical modeling of articular cartilage",
    "authors": [
      "Reza Kakavand",
      "Mehrdad Palizi",
      "Peyman Tahghighi",
      "Reza Ahmadi",
      "Neha Gianchandani",
      "Samer Adeeb",
      "Roberto Souza",
      "W. Brent Edwards",
      "Amin Komeili"
    ],
    "abstract": "Simulation studies like finite element (FE) modeling provide insight into knee joint mechanics without patient experimentation. Generic FE models represent biomechanical behavior of the tissue by overlooking variations in geometry, loading, and material properties of a population. On the other hand, subject-specific models include these specifics, resulting in enhanced predictive precision. However, creating such models is laborious and time-intensive. The present study aimed to enhance subject-specific knee joint FE modeling by incorporating a semi-automated segmentation algorithm. This segmentation was a 3D Swin UNETR for an initial segmentation of the femur and tibia, followed by a statistical shape model (SSM) adjustment to improve surface roughness and continuity. Five hundred and seven magnetic resonance images (MRIs) from the Osteoarthritis Initiative (OAI) database were used to build and validate the segmentation model. A semi-automated FE model was developed using this semi-automated segmentation. On the other hand, a manual FE model was developed through manual segmentation (i.e., the gold standard approach). Both FE models were subjected to gait loading. The predicted mechanical response of manual and semi-automated FE models were compared. In the result, our semi-automated segmentation achieved Dice similarity coefficient (DSC) over 98% for both femur and tibia. The mechanical results (max principal stress, max principal strain, fluid pressure, fibril strain, and contact area) showed no significant differences between the manual and semi-automated FE models, indicating the effectiveness of the proposed semi-automated segmentation in creating accurate knee joint FE models. ( https://data.mendeley.com/datasets/k5hdc9cz7w/1 ).\n        \u25b3 Less",
    "submission_date": "18 September, 2023",
    "eprint_id": "2312.00169"
  },
  "2312.00168": {
    "title": "Navigating News Narratives: A Media Bias Analysis Dataset",
    "authors": [
      "Shaina Raza"
    ],
    "abstract": "The proliferation of biased news narratives across various media platforms has become a prominent challenge, influencing public opinion on critical topics like politics, health, and climate change. This paper introduces the \"Navigating News Narratives: A Media Bias Analysis Dataset\", a comprehensive dataset to address the urgent need for tools to detect and analyze media bias. This dataset encompasses a broad spectrum of biases, making it a unique and valuable asset in the field of media studies and artificial intelligence. The dataset is available at https://huggingface.co/datasets/newsmediabias/news-bias-full-data.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00168"
  },
  "2312.00164": {
    "title": "Towards Accurate Differential Diagnosis with Large Language Models",
    "authors": [
      "Daniel McDuff",
      "Mike Schaekermann",
      "Tao Tu",
      "Anil Palepu",
      "Amy Wang",
      "Jake Garrison",
      "Karan Singhal",
      "Yash Sharma",
      "Shekoofeh Azizi",
      "Kavita Kulkarni",
      "Le Hou",
      "Yong Cheng",
      "Yun Liu",
      "S Sara Mahdavi",
      "Sushant Prakash",
      "Anupam Pathak",
      "Christopher Semturs",
      "Shwetak Patel",
      "Dale R Webster",
      "Ewa Dominowska",
      "Juraj Gottweis",
      "Joelle Barral",
      "Katherine Chou",
      "Greg S Corrado",
      "Yossi Matias",
      "et al. (3 additional authors not shown)"
    ],
    "abstract": "An accurate differential diagnosis (DDx) is a cornerstone of medical care, often reached through an iterative process of interpretation that combines clinical history, physical examination, investigations and procedures. Interactive interfaces powered by Large Language Models (LLMs) present new opportunities to both assist and automate aspects of this process. In this study, we introduce an LLM optimized for diagnostic reasoning, and evaluate its ability to generate a DDx alone or as an aid to clinicians. 20 clinicians evaluated 302 challenging, real-world medical cases sourced from the New England Journal of Medicine (NEJM) case reports. Each case report was read by two clinicians, who were randomized to one of two assistive conditions: either assistance from search engines and standard medical resources, or LLM assistance in addition to these tools. All clinicians provided a baseline, unassisted DDx prior to using the respective assistive tools. Our LLM for DDx exhibited standalone performance that exceeded that of unassisted clinicians (top-10 accuracy 59.1% vs 33.6%, [p = 0.04]). Comparing the two assisted study arms, the DDx quality score was higher for clinicians assisted by our LLM (top-10 accuracy 51.7%) compared to clinicians without its assistance (36.1%) (McNemar's Test: 45.7, p < 0.01) and clinicians with search (44.4%) (4.75, p = 0.03). Further, clinicians assisted by our LLM arrived at more comprehensive differential lists than those without its assistance. Our study suggests that our LLM for DDx has potential to improve clinicians' diagnostic reasoning and accuracy in challenging cases, meriting further real-world evaluation for its ability to empower physicians and widen patients' access to specialist-level expertise.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00164"
  },
  "2312.00157": {
    "title": "Universal Backdoor Attacks",
    "authors": [
      "Benjamin Schneider",
      "Nils Lukas",
      "Florian Kerschbaum"
    ],
    "abstract": "Web-scraped datasets are vulnerable to data poisoning, which can be used for backdooring deep image classifiers during training. Since training on large datasets is expensive, a model is trained once and re-used many times. Unlike adversarial examples, backdoor attacks often target specific classes rather than any class learned by the model. One might expect that targeting many classes through a naive composition of attacks vastly increases the number of poison samples. We show this is not necessarily true and more efficient, universal data poisoning attacks exist that allow controlling misclassifications from any source class into any target class with a small increase in poison samples. Our idea is to generate triggers with salient characteristics that the model can learn. The triggers we craft exploit a phenomenon we call inter-class poison transferability, where learning a trigger from one class makes the model more vulnerable to learning triggers for other classes. We demonstrate the effectiveness and robustness of our universal backdoor attacks by controlling models with up to 6,000 classes while poisoning only 0.15% of the training dataset. Our source code is available at https://github.com/Ben-Schneider-code/Universal-Backdoor-Attacks.\n        \u25b3 Less",
    "submission_date": "19 January, 2024",
    "eprint_id": "2312.00157"
  },
  "2312.00151": {
    "title": "Which way is `right'?: Uncovering limitations of Vision-and-Language Navigation model",
    "authors": [
      "Meera Hahn",
      "Amit Raj",
      "James M. Rehg"
    ],
    "abstract": "The challenging task of Vision-and-Language Navigation (VLN) requires embodied agents to follow natural language instructions to reach a goal location or object (e.g. `walk down the hallway and turn left at the piano'). For agents to complete this task successfully, they must be able to ground objects referenced into the instruction (e.g.`piano') into the visual scene as well as ground directional phrases (e.g.`turn left') into actions. In this work we ask the following question -- to what degree are spatial and directional language cues informing the navigation model's decisions? We propose a series of simple masking experiments to inspect the model's reliance on different parts of the instruction. Surprisingly we uncover that certain top performing models rely only on the noun tokens of the instructions. We propose two training methods to alleviate this concerning limitation.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00151"
  },
  "2312.00148": {
    "title": "Pedaling, Fast and Slow: The Race Towards an Optimized Power Strategy",
    "authors": [
      "Steven DiSilvio",
      "Anthony Ozerov",
      "Leon Zhou"
    ],
    "abstract": "With the advent of power-meters allowing cyclists to precisely track their power outputs throughout the duration of a race, devising optimal power output strategies for races has become increasingly important in competitive cycling. To do so, the track, weather, and individual cyclist's abilities must all be considered. We propose differential equation models of fatigue and kinematics to simulate the performance of such strategies, and an innovative optimization algorithm to find the optimal strategy.\n  Our model for fatigue translates a cyclist's power curve (obtained by fitting the Omni-Power Duration Model to power curve data) into a differential equation to capture which power output strategies are feasible. Our kinematics model calculates the forces on the rider, and with power output models the cyclist's velocity and position via a system of differential equations. Using track data, including the slope of the track and velocity of the wind, the model accurately computes race times given a power output strategy on the exact track being raced.\n  To make power strategy optimization computationally tractable, we split the track into segments based on changes in slope and discretize the power output levels. As the space of possible strategies is large, we vectorize the differential equation model for efficient numerical integration of many simulations at once and develop a parallelized Tree Exploration with Monte-Carlo Evaluation algorithm. The algorithm is efficient, running in $O(ab\\sqrt{n})$ time and $O(n)$ space where $n$ is the number of simulations done for each choice, $a$ is the number of segments, and $b$ is the number of discrete power output levels.\n  We present results of this optimization for several different tracks and athletes. As an example, the model's time for Filippo Ganna in Tokyo 2020 differs from his real time by just 18%, supporting our model's efficacy.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00148"
  },
  "2312.00140": {
    "title": "The Stochastic Dynamic Post-Disaster Inventory Allocation Problem with Trucks and UAVs",
    "authors": [
      "Robert van Steenbergen",
      "Wouter van Heeswijk",
      "Martijn Mes"
    ],
    "abstract": "Humanitarian logistics operations face increasing difficulties due to rising demands for aid in disaster areas. This paper investigates the dynamic allocation of scarce relief supplies across multiple affected districts over time. It introduces a novel stochastic dynamic post-disaster inventory allocation problem with trucks and unmanned aerial vehicles delivering relief goods under uncertain supply and demand. The relevance of this humanitarian logistics problem lies in the importance of considering the inter-temporal social impact of deliveries. We achieve this by incorporating deprivation costs when allocating scarce supplies. Furthermore, we consider the inherent uncertainties of disaster areas and the potential use of cargo UAVs to enhance operational efficiency. This study proposes two anticipatory solution methods based on approximate dynamic programming, specifically decomposed linear value function approximation and neural network value function approximation to effectively manage uncertainties in the dynamic allocation process. We compare DL-VFA and NN-VFA with various state-of-the-art methods (exact re-optimization, PPO) and results show a 6-8% improvement compared to the best benchmarks. NN-VFA provides the best performance and captures nonlinearities in the problem, whereas DL-VFA shows excellent scalability against a minor performance loss. The experiments reveal that consideration of deprivation costs results in improved allocation of scarce supplies both across affected districts and over time. Finally, results show that deploying UAVs can play a crucial role in the allocation of relief goods, especially in the first stages after a disaster. The use of UAVs reduces transportation- and deprivation costs together by 16-20% and reduces maximum deprivation times by 19-40%, while maintaining similar levels of demand coverage, showcasing efficient and effective operations.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00140"
  },
  "2312.00137": {
    "title": "The Multiverse of Dynamic Mode Decomposition Algorithms",
    "authors": [
      "Matthew J. Colbrook"
    ],
    "abstract": "Dynamic Mode Decomposition (DMD) is a popular data-driven analysis technique used to decompose complex, nonlinear systems into a set of modes, revealing underlying patterns and dynamics through spectral analysis. This review presents a comprehensive and pedagogical examination of DMD, emphasizing the role of Koopman operators in transforming complex nonlinear dynamics into a linear framework. A distinctive feature of this review is its focus on the relationship between DMD and the spectral properties of Koopman operators, with particular emphasis on the theory and practice of DMD algorithms for spectral computations. We explore the diverse \"multiverse\" of DMD methods, categorized into three main areas: linear regression-based methods, Galerkin approximations, and structure-preserving techniques. Each category is studied for its unique contributions and challenges, providing a detailed overview of significant algorithms and their applications as outlined in Table 1. We include a MATLAB package with examples and applications to enhance the practical understanding of these methods. This review serves as both a practical guide and a theoretical reference for various DMD methods, accessible to both experts and newcomers, and enabling readers to delve into their areas of interest in the expansive field of DMD.\n        \u25b3 Less",
    "submission_date": "21 December, 2023",
    "eprint_id": "2312.00137"
  },
  "2312.00123": {
    "title": "Flow Matching Beyond Kinematics: Generating Jets with Particle-ID and Trajectory Displacement Information",
    "authors": [
      "Joschka Birk",
      "Erik Buhmann",
      "Cedric Ewen",
      "Gregor Kasieczka",
      "David Shih"
    ],
    "abstract": "We introduce the first generative model trained on the JetClass dataset. Our model generates jets at the constituent level, and it is a permutation-equivariant continuous normalizing flow (CNF) trained with the flow matching technique. It is conditioned on the jet type, so that a single model can be used to generate the ten different jet types of JetClass. For the first time, we also introduce a generative model that goes beyond the kinematic features of jet constituents. The JetClass dataset includes more features, such as particle-ID and track impact parameter, and we demonstrate that our CNF can accurately model all of these additional features as well. Our generative model for JetClass expands on the versatility of existing jet generation techniques, enhancing their potential utility in high-energy physics research, and offering a more comprehensive understanding of the generated jets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00123"
  },
  "2312.00116": {
    "title": "S2ST: Image-to-Image Translation in the Seed Space of Latent Diffusion",
    "authors": [
      "Or Greenberg",
      "Eran Kishon",
      "Dani Lischinski"
    ],
    "abstract": "Image-to-image translation (I2IT) refers to the process of transforming images from a source domain to a target domain while maintaining a fundamental connection in terms of image content. In the past few years, remarkable advancements in I2IT were achieved by Generative Adversarial Networks (GANs), which nevertheless struggle with translations requiring high precision. Recently, Diffusion Models have established themselves as the engine of choice for image generation. In this paper we introduce S2ST, a novel framework designed to accomplish global I2IT in complex photorealistic images, such as day-to-night or clear-to-rain translations of automotive scenes. S2ST operates within the seed space of a Latent Diffusion Model, thereby leveraging the powerful image priors learned by the latter. We show that S2ST surpasses state-of-the-art GAN-based I2IT methods, as well as diffusion-based approaches, for complex automotive scenes, improving fidelity while respecting the target domain's appearance across a variety of domains. Notably, S2ST obviates the necessity for training domain-specific translation networks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00116"
  },
  "2312.00115": {
    "title": "A Video is Worth 10,000 Words: Training and Benchmarking with Diverse Captions for Better Long Video Retrieval",
    "authors": [
      "Matthew Gwilliam",
      "Michael Cogswell",
      "Meng Ye",
      "Karan Sikka",
      "Abhinav Shrivastava",
      "Ajay Divakaran"
    ],
    "abstract": "Existing long video retrieval systems are trained and tested in the paragraph-to-video retrieval regime, where every long video is described by a single long paragraph. This neglects the richness and variety of possible valid descriptions of a video, which could be described in moment-by-moment detail, or in a single phrase summary, or anything in between. To provide a more thorough evaluation of the capabilities of long video retrieval systems, we propose a pipeline that leverages state-of-the-art large language models to carefully generate a diverse set of synthetic captions for long videos. We validate this pipeline's fidelity via rigorous human inspection. We then benchmark a representative set of video language models on these synthetic captions using a few long video datasets, showing that they struggle with the transformed data, especially the shortest captions. We also propose a lightweight fine-tuning method, where we use a contrastive loss to learn a hierarchical embedding loss based on the differing levels of information among the various captions. Our method improves performance both on the downstream paragraph-to-video retrieval task (+1.1% R@1 on ActivityNet), as well as for the various long video retrieval metrics we compute using our synthetic data (+3.6% R@1 for short descriptions on ActivityNet). For data access and other details, please refer to our project website at https://mgwillia.github.io/10k-words.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00115"
  },
  "2312.00114": {
    "title": "Un-EvMoSeg: Unsupervised Event-based Independent Motion Segmentation",
    "authors": [
      "Ziyun Wang",
      "Jinyuan Guo",
      "Kostas Daniilidis"
    ],
    "abstract": "Event cameras are a novel type of biologically inspired vision sensor known for their high temporal resolution, high dynamic range, and low power consumption. Because of these properties, they are well-suited for processing fast motions that require rapid reactions. Although event cameras have recently shown competitive performance in unsupervised optical flow estimation, performance in detecting independently moving objects (IMOs) is lacking behind, although event-based methods would be suited for this task based on their low latency and HDR properties. Previous approaches to event-based IMO segmentation have been heavily dependent on labeled data. However, biological vision systems have developed the ability to avoid moving objects through daily tasks without being given explicit labels. In this work, we propose the first event framework that generates IMO pseudo-labels using geometric constraints. Due to its unsupervised nature, our method can handle an arbitrary number of not predetermined objects and is easily scalable to datasets where expensive IMO labels are not readily available. We evaluate our approach on the EVIMO dataset and show that it performs competitively with supervised methods, both quantitatively and qualitatively.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00114"
  },
  "2312.00113": {
    "title": "Event-based Continuous Color Video Decompression from Single Frames",
    "authors": [
      "Ziyun Wang",
      "Friedhelm Hamann",
      "Kenneth Chaney",
      "Wen Jiang",
      "Guillermo Gallego",
      "Kostas Daniilidis"
    ],
    "abstract": "We present ContinuityCam, a novel approach to generate a continuous video from a single static RGB image, using an event camera. Conventional cameras struggle with high-speed motion capture due to bandwidth and dynamic range limitations. Event cameras are ideal sensors to solve this problem because they encode compressed change information at high temporal resolution. In this work, we propose a novel task called event-based continuous color video decompression, pairing single static color frames and events to reconstruct temporally continuous videos. Our approach combines continuous long-range motion modeling with a feature-plane-based synthesis neural integration model, enabling frame prediction at arbitrary times within the events. Our method does not rely on additional frames except for the initial image, increasing, thus, the robustness to sudden light changes, minimizing the prediction latency, and decreasing the bandwidth requirement. We introduce a novel single objective beamsplitter setup that acquires aligned images and events and a novel and challenging Event Extreme Decompression Dataset (E2D2) that tests the method in various lighting and motion profiles. We thoroughly evaluate our method through benchmarking reconstruction as well as various downstream tasks. Our approach significantly outperforms the event- and image- based baselines in the proposed task.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00113"
  },
  "2312.00112": {
    "title": "DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis with 3D Gaussian Splatting",
    "authors": [
      "Agelos Kratimenos",
      "Jiahui Lei",
      "Kostas Daniilidis"
    ],
    "abstract": "Accurately and efficiently modeling dynamic scenes and motions is considered so challenging a task due to temporal dynamics and motion complexity. To address these challenges, we propose DynMF, a compact and efficient representation that decomposes a dynamic scene into a few neural trajectories. We argue that the per-point motions of a dynamic scene can be decomposed into a small set of explicit or learned trajectories. Our carefully designed neural framework consisting of a tiny set of learned basis queried only in time allows for rendering speed similar to 3D Gaussian Splatting, surpassing 120 FPS, while at the same time, requiring only double the storage compared to static scenes. Our neural representation adequately constrains the inherently underconstrained motion field of a dynamic scene leading to effective and fast optimization. This is done by biding each point to motion coefficients that enforce the per-point sharing of basis trajectories. By carefully applying a sparsity loss to the motion coefficients, we are able to disentangle the motions that comprise the scene, independently control them, and generate novel motion combinations that have never been seen before. We can reach state-of-the-art render quality within just 5 minutes of training and in less than half an hour, we can synthesize novel views of dynamic scenes with superior photorealistic quality. Our representation is interpretable, efficient, and expressive enough to offer real-time view synthesis of complex dynamic scene motions, in monocular and multi-view scenarios.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00112"
  },
  "2312.00109": {
    "title": "Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering",
    "authors": [
      "Tao Lu",
      "Mulin Yu",
      "Linning Xu",
      "Yuanbo Xiangli",
      "Limin Wang",
      "Dahua Lin",
      "Bo Dai"
    ],
    "abstract": "Neural rendering methods have significantly advanced photo-realistic 3D scene rendering in various academic and industrial applications. The recent 3D Gaussian Splatting method has achieved the state-of-the-art rendering quality and speed combining the benefits of both primitive-based representations and volumetric representations. However, it often leads to heavily redundant Gaussians that try to fit every training view, neglecting the underlying scene geometry. Consequently, the resulting model becomes less robust to significant view changes, texture-less area and lighting effects. We introduce Scaffold-GS, which uses anchor points to distribute local 3D Gaussians, and predicts their attributes on-the-fly based on viewing direction and distance within the view frustum. Anchor growing and pruning strategies are developed based on the importance of neural Gaussians to reliably improve the scene coverage. We show that our method effectively reduces redundant Gaussians while delivering high-quality rendering. We also demonstrates an enhanced capability to accommodate scenes with varying levels-of-detail and view-dependent observations, without sacrificing the rendering speed.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00109"
  },
  "2312.00105": {
    "title": "Improving the Robustness of Quantized Deep Neural Networks to White-Box Attacks using Stochastic Quantization and Information-Theoretic Ensemble Training",
    "authors": [
      "Saurabh Farkya",
      "Aswin Raghavan",
      "Avi Ziskind"
    ],
    "abstract": "Most real-world applications that employ deep neural networks (DNNs) quantize them to low precision to reduce the compute needs. We present a method to improve the robustness of quantized DNNs to white-box adversarial attacks. We first tackle the limitation of deterministic quantization to fixed ``bins'' by introducing a differentiable Stochastic Quantizer (SQ). We explore the hypothesis that different quantizations may collectively be more robust than each quantized DNN. We formulate a training objective to encourage different quantized DNNs to learn different representations of the input image. The training objective captures diversity and accuracy via mutual information between ensemble members. Through experimentation, we demonstrate substantial improvement in robustness against $L_\\infty$ attacks even if the attacker is allowed to backpropagate through SQ (e.g., > 50\\% accuracy to PGD(5/255) on CIFAR10 without adversarial training), compared to vanilla DNNs as well as existing ensembles of quantized DNNs. We extend the method to detect attacks and generate robustness profiles in the adversarial information plane (AIP), towards a unified analysis of different threat models by correlating the MI and accuracy.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00105"
  },
  "2312.00104": {
    "title": "A Metadata Generation System with Semantic Understanding for Video Retrieval in Film Production",
    "authors": [
      "Feilin Han",
      "Zhaoxu Meng"
    ],
    "abstract": "In film production, metadata plays an important role in original raw video indexing and classification within the industrial post-production software. Inspired by deep visual-semantic methods, we propose an automated image information extraction process to extend the diversity of metadata entities for massive large-scale raw video searching and retrieval. In this paper, we introduce the proposed system architecture and modules, integrating semantic annotation models and user-demand-oriented information fusion. We conducted experiments to validate the effectiveness of our system on Film Raw Video Semantic Annotation Dataset (Film-RVSAD) and Slate Board Template Dataset (SBTD), two benchmark datasets built for cinematography-related semantic annotation and slate detection. Experimental results show that the proposed system provides an effective strategy to improve the efficiency of metadata generation and transformation, which is necessary and convenient for collaborative work in the filmmaking process.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00104"
  },
  "2312.00103": {
    "title": "DeepEn2023: Energy Datasets for Edge Artificial Intelligence",
    "authors": [
      "Xiaolong Tu",
      "Anik Mallik",
      "Haoxin Wang",
      "Jiang Xie"
    ],
    "abstract": "Climate change poses one of the most significant challenges to humanity. As a result of these climatic changes, the frequency of weather, climate, and water-related disasters has multiplied fivefold over the past 50 years, resulting in over 2 million deaths and losses exceeding $3.64 trillion USD. Leveraging AI-powered technologies for sustainable development and combating climate change is a promising avenue. Numerous significant publications are dedicated to using AI to improve renewable energy forecasting, enhance waste management, and monitor environmental changes in real time. However, very few research studies focus on making AI itself environmentally sustainable. This oversight regarding the sustainability of AI within the field might be attributed to a mindset gap and the absence of comprehensive energy datasets. In addition, with the ubiquity of edge AI systems and applications, especially on-device learning, there is a pressing need to measure, analyze, and optimize their environmental sustainability, such as energy efficiency. To this end, in this paper, we propose large-scale energy datasets for edge AI, named DeepEn2023, covering a wide range of kernels, state-of-the-art deep neural network models, and popular edge AI applications. We anticipate that DeepEn2023 will improve transparency in sustainability in on-device deep learning across a range of edge AI systems and applications. For more information, including access to the dataset and code, please visit https://amai-gsu.github.io/DeepEn2023.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00103"
  },
  "2312.00102": {
    "title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network And Feature Embedding Aggregation",
    "authors": [
      "Fanfei Meng",
      "Lele Zhang",
      "Yu Chen",
      "Yuxin Wang"
    ],
    "abstract": "Federated learning (FL) is an emerging paradigm for decentralized training of machine learning models on distributed clients, without revealing the data to the central server. The learning scheme may be horizontal, vertical or hybrid (both vertical and horizontal). Most existing research work with deep neural network (DNN) modelling is focused on horizontal data distributions, while vertical and hybrid schemes are much less studied. In this paper, we propose a generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based learning. The idea of our algorithm is characterised by higher inference accuracy, stronger privacy-preserving properties, and lower client-server communication bandwidth demands as compared with existing work. The experimental results show that FedEmb is an effective method to tackle both split feature & subject space decentralized problems, shows 0.3% to 4.2% inference accuracy improvement with limited privacy revealing for datasets stored in local clients, and reduces 88.9 % time complexity over vertical baseline method.\n        \u25b3 Less",
    "submission_date": "10 January, 2024",
    "eprint_id": "2312.00102"
  },
  "2312.00101": {
    "title": "Towards Unsupervised Representation Learning: Learning, Evaluating and Transferring Visual Representations",
    "authors": [
      "Bonifaz Stuhr"
    ],
    "abstract": "Unsupervised representation learning aims at finding methods that learn representations from data without annotation-based signals. Abstaining from annotations not only leads to economic benefits but may - and to some extent already does - result in advantages regarding the representation's structure, robustness, and generalizability to different tasks. In the long run, unsupervised methods are expected to surpass their supervised counterparts due to the reduction of human intervention and the inherently more general setup that does not bias the optimization towards an objective originating from specific annotation-based signals. While major advantages of unsupervised representation learning have been recently observed in natural language processing, supervised methods still dominate in vision domains for most tasks. In this dissertation, we contribute to the field of unsupervised (visual) representation learning from three perspectives: (i) Learning representations: We design unsupervised, backpropagation-free Convolutional Self-Organizing Neural Networks (CSNNs) that utilize self-organization- and Hebbian-based learning rules to learn convolutional kernels and masks to achieve deeper backpropagation-free models. (ii) Evaluating representations: We build upon the widely used (non-)linear evaluation protocol to define pretext- and target-objective-independent metrics for measuring and investigating the objective function mismatch between various unsupervised pretext tasks and target tasks. (iii) Transferring representations: We contribute CARLANE, the first 3-way sim-to-real domain adaptation benchmark for 2D lane detection, and a method based on prototypical self-supervised learning. Finally, we contribute a content-consistent unpaired image-to-image translation method that utilizes masks, global and local discriminators, and similarity sampling to mitigate content inconsistencies.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00101"
  },
  "2312.00100": {
    "title": "Introducing Rhetorical Parallelism Detection: A New Task with Datasets, Metrics, and Baselines",
    "authors": [
      "Stephen Bothwell",
      "Justin DeBenedetto",
      "Theresa Crnkovich",
      "Hildegund M\u00fcller",
      "David Chiang"
    ],
    "abstract": "Rhetoric, both spoken and written, involves not only content but also style. One common stylistic tool is $\\textit{parallelism}$: the juxtaposition of phrases which have the same sequence of linguistic ($\\textit{e.g.}$, phonological, syntactic, semantic) features. Despite the ubiquity of parallelism, the field of natural language processing has seldom investigated it, missing a chance to better understand the nature of the structure, meaning, and intent that humans convey. To address this, we introduce the task of $\\textit{rhetorical parallelism detection}$. We construct a formal definition of it; we provide one new Latin dataset and one adapted Chinese dataset for it; we establish a family of metrics to evaluate performance on it; and, lastly, we create baseline systems and novel sequence labeling schemes to capture it. On our strictest metric, we attain $F_{1}$ scores of $0.40$ and $0.43$ on our Latin and Chinese datasets, respectively.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00100"
  },
  "2312.00099": {
    "title": "Online Influence Maximization: Concept and Algorithm",
    "authors": [
      "Jianxiong Guo"
    ],
    "abstract": "In this survey, we offer an extensive overview of the Online Influence Maximization (IM) problem by covering both theoretical aspects and practical applications. For the integrity of the article and because the online algorithm takes an offline oracle as a subroutine, we first make a clear definition of the Offline IM problem and summarize those commonly used Offline IM algorithms, which include traditional approximation or heuristic algorithms and ML-based algorithms. Then, we give a standard definition of the Online IM problem and a basic Combinatorial Multi-Armed Bandit (CMAB) framework, CMAB-T. Here, we summarize three types of feedback in the CMAB model and discuss in detail how to study the Online IM problem based on the CMAB-T model. This paves the way for solving the Online IM problem by using online learning methods. Furthermore, we have covered almost all Online IM algorithms up to now, focusing on characteristics and theoretical guarantees of online algorithms for different feedback types. Here, we elaborately explain their working principle and how to obtain regret bounds. Besides, we also collect plenty of innovative ideas about problem definition and algorithm designs and pioneering works for variants of the Online IM problem and their corresponding algorithms. Finally, we encapsulate current challenges and outline prospective research directions from four distinct perspectives.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00099"
  },
  "2312.00098": {
    "title": "Identifying tourist destinations from movie scenes using Deep Learning",
    "authors": [
      "Mahendran Narayanan"
    ],
    "abstract": "Movies wield significant influence in our lives, playing a pivotal role in the tourism industry of any country. The inclusion of picturesque landscapes, waterfalls, and mountains as backdrops in films serves to enhance the allure of specific scenarios. Recognizing the impact of movies on tourism, this paper introduces a method for identifying tourist destinations featured in films. We propose the development of a deep learning model capable of recognizing these locations during movie viewing. The model is trained on a dataset comprising major tourism destinations worldwide. Through this research, the goal is to enable viewers to identify the real-world locations depicted in movie scenes, offering a novel way to connect cinema with global travel experiences.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00098"
  },
  "2312.00097": {
    "title": "SparseDC: Depth Completion from sparse and non-uniform inputs",
    "authors": [
      "Chen Long",
      "Wenxiao Zhang",
      "Zhe Chen",
      "Haiping Wang",
      "Yuan Liu",
      "Zhen Cao",
      "Zhen Dong",
      "Bisheng Yang"
    ],
    "abstract": "We propose SparseDC, a model for Depth Completion of Sparse and non-uniform depth inputs. Unlike previous methods focusing on completing fixed distributions on benchmark datasets (e.g., NYU with 500 points, KITTI with 64 lines), SparseDC is specifically designed to handle depth maps with poor quality in real usage. The key contributions of SparseDC are two-fold. First, we design a simple strategy, called SFFM, to improve the robustness under sparse input by explicitly filling the unstable depth features with stable image features. Second, we propose a two-branch feature embedder to predict both the precise local geometry of regions with available depth values and accurate structures in regions with no depth. The key of the embedder is an uncertainty-based fusion module called UFFM to balance the local and long-term information extracted by CNNs and ViTs. Extensive indoor and outdoor experiments demonstrate the robustness of our framework when facing sparse and non-uniform input depths. The pre-trained model and code are available at https://github.com/WHU-USI3DV/SparseDC.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00097"
  },
  "2312.00095": {
    "title": "Textual-Knowledge-Guided Numerical Feature Discovery Method for Power Demand Forecasting",
    "authors": [
      "Zifan Ning",
      "Min Jin"
    ],
    "abstract": "Power demand forecasting is a crucial and challenging task for new power system and integrated energy system. However, as public feature databases and the theoretical mechanism of power demand changes are unavailable, the known features of power demand fluctuation are much limited. Recently, multimodal learning approaches have shown great vitality in machine learning and AIGC. In this paper, we interact two modal data and propose a textual-knowledge-guided numerical feature discovery (TKNFD) method for short-term power demand forecasting. TKNFD extensively accumulates qualitative textual knowledge, expands it into a candidate feature-type set, collects numerical data of these features, and eventually builds four-dimensional multivariate source-tracking databases (4DM-STDs). Next, TKNFD presents a two-level quantitative feature identification strategy independent of forecasting models, finds 43-48 features, and systematically analyses feature contribution and dependency correlation. Benchmark experiments in two different regions around the world demonstrate that the forecasting accuracy of TKNFD-discovered features reliably outperforms that of SoTA feature schemes by 16.84% to 36.36% MAPE. In particular, TKNFD reveals many unknown features, especially several dominant features in the unknown energy and astronomical dimensions, which extend the knowledge on the origin of strong randomness and non-linearity in power demand fluctuation. Besides, 4DM-STDs can serve as public baseline databases.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00095"
  },
  "2312.00091": {
    "title": "Sound Terminology Describing Production and Perception of Sonification",
    "authors": [
      "Tim Ziemer"
    ],
    "abstract": "Sonification research is intrinsically interdisciplinary. Consequently, a proper documentation of, and interdisciplinary discourse about a sonification is often hindered by terminology discrepancies between involved disciplines, i.e., the lack of a common sound terminology in sonification research. Without a common ground, a researcher from one discipline may have troubles understanding the implementation and imagining the resulting sound perception of a sonification, if the sonification is described by a researcher from another discipline. To find a common ground, I consulted literature on interdisciplinary research and discourse, identified problems that occur in sonification, and applied the recommended solutions. As a result, I recommend considering three aspects of sonification individually, namely 1.) Sound Design Concept, 2.) Objective and 3.) Method, clarifying which discipline is involved in which aspect, and sticking to this discipline's terminology. As two requirements of sonifications are that they are a) reproducible and b) interpretable, I recommend documenting and discussing every sonification design once using audio engineering terminology, and once using psychoacoustic terminology. The appendix provides comprehensive lists of sound terms from both disciplines, together with relevant literature and a clarification of often misunderstood and misused terms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00091"
  },
  "2312.00090": {
    "title": "Tree-based Forecasting of Day-ahead Solar Power Generation from Granular Meteorological Features",
    "authors": [
      "Nick Berlanger",
      "Noah van Ophoven",
      "Tim Verdonck",
      "Ines Wilms"
    ],
    "abstract": "Accurate forecasts for day-ahead photovoltaic (PV) power generation are crucial to support a high PV penetration rate in the local electricity grid and to assure stability in the grid. We use state-of-the-art tree-based machine learning methods to produce such forecasts and, unlike previous studies, we hereby account for (i) the effects various meteorological as well as astronomical features have on PV power production, and this (ii) at coarse as well as granular spatial locations. To this end, we use data from Belgium and forecast day-ahead PV power production at an hourly resolution. The insights from our study can assist utilities, decision-makers, and other stakeholders in optimizing grid operations, economic dispatch, and in facilitating the integration of distributed PV power into the electricity grid.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00090"
  },
  "2312.00088": {
    "title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing",
    "authors": [
      "Geethu Joseph",
      "Chen Zhong",
      "M. Cenk Gursoy",
      "Senem Velipasalar",
      "Pramod K. Varshney"
    ],
    "abstract": "In this paper, we address the problem of detecting anomalies among a given set of binary processes via learning-based controlled sensing. Each process is parameterized by a binary random variable indicating whether the process is anomalous. To identify the anomalies, the decision-making agent is allowed to observe a subset of the processes at each time instant. Also, probing each process has an associated cost. Our objective is to design a sequential selection policy that dynamically determines which processes to observe at each time with the goal to minimize the delay in making the decision and the total sensing cost. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes. This formulation utilizes both a Bayesian log-likelihood ratio-based reward and an entropy-based reward. The problem is then solved using two approaches: 1) a deep reinforcement learning-based approach where we design both deep Q-learning and policy gradient actor-critic algorithms; and 2) a deep active inference-based approach. Using numerical experiments, we demonstrate the efficacy of our algorithms and show that our algorithms adapt to any unknown statistical dependence pattern of the processes.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00088"
  },
  "2312.00087": {
    "title": "Generative Artificial Intelligence in Learning Analytics: Contextualising Opportunities and Challenges through the Learning Analytics Cycle",
    "authors": [
      "Lixiang Yan",
      "Roberto Martinez-Maldonado",
      "Dragan Ga\u0161evi\u0107"
    ],
    "abstract": "Generative artificial intelligence (GenAI), exemplified by ChatGPT, Midjourney, and other state-of-the-art large language models and diffusion models, holds significant potential for transforming education and enhancing human productivity. While the prevalence of GenAI in education has motivated numerous research initiatives, integrating these technologies within the learning analytics (LA) cycle and their implications for practical interventions remain underexplored. This paper delves into the prospective opportunities and challenges GenAI poses for advancing LA. We present a concise overview of the current GenAI landscape and contextualise its potential roles within Clow's generic framework of the LA cycle. We posit that GenAI can play pivotal roles in analysing unstructured data, generating synthetic learner data, enriching multimodal learner interactions, advancing interactive and explanatory analytics, and facilitating personalisation and adaptive interventions. As the lines blur between learners and GenAI tools, a renewed understanding of learners is needed. Future research can delve deep into frameworks and methodologies that advocate for human-AI collaboration. The LA community can play a pivotal role in capturing data about human and AI contributions and exploring how they can collaborate most effectively. As LA advances, it is essential to consider the pedagogical implications and broader socioeconomic impact of GenAI for ensuring an inclusive future.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00087"
  },
  "2312.00086": {
    "title": "Star colouring and locally constrained graph homomorphisms",
    "authors": [
      "Shalu M. A.",
      "Cyriac Antony"
    ],
    "abstract": "Dvo\u0159\u00e1k, Mohar and \u0160\u00e1mal (J. Graph Theory, 2013) proved that for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ admits a locally bijective homomorphism to the cube $Q_3$. We generalise this result as follows: for $p\\geq 2$, a $K_{1,p+1}$-free $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ admits a locally bijective homomorphism to a fixed $2p$-regular graph named $G_{2p}$. We also prove the following: (i) for $p\\geq 2$, a $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ has an orientation $\\vec{G}$ that admits an out-neighbourhood bijective homomorphism to a fixed orientation $\\vec{G_{2p}}$ of $G2p$; (ii) for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ is bipartite and distance-two 4-colourable; and (iii) it is NP-complete to check whether a planar 4-regular 3-connected graph is 4-star colourable.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2312.00086"
  },
  "2312.00080": {
    "title": "PDB-Struct: A Comprehensive Benchmark for Structure-based Protein Design",
    "authors": [
      "Chuanrui Wang",
      "Bozitao Zhong",
      "Zuobai Zhang",
      "Narendra Chaudhary",
      "Sanchit Misra",
      "Jian Tang"
    ],
    "abstract": "Structure-based protein design has attracted increasing interest, with numerous methods being introduced in recent years. However, a universally accepted method for evaluation has not been established, since the wet-lab validation can be overly time-consuming for the development of new algorithms, and the $\\textit{in silico}$ validation with recovery and perplexity metrics is efficient but may not precisely reflect true foldability. To address this gap, we introduce two novel metrics: refoldability-based metric, which leverages high-accuracy protein structure prediction models as a proxy for wet lab experiments, and stability-based metric, which assesses whether models can assign high likelihoods to experimentally stable proteins. We curate datasets from high-quality CATH protein data, high-throughput $\\textit{de novo}$ designed proteins, and mega-scale experimental mutagenesis experiments, and in doing so, present the $\\textbf{PDB-Struct}$ benchmark that evaluates both recent and previously uncompared protein design methods. Experimental results indicate that ByProt, ProteinMPNN, and ESM-IF perform exceptionally well on our benchmark, while ESM-Design and AF-Design fall short on the refoldability metric. We also show that while some methods exhibit high sequence recovery, they do not perform as well on our new benchmark. Our proposed benchmark paves the way for a fair and comprehensive evaluation of protein design methods in the future. Code is available at https://github.com/WANG-CR/PDB-Struct.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00080"
  },
  "2312.00079": {
    "title": "HiFi Tuner: High-Fidelity Subject-Driven Fine-Tuning for Diffusion Models",
    "authors": [
      "Zhonghao Wang",
      "Wei Wei",
      "Yang Zhao",
      "Zhisheng Xiao",
      "Mark Hasegawa-Johnson",
      "Humphrey Shi",
      "Tingbo Hou"
    ],
    "abstract": "This paper explores advancements in high-fidelity personalized image generation through the utilization of pre-trained text-to-image diffusion models. While previous approaches have made significant strides in generating versatile scenes based on text descriptions and a few input images, challenges persist in maintaining the subject fidelity within the generated images. In this work, we introduce an innovative algorithm named HiFi Tuner to enhance the appearance preservation of objects during personalized image generation. Our proposed method employs a parameter-efficient fine-tuning framework, comprising a denoising process and a pivotal inversion process. Key enhancements include the utilization of mask guidance, a novel parameter regularization technique, and the incorporation of step-wise subject representations to elevate the sample fidelity. Additionally, we propose a reference-guided generation approach that leverages the pivotal inversion of a reference image to mitigate unwanted subject variations and artifacts. We further extend our method to a novel image editing task: substituting the subject in an image through textual manipulations. Experimental evaluations conducted on the DreamBooth dataset using the Stable Diffusion model showcase promising results. Fine-tuning solely on textual embeddings improves CLIP-T score by 3.6 points and improves DINO score by 9.6 points over Textual Inversion. When fine-tuning all parameters, HiFi Tuner improves CLIP-T score by 1.2 points and improves DINO score by 1.2 points over DreamBooth, establishing a new state of the art.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00079"
  },
  "2312.00076": {
    "title": "Towards A Foundation Model For Trajectory Intelligence",
    "authors": [
      "Alameen Najjar"
    ],
    "abstract": "We present the results of training a large trajectory model using real-world user check-in data. Our approach follows a pre-train and fine-tune paradigm, where a base model is pre-trained via masked trajectory modeling and then adapted through fine-tuning for various downstream tasks. To address challenges posed by noisy data and large spatial vocabularies, we propose a novel spatial tokenization block. Our empirical analysis utilizes a comprehensive dataset of over 2 billion check-ins generated by more than 6 million users. Through fine-tuning on 3 downstream tasks we demonstrate that our base model has effectively learned valuable underlying patterns in raw data, enabling its application in meaningful trajectory intelligence tasks. Despite some limitations, we believe this work represents an important step forward in the realization of a foundation model for trajectory intelligence.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00076"
  },
  "2312.00075": {
    "title": "Accelerating Neural Field Training via Soft Mining",
    "authors": [
      "Shakiba Kheradmand",
      "Daniel Rebain",
      "Gopal Sharma",
      "Hossam Isack",
      "Abhishek Kar",
      "Andrea Tagliasacchi",
      "Kwang Moo Yi"
    ],
    "abstract": "We present an approach to accelerate Neural Field training by efficiently selecting sampling locations. While Neural Fields have recently become popular, it is often trained by uniformly sampling the training domain, or through handcrafted heuristics. We show that improved convergence and final training quality can be achieved by a soft mining technique based on importance sampling: rather than either considering or ignoring a pixel completely, we weigh the corresponding loss by a scalar. To implement our idea we use Langevin Monte-Carlo sampling. We show that by doing so, regions with higher error are being selected more frequently, leading to more than 2x improvement in convergence speed. The code and related resources for this study are publicly available at https://ubc-vision.github.io/nf-soft-mining/.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00075"
  },
  "2312.00073": {
    "title": "Binary perceptrons capacity via fully lifted random duality theory",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "We study the statistical capacity of the classical binary perceptrons with general thresholds $\u03ba$. After recognizing the connection between the capacity and the bilinearly indexed (bli) random processes, we utilize a recent progress in studying such processes to characterize the capacity. In particular, we rely on \\emph{fully lifted} random duality theory (fl RDT) established in \\cite{Stojnicflrdt23} to create a general framework for studying the perceptrons' capacities. Successful underlying numerical evaluations are required for the framework (and ultimately the entire fl RDT machinery) to become fully practically operational. We present results obtained in that directions and uncover that the capacity characterizations are achieved on the second (first non-trivial) level of \\emph{stationarized} full lifting. The obtained results \\emph{exactly} match the replica symmetry breaking predictions obtained through statistical physics replica methods in \\cite{KraMez89}. Most notably, for the famous zero-threshold scenario, $\u03ba=0$, we uncover the well known $\u03b1\\approx0.8330786$ scaled capacity.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00073"
  },
  "2312.00072": {
    "title": "CRAFT: Contextual Re-Activation of Filters for face recognition Training",
    "authors": [
      "Aman Bhatta",
      "Domingo Mery",
      "Haiyu Wu",
      "Kevin W. Bowyer"
    ],
    "abstract": "The first layer of a deep CNN backbone applies filters to an image to extract the basic features available to later layers. During training, some filters may go inactive, mean ing all weights in the filter approach zero. An inactive fil ter in the final model represents a missed opportunity to extract a useful feature. This phenomenon is especially prevalent in specialized CNNs such as for face recogni tion (as opposed to, e.g., ImageNet). For example, in one the most widely face recognition model (ArcFace), about half of the convolution filters in the first layer are inactive. We propose a novel approach designed and tested specif ically for face recognition networks, known as \"CRAFT: Contextual Re-Activation of Filters for Face Recognition Training\". CRAFT identifies inactive filters during training and reinitializes them based on the context of strong filters at that stage in training. We show that CRAFT reduces fraction of inactive filters from 44% to 32% on average and discovers filter patterns not found by standard training. Compared to standard training without reactivation, CRAFT demonstrates enhanced model accuracy on standard face-recognition benchmark datasets including AgeDB-30, CPLFW, LFW, CALFW, and CFP-FP, as well as on more challenging datasets like IJBB and IJBC.\n        \u25b3 Less",
    "submission_date": "4 December, 2023",
    "eprint_id": "2312.00072"
  },
  "2312.00071": {
    "title": "Studying Hopfield models via fully lifted random duality theory",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "Relying on a recent progress made in studying bilinearly indexed (bli) random processes in \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23}, the main foundational principles of fully lifted random duality theory (fl RDT) were established in \\cite{Stojnicflrdt23}. We here study famous Hopfield models and show that their statistical behavior can be characterized via the fl RDT. Due to a nestedly lifted nature, the resulting characterizations and, therefore, the whole analytical machinery that produces them, become fully operational only if one can successfully conduct underlying numerical evaluations. After conducting such evaluations for both positive and negative Hopfield models, we observe a remarkably fast convergence of the fl RDT mechanism. Namely, for the so-called square case, the fourth decimal precision is achieved already on the third (second non-trivial) level of lifting (3-sfl RDT) for the positive and on the fourth (third non-trivial) level of lifting (4-sfl RDT) for the corresponding negative model. In particular, we obtain the scaled ground state free energy $\\approx 1.7788$ for the positive and $\\approx 0.3279$ for the negative model.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00071"
  },
  "2312.00070": {
    "title": "Fully lifted random duality theory",
    "authors": [
      "Mihailo Stojnic"
    ],
    "abstract": "We study a generic class of \\emph{random optimization problems} (rops) and their typical behavior. The foundational aspects of the random duality theory (RDT), associated with rops, were discussed in \\cite{StojnicRegRndDlt10}, where it was shown that one can often infer rops' behavior even without actually solving them. Moreover, \\cite{StojnicRegRndDlt10} uncovered that various quantities relevant to rops (including, for example, their typical objective values) can be determined (in a large dimensional context) even completely analytically. The key observation was that the \\emph{strong deterministic duality} implies the, so-called, \\emph{strong random duality} and therefore the full exactness of the analytical RDT characterizations. Here, we attack precisely those scenarios where the strong deterministic duality is not necessarily present and connect them to the recent progress made in studying bilinearly indexed (bli) random processes in \\cite{Stojnicnflgscompyx23,Stojnicsflgscompyx23}. In particular, utilizing a fully lifted (fl) interpolating comparison mechanism introduced in \\cite{Stojnicnflgscompyx23}, we establish corresponding \\emph{fully lifted} RDT (fl RDT). We then rely on a stationarized fl interpolation realization introduced in \\cite{Stojnicsflgscompyx23} to obtain complete \\emph{statitionarized} fl RDT (sfl RDT). A few well known problems are then discussed as illustrations of a wide range of practical applications implied by the generality of the considered rops.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00070"
  },
  "2312.00069": {
    "title": "SICKLE: A Multi-Sensor Satellite Imagery Dataset Annotated with Multiple Key Cropping Parameters",
    "authors": [
      "Depanshu Sani",
      "Sandeep Mahato",
      "Sourabh Saini",
      "Harsh Kumar Agarwal",
      "Charu Chandra Devshali",
      "Saket Anand",
      "Gaurav Arora",
      "Thiagarajan Jayaraman"
    ],
    "abstract": "The availability of well-curated datasets has driven the success of Machine Learning (ML) models. Despite greater access to earth observation data in agriculture, there is a scarcity of curated and labelled datasets, which limits the potential of its use in training ML models for remote sensing (RS) in agriculture. To this end, we introduce a first-of-its-kind dataset called SICKLE, which constitutes a time-series of multi-resolution imagery from 3 distinct satellites: Landsat-8, Sentinel-1 and Sentinel-2. Our dataset constitutes multi-spectral, thermal and microwave sensors during January 2018 - March 2021 period. We construct each temporal sequence by considering the cropping practices followed by farmers primarily engaged in paddy cultivation in the Cauvery Delta region of Tamil Nadu, India; and annotate the corresponding imagery with key cropping parameters at multiple resolutions (i.e. 3m, 10m and 30m). Our dataset comprises 2,370 season-wise samples from 388 unique plots, having an average size of 0.38 acres, for classifying 21 crop types across 4 districts in the Delta, which amounts to approximately 209,000 satellite images. Out of the 2,370 samples, 351 paddy samples from 145 plots are annotated with multiple crop parameters; such as the variety of paddy, its growing season and productivity in terms of per-acre yields. Ours is also one among the first studies that consider the growing season activities pertinent to crop phenology (spans sowing, transplanting and harvesting dates) as parameters of interest. We benchmark SICKLE on three tasks: crop type, crop phenology (sowing, transplanting, harvesting), and yield prediction\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00069"
  },
  "2312.00067": {
    "title": "Predicting breast cancer with AI for individual risk-adjusted MRI screening and early detection",
    "authors": [
      "Lukas Hirsch",
      "Yu Huang",
      "Hernan A. Makse",
      "Danny F. Martinez",
      "Mary Hughes",
      "Sarah Eskreis-Winkler",
      "Katja Pinker",
      "Elizabeth Morris",
      "Lucas C. Parra",
      "Elizabeth J. Sutton"
    ],
    "abstract": "Women with an increased life-time risk of breast cancer undergo supplemental annual screening MRI. We propose to predict the risk of developing breast cancer within one year based on the current MRI, with the objective of reducing screening burden and facilitating early detection. An AI algorithm was developed on 53,858 breasts from 12,694 patients who underwent screening or diagnostic MRI and accrued over 12 years, with 2,331 confirmed cancers. A first U-Net was trained to segment lesions and identify regions of concern. A second convolutional network was trained to detect malignant cancer using features extracted by the U-Net. This network was then fine-tuned to estimate the risk of developing cancer within a year in cases that radiologists considered normal or likely benign. Risk predictions from this AI were evaluated with a retrospective analysis of 9,183 breasts from a high-risk screening cohort, which were not used for training. Statistical analysis focused on the tradeoff between number of omitted exams versus negative predictive value, and number of potential early detections versus positive predictive value. The AI algorithm identified regions of concern that coincided with future tumors in 52% of screen-detected cancers. Upon directed review, a radiologist found that 71.3% of cancers had a visible correlate on the MRI prior to diagnosis, 65% of these correlates were identified by the AI model. Reevaluating these regions in 10% of all cases with higher AI-predicted risk could have resulted in up to 33% early detections by a radiologist. Additionally, screening burden could have been reduced in 16% of lower-risk cases by recommending a later follow-up without compromising current interval cancer rate. With increasing datasets and improving image quality we expect this new AI-aided, adaptive screening to meaningfully reduce screening burden and improve early detection.\n        \u25b3 Less",
    "submission_date": "18 January, 2024",
    "eprint_id": "2312.00067"
  },
  "2312.00066": {
    "title": "Exploring Factors Affecting Pedestrian Crash Severity Using TabNet: A Deep Learning Approach",
    "authors": [
      "Amir Rafe",
      "Patrick A. Singleton"
    ],
    "abstract": "This study presents the first investigation of pedestrian crash severity using the TabNet model, a novel tabular deep learning method exceptionally suited for analyzing the tabular data inherent in transportation safety research. Through the application of TabNet to a comprehensive dataset from Utah covering the years 2010 to 2022, we uncover intricate factors contributing to pedestrian crash severity. The TabNet model, capitalizing on its compatibility with structured data, demonstrates remarkable predictive accuracy, eclipsing that of traditional models. It identifies critical variables, such as pedestrian age, involvement in left or right turns, lighting conditions, and alcohol consumption, which significantly influence crash outcomes. The utilization of SHapley Additive exPlanations (SHAP) enhances our ability to interpret the TabNet model's predictions, ensuring transparency and understandability in our deep learning approach. The insights derived from our analysis provide a valuable compass for transportation safety engineers and policymakers, enabling the identification of pivotal factors that affect pedestrian crash severity. Such knowledge is instrumental in formulating precise, data-driven interventions aimed at bolstering pedestrian safety across diverse urban and rural settings.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00066"
  },
  "2312.00063": {
    "title": "MoMask: Generative Masked Modeling of 3D Human Motions",
    "authors": [
      "Chuan Guo",
      "Yuxuan Mu",
      "Muhammad Gohar Javed",
      "Sen Wang",
      "Li Cheng"
    ],
    "abstract": "We introduce MoMask, a novel masked modeling framework for text-driven 3D human motion generation. In MoMask, a hierarchical quantization scheme is employed to represent human motion as multi-layer discrete motion tokens with high-fidelity details. Starting at the base layer, with a sequence of motion tokens obtained by vector quantization, the residual tokens of increasing orders are derived and stored at the subsequent layers of the hierarchy. This is consequently followed by two distinct bidirectional transformers. For the base-layer motion tokens, a Masked Transformer is designated to predict randomly masked motion tokens conditioned on text input at training stage. During generation (i.e. inference) stage, starting from an empty sequence, our Masked Transformer iteratively fills up the missing tokens; Subsequently, a Residual Transformer learns to progressively predict the next-layer tokens based on the results from current layer. Extensive experiments demonstrate that MoMask outperforms the state-of-art methods on the text-to-motion generation task, with an FID of 0.045 (vs e.g. 0.141 of T2M-GPT) on the HumanML3D dataset, and 0.228 (vs 0.514) on KIT-ML, respectively. MoMask can also be seamlessly applied in related tasks without further model fine-tuning, such as text-guided temporal inpainting.\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00063"
  },
  "2312.00060": {
    "title": "Open data ecosystems: what models to co-create service innovations in smart cities?",
    "authors": [
      "Arthur Sarazin"
    ],
    "abstract": "While smart cities are recently providing open data, how to organise the collective creation of data, knowledge and related products and services produced from this collective resource, still remains to be thought. This paper aims at gathering the literature review on open data ecosystems to tackle the following research question: what models can be imagined to stimulate the collective co-creation of services between smart cities' stakeholders acting as providers and users of open data? Such issue is currently at stake in many municipalities such as Lisbon which decided to position itself as a platform (O'Reilly, 2010) in the local digital ecosystem. With the implementation of its City Operation Center (COI), Lisbon's municipality provides an Information Infrastructure (Bowker et al., 2009) to many different types of actors such as telecom companies, municipalities, energy utilities or transport companies. Through this infrastructure, Lisbon encourages such actors to gather, integrate and release heterogeneous datasets and tries to orchestrate synergies among them so data-driven solution to urban problems can emerge (Carvalho and Vale, 2018). The remaining question being: what models for the municipalities such as Lisbon to lean on so as to drive this cutting-edge type of service innovation?\n        \u25b3 Less",
    "submission_date": "29 November, 2023",
    "eprint_id": "2312.00060"
  },
  "2312.00055": {
    "title": "LEAP: LLM-Generation of Egocentric Action Programs",
    "authors": [
      "Eadom Dessalene",
      "Michael Maynord",
      "Cornelia Ferm\u00fcller",
      "Yiannis Aloimonos"
    ],
    "abstract": "We introduce LEAP (illustrated in Figure 1), a novel method for generating video-grounded action programs through use of a Large Language Model (LLM). These action programs represent the motoric, perceptual, and structural aspects of action, and consist of sub-actions, pre- and post-conditions, and control flows. LEAP's action programs are centered on egocentric video and employ recent developments in LLMs both as a source for program knowledge and as an aggregator and assessor of multimodal video information. We apply LEAP over a majority (87\\%) of the training set of the EPIC Kitchens dataset, and release the resulting action programs as a publicly available dataset here (https://drive.google.com/drive/folders/1Cpkw_TI1IIxXdzor0pOXG3rWJWuKU5Ex?usp=drive_link). We employ LEAP as a secondary source of supervision, using its action programs in a loss term applied to action recognition and anticipation networks. We demonstrate sizable improvements in performance in both tasks due to training with the LEAP dataset. Our method achieves 1st place on the EPIC Kitchens Action Recognition leaderboard as of November 17 among the networks restricted to RGB-input (see Supplementary Materials).\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.00055"
  },
  "2312.00053": {
    "title": "Anti-Sexism Alert System: Identification of Sexist Comments on Social Media Using AI Techniques",
    "authors": [
      "Rebeca P. D\u00edaz Redondo",
      "Ana Fern\u00e1ndez Vilas",
      "Mateo Ramos Merino",
      "Sonia Valladares",
      "Soledad Torres Guijarro",
      "Manar Mohamed Hafez"
    ],
    "abstract": "Social relationships in the digital sphere are becoming more usual and frequent, and they constitute a very important aspect for all of us. {Violent interactions in this sphere are very frequent, and have serious effects on the victims}. Within this global scenario, there is one kind of digital violence that is becoming really worrying: sexism against women. Sexist comments that are publicly posted in social media (newspaper comments, social networks, etc.), usually obtain a lot of attention and become viral, with consequent damage to the persons involved. In this paper, we introduce an anti-sexism alert system, based on natural language processing (NLP) and artificial intelligence (AI), that analyzes any public post, and decides if it could be considered a sexist comment or not. Additionally, this system also works on analyzing all the public comments linked to any multimedia content (piece of news, video, tweet, etc.) and decides, using a color-based system similar to traffic lights, if there is sexism in the global set of posts. We have created a labeled data set in Spanish, since the majority of studies focus on English, to train our system, which offers a very good performance after the validation experiments.\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.00053"
  },
  "2312.00052": {
    "title": "A Case for Competent AI Systems $-$ A Concept Note",
    "authors": [
      "Kamalakar Karlapalem"
    ],
    "abstract": "The efficiency of an AI system is contingent upon its ability to align with the specified requirements of a given task. How-ever, the inherent complexity of tasks often introduces the potential for harmful implications or adverse actions. This note explores the critical concept of capability within AI systems, representing what the system is expected to deliver. The articulation of capability involves specifying well-defined out-comes. Yet, the achievement of this capability may be hindered by deficiencies in implementation and testing, reflecting a gap in the system's competency (what it can do vs. what it does successfully).\n  A central challenge arises in elucidating the competency of an AI system to execute tasks effectively. The exploration of system competency in AI remains in its early stages, occasionally manifesting as confidence intervals denoting the probability of success. Trust in an AI system hinges on the explicit modeling and detailed specification of its competency, connected intricately to the system's capability. This note explores this gap by proposing a framework for articulating the competency of AI systems.\n  Motivated by practical scenarios such as the Glass Door problem, where an individual inadvertently encounters a glass obstacle due to a failure in their competency, this research underscores the imperative of delving into competency dynamics. Bridging the gap between capability and competency at a detailed level, this note contributes to advancing the discourse on bolstering the reliability of AI systems in real-world applications.\n        \u25b3 Less",
    "submission_date": "7 December, 2023",
    "eprint_id": "2312.00052"
  },
  "2312.00051": {
    "title": "MIA-BAD: An Approach for Enhancing Membership Inference Attack and its Mitigation with Federated Learning",
    "authors": [
      "Soumya Banerjee",
      "Sandip Roy",
      "Sayyed Farid Ahamed",
      "Devin Quinn",
      "Marc Vucovich",
      "Dhruv Nandakumar",
      "Kevin Choi",
      "Abdul Rahman",
      "Edward Bowen",
      "Sachin Shetty"
    ],
    "abstract": "The membership inference attack (MIA) is a popular paradigm for compromising the privacy of a machine learning (ML) model. MIA exploits the natural inclination of ML models to overfit upon the training data. MIAs are trained to distinguish between training and testing prediction confidence to infer membership information. Federated Learning (FL) is a privacy-preserving ML paradigm that enables multiple clients to train a unified model without disclosing their private data. In this paper, we propose an enhanced Membership Inference Attack with the Batch-wise generated Attack Dataset (MIA-BAD), a modification to the MIA approach. We investigate that the MIA is more accurate when the attack dataset is generated batch-wise. This quantitatively decreases the attack dataset while qualitatively improving it. We show how training an ML model through FL, has some distinct advantages and investigate how the threat introduced with the proposed MIA-BAD approach can be mitigated with FL approaches. Finally, we demonstrate the qualitative effects of the proposed MIA-BAD methodology by conducting extensive experiments with various target datasets, variable numbers of federated clients, and training batch sizes.\n        \u25b3 Less",
    "submission_date": "28 November, 2023",
    "eprint_id": "2312.00051"
  },
  "2312.00048": {
    "title": "Tokenized Model: A Blockchain-Empowered Decentralized Model Ownership Verification Platform",
    "authors": [
      "Yihao Li",
      "Yanyi Lai",
      "Tianchi Liao",
      "Chuan Chen",
      "Zibin Zheng"
    ],
    "abstract": "With the development of practical deep learning models like generative AI, their excellent performance has brought huge economic value. For instance, ChatGPT has attracted more than 100 million users in three months. Since the model training requires a lot of data and computing power, a well-performing deep learning model is behind a huge effort and cost. Facing various model attacks, unauthorized use and abuse from the network that threaten the interests of model owners, in addition to considering legal and other administrative measures, it is equally important to protect the model's copyright from the technical means. By using the model watermarking technology, we point out the possibility of building a unified platform for model ownership verification. Given the application history of blockchain in copyright verification and the drawbacks of a centralized third-party, this paper considers combining model watermarking technology and blockchain to build a unified model copyright protection platform. By a new solution we called Tokenized Model, it protects the model's copyright by reliable ownership record and verification mechanism. It also promotes the financial value of model by constructing the model's transaction process and contribution shares of a model. In the typical case study, we also study the various performance under usual scenario to verify the effectiveness of this platform.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.00048"
  },
  "2312.00047": {
    "title": "chatGPT for generating questions and assessments based on accreditations",
    "authors": [
      "Rania Anwar Aboalela"
    ],
    "abstract": "This research aims to take advantage of artificial intelligence techniques in producing students assessment that is compatible with the different academic accreditations of the same program. The possibility of using generative artificial intelligence technology was studied to produce an academic accreditation compliant test the National Center for Academic Accreditation of Kingdom of Saudi Arabia and Accreditation Board for Engineering and Technology. A novel method was introduced to map the verbs used to create the questions introduced in the tests. The method allows a possibility of using the generative artificial intelligence technology to produce and check the validity of questions that measure educational outcomes. A questionnaire was distributed to ensure that the use of generative artificial intelligence to create exam questions is acceptable by the faculty members, as well as to ask about the acceptance of assistance in validating questions submitted by faculty members and amending them in accordance with academic accreditations. The questionnaire was distributed to faculty members of different majors in the Kingdom of Saudi Arabias universities. one hundred twenty responses obtained with eight five percentile approval percentage for generate complete exam questions by generative artificial intelligence . Whereas ninety eight percentage was the approval percentage for editing and improving already existed questions.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.00047"
  },
  "2312.00046": {
    "title": "Retail Analytics in the New Normal: The Influence of Artificial Intelligence and the Covid-19 Pandemic",
    "authors": [
      "Yossiri Adulyasak",
      "Maxime C. Cohen",
      "Warut Khern-am-nuai",
      "Michael Krause"
    ],
    "abstract": "The COVID-19 pandemic has severely disrupted the retail landscape and has accelerated the adoption of innovative technologies. A striking example relates to the proliferation of online grocery orders and the technology deployed to facilitate such logistics. In fact, for many retailers, this disruption was a wake-up call after which they started recognizing the power of data analytics and artificial intelligence (AI). In this article, we discuss the opportunities that AI can offer to retailers in the new normal retail landscape. Some of the techniques described have been applied at scale to adapt previously deployed AI models, whereas in other instances, fresh solutions needed to be developed to help retailers cope with recent disruptions, such as unexpected panic buying, retraining predictive models, and leveraging online-offline synergies.\n        \u25b3 Less",
    "submission_date": "27 November, 2023",
    "eprint_id": "2312.00046"
  },
  "2312.00045": {
    "title": "AI-driven E-Liability Knowledge Graphs: A Comprehensive Framework for Supply Chain Carbon Accounting and Emissions Liability Management",
    "authors": [
      "Olamide Oladeji",
      "Seyed Shahabeddin Mousavi",
      "Marc Roston"
    ],
    "abstract": "While carbon accounting plays a fundamental role in our fight against climate change, it is not without its challenges. We begin the paper with a critique of the conventional carbon accounting practices, after which we proceed to introduce the E-liability carbon accounting methodology and Emissions Liability Management (ELM) originally proposed by Kaplan and Ramanna, highlighting their strengths. Recognizing the immense value of this novel approach for real-world carbon accounting improvement, we introduce a novel data-driven integrative framework that leverages AI and computation - the E-Liability Knowledge Graph framework - to achieve real-world implementation of the E-liability carbon accounting methodology. In addition to providing a path-to-implementation, our proposed framework brings clarity to the complex environmental interactions within supply chains, thus enabling better informed and more responsible decision-making. We analyze the implementation aspects of this framework and conclude with a discourse on the role of this AI-aided knowledge graph in ensuring the transparency and decarbonization of global supply chains.\n        \u25b3 Less",
    "submission_date": "26 November, 2023",
    "eprint_id": "2312.00045"
  },
  "2312.00044": {
    "title": "Advancing AI Audits for Enhanced AI Governance",
    "authors": [
      "Arisa Ema",
      "Ryo Sato",
      "Tomoharu Hase",
      "Masafumi Nakano",
      "Shinji Kamimura",
      "Hiromu Kitamura"
    ],
    "abstract": "As artificial intelligence (AI) is integrated into various services and systems in society, many companies and organizations have proposed AI principles, policies, and made the related commitments. Conversely, some have proposed the need for independent audits, arguing that the voluntary principles adopted by the developers and providers of AI services and systems insufficiently address risk. This policy recommendation summarizes the issues related to the auditing of AI services and systems and presents three recommendations for promoting AI auditing that contribute to sound AI governance. Recommendation1.Development of institutional design for AI audits. Recommendation2.Training human resources for AI audits. Recommendation3. Updating AI audits in accordance with technological progress.\n  In this policy recommendation, AI is assumed to be that which recognizes and predicts data with the last chapter outlining how generative AI should be audited.\n        \u25b3 Less",
    "submission_date": "26 November, 2023",
    "eprint_id": "2312.00044"
  },
  "2312.00043": {
    "title": "Who is leading in AI? An analysis of industry AI research",
    "authors": [
      "Ben Cottier",
      "Tamay Besiroglu",
      "David Owen"
    ],
    "abstract": "AI research is increasingly industry-driven, making it crucial to understand company contributions to this field. We compare leading AI companies by research publications, citations, size of training runs, and contributions to algorithmic innovations. Our analysis reveals the substantial role played by Google, OpenAI and Meta. We find that these three companies have been responsible for some of the largest training runs, developed a large fraction of the algorithmic innovations that underpin large language models, and led in various metrics of citation impact. In contrast, leading Chinese companies such as Tencent and Baidu had a lower impact on many of these metrics compared to US counterparts. We observe many industry labs are pursuing large training runs, and that training runs from relative newcomers -- such as OpenAI and Anthropic -- have matched or surpassed those of long-standing incumbents such as Google. The data reveals a diverse ecosystem of companies steering AI progress, though US labs such as Google, OpenAI and Meta lead across critical metrics.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2312.00043"
  },
  "2312.00042": {
    "title": "DeepTreeGANv2: Iterative Pooling of Point Clouds",
    "authors": [
      "Moritz Alfons Wilhelm Scham",
      "Dirk Kr\u00fccker",
      "Kerstin Borras"
    ],
    "abstract": "In High Energy Physics, detailed and time-consuming simulations are used for particle interactions with detectors. To bypass these simulations with a generative model, the generation of large point clouds in a short time is required, while the complex dependencies between the particles must be correctly modelled. Particle showers are inherently tree-based processes, as each particle is produced by the decay or detector interaction of a particle of the previous generation. In this work, we present a significant extension to DeepTreeGAN, featuring a critic, that is able to aggregate such point clouds iteratively in a tree-based manner. We show that this model can reproduce complex distributions, and we evaluate its performance on the public JetNet 150 dataset.\n        \u25b3 Less",
    "submission_date": "2 January, 2024",
    "eprint_id": "2312.00042"
  },
  "2312.00041": {
    "title": "Presentation Attack Detection using Convolutional Neural Networks and Local Binary Patterns",
    "authors": [
      "Justin Spencer",
      "Deborah Lawrence",
      "Prosenjit Chatterjee",
      "Kaushik Roy",
      "Albert Esterline",
      "Jung-Hee Kim"
    ],
    "abstract": "The use of biometrics to authenticate users and control access to secure areas has become extremely popular in recent years, and biometric access control systems are frequently used by both governments and private corporations. However, these systems may represent risks to security when deployed without considering the possibility of biometric presentation attacks (also known as spoofing). Presentation attacks are a serious threat because they do not require significant time, expense, or skill to carry out while remaining effective against many biometric systems in use today. This research compares three different software-based methods for facial and iris presentation attack detection in images. The first method uses Inception-v3, a pre-trained deep Convolutional Neural Network (CNN) made by Google for the ImageNet challenge, which is retrained for this problem. The second uses a shallow CNN based on a modified Spoofnet architecture, which is trained normally. The third is a texture-based method using Local Binary Patterns (LBP). The datasets used are the ATVS-FIr dataset, which contains real and fake iris images, and the CASIA Face Anti-Spoofing Dataset, which contains real images as well as warped photos, cut photos, and video replay presentation attacks. We also present a third set of results, based on cropped versions of the CASIA images.\n        \u25b3 Less",
    "submission_date": "23 November, 2023",
    "eprint_id": "2312.00041"
  },
  "2312.00040": {
    "title": "Presentation Attack detection using Wavelet Transform and Deep Residual Neural Net",
    "authors": [
      "Prosenjit Chatterjee",
      "Alex Yalchin",
      "Joseph Shelton",
      "Kaushik Roy",
      "Xiaohong Yuan",
      "Kossi D. Edoh"
    ],
    "abstract": "Biometric authentication is becoming more prevalent for secured authentication systems. However, the biometric substances can be deceived by the imposters in several ways. Among other imposter attacks, print attacks, mask attacks, and replay attacks fall under the presentation attack category. The bio-metric images, especially the iris and face, are vulnerable to different presentation attacks. This research applies deep learning approaches to mitigate presentation attacks in a biometric access control system. Our contribution in this paper is two-fold: First, we applied the wavelet transform to extract the features from the biometric images. Second, we modified the deep residual neural net and applied it to the spoof datasets in an attempt to detect the presentation attacks. This research applied the proposed approach to biometric spoof datasets, namely ATVS, CASIA two class, and CASIA cropped image sets. The datasets used in this research contain images that are captured in both a controlled and uncontrolled environment along with different resolutions and sizes. We obtained the best accuracy of 93% on the ATVS Iris datasets. For CASIA two class and CASIA cropped datasets, we achieved test accuracies of 91% and 82%, respectively.\n        \u25b3 Less",
    "submission_date": "23 November, 2023",
    "eprint_id": "2312.00040"
  },
  "2312.00039": {
    "title": "Acoustic Cybersecurity: Exploiting Voice-Activated Systems",
    "authors": [
      "Forrest McKee",
      "David Noever"
    ],
    "abstract": "In this study, we investigate the emerging threat of inaudible acoustic attacks targeting digital voice assistants, a critical concern given their projected prevalence to exceed the global population by 2024. Our research extends the feasibility of these attacks across various platforms like Amazon's Alexa, Android, iOS, and Cortana, revealing significant vulnerabilities in smart devices. The twelve attack vectors identified include successful manipulation of smart home devices and automotive systems, potential breaches in military communication, and challenges in critical infrastructure security. We quantitatively show that attack success rates hover around 60%, with the ability to activate devices remotely from over 100 feet away. Additionally, these attacks threaten critical infrastructure, emphasizing the need for multifaceted defensive strategies combining acoustic shielding, advanced signal processing, machine learning, and robust user authentication to mitigate these risks.\n        \u25b3 Less",
    "submission_date": "22 November, 2023",
    "eprint_id": "2312.00039"
  },
  "2312.00037": {
    "title": "Photonic Neural Networks and Optics-informed Deep Learning Fundamentals",
    "authors": [
      "A. Tsakyridis",
      "M. Moralis-Pegios",
      "G. Giamougiannis",
      "M. Kirtas",
      "N. Passalis",
      "A. Tefas",
      "N. Pleros"
    ],
    "abstract": "The recent explosive compute growth, mainly fueled by the boost of AI and DNNs, is currently instigating the demand for a novel computing paradigm that can overcome the insurmountable barriers imposed by conventional electronic computing architectures. PNNs implemented on silicon integration platforms stand out as a promising candidate to endow NN hardware, offering the potential for energy efficient and ultra-fast computations through the utilization of the unique primitives of photonics i.e. energy efficiency, THz bandwidth and low-latency. Thus far, several demonstrations have revealed the huge potential of PNNs in performing both linear and non-linear NN operations at unparalleled speed and energy consumption metrics. Transforming this potential into a tangible reality for DL applications requires, however, a deep understanding of the basic PNN principles, requirements and challenges across all constituent architectural, technological and training aspects. In this tutorial, we, initially, review the principles of DNNs along with their fundamental building blocks, analyzing also the key mathematical operations needed for their computation in a photonic hardware. Then, we investigate, through an intuitive mathematical analysis, the interdependence of bit precision and energy efficiency in analog photonic circuitry, discussing the opportunities and challenges of PNNs. Followingly, a performance overview of PNN architectures, weight technologies and activation functions is presented, summarizing their impact in speed, scalability and power consumption. Finally, we provide an holistic overview of the optics-informed NN training framework that incorporates the physical properties of photonic building blocks into the training process in order to improve the NN classification accuracy and effectively elevate neuromorphic photonic hardware into high-performance DL computational settings.\n        \u25b3 Less",
    "submission_date": "22 November, 2023",
    "eprint_id": "2312.00037"
  },
  "2312.00036": {
    "title": "Privacy-Preserving Load Forecasting via Personalized Model Obfuscation",
    "authors": [
      "Shourya Bose",
      "Yu Zhang",
      "Kibaek Kim"
    ],
    "abstract": "The widespread adoption of smart meters provides access to detailed and localized load consumption data, suitable for training building-level load forecasting models. To mitigate privacy concerns stemming from model-induced data leakage, federated learning (FL) has been proposed. This paper addresses the performance challenges of short-term load forecasting models trained with FL on heterogeneous data, emphasizing privacy preservation through model obfuscation. Our proposed algorithm, Privacy Preserving Federated Learning (PPFL), incorporates personalization layers for localized training at each smart meter. Additionally, we employ a differentially private mechanism to safeguard against data leakage from shared layers. Simulations on the NREL ComStock dataset corroborate the effectiveness of our approach.\n        \u25b3 Less",
    "submission_date": "20 November, 2023",
    "eprint_id": "2312.00036"
  },
  "2312.00034": {
    "title": "Enhancing IoT Security via Automatic Network Traffic Analysis: The Transition from Machine Learning to Deep Learning",
    "authors": [
      "Mounia Hamidouche",
      "Eugeny Popko",
      "Bassem Ouni"
    ],
    "abstract": "This work provides a comparative analysis illustrating how Deep Learning (DL) surpasses Machine Learning (ML) in addressing tasks within Internet of Things (IoT), such as attack classification and device-type identification. Our approach involves training and evaluating a DL model using a range of diverse IoT-related datasets, allowing us to gain valuable insights into how adaptable and practical these models can be when confronted with various IoT configurations. We initially convert the unstructured network traffic data from IoT networks, stored in PCAP files, into images by processing the packet data. This conversion process adapts the data to meet the criteria of DL classification methods. The experiments showcase the ability of DL to surpass the constraints tied to manually engineered features, achieving superior results in attack detection and maintaining comparable outcomes in device-type identification. Additionally, a notable feature extraction time difference becomes evident in the experiments: traditional methods require around 29 milliseconds per data packet, while DL accomplishes the same task in just 2.9 milliseconds. The significant time gap, DL's superior performance, and the recognized limitations of manually engineered features, presents a compelling call to action within the IoT community. This encourages us to shift from exploring new IoT features for each dataset to addressing the challenges of integrating DL into IoT, making it a more efficient solution for real-world IoT scenarios.\n        \u25b3 Less",
    "submission_date": "20 November, 2023",
    "eprint_id": "2312.00034"
  },
  "2312.00033": {
    "title": "DeFi Security: Turning The Weakest Link Into The Strongest Attraction",
    "authors": [
      "Ravi Kashyap"
    ],
    "abstract": "The primary innovation we pioneer -- focused on blockchain information security -- is called the Safe-House. The Safe-House is badly needed since there are many ongoing hacks and security concerns in the DeFi space right now. The Safe-House is a piece of engineering sophistication that utilizes existing blockchain principles to bring about greater security when customer assets are moved around. The Safe-House logic is easily implemented as smart contracts on any decentralized system. The amount of funds at risk from both internal and external parties -- and hence the maximum one time loss -- is guaranteed to stay within the specified limits based on cryptographic fundamentals.\n  To improve the safety of the Safe-House even further, we adapt the one time password (OPT) concept to operate using blockchain technology. Well suited to blockchain cryptographic nuances, our secondary advancement can be termed the one time next time password (OTNTP) mechanism. The OTNTP is designed to complement the Safe-House making it even more safe.\n  We provide a detailed threat assessment model -- discussing the risks faced by DeFi protocols and the specific risks that apply to blockchain fund management -- and give technical arguments regarding how these threats can be overcome in a robust manner. We discuss how the Safe-House can participate with other external yield generation protocols in a secure way. We provide reasons for why the Safe-House increases safety without sacrificing the efficiency of operation. We start with a high level intuitive description of the landscape, the corresponding problems and our solutions. We then supplement this overview with detailed discussions including the corresponding mathematical formulations and pointers for technological implementation. This approach ensures that the article is accessible to a broad audience.\n        \u25b3 Less",
    "submission_date": "20 November, 2023",
    "eprint_id": "2312.00033"
  },
  "2312.00031": {
    "title": "Crypto analysis of the key distribution scheme using noise-free resistances",
    "authors": [
      "Laszlo B. Kish"
    ],
    "abstract": "Known key exchange schemes offering information-theoretic (unconditional) security are complex and costly to implement. Nonetheless, they remain the only known methods for achieving unconditional security in key exchange. Therefore, the explorations for simpler solutions for information-theoretic security are highly justified. Lin et al. [1] proposed an interesting hardware key distribution scheme that utilizes thermal-noise-free resistances and DC voltages.\n  A crypto analysis of this system is presented. It is shown that, if Eve gains access to the initial shared secret at any time in the past or future, she can successfully crack all the generated keys in the past and future, even retroactively, using passively obtained and recorded voltages and currents. Therefore, the scheme is not a secure key exchanger, but it is rather a key expander with no more information entropy than the originally shared secret at the beginning.\n  We also point out that the proposed defense methods against active attacks do not function when the original shared secret is compromised because then the communication cannot be efficiently authenticated. However, they do work when an unconditionally secure key exchanger is applied to enable the authenticated communication protocol.\n        \u25b3 Less",
    "submission_date": "18 November, 2023",
    "eprint_id": "2312.00031"
  },
  "2312.00030": {
    "title": "Artificial Intelligence in Sustainable Vertical Farming",
    "authors": [
      "Hribhu Chowdhury",
      "Debo Brata Paul Argha",
      "Md Ashik Ahmed"
    ],
    "abstract": "As global challenges of population growth, climate change, and resource scarcity intensify, the agricultural landscape is at a critical juncture. Sustainable vertical farming emerges as a transformative solution to address these challenges by maximizing crop yields in controlled environments. This paradigm shift necessitates the integration of cutting-edge technologies, with Artificial Intelligence (AI) at the forefront. The paper provides a comprehensive exploration of the role of AI in sustainable vertical farming, investigating its potential, challenges, and opportunities. The review synthesizes the current state of AI applications, encompassing machine learning, computer vision, the Internet of Things (IoT), and robotics, in optimizing resource usage, automating tasks, and enhancing decision-making. It identifies gaps in research, emphasizing the need for optimized AI models, interdisciplinary collaboration, and the development of explainable AI in agriculture. The implications extend beyond efficiency gains, considering economic viability, reduced environmental impact, and increased food security. The paper concludes by offering insights for stakeholders and suggesting avenues for future research, aiming to guide the integration of AI technologies in sustainable vertical farming for a resilient and sustainable future in agriculture.\n        \u25b3 Less",
    "submission_date": "17 November, 2023",
    "eprint_id": "2312.00030"
  },
  "2312.00026": {
    "title": "A Quality-of-Service Compliance System using Federated Learning and Optimistic Rollups",
    "authors": [
      "Joao Paulo de Brito Goncalves",
      "Guilherme Emerick Sathler",
      "Rodolfo da Silva Villaca"
    ],
    "abstract": "Edge computing brings a new paradigm in which the sharing of computing, storage, and bandwidth resources as close as possible to the mobile devices or sensors generating a large amount of data. A parallel trend is the rise of phones and tablets as primary computing devices for many people. The powerful sensors present on these devices combined with the fact that they are mobile, mean they have access to data of an unprecedentedly diverse and private nature. Models learned on such data hold the promise of greatly improving usability by powering more intelligent applications, but the sensitive nature of the data means there are risks and responsibilities to storing it in a centralized location. To address the data privacy required for some data in these devices we propose the use of Federated Learning (FL) so that specific data about services performed by clients do not leave the source machines. Instead of sharing data, users collaboratively train a model by only sending weight updates to a server. However, the naive use of FL in those scenarios exposes it to a risk of corruption, whether intentional or not, during the training phase. To improve the security of the FL structure, we propose a decentralized Blockchain-based FL in an edge computing scenario. We also apply blockchain to create a reward mechanism in FL to enable incentive strategy for trainers.\n        \u25b3 Less",
    "submission_date": "14 November, 2023",
    "eprint_id": "2312.00026"
  },
  "2312.00023": {
    "title": "Hypergraph Topological Features for Autoencoder-Based Intrusion Detection for Cybersecurity Data",
    "authors": [
      "Bill Kay",
      "Sinan G. Aksoy",
      "Molly Baird",
      "Daniel M. Best",
      "Helen Jenne",
      "Cliff Joslyn",
      "Christopher Potvin",
      "Gregory Henselman-Petrusek",
      "Garret Seppala",
      "Stephen J. Young",
      "Emilie Purvine"
    ],
    "abstract": "In this position paper, we argue that when hypergraphs are used to capture multi-way local relations of data, their resulting topological features describe global behaviour. Consequently, these features capture complex correlations that can then serve as high fidelity inputs to autoencoder-driven anomaly detection pipelines. We propose two such potential pipelines for cybersecurity data, one that uses an autoencoder directly to determine network intrusions, and one that de-noises input data for a persistent homology system, PHANTOM. We provide heuristic justification for the use of the methods described therein for an intrusion detection pipeline for cyber data. We conclude by showing a small example over synthetic cyber attack data.\n        \u25b3 Less",
    "submission_date": "9 November, 2023",
    "eprint_id": "2312.00023"
  },
  "2312.00021": {
    "title": "Technical Report relating to CVE-2022-46480, CVE-2023-26941, CVE-2023-26942, and CVE-2023-26943",
    "authors": [
      "Ashley Allen",
      "Alexios Mylonas",
      "Stilianos Vidalis"
    ],
    "abstract": "The following technical report provides background information relating to four CVEs found in the following products: Ultraloq UL3 BT (CVE-2022-46480); Yale Conexis L1 Smart Lock (CVE-2023-26941); Yale IA-210 Intruder Alarm (CVE-2023-26942); Yale Keyless Smart Lock (CVE-2023-26943). The work discussed here was carried out by Ash Allen, Dr. Alexios Mylonas, and Dr. Stilianos Vidalis as part of a wider research project into smart device security. Responsible disclosure of all four issues has been made with the appropriate vendors, and they have been acknowledged as vulnerabilities.\n        \u25b3 Less",
    "submission_date": "8 November, 2023",
    "eprint_id": "2312.00021"
  },
  "2312.00019": {
    "title": "The theoretical limits of biometry",
    "authors": [
      "Ga\u00eblle Candel"
    ],
    "abstract": "Biometry has proved its capability in terms of recognition accuracy. Now, it is widely used for automated border control with the biometric passport, to unlock a smartphone or a computer with a fingerprint or a face recognition algorithm. While identity verification is widely democratized, pure identification with no additional clues is still a work in progress. The identification difficulty depends on the population size, as the larger the group is, the larger the confusion risk. For collision prevention, biometric traits must be sufficiently distinguishable to scale to considerable groups, and algorithms should be able to capture their differences accurately.\n  Most biometric works are purely experimental, and it is impossible to extrapolate the results to a smaller or a larger group. In this work, we propose a theoretical analysis of the distinguishability problem, which governs the error rates of biometric systems. We demonstrate simple relationships between the population size and the number of independent bits necessary to prevent collision in the presence of noise. This work provides the lowest lower bound for memory requirements. The results are very encouraging, as the biometry of the whole Earth population can fit in a regular disk, leaving some space for noise and redundancy.\n        \u25b3 Less",
    "submission_date": "6 November, 2023",
    "eprint_id": "2312.00019"
  },
  "2312.00018": {
    "title": "Security Challenges in Autonomous Systems Design",
    "authors": [
      "Mohammad Hamad",
      "Sebastian Steinhorst"
    ],
    "abstract": "Autonomous systems are emerging in many application domains. With the recent advancements in artificial intelligence and machine learning, sensor technology, perception algorithms and robotics, scenarios previously requiring strong human involvement can be handled by autonomous systems. With the independence from human control, cybersecurity of such systems becomes even more critical as no human intervention in case of undesired behavior is possible. In this context, this paper discusses emerging security challenges in autonomous systems design which arise in many domains such as autonomous incident response, risk assessment, data availability, systems interaction, trustworthiness, updatability, access control, as well as the reliability and explainability of machine learning methods. In all these areas, this paper thoroughly discusses the state of the art, identifies emerging security challenges and proposes research directions to address these challenges for developing secure autonomous systems.\n        \u25b3 Less",
    "submission_date": "3 December, 2023",
    "eprint_id": "2312.00018"
  },
  "2312.00016": {
    "title": "Preserving The Safety And Confidentiality Of Data Mining Information In Health Care: A literature review",
    "authors": [
      "Robinson Onyemechi Oturugbum"
    ],
    "abstract": "Daily, massive volume of data are produced due to the internet of things' rapid development, which has now permeated the healthcare industry. Recent advances in data mining have spawned a new field of a study dubbed privacy-preserving data mining (PPDM). PPDM technique or approach enables the extraction of actionable insight from enormous volume of data while safeguarding the privacy of individual information and benefiting the entire society Medical research has taken a new course as a result of data mining with healthcare data to detect diseases earlier and improve patient care. Data integration necessitates the sharing of sensitive patient information. However, substantial privacy issues are raised in connection with the storage and transmission of potentially sensitive information. Disclosing sensitive information infringes on patients' privacy. This paper aims to conduct a review of related work on privacy-preserving mechanisms, data protection regulations, and mitigating tactics. The review concluded that no single strategy outperforms all others. Hence, future research should focus on adequate techniques for privacy solutions in the age of massive medical data and the standardization of evaluation standards.\n        \u25b3 Less",
    "submission_date": "30 October, 2023",
    "eprint_id": "2312.00016"
  },
  "2312.00013": {
    "title": "Biometric Technologies and the Law: Developing a Taxonomy for Guiding Policymakers",
    "authors": [
      "Luis Felipe M. Ramos"
    ],
    "abstract": "Despite the increasing adoption of biometric technologies, their regulation has not kept up with the same pace, particularly with regard to safeguarding individuals' privacy and personal data. Policymakers may struggle to comprehend the technology behind biometric systems and their potential impact on fundamental rights, resulting in insufficient or inadequate legal regulation. This study seeks to bridge this gap by proposing a taxonomy of biometric technologies that can aid in their effective deployment and supervision. Through a literature review, the technical characteristics of biometric systems were identified and categorised. The resulting taxonomy can enhance the understanding of biometric technologies and facilitate the development of regulation that prioritises privacy and personal data protection.\n        \u25b3 Less",
    "submission_date": "27 October, 2023",
    "eprint_id": "2312.00013"
  },
  "2312.00009": {
    "title": "Risk-Aware and Explainable Framework for Ensuring Guaranteed Coverage in Evolving Hardware Trojan Detection",
    "authors": [
      "Rahul Vishwakarma",
      "Amin Rezaei"
    ],
    "abstract": "As the semiconductor industry has shifted to a fabless paradigm, the risk of hardware Trojans being inserted at various stages of production has also increased. Recently, there has been a growing trend toward the use of machine learning solutions to detect hardware Trojans more effectively, with a focus on the accuracy of the model as an evaluation metric. However, in a high-risk and sensitive domain, we cannot accept even a small misclassification. Additionally, it is unrealistic to expect an ideal model, especially when Trojans evolve over time. Therefore, we need metrics to assess the trustworthiness of detected Trojans and a mechanism to simulate unseen ones. In this paper, we generate evolving hardware Trojans using our proposed novel conformalized generative adversarial networks and offer an efficient approach to detecting them based on a non-invasive algorithm-agnostic statistical inference framework that leverages the Mondrian conformal predictor. The method acts like a wrapper over any of the machine learning models and produces set predictions along with uncertainty quantification for each new detected Trojan for more robust decision-making. In the case of a NULL set, a novel method to reject the decision by providing a calibrated explainability is discussed. The proposed approach has been validated on both synthetic and real chip-level benchmarks and proven to pave the way for researchers looking to find informed machine learning solutions to hardware security problems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2312.00009"
  },
  "2312.00006": {
    "title": "Enhancing ML-Based DoS Attack Detection Through Combinatorial Fusion Analysis",
    "authors": [
      "Evans Owusu",
      "Mohamed Rahouti",
      "D. Frank Hsu",
      "Kaiqi Xiong",
      "Yufeng Xin"
    ],
    "abstract": "Mitigating Denial-of-Service (DoS) attacks is vital for online service security and availability. While machine learning (ML) models are used for DoS attack detection, new strategies are needed to enhance their performance. We suggest an innovative method, combinatorial fusion, which combines multiple ML models using advanced algorithms. This includes score and rank combinations, weighted techniques, and diversity strength of scoring systems. Through rigorous evaluations, we demonstrate the effectiveness of this fusion approach, considering metrics like precision, recall, and F1-score. We address the challenge of low-profiled attack classification by fusing models to create a comprehensive solution. Our findings emphasize the potential of this approach to improve DoS attack detection and contribute to stronger defense mechanisms.\n        \u25b3 Less",
    "submission_date": "1 October, 2023",
    "eprint_id": "2312.00006"
  },
  "2312.00003": {
    "title": "Transport Equation based Physics Informed Neural Network to predict the Yield Strength of Architected Materials",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "In this research, the application of the Physics-Informed Neural Network (PINN) model is explored to solve transport equation-based Partial Differential Equations (PDEs). The primary objective is to analyze the impact of different activation functions incorporated within the PINN model on its predictive performance, specifically assessing the Mean Squared Error (MSE) and Mean Absolute Error (MAE). The dataset used in the study consists of a varied set of input parameters related to strut diameter, unit cell size, and the corresponding yield stress values. Through this investigation the aim is to understand the effectiveness of the PINN model and the significance of choosing appropriate activation functions for solving complex PDEs in real-world applications. The outcomes suggest that the choice of activation function may have minimal influence on the model's predictive accuracy for this particular problem. The PINN model showcases exceptional generalization capabilities, indicating its capacity to avoid overfitting with the provided dataset. The research underscores the importance of striking a balance between performance and computational efficiency while selecting an activation function for specific real-world applications. These valuable findings contribute to advancing the understanding and potential adoption of PINN as an effective tool for solving challenging PDEs in diverse scientific and engineering domains.\n        \u25b3 Less",
    "submission_date": "29 July, 2023",
    "eprint_id": "2312.00003"
  },
  "2312.00001": {
    "title": "On random pairwise comparisons matrices and their geometry",
    "authors": [
      "Jean-Pierre Magnot"
    ],
    "abstract": "We describe a framework for random pairwise comparisons matrices, inspired by selected constructions releted to the so called inconsistency reduction of pairwise comparisons (PC) matrices. In to build up structures on random pairwise comparisons matrices, the set up for (deterministic) PC matrices for non-reciprocal PC matrices is completed. The extension of basic concepts such as inconsistency indexes and geometric mean method are extended to random pairwise comparisons matrices and completed by new notions which seem useful to us. Two procedures for (random) inconsistency reduction are sketched, based on well-known existing objects, and a fiber bundle-like decomposition of random pairwise comparisons is proposed.\n        \u25b3 Less",
    "submission_date": "8 July, 2023",
    "eprint_id": "2312.00001"
  },
  "2311.18840": {
    "title": "Just Add $\u03c0$! Pose Induced Video Transformers for Understanding Activities of Daily Living",
    "authors": [
      "Dominick Reilly",
      "Srijan Das"
    ],
    "abstract": "Video transformers have become the de facto standard for human action recognition, yet their exclusive reliance on the RGB modality still limits their adoption in certain domains. One such domain is Activities of Daily Living (ADL), where RGB alone is not sufficient to distinguish between visually similar actions, or actions observed from multiple viewpoints. To facilitate the adoption of video transformers for ADL, we hypothesize that the augmentation of RGB with human pose information, known for its sensitivity to fine-grained motion and multiple viewpoints, is essential. Consequently, we introduce the first Pose Induced Video Transformer: PI-ViT (or $\u03c0$-ViT), a novel approach that augments the RGB representations learned by video transformers with 2D and 3D pose information. The key elements of $\u03c0$-ViT are two plug-in modules, 2D Skeleton Induction Module and 3D Skeleton Induction Module, that are responsible for inducing 2D and 3D pose information into the RGB representations. These modules operate by performing pose-aware auxiliary tasks, a design choice that allows $\u03c0$-ViT to discard the modules during inference. Notably, $\u03c0$-ViT achieves the state-of-the-art performance on three prominent ADL datasets, encompassing both real-world and large-scale RGB-D datasets, without requiring poses or additional computational overhead at inference.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18840"
  },
  "2311.18839": {
    "title": "TrafficMOT: A Challenging Dataset for Multi-Object Tracking in Complex Traffic Scenarios",
    "authors": [
      "Lihao Liu",
      "Yanqi Cheng",
      "Zhongying Deng",
      "Shujun Wang",
      "Dongdong Chen",
      "Xiaowei Hu",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica Aviles-Rivero"
    ],
    "abstract": "Multi-object tracking in traffic videos is a crucial research area, offering immense potential for enhancing traffic monitoring accuracy and promoting road safety measures through the utilisation of advanced machine learning algorithms. However, existing datasets for multi-object tracking in traffic videos often feature limited instances or focus on single classes, which cannot well simulate the challenges encountered in complex traffic scenarios. To address this gap, we introduce TrafficMOT, an extensive dataset designed to encompass diverse traffic situations with complex scenarios. To validate the complexity and challenges presented by TrafficMOT, we conducted comprehensive empirical studies using three different settings: fully-supervised, semi-supervised, and a recent powerful zero-shot foundation model Tracking Anything Model (TAM). The experimental results highlight the inherent complexity of this dataset, emphasising its value in driving advancements in the field of traffic monitoring and multi-object tracking.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18839"
  },
  "2311.18838": {
    "title": "Dataset Distillation in Large Data Era",
    "authors": [
      "Zeyuan Yin",
      "Zhiqiang Shen"
    ],
    "abstract": "Dataset distillation aims to generate a smaller but representative subset from a large dataset, which allows a model to be trained efficiently, meanwhile evaluating on the original testing data distribution to achieve decent performance. Many prior works have aimed to align with diverse aspects of the original datasets, such as matching the training weight trajectories, gradient, feature/BatchNorm distributions, etc. In this work, we show how to distill various large-scale datasets such as full ImageNet-1K/21K under a conventional input resolution of 224$\\times$224 to achieve the best accuracy over all previous approaches, including SRe$^2$L, TESLA and MTT. To achieve this, we introduce a simple yet effective ${\\bf C}$urriculum ${\\bf D}$ata ${\\bf A}$ugmentation ($\\texttt{CDA}$) during data synthesis that obtains the accuracy on large-scale ImageNet-1K and 21K with 63.2% under IPC (Images Per Class) 50 and 36.1% under IPC 20, respectively. Finally, we show that, by integrating all our enhancements together, the proposed model beats the current state-of-the-art by more than 4% Top-1 accuracy on ImageNet-1K/21K and for the first time, reduces the gap to its full-data training counterpart to less than absolute 15%. Moreover, this work represents the inaugural success in dataset distillation on larger-scale ImageNet-21K under the standard 224$\\times$224 resolution. Our code and distilled ImageNet-21K dataset of 20 IPC, 2K recovery budget are available at https://github.com/VILA-Lab/SRe2L/tree/main/CDA.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18838"
  },
  "2311.18837": {
    "title": "VIDiff: Translating Videos via Multi-Modal Instructions with Diffusion Models",
    "authors": [
      "Zhen Xing",
      "Qi Dai",
      "Zihao Zhang",
      "Hui Zhang",
      "Han Hu",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "abstract": "Diffusion models have achieved significant success in image and video generation. This motivates a growing interest in video editing tasks, where videos are edited according to provided text descriptions. However, most existing approaches only focus on video editing for short clips and rely on time-consuming tuning or inference. We are the first to propose Video Instruction Diffusion (VIDiff), a unified foundation model designed for a wide range of video tasks. These tasks encompass both understanding tasks (such as language-guided video object segmentation) and generative tasks (video editing and enhancement). Our model can edit and translate the desired results within seconds based on user instructions. Moreover, we design an iterative auto-regressive method to ensure consistency in editing and enhancing long videos. We provide convincing generative results for diverse input videos and written instructions, both qualitatively and quantitatively. More examples can be found at our website https://ChenHsing.github.io/VIDiff.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18837"
  },
  "2311.18835": {
    "title": "InstructSeq: Unifying Vision Tasks with Instruction-conditioned Multi-modal Sequence Generation",
    "authors": [
      "Rongyao Fang",
      "Shilin Yan",
      "Zhaoyang Huang",
      "Jingqiu Zhou",
      "Hao Tian",
      "Jifeng Dai",
      "Hongsheng Li"
    ],
    "abstract": "Empowering models to dynamically accomplish tasks specified through natural language instructions represents a promising path toward more capable and general artificial intelligence. In this work, we introduce InstructSeq, an instruction-conditioned multi-modal modeling framework that unifies diverse vision tasks through flexible natural language control and handling of both visual and textual data. InstructSeq employs a multimodal transformer architecture encompassing visual, language, and sequential modeling. We utilize a visual encoder to extract image features and a text encoder to encode instructions. An autoregressive transformer fuses the representations and generates sequential task outputs. By training with LLM-generated natural language instructions, InstructSeq acquires a strong comprehension of free-form instructions for specifying visual tasks. This provides an intuitive interface for directing capabilities using flexible natural instructions. Without any task-specific tuning, InstructSeq achieves compelling performance on semantic segmentation, referring expression segmentation/comprehension, and image captioning. The flexible control and multi-task unification empower the model with more human-like versatility and generalizability for computer vision. The code will be released soon at https://github.com/rongyaofang/InstructSeq.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18835"
  },
  "2311.18834": {
    "title": "ART$\\boldsymbol{\\cdot}$V: Auto-Regressive Text-to-Video Generation with Diffusion Models",
    "authors": [
      "Wenming Weng",
      "Ruoyu Feng",
      "Yanhui Wang",
      "Qi Dai",
      "Chunyu Wang",
      "Dacheng Yin",
      "Zhiyuan Zhao",
      "Kai Qiu",
      "Jianmin Bao",
      "Yuhui Yuan",
      "Chong Luo",
      "Yueyi Zhang",
      "Zhiwei Xiong"
    ],
    "abstract": "We present ART$\\boldsymbol{\\cdot}$V, an efficient framework for auto-regressive video generation with diffusion models. Unlike existing methods that generate entire videos in one-shot, ART$\\boldsymbol{\\cdot}$V generates a single frame at a time, conditioned on the previous ones. The framework offers three distinct advantages. First, it only learns simple continual motions between adjacent frames, therefore avoiding modeling complex long-range motions that require huge training data. Second, it preserves the high-fidelity generation ability of the pre-trained image diffusion models by making only minimal network modifications. Third, it can generate arbitrarily long videos conditioned on a variety of prompts such as text, image or their combinations, making it highly versatile and flexible. To combat the common drifting issue in AR models, we propose masked diffusion model which implicitly learns which information can be drawn from reference images rather than network predictions, in order to reduce the risk of generating inconsistent appearances that cause drifting. Moreover, we further enhance generation coherence by conditioning it on the initial frame, which typically contains minimal noise. This is particularly useful for long video generation. When trained for only two weeks on four GPUs, ART$\\boldsymbol{\\cdot}$V already can generate videos with natural motions, rich details and a high level of aesthetic quality. Besides, it enables various appealing applications, e.g., composing a long video from multiple text prompts.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18834"
  },
  "2311.18830": {
    "title": "MotionEditor: Editing Video Motion via Content-Aware Diffusion",
    "authors": [
      "Shuyuan Tu",
      "Qi Dai",
      "Zhi-Qi Cheng",
      "Han Hu",
      "Xintong Han",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "abstract": "Existing diffusion-based video editing models have made gorgeous advances for editing attributes of a source video over time but struggle to manipulate the motion information while preserving the original protagonist's appearance and background. To address this, we propose MotionEditor, a diffusion model for video motion editing. MotionEditor incorporates a novel content-aware motion adapter into ControlNet to capture temporal motion correspondence. While ControlNet enables direct generation based on skeleton poses, it encounters challenges when modifying the source motion in the inverted noise due to contradictory signals between the noise (source) and the condition (reference). Our adapter complements ControlNet by involving source content to transfer adapted control signals seamlessly. Further, we build up a two-branch architecture (a reconstruction branch and an editing branch) with a high-fidelity attention injection mechanism facilitating branch interaction. This mechanism enables the editing branch to query the key and value from the reconstruction branch in a decoupled manner, making the editing branch retain the original background and protagonist appearance. We also propose a skeleton alignment algorithm to address the discrepancies in pose size and position. Experiments demonstrate the promising motion editing ability of MotionEditor, both qualitatively and quantitatively.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18830"
  },
  "2311.18829": {
    "title": "MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation",
    "authors": [
      "Yanhui Wang",
      "Jianmin Bao",
      "Wenming Weng",
      "Ruoyu Feng",
      "Dacheng Yin",
      "Tao Yang",
      "Jingxu Zhang",
      "Qi Dai Zhiyuan Zhao",
      "Chunyu Wang",
      "Kai Qiu",
      "Yuhui Yuan",
      "Chuanxin Tang",
      "Xiaoyan Sun",
      "Chong Luo",
      "Baining Guo"
    ],
    "abstract": "We present MicroCinema, a straightforward yet effective framework for high-quality and coherent text-to-video generation. Unlike existing approaches that align text prompts with video directly, MicroCinema introduces a Divide-and-Conquer strategy which divides the text-to-video into a two-stage process: text-to-image generation and image\\&text-to-video generation. This strategy offers two significant advantages. a) It allows us to take full advantage of the recent advances in text-to-image models, such as Stable Diffusion, Midjourney, and DALLE, to generate photorealistic and highly detailed images. b) Leveraging the generated image, the model can allocate less focus to fine-grained appearance details, prioritizing the efficient learning of motion dynamics. To implement this strategy effectively, we introduce two core designs. First, we propose the Appearance Injection Network, enhancing the preservation of the appearance of the given image. Second, we introduce the Appearance Noise Prior, a novel mechanism aimed at maintaining the capabilities of pre-trained 2D diffusion models. These design elements empower MicroCinema to generate high-quality videos with precise motion, guided by the provided text prompts. Extensive experiments demonstrate the superiority of the proposed framework. Concretely, MicroCinema achieves SOTA zero-shot FVD of 342.86 on UCF-101 and 377.40 on MSR-VTT. See https://wangyanhui666.github.io/MicroCinema.github.io/ for video samples.\n        \u25b3 Less",
    "submission_date": "29 December, 2023",
    "eprint_id": "2311.18829"
  },
  "2311.18828": {
    "title": "One-step Diffusion with Distribution Matching Distillation",
    "authors": [
      "Tianwei Yin",
      "Micha\u00ebl Gharbi",
      "Richard Zhang",
      "Eli Shechtman",
      "Fredo Durand",
      "William T. Freeman",
      "Taesung Park"
    ],
    "abstract": "Diffusion models generate high-quality images but require dozens of forward passes. We introduce Distribution Matching Distillation (DMD), a procedure to transform a diffusion model into a one-step image generator with minimal impact on image quality. We enforce the one-step image generator match the diffusion model at distribution level, by minimizing an approximate KL divergence whose gradient can be expressed as the difference between 2 score functions, one of the target distribution and the other of the synthetic distribution being produced by our one-step generator. The score functions are parameterized as two diffusion models trained separately on each distribution. Combined with a simple regression loss matching the large-scale structure of the multi-step diffusion outputs, our method outperforms all published few-step diffusion approaches, reaching 2.62 FID on ImageNet 64x64 and 11.49 FID on zero-shot COCO-30k, comparable to Stable Diffusion but orders of magnitude faster. Utilizing FP16 inference, our model generates images at 20 FPS on modern hardware.\n        \u25b3 Less",
    "submission_date": "5 December, 2023",
    "eprint_id": "2311.18828"
  },
  "2311.18827": {
    "title": "Motion-Conditioned Image Animation for Video Editing",
    "authors": [
      "Wilson Yan",
      "Andrew Brown",
      "Pieter Abbeel",
      "Rohit Girdhar",
      "Samaneh Azadi"
    ],
    "abstract": "We introduce MoCA, a Motion-Conditioned Image Animation approach for video editing. It leverages a simple decomposition of the video editing problem into image editing followed by motion-conditioned image animation. Furthermore, given the lack of robust evaluation datasets for video editing, we introduce a new benchmark that measures edit capability across a wide variety of tasks, such as object replacement, background changes, style changes, and motion edits. We present a comprehensive human evaluation of the latest video editing methods along with MoCA, on our proposed benchmark. MoCA establishes a new state-of-the-art, demonstrating greater human preference win-rate, and outperforming notable recent approaches including Dreamix (63%), MasaCtrl (75%), and Tune-A-Video (72%), with especially significant improvements for motion edits.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18827"
  },
  "2311.18824": {
    "title": "An Adaptive Framework for Generalizing Network Traffic Prediction towards Uncertain Environments",
    "authors": [
      "Alexander Downey",
      "Evren Tuna",
      "Alkan Soysal"
    ],
    "abstract": "We have developed a new framework using time-series analysis for dynamically assigning mobile network traffic prediction models in previously unseen wireless environments. Our framework selectively employs learned behaviors, outperforming any single model with over a 50% improvement relative to current studies. More importantly, it surpasses traditional approaches without needing prior knowledge of a cell. While this paper focuses on network traffic prediction using our adaptive forecasting framework, this framework can also be applied to other machine learning applications in uncertain environments.\n  The framework begins with unsupervised clustering of time-series data to identify unique trends and seasonal patterns. Subsequently, we apply supervised learning for traffic volume prediction within each cluster. This specialization towards specific traffic behaviors occurs without penalties from spatial and temporal variations. Finally, the framework adaptively assigns trained models to new, previously unseen cells. By analyzing real-time measurements of a cell, our framework intelligently selects the most suitable cluster for that cell at any given time, with cluster assignment dynamically adjusting to spatio-temporal fluctuations.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18824"
  },
  "2311.18823": {
    "title": "Initializing Models with Larger Ones",
    "authors": [
      "Zhiqiu Xu",
      "Yanjie Chen",
      "Kirill Vishniakov",
      "Yida Yin",
      "Zhiqiang Shen",
      "Trevor Darrell",
      "Lingjie Liu",
      "Zhuang Liu"
    ],
    "abstract": "Weight initialization plays an important role in neural network training. Widely used initialization methods are proposed and evaluated for networks that are trained from scratch. However, the growing number of pretrained models now offers new opportunities for tackling this classical problem of weight initialization. In this work, we introduce weight selection, a method for initializing smaller models by selecting a subset of weights from a pretrained larger model. This enables the transfer of knowledge from pretrained weights to smaller models. Our experiments demonstrate that weight selection can significantly enhance the performance of small models and reduce their training time. Notably, it can also be used together with knowledge distillation. Weight selection offers a new approach to leverage the power of pretrained models in resource-constrained settings, and we hope it can be a useful tool for training small models in the large-model era. Code is available at https://github.com/OscarXZQ/weight-selection.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18823"
  },
  "2311.18820": {
    "title": "Adversarial Attacks and Defenses for Wireless Signal Classifiers using CDI-aware GANs",
    "authors": [
      "Sujata Sinha",
      "Alkan Soysal"
    ],
    "abstract": "We introduce a Channel Distribution Information (CDI)-aware Generative Adversarial Network (GAN), designed to address the unique challenges of adversarial attacks in wireless communication systems. The generator in this CDI-aware GAN maps random input noise to the feature space, generating perturbations intended to deceive a target modulation classifier. Its discriminators play a dual role: one enforces that the perturbations follow a Gaussian distribution, making them indistinguishable from Gaussian noise, while the other ensures these perturbations account for realistic channel effects and resemble no-channel perturbations.\n  Our proposed CDI-aware GAN can be used as an attacker and a defender. In attack scenarios, the CDI-aware GAN demonstrates its prowess by generating robust adversarial perturbations that effectively deceive the target classifier, outperforming known methods. Furthermore, CDI-aware GAN as a defender significantly improves the target classifier's resilience against adversarial attacks.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18820"
  },
  "2311.18814": {
    "title": "Is Underwater Image Enhancement All Object Detectors Need?",
    "authors": [
      "Yudong Wang",
      "Jichang Guo",
      "Wanru He",
      "Huan Gao",
      "Huihui Yue",
      "Zenan Zhang",
      "Chongyi Li"
    ],
    "abstract": "Underwater object detection is a crucial and challenging problem in marine engineering and aquatic robot. The difficulty is partly because of the degradation of underwater images caused by light selective absorption and scattering. Intuitively, enhancing underwater images can benefit high-level applications like underwater object detection. However, it is still unclear whether all object detectors need underwater image enhancement as pre-processing. We therefore pose the questions \"Does underwater image enhancement really improve underwater object detection?\" and \"How does underwater image enhancement contribute to underwater object detection?\". With these two questions, we conduct extensive studies. Specifically, we use 18 state-of-the-art underwater image enhancement algorithms, covering traditional, CNN-based, and GAN-based algorithms, to pre-process underwater object detection data. Then, we retrain 7 popular deep learning-based object detectors using the corresponding results enhanced by different algorithms, obtaining 126 underwater object detection models. Coupled with 7 object detection models retrained using raw underwater images, we employ these 133 models to comprehensively analyze the effect of underwater image enhancement on underwater object detection. We expect this study can provide sufficient exploration to answer the aforementioned questions and draw more attention of the community to the joint problem of underwater image enhancement and underwater object detection. The pre-trained models and results are publicly available and will be regularly updated. Project page: https://github.com/BIGWangYuDong/lqit/tree/main/configs/detection/uw_enhancement_affect_detection.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18814"
  },
  "2311.18812": {
    "title": "What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations",
    "authors": [
      "Raphael Tang",
      "Xinyu Zhang",
      "Jimmy Lin",
      "Ferhan Ture"
    ],
    "abstract": "Do large language models (LLMs) exhibit sociodemographic biases, even when they decline to respond? To bypass their refusal to \"speak,\" we study this research question by probing contextualized embeddings and exploring whether this bias is encoded in its latent representations. We propose a logistic Bradley-Terry probe which predicts word pair preferences of LLMs from the words' hidden vectors. We first validate our probe on three pair preference tasks and thirteen LLMs, where we outperform the word embedding association test (WEAT), a standard approach in testing for implicit association, by a relative 27% in error rate. We also find that word pair preferences are best represented in the middle layers. Next, we transfer probes trained on harmless tasks (e.g., pick the larger number) to controversial ones (compare ethnicities) to examine biases in nationality, politics, religion, and gender. We observe substantial bias for all target classes: for instance, the Mistral model implicitly prefers Europe to Africa, Christianity to Judaism, and left-wing to right-wing politics, despite declining to answer. This suggests that instruction fine-tuning does not necessarily debias contextualized embeddings. Our codebase is at https://github.com/castorini/biasprobe.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18812"
  },
  "2311.18810": {
    "title": "Convergence of Nonconvex PnP-ADMM with MMSE Denoisers",
    "authors": [
      "Chicago Park",
      "Shirin Shoushtari",
      "Weijie Gan",
      "Ulugbek S. Kamilov"
    ],
    "abstract": "Plug-and-Play Alternating Direction Method of Multipliers (PnP-ADMM) is a widely-used algorithm for solving inverse problems by integrating physical measurement models and convolutional neural network (CNN) priors. PnP-ADMM has been theoretically proven to converge for convex data-fidelity terms and nonexpansive CNNs. It has however been observed that PnP-ADMM often empirically converges even for expansive CNNs. This paper presents a theoretical explanation for the observed stability of PnP-ADMM based on the interpretation of the CNN prior as a minimum mean-squared error (MMSE) denoiser. Our explanation parallels a similar argument recently made for the iterative shrinkage/thresholding algorithm variant of PnP (PnP-ISTA) and relies on the connection between MMSE denoisers and proximal operators. We also numerically evaluate the performance gap between PnP-ADMM using a nonexpansive DnCNN denoiser and expansive DRUNet denoiser, thus motivating the use of expansive CNNs.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18810"
  },
  "2311.18807": {
    "title": "Pre-registration for Predictive Modeling",
    "authors": [
      "Jake M. Hofman",
      "Angelos Chatzimparmpas",
      "Amit Sharma",
      "Duncan J. Watts",
      "Jessica Hullman"
    ],
    "abstract": "Amid rising concerns of reproducibility and generalizability in predictive modeling, we explore the possibility and potential benefits of introducing pre-registration to the field. Despite notable advancements in predictive modeling, spanning core machine learning tasks to various scientific applications, challenges such as overlooked contextual factors, data-dependent decision-making, and unintentional re-use of test data have raised questions about the integrity of results. To address these issues, we propose adapting pre-registration practices from explanatory modeling to predictive modeling. We discuss current best practices in predictive modeling and their limitations, introduce a lightweight pre-registration template, and present a qualitative study with machine learning researchers to gain insight into the effectiveness of pre-registration in preventing biased estimates and promoting more reliable research outcomes. We conclude by exploring the scope of problems that pre-registration can address in predictive modeling and acknowledging its limitations within this context.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18807"
  },
  "2311.18806": {
    "title": "Efficient Baseline for Quantitative Precipitation Forecasting in Weather4cast 2023",
    "authors": [
      "Akshay Punjabi",
      "Pablo Izquierdo Ayala"
    ],
    "abstract": "Accurate precipitation forecasting is indispensable for informed decision-making across various industries. However, the computational demands of current models raise environmental concerns. We address the critical need for accurate precipitation forecasting while considering the environmental impact of computational resources and propose a minimalist U-Net architecture to be used as a baseline for future weather forecasting initiatives.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18806"
  },
  "2311.18805": {
    "title": "Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text",
    "authors": [
      "Qi Cao",
      "Takeshi Kojima",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "abstract": "While Large Language Models (LLMs) have achieved remarkable performance in many tasks, much about their inner workings remains unclear. In this study, we present novel experimental insights into the resilience of LLMs, particularly GPT-4, when subjected to extensive character-level permutations. To investigate this, we first propose the Scrambled Bench, a suite designed to measure the capacity of LLMs to handle scrambled input, in terms of both recovering scrambled sentences and answering questions given scrambled context. The experimental results indicate that most powerful LLMs demonstrate the capability akin to typoglycemia, a phenomenon where humans can understand the meaning of words even when the letters within those words are scrambled, as long as the first and last letters remain in place. More surprisingly, we found that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even under the extreme condition, a task that poses significant challenges for other LLMs and often even for humans. Specifically, GPT-4 can almost perfectly reconstruct the original sentences from scrambled ones, decreasing the edit distance by 95%, even when all letters within each word are entirely scrambled. It is counter-intuitive that LLMs can exhibit such resilience despite severe disruption to input tokenization caused by scrambled text.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18805"
  },
  "2311.18801": {
    "title": "Distributed Global Structure-from-Motion with a Deep Front-End",
    "authors": [
      "Ayush Baid",
      "John Lambert",
      "Travis Driver",
      "Akshay Krishnan",
      "Hayk Stepanyan",
      "Frank Dellaert"
    ],
    "abstract": "While initial approaches to Structure-from-Motion (SfM) revolved around both global and incremental methods, most recent applications rely on incremental systems to estimate camera poses due to their superior robustness. Though there has been tremendous progress in SfM `front-ends' powered by deep models learned from data, the state-of-the-art (incremental) SfM pipelines still rely on classical SIFT features, developed in 2004. In this work, we investigate whether leveraging the developments in feature extraction and matching helps global SfM perform on par with the SOTA incremental SfM approach (COLMAP). To do so, we design a modular SfM framework that allows us to easily combine developments in different stages of the SfM pipeline. Our experiments show that while developments in deep-learning based two-view correspondence estimation do translate to improvements in point density for scenes reconstructed with global SfM, none of them outperform SIFT when comparing with incremental SfM results on a range of datasets. Our SfM system is designed from the ground up to leverage distributed computation, enabling us to parallelize computation on multiple machines and scale to large scenes.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18801"
  },
  "2311.18792": {
    "title": "Resource Sharing in Energy Communities: A Cooperative Game Approach",
    "authors": [
      "Ahmed S. Alahmed",
      "Lang Tong"
    ],
    "abstract": "We analyze the overall benefits of an energy community cooperative game under which distributed energy resources (DER) are shared behind a regulated distribution utility meter under a general net energy metering (NEM) tariff. Two community DER scheduling algorithms are examined. The first is a community with centrally controlled DER, whereas the second is decentralized letting its members schedule their own DER locally. For both communities, we prove that the cooperative game's value function is superadditive, hence the grand coalition achieves the highest welfare. We also prove the balancedness of the cooperative game under the two DER scheduling algorithms, which means that there is a welfare re-distribution scheme that de-incentivizes players from leaving the grand coalition to form smaller ones. Lastly, we present five ex-post and an ex-ante welfare re-distribution mechanisms and evaluate them in simulation, in addition to investigating the performance of various community sizes under the two DER scheduling algorithms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18792"
  },
  "2311.18789": {
    "title": "Unsupervised learning architecture based on neural Darwinism and Hopfield networks recognizes symbols with high accuracy",
    "authors": [
      "Mario Stepanik"
    ],
    "abstract": "This paper introduces a novel unsupervised learning paradigm inspired by Gerald Edelman's theory of neuronal group selection (\"Neural Darwinism\"). The presented automaton learns to recognize arbitrary symbols (e.g., letters of an alphabet) when they are presented repeatedly, as they are when children learn to read. On a second hierarchical level, the model creates abstract categories representing the learnt symbols. The fundamental computational unit are simple McCulloch-Pitts neurons arranged into fully-connected groups (Hopfield networks with randomly initialized weights), which are \"selected\", in an evolutionary sense, through symbol presentation. The learning process is fully tractable and easily interpretable for humans, in contrast to most neural network architectures. Computational properties of Hopfield networks enabling pattern recognition are discussed. In simulations, the model achieves high accuracy in learning the letters of the Latin alphabet, presented as binary patterns on a grid. This paper is a proof of concept with no claims to state-of-the-art performance in letter recognition, but hopefully inspires new thinking in bio-inspired machine learning.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18789"
  },
  "2311.18788": {
    "title": "Automated interpretation of congenital heart disease from multi-view echocardiograms",
    "authors": [
      "Jing Wang",
      "Xiaofeng Liu",
      "Fangyun Wang",
      "Lin Zheng",
      "Fengqiao Gao",
      "Hanwen Zhang",
      "Xin Zhang",
      "Wanqing Xie",
      "Binbin Wang"
    ],
    "abstract": "Congenital heart disease (CHD) is the most common birth defect and the leading cause of neonate death in China. Clinical diagnosis can be based on the selected 2D key-frames from five views. Limited by the availability of multi-view data, most methods have to rely on the insufficient single view analysis. This study proposes to automatically analyze the multi-view echocardiograms with a practical end-to-end framework. We collect the five-view echocardiograms video records of 1308 subjects (including normal controls, ventricular septal defect (VSD) patients and atrial septal defect (ASD) patients) with both disease labels and standard-view key-frame labels. Depthwise separable convolution-based multi-channel networks are adopted to largely reduce the network parameters. We also approach the imbalanced class problem by augmenting the positive training samples. Our 2D key-frame model can diagnose CHD or negative samples with an accuracy of 95.4\\%, and in negative, VSD or ASD classification with an accuracy of 92.3\\%. To further alleviate the work of key-frame selection in real-world implementation, we propose an adaptive soft attention scheme to directly explore the raw video data. Four kinds of neural aggregation methods are systematically investigated to fuse the information of an arbitrary number of frames in a video. Moreover, with a view detection module, the system can work without the view records. Our video-based model can diagnose with an accuracy of 93.9\\% (binary classification), and 92.1\\% (3-class classification) in a collected 2D video testing set, which does not need key-frame selection and view annotation in testing. The detailed ablation study and the interpretability analysis are provided.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18788"
  },
  "2311.18787": {
    "title": "Communication-Efficient Federated Optimization over Semi-Decentralized Networks",
    "authors": [
      "He Wang",
      "Yuejie Chi"
    ],
    "abstract": "In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.\n        \u25b3 Less",
    "submission_date": "11 January, 2024",
    "eprint_id": "2311.18787"
  },
  "2311.18778": {
    "title": "Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language Models for Violence Inciting Text Detection",
    "authors": [
      "Saurabh Page",
      "Sudeep Mangalvedhekar",
      "Kshitij Deshpande",
      "Tanmay Chavan",
      "Sheetal Sonawane"
    ],
    "abstract": "This paper presents our work for the Violence Inciting Text Detection shared task in the First Workshop on Bangla Language Processing. Social media has accelerated the propagation of hate and violence-inciting speech in society. It is essential to develop efficient mechanisms to detect and curb the propagation of such texts. The problem of detecting violence-inciting texts is further exacerbated in low-resource settings due to sparse research and less data. The data provided in the shared task consists of texts in the Bangla language, where each example is classified into one of the three categories defined based on the types of violence-inciting texts. We try and evaluate several BERT-based models, and then use an ensemble of the models as our final submission. Our submission is ranked 10th in the final leaderboard of the shared task with a macro F1 score of 0.737.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18778"
  },
  "2311.18775": {
    "title": "CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation",
    "authors": [
      "Zineng Tang",
      "Ziyi Yang",
      "Mahmoud Khademi",
      "Yang Liu",
      "Chenguang Zhu",
      "Mohit Bansal"
    ],
    "abstract": "We present CoDi-2, a versatile and interactive Multimodal Large Language Model (MLLM) that can follow complex multimodal interleaved instructions, conduct in-context learning (ICL), reason, chat, edit, etc., in an any-to-any input-output modality paradigm. By aligning modalities with language for both encoding and generation, CoDi-2 empowers Large Language Models (LLMs) to not only understand complex modality-interleaved instructions and in-context examples, but also autoregressively generate grounded and coherent multimodal outputs in the continuous feature space. To train CoDi-2, we build a large-scale generation dataset encompassing in-context multimodal instructions across text, vision, and audio. CoDi-2 demonstrates a wide range of zero-shot capabilities for multimodal generation, such as in-context learning, reasoning, and compositionality of any-to-any modality generation through multi-round interactive conversation. CoDi-2 surpasses previous domain-specific models on tasks such as subject-driven image generation, vision transformation, and audio editing. CoDi-2 signifies a substantial breakthrough in developing a comprehensive multimodal foundation model adept at interpreting in-context language-vision-audio interleaved instructions and producing multimodal outputs.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18775"
  },
  "2311.18772": {
    "title": "Experimental Study of the Game Exact Nim(5, 2)",
    "authors": [
      "Vladimir Gurvich",
      "Artem Parfenov",
      "Michael Vyalyi"
    ],
    "abstract": "We compare to different extensions of the ancient game of nim: Moore's nim$(n, \\leq k)$ and exact nim$(n, = k)$. Given integers $n$ and $k$ such that $0 < k \\leq n$, we consider $n$ piles of stones. Two players alternate turns. By one move it is allowed to choose and reduce any (i) at most $k$ or (ii) exactly $k$ piles of stones in games nim$(n, \\leq k)$ and nim$(n, = k)$, respectively. The player who has to move but cannot is the loser. Both games coincide with nim when $k=1$. Game nim$(n, \\leq k)$ was introduced by Moore (1910) who characterized its Sprague-Grundy (SG) values 0 (that is, P-positions) and 1. The first open case is SG values 2 for nim$(4, \\leq 2)$. Game nim$(n, = k)$, was introduced in 2018. An explicit formula for its SG function was computed for $2k \\geq n$. In contrast, case $2k < n$ seems difficult: even the P-positions are not known already for nim$(5,=2)$. Yet, it seems that the P-position of games nim$(n+1,=2)$ and nim$(n+1,\\leq 2)$ are closely related. (Note that P-positions of the latter are known.) Here we provide some theoretical and computational evidence of such a relation for $n=5$.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18772"
  },
  "2311.18769": {
    "title": "Online Change Points Detection for Linear Dynamical Systems with Finite Sample Guarantees",
    "authors": [
      "Lei Xin",
      "George Chiu",
      "Shreyas Sundaram"
    ],
    "abstract": "The problem of online change point detection is to detect abrupt changes in properties of time series, ideally as soon as possible after those changes occur. Existing work on online change point detection either assumes i.i.d data, focuses on asymptotic analysis, does not present theoretical guarantees on the trade-off between detection accuracy and detection delay, or is only suitable for detecting single change points. In this work, we study the online change point detection problem for linear dynamical systems with unknown dynamics, where the data exhibits temporal correlations and the system could have multiple change points. We develop a data-dependent threshold that can be used in our test that allows one to achieve a pre-specified upper bound on the probability of making a false alarm. We further provide a finite-sample-based bound for the probability of detecting a change point. Our bound demonstrates how parameters used in our algorithm affect the detection probability and delay, and provides guidance on the minimum required time between changes to guarantee detection.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18769"
  },
  "2311.18768": {
    "title": "Evaluating the Impact of Flaky Simulators on Testing Autonomous Driving Systems",
    "authors": [
      "Mohammad Hossein Amini",
      "Shervin Naseri",
      "Shiva Nejati"
    ],
    "abstract": "Simulators are widely used to test Autonomous Driving Systems (ADS), but their potential flakiness can lead to inconsistent test results. We investigate test flakiness in simulation-based testing of ADS by addressing two key questions: (1) How do flaky ADS simulations impact automated testing that relies on randomized algorithms? and (2) Can machine learning (ML) effectively identify flaky ADS tests while decreasing the required number of test reruns? Our empirical results, obtained from two widely-used open-source ADS simulators and five diverse ADS test setups, show that test flakiness in ADS is a common occurrence and can significantly impact the test results obtained by randomized algorithms. Further, our ML classifiers effectively identify flaky ADS tests using only a single test run, achieving F1-scores of $85$%, $82$% and $96$% for three different ADS test setups. Our classifiers significantly outperform our non-ML baseline, which requires executing tests at least twice, by $31$%, $21$%, and $13$% in F1-score performance, respectively. We conclude with a discussion on the scope, implications and limitations of our study. We provide our complete replication package in a Github repository.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18768"
  },
  "2311.18761": {
    "title": "Can training neural language models on a curriculum with developmentally plausible data improve alignment with human reading behavior?",
    "authors": [
      "Aryaman Chobey",
      "Oliver Smith",
      "Anzi Wang",
      "Grusha Prasad"
    ],
    "abstract": "The use of neural language models to model human behavior has met with mixed success. While some work has found that the surprisal estimates from these models can be used to predict a wide range of human neural and behavioral responses, other work studying more complex syntactic phenomena has found that these surprisal estimates generate incorrect behavioral predictions. This paper explores the extent to which the misalignment between empirical and model-predicted behavior can be minimized by training models on more developmentally plausible data, such as in the BabyLM Challenge. We trained teacher language models on the BabyLM \"strict-small\" dataset and used sentence level surprisal estimates from these teacher models to create a curriculum. We found tentative evidence that our curriculum made it easier for models to acquire linguistic knowledge from the training data: on the subset of tasks in the BabyLM challenge suite evaluating models' grammatical knowledge of English, models first trained on the BabyLM data curriculum and then on a few randomly ordered training epochs performed slightly better than models trained on randomly ordered epochs alone. This improved linguistic knowledge acquisition did not result in better alignment with human reading behavior, however: models trained on the BabyLM dataset (with or without a curriculum) generated predictions that were as misaligned with human behavior as models trained on larger less curated datasets. This suggests that training on developmentally plausible datasets alone is likely insufficient to generate language models capable of accurately predicting human language processing.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18761"
  },
  "2311.18760": {
    "title": "TaskBench: Benchmarking Large Language Models for Task Automation",
    "authors": [
      "Yongliang Shen",
      "Kaitao Song",
      "Xu Tan",
      "Wenqi Zhang",
      "Kan Ren",
      "Siyu Yuan",
      "Weiming Lu",
      "Dongsheng Li",
      "Yueting Zhuang"
    ],
    "abstract": "Recently, the incredible progress of large language models (LLMs) has ignited the spark of task automation, which decomposes the complex tasks described by user instructions into sub-tasks, and invokes external tools to execute them, and plays a central role in autonomous agents. However, there lacks a systematic and standardized benchmark to foster the development of LLMs in task automation. To this end, we introduce TaskBench to evaluate the capability of LLMs in task automation. Specifically, task automation can be formulated into three critical stages: task decomposition, tool invocation, and parameter prediction to fulfill user intent. This complexity makes data collection and evaluation more challenging compared to common NLP tasks. To generate high-quality evaluation datasets, we introduce the concept of Tool Graph to represent the decomposed tasks in user intent, and adopt a back-instruct method to simulate user instruction and annotations. Furthermore, we propose TaskEval to evaluate the capability of LLMs from different aspects, including task decomposition, tool invocation, and parameter prediction. Experimental results demonstrate that TaskBench can effectively reflects the capability of LLMs in task automation. Benefiting from the mixture of automated data construction and human verification, TaskBench achieves a high consistency compared to the human evaluation, which can be utilized as a comprehensive and faithful benchmark for LLM-based autonomous agents.\n        \u25b3 Less",
    "submission_date": "9 December, 2023",
    "eprint_id": "2311.18760"
  },
  "2311.18758": {
    "title": "Semi-supervised Semantic Segmentation via Boosting Uncertainty on Unlabeled Data",
    "authors": [
      "Daoan Zhang",
      "Yunhao Luo",
      "Jianguo Zhang"
    ],
    "abstract": "We bring a new perspective to semi-supervised semantic segmentation by providing an analysis on the labeled and unlabeled distributions in training datasets. We first figure out that the distribution gap between labeled and unlabeled datasets cannot be ignored, even though the two datasets are sampled from the same distribution. To address this issue, we theoretically analyze and experimentally prove that appropriately boosting uncertainty on unlabeled data can help minimize the distribution gap, which benefits the generalization of the model. We propose two strategies and design an uncertainty booster algorithm, specially for semi-supervised semantic segmentation. Extensive experiments are carried out based on these theories, and the results confirm the efficacy of the algorithm and strategies. Our plug-and-play uncertainty booster is tiny, efficient, and robust to hyperparameters but can significantly promote performance. Our approach achieves state-of-the-art performance in our experiments compared to the current semi-supervised semantic segmentation methods on the popular benchmarks: Cityscapes and PASCAL VOC 2012 with different train settings.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18758"
  },
  "2311.18749": {
    "title": "TransCORALNet: A Two-Stream Transformer CORAL Networks for Supply Chain Credit Assessment Cold Start",
    "authors": [
      "Jie Shi",
      "Arno P. J. M. Siebes",
      "Siamak Mehrkanoon"
    ],
    "abstract": "This paper proposes an interpretable two-stream transformer CORAL networks (TransCORALNet) for supply chain credit assessment under the segment industry and cold start problem. The model aims to provide accurate credit assessment prediction for new supply chain borrowers with limited historical data. Here, the two-stream domain adaptation architecture with correlation alignment (CORAL) loss is used as a core model and is equipped with transformer, which provides insights about the learned features and allow efficient parallelization during training. Thanks to the domain adaptation capability of the proposed model, the domain shift between the source and target domain is minimized. Therefore, the model exhibits good generalization where the source and target do not follow the same distribution, and a limited amount of target labeled instances exist. Furthermore, we employ Local Interpretable Model-agnostic Explanations (LIME) to provide more insight into the model prediction and identify the key features contributing to supply chain credit assessment decisions. The proposed model addresses four significant supply chain credit assessment challenges: domain shift, cold start, imbalanced-class and interpretability. Experimental results on a real-world data set demonstrate the superiority of TransCORALNet over a number of state-of-the-art baselines in terms of accuracy. The code is available on GitHub https://github.com/JieJieNiu/TransCORALN .\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18749"
  },
  "2311.18746": {
    "title": "A data-science pipeline to enable the Interpretability of Many-Objective Feature Selection",
    "authors": [
      "Uchechukwu F. Njoku",
      "Alberto Abell\u00f3",
      "Besim Bilalli",
      "Gianluca Bontempi"
    ],
    "abstract": "Many-Objective Feature Selection (MOFS) approaches use four or more objectives to determine the relevance of a subset of features in a supervised learning task. As a consequence, MOFS typically returns a large set of non-dominated solutions, which have to be assessed by the data scientist in order to proceed with the final choice. Given the multi-variate nature of the assessment, which may include criteria (e.g. fairness) not related to predictive accuracy, this step is often not straightforward and suffers from the lack of existing tools. For instance, it is common to make use of a tabular presentation of the solutions, which provide little information about the trade-offs and the relations between criteria over the set of solutions.\n  This paper proposes an original methodology to support data scientists in the interpretation and comparison of the MOFS outcome by combining post-processing and visualisation of the set of solutions. The methodology supports the data scientist in the selection of an optimal feature subset by providing her with high-level information at three different levels: objectives, solutions, and individual features.\n  The methodology is experimentally assessed on two feature selection tasks adopting a GA-based MOFS with six objectives (number of selected features, balanced accuracy, F1-Score, variance inflation factor, statistical parity, and equalised odds). The results show the added value of the methodology in the selection of the final subset of features.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18746"
  },
  "2311.18740": {
    "title": "First-Order Model Checking on Monadically Stable Graph Classes",
    "authors": [
      "Jan Dreier",
      "Ioannis Eleftheriadis",
      "Nikolas M\u00e4hlmann",
      "Rose McCarty",
      "Micha\u0142 Pilipczuk",
      "Szymon Toru\u0144czyk"
    ],
    "abstract": "A graph class $\\mathscr{C}$ is called monadically stable if one cannot interpret, in first-order logic, arbitrary large linear orders in colored graphs from $\\mathscr{C}$. We prove that the model checking problem for first-order logic is fixed-parameter tractable on every monadically stable graph class. This extends the results of [Grohe, Kreutzer, and Siebertz; J. ACM '17] for nowhere dense classes and of [Dreier, M\u00e4hlmann, and Siebertz; STOC '23] for structurally nowhere dense classes to all monadically stable classes.\n  As a complementary hardness result, we prove that for every hereditary graph class $\\mathscr{C}$ that is edge-stable (excludes some half-graph as a semi-induced subgraph) but not monadically stable, first-order model checking is $\\mathrm{AW}[*]$-hard on $\\mathscr{C}$, and $\\mathrm{W}[1]$-hard when restricted to existential sentences. This confirms, in the special case of edge-stable classes, an on-going conjecture that the notion of monadic NIP delimits the tractability of first-order model checking on hereditary classes of graphs.\n  For our tractability result, we first prove that monadically stable graph classes have almost linear neighborhood complexity. Using this, we construct sparse neighborhood covers for monadically stable classes, which provides the missing ingredient for the algorithm of [Dreier, M\u00e4hlmann, and Siebertz; STOC '23]. The key component of this construction is the usage of orders with low crossing number [Welzl; SoCG '88], a tool from the area of range queries.\n  For our hardness result, we prove a new characterization of monadically stable graph classes in terms of forbidden induced subgraphs. We then use this characterization to show that in hereditary classes that are edge-stable but not monadically stable, one can effectively interpret the class of all graphs using only existential formulas.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18740"
  },
  "2311.18739": {
    "title": "Mavericks at NADI 2023 Shared Task: Unravelling Regional Nuances through Dialect Identification using Transformer-based Approach",
    "authors": [
      "Vedant Deshpande",
      "Yash Patwardhan",
      "Kshitij Deshpande",
      "Sudeep Mangalvedhekar",
      "Ravindra Murumkar"
    ],
    "abstract": "In this paper, we present our approach for the \"Nuanced Arabic Dialect Identification (NADI) Shared Task 2023\". We highlight our methodology for subtask 1 which deals with country-level dialect identification. Recognizing dialects plays an instrumental role in enhancing the performance of various downstream NLP tasks such as speech recognition and translation. The task uses the Twitter dataset (TWT-2023) that encompasses 18 dialects for the multi-class classification problem. Numerous transformer-based models, pre-trained on Arabic language, are employed for identifying country-level dialects. We fine-tune these state-of-the-art models on the provided dataset. The ensembling method is leveraged to yield improved performance of the system. We achieved an F1-score of 76.65 (11th rank on the leaderboard) on the test dataset.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18739"
  },
  "2311.18735": {
    "title": "Dimension Mixer: A Generalized Method for Structured Sparsity in Deep Neural Networks",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "abstract": "The recent success of multiple neural architectures like CNNs, Transformers, and MLP-Mixers motivated us to look for similarities and differences between them. We found that these architectures can be interpreted through the lens of a general concept of dimension mixing. Research on coupling flows and the butterfly transform shows that partial and hierarchical signal mixing schemes are sufficient for efficient and expressive function approximation. In this work, we study group-wise sparse, non-linear, multi-layered and learnable mixing schemes of inputs and find that they are complementary to many standard neural architectures. Following our observations and drawing inspiration from the Fast Fourier Transform, we generalize Butterfly Structure to use non-linear mixer function allowing for MLP as mixing function called Butterfly MLP. We were also able to mix along sequence dimension for Transformer-based architectures called Butterfly Attention. Experiments on CIFAR and LRA datasets demonstrate that the proposed Non-Linear Butterfly Mixers are efficient and scale well when the host architectures are used as mixing function. Additionally, we propose Patch-Only MLP-Mixer for processing spatial 2D signals demonstrating a different dimension mixing strategy.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18735"
  },
  "2311.18734": {
    "title": "Structural results for the Tree Builder Random Walk",
    "authors": [
      "Janos Engl\u00e4nder",
      "Giulio Iacobelli",
      "G\u00e1bor Pete",
      "Rodrigo Ribeiro"
    ],
    "abstract": "We study the Tree Builder Random Walk: a randomly growing tree, built by a walker as she is walking around the tree. Namely, at each time $n$, she adds a leaf to her current vertex with probability $p_n=n^{-\u03b3}$, $\u03b3\\in (2/3,1]$, then moves to a uniform random neighbor on the possibly modified tree. We show that the tree process at its growth times, after a random finite number of steps, can be coupled to be identical to the Barab\u00e1si-Albert preferential attachment tree model. Thus, our TBRW-model is a local dynamics giving rise to the BA-model. The coupling also implies that many properties known for the BA-model, such as diameter and degree distribution, can be directly transferred to our TBRW-model, extending previous results.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18734"
  },
  "2311.18732": {
    "title": "Indoor Millimeter Wave Localization using Multiple Self-Supervised Tiny Neural Networks",
    "authors": [
      "Anish Shastri",
      "Andres Garcia-Saavedra",
      "Paolo Casari"
    ],
    "abstract": "We consider the localization of a mobile millimeter-wave client in a large indoor environment using multilayer perceptron neural networks (NNs). Instead of training and deploying a single deep model, we proceed by choosing among multiple tiny NNs trained in a self-supervised manner. The main challenge then becomes to determine and switch to the best NN among the available ones, as an incorrect NN will fail to localize the client. In order to upkeep the localization accuracy, we propose two switching schemes: one based on a Kalman filter, and one based on the statistical distribution of the training data. We analyze the proposed schemes via simulations, showing that our approach outperforms both geometric localization schemes and the use of a single NN.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18732"
  },
  "2311.18730": {
    "title": "Mavericks at ArAIEval Shared Task: Towards a Safer Digital Space -- Transformer Ensemble Models Tackling Deception and Persuasion",
    "authors": [
      "Sudeep Mangalvedhekar",
      "Kshitij Deshpande",
      "Yash Patwardhan",
      "Vedant Deshpande",
      "Ravindra Murumkar"
    ],
    "abstract": "In this paper, we highlight our approach for the \"Arabic AI Tasks Evaluation (ArAiEval) Shared Task 2023\". We present our approaches for task 1-A and task 2-A of the shared task which focus on persuasion technique detection and disinformation detection respectively. Detection of persuasion techniques and disinformation has become imperative to avoid distortion of authentic information. The tasks use multigenre snippets of tweets and news articles for the given binary classification problem. We experiment with several transformer-based models that were pre-trained on the Arabic language. We fine-tune these state-of-the-art models on the provided dataset. Ensembling is employed to enhance the performance of the systems. We achieved a micro F1-score of 0.742 on task 1-A (8th rank on the leaderboard) and 0.901 on task 2-A (7th rank on the leaderboard) respectively.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18730"
  },
  "2311.18725": {
    "title": "AI in Pharma for Personalized Sequential Decision-Making: Methods, Applications and Opportunities",
    "authors": [
      "Yuhan Li",
      "Hongtao Zhang",
      "Keaven Anderson",
      "Songzi Li",
      "Ruoqing Zhu"
    ],
    "abstract": "In the pharmaceutical industry, the use of artificial intelligence (AI) has seen consistent growth over the past decade. This rise is attributed to major advancements in statistical machine learning methodologies, computational capabilities and the increased availability of large datasets. AI techniques are applied throughout different stages of drug development, ranging from drug discovery to post-marketing benefit-risk assessment. Kolluri et al. provided a review of several case studies that span these stages, featuring key applications such as protein structure prediction, success probability estimation, subgroup identification, and AI-assisted clinical trial monitoring. From a regulatory standpoint, there was a notable uptick in submissions incorporating AI components in 2021. The most prevalent therapeutic areas leveraging AI were oncology (27%), psychiatry (15%), gastroenterology (12%), and neurology (11%). The paradigm of personalized or precision medicine has gained significant traction in recent research, partly due to advancements in AI techniques \\cite{hamburg2010path}. This shift has had a transformative impact on the pharmaceutical industry. Departing from the traditional \"one-size-fits-all\" model, personalized medicine incorporates various individual factors, such as environmental conditions, lifestyle choices, and health histories, to formulate customized treatment plans. By utilizing sophisticated machine learning algorithms, clinicians and researchers are better equipped to make informed decisions in areas such as disease prevention, diagnosis, and treatment selection, thereby optimizing health outcomes for each individual.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18725"
  },
  "2311.18724": {
    "title": "Routing-Guided Learned Product Quantization for Graph-Based Approximate Nearest Neighbor Search",
    "authors": [
      "Qiang Yue",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Yikun Tao",
      "Xuliyuan Luo"
    ],
    "abstract": "Given a vector dataset $\\mathcal{X}$, a query vector $\\vec{x}_q$, graph-based Approximate Nearest Neighbor Search (ANNS) aims to build a proximity graph (PG) as an index of $\\mathcal{X}$ and approximately return vectors with minimum distances to $\\vec{x}_q$ by searching over the PG index. It suffers from the large-scale $\\mathcal{X}$ because a PG with full vectors is too large to fit into the memory, e.g., a billion-scale $\\mathcal{X}$ in 128 dimensions would consume nearly 600 GB memory. To solve this, Product Quantization (PQ) integrated graph-based ANNS is proposed to reduce the memory usage, using smaller compact codes of quantized vectors in memory instead of the large original vectors. Existing PQ methods do not consider the important routing features of PG, resulting in low-quality quantized vectors that affect the ANNS's effectiveness. In this paper, we present an end-to-end Routing-guided learned Product Quantization (RPQ) for graph-based ANNS. It consists of (1) a \\textit{differentiable quantizer} used to make the standard discrete PQ differentiable to suit for back-propagation of end-to-end learning, (2) a \\textit{sampling-based feature extractor} used to extract neighborhood and routing features of a PG, and (3) a \\textit{multi-feature joint training module} with two types of feature-aware losses to continuously optimize the differentiable quantizer. As a result, the inherent features of a PG would be embedded into the learned PQ, generating high-quality quantized vectors. Moreover, we integrate our RPQ with the state-of-the-art DiskANN and existing popular PGs to improve their performance. Comprehensive experiments on real-world large-scale datasets (from 1M to 1B) demonstrate RPQ's superiority, e.g., 1.7$\\times$-4.2$\\times$ improvement on QPS at the same recall@10 of 95\\%.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18724"
  },
  "2311.18714": {
    "title": "DAOS as HPC Storage: Exploring Interfaces",
    "authors": [
      "Adrian Jackson",
      "Nicolau Manubens"
    ],
    "abstract": "This work in progress paper outlines research looking at the performance impact of using different storage interfaces to access the high performance object store DAOS. We demonstrate that using DAOS through a FUSE based filesystem interface can provide high performance, but there are impacts when choosing what I/O library or interface to utilises, with HDF5 exhibiting the highest impact. However, this varied depending on what type of I/O operations were undertaken.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18714"
  },
  "2311.18712": {
    "title": "CoRec: An Easy Approach for Coordination Recognition",
    "authors": [
      "Qing Wang",
      "Haojie Jia",
      "Wenfei Song",
      "Qi Li"
    ],
    "abstract": "In this paper, we observe and address the challenges of the coordination recognition task. Most existing methods rely on syntactic parsers to identify the coordinators in a sentence and detect the coordination boundaries. However, state-of-the-art syntactic parsers are slow and suffer from errors, especially for long and complicated sentences. To better solve the problems, we propose a pipeline model COordination RECognizer (CoRec). It consists of two components: coordinator identifier and conjunct boundary detector. The experimental results on datasets from various domains demonstrate the effectiveness and efficiency of the proposed method. Further experiments show that CoRec positively impacts downstream tasks, improving the yield of state-of-the-art Open IE models.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18712"
  },
  "2311.18710": {
    "title": "Meta-Prior: Meta learning for Adaptive Inverse Problem Solvers",
    "authors": [
      "Matthieu Terris",
      "Thomas Moreau"
    ],
    "abstract": "Deep neural networks have become a foundational tool for addressing imaging inverse problems. They are typically trained for a specific task, with a supervised loss to learn a mapping from the observations to the image to recover. However, real-world imaging challenges often lack ground truth data, rendering traditional supervised approaches ineffective. Moreover, for each new imaging task, a new model needs to be trained from scratch, wasting time and resources. To overcome these limitations, we introduce a novel approach based on meta-learning. Our method trains a meta-model on a diverse set of imaging tasks that allows the model to be efficiently fine-tuned for specific tasks with few fine-tuning steps. We show that the proposed method extends to the unsupervised setting, where no ground truth data is available. In its bilevel formulation, the outer level uses a supervised loss, that evaluates how well the fine-tuned model performs, while the inner loss can be either supervised or unsupervised, relying only on the measurement operator. This allows the meta-model to leverage a few ground truth samples for each task while being able to generalize to new imaging tasks. We show that in simple settings, this approach recovers the Bayes optimal estimator, illustrating the soundness of our approach. We also demonstrate our method's effectiveness on various tasks, including image processing and magnetic resonance imaging.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18710"
  },
  "2311.18695": {
    "title": "Seg2Reg: Differentiable 2D Segmentation to 1D Regression Rendering for 360 Room Layout Reconstruction",
    "authors": [
      "Cheng Sun",
      "Wei-En Tai",
      "Yu-Lin Shih",
      "Kuan-Wei Chen",
      "Yong-Jing Syu",
      "Kent Selwyn The",
      "Yu-Chiang Frank Wang",
      "Hwann-Tzong Chen"
    ],
    "abstract": "State-of-the-art single-view 360-degree room layout reconstruction methods formulate the problem as a high-level 1D (per-column) regression task. On the other hand, traditional low-level 2D layout segmentation is simpler to learn and can represent occluded regions, but it requires complex post-processing for the targeting layout polygon and sacrifices accuracy. We present Seg2Reg to render 1D layout depth regression from the 2D segmentation map in a differentiable and occlusion-aware way, marrying the merits of both sides. Specifically, our model predicts floor-plan density for the input equirectangular 360-degree image. Formulating the 2D layout representation as a density field enables us to employ `flattened' volume rendering to form 1D layout depth regression. In addition, we propose a novel 3D warping augmentation on layout to improve generalization. Finally, we re-implement recent room layout reconstruction methods into our codebase for benchmarking and explore modern backbones and training techniques to serve as the strong baseline. Our model significantly outperforms previous arts. The code will be made available upon publication.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18695"
  },
  "2311.18694": {
    "title": "Balancing Summarization and Change Detection in Graph Streams",
    "authors": [
      "Shintaro Fukushima",
      "Kenji Yamanishi"
    ],
    "abstract": "This study addresses the issue of balancing graph summarization and graph change detection. Graph summarization compresses large-scale graphs into a smaller scale. However, the question remains: To what extent should the original graph be compressed? This problem is solved from the perspective of graph change detection, aiming to detect statistically significant changes using a stream of summary graphs. If the compression rate is extremely high, important changes can be ignored, whereas if the compression rate is extremely low, false alarms may increase with more memory. This implies that there is a trade-off between compression rate in graph summarization and accuracy in change detection. We propose a novel quantitative methodology to balance this trade-off to simultaneously realize reliable graph summarization and change detection. We introduce a probabilistic structure of hierarchical latent variable model into a graph, thereby designing a parameterized summary graph on the basis of the minimum description length principle. The parameter specifying the summary graph is then optimized so that the accuracy of change detection is guaranteed to suppress Type I error probability (probability of raising false alarms) to be less than a given confidence level. First, we provide a theoretical framework for connecting graph summarization with change detection. Then, we empirically demonstrate its effectiveness on synthetic and real datasets.\n        \u25b3 Less",
    "submission_date": "12 December, 2023",
    "eprint_id": "2311.18694"
  },
  "2311.18689": {
    "title": "Subspace Hybrid MVDR Beamforming for Augmented Hearing",
    "authors": [
      "Sina Hafezi",
      "Alastair H. Moore",
      "Pierre H. Guiraud",
      "Patrick A. Naylor",
      "Jacob Donley",
      "Vladimir Tourbabin",
      "Thomas Lunner"
    ],
    "abstract": "Signal-dependent beamformers are advantageous over signal-independent beamformers when the acoustic scenario - be it real-world or simulated - is straightforward in terms of the number of sound sources, the ambient sound field and their dynamics. However, in the context of augmented reality audio using head-worn microphone arrays, the acoustic scenarios encountered are often far from straightforward. The design of robust, high-performance, adaptive beamformers for such scenarios is an on-going challenge. This is due to the violation of the typically required assumptions on the noise field caused by, for example, rapid variations resulting from complex acoustic environments, and/or rotations of the listener's head. This work proposes a multi-channel speech enhancement algorithm which utilises the adaptability of signal-dependent beamformers while still benefiting from the computational efficiency and robust performance of signal-independent super-directive beamformers. The algorithm has two stages. (i) The first stage is a hybrid beamformer based on a dictionary of weights corresponding to a set of noise field models. (ii) The second stage is a wide-band subspace post-filter to remove any artifacts resulting from (i). The algorithm is evaluated using both real-world recordings and simulations of a cocktail-party scenario. Noise suppression, intelligibility and speech quality results show a significant performance improvement by the proposed algorithm compared to the baseline super-directive beamformer. A data-driven implementation of the noise field dictionary is shown to provide more noise suppression, and similar speech intelligibility and quality, compared to a parametric dictionary.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18689"
  },
  "2311.18684": {
    "title": "Handling Cost and Constraints with Off-Policy Deep Reinforcement Learning",
    "authors": [
      "Jared Markowitz",
      "Jesse Silverberg",
      "Gary Collins"
    ],
    "abstract": "By reusing data throughout training, off-policy deep reinforcement learning algorithms offer improved sample efficiency relative to on-policy approaches. For continuous action spaces, the most popular methods for off-policy learning include policy improvement steps where a learned state-action ($Q$) value function is maximized over selected batches of data. These updates are often paired with regularization to combat associated overestimation of $Q$ values. With an eye toward safety, we revisit this strategy in environments with \"mixed-sign\" reward functions; that is, with reward functions that include independent positive (incentive) and negative (cost) terms. This setting is common in real-world applications, and may be addressed with or without constraints on the cost terms. We find the combination of function approximation and a term that maximizes $Q$ in the policy update to be problematic in such environments, because systematic errors in value estimation impact the contributions from the competing terms asymmetrically. This results in overemphasis of either incentives or costs and may severely limit learning. We explore two remedies to this issue. First, consistent with prior work, we find that periodic resetting of $Q$ and policy networks can be used to reduce value estimation error and improve learning in this setting. Second, we formulate novel off-policy actor-critic methods for both unconstrained and constrained learning that do not explicitly maximize $Q$ in the policy update. We find that this second approach, when applied to continuous action spaces with mixed-sign rewards, consistently and significantly outperforms state-of-the-art methods augmented by resetting. We further find that our approach produces agents that are both competitive with popular methods overall and more reliably competent on frequently-studied control problems that do not have mixed-sign rewards.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18684"
  },
  "2311.18681": {
    "title": "RaDialog: A Large Vision-Language Model for Radiology Report Generation and Conversational Assistance",
    "authors": [
      "Chantal Pellegrini",
      "Ege \u00d6zsoy",
      "Benjamin Busam",
      "Nassir Navab",
      "Matthias Keicher"
    ],
    "abstract": "Conversational AI tools that can generate and discuss clinically correct radiology reports for a given medical image have the potential to transform radiology. Such a human-in-the-loop radiology assistant could facilitate a collaborative diagnostic process, thus saving time and improving the quality of reports. Towards this goal, we introduce RaDialog, the first thoroughly evaluated and publicly available large vision-language model for radiology report generation and interactive dialog. RaDialog effectively integrates visual image features and structured pathology findings with a large language model (LLM) while simultaneously adapting it to a specialized domain using parameter-efficient fine-tuning. To keep the conversational abilities of the underlying LLM, we propose a comprehensive, semi-automatically labeled, image-grounded instruct dataset for chest X-ray radiology tasks. By training with this dataset, our method achieves state-of-the-art clinical correctness in report generation and shows impressive abilities in interactive tasks such as correcting reports and answering questions, serving as a foundational step toward clinical dialog systems. Our code is available on github: https://github.com/ChantalMP/RaDialog.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18681"
  },
  "2311.18679": {
    "title": "A proposal for federated chatbots for distributed information access (extended version)",
    "authors": [
      "Fernando Tricas-Garc\u00eda"
    ],
    "abstract": "Chatbots can be a good way to interact with IoT devices, and other information systems: they can provide information with a convenient interface for casual or frequent interaction. Sometimes there can be good reasons to have more than one chatbot: maybe we have several computers, or diverse infrastructure, with different access conditions. This work concentrates on this case, when it can be useful to establish a method for them to work in a cooperative way. In principle, coordination is a good property: each one of these chatbots can be devoted to solve different tasks and our users can have different needs when accessing to every capability of each chatbot.\n  In this paper we are proposing an architecture for several chatbots that can interact via a command and control channel, requesting actions for other bots and collecting the replies in order to pass them to the user. The chatbot infrastructure is lightweight, and it can use public (but not publicly viewable) infrastructure providing an easy way to start a project with it.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18679"
  },
  "2311.18676": {
    "title": "DQSSA: A Quantum-Inspired Solution for Maximizing Influence in Online Social Networks (Student Abstract)",
    "authors": [
      "Aryaman Rao",
      "Parth Singh",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "abstract": "Influence Maximization is the task of selecting optimal nodes maximising the influence spread in social networks. This study proposes a Discretized Quantum-based Salp Swarm Algorithm (DQSSA) for optimizing influence diffusion in social networks. By discretizing meta-heuristic algorithms and infusing them with quantum-inspired enhancements, we address issues like premature convergence and low efficacy. The proposed method, guided by quantum principles, offers a promising solution for Influence Maximisation. Experiments on four real-world datasets reveal DQSSA's superior performance as compared to established cutting-edge algorithms.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18676"
  },
  "2311.18675": {
    "title": "Cascaded Interaction with Eroded Deep Supervision for Salient Object Detection",
    "authors": [
      "Hewen Xiao",
      "Jie Mei",
      "Guangfu Ma",
      "Weiren Wu"
    ],
    "abstract": "Deep convolutional neural networks have been widely applied in salient object detection and have achieved remarkable results in this field. However, existing models suffer from information distortion caused by interpolation during up-sampling and down-sampling. In response to this drawback, this article starts from two directions in the network: feature and label. On the one hand, a novel cascaded interaction network with a guidance module named global-local aligned attention (GAA) is designed to reduce the negative impact of interpolation on the feature side. On the other hand, a deep supervision strategy based on edge erosion is proposed to reduce the negative guidance of label interpolation on lateral output. Extensive experiments on five popular datasets demonstrate the superiority of our method.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18675"
  },
  "2311.18671": {
    "title": "Solution to an open problem on the closeness of graphs",
    "authors": [
      "Fazal Hayat",
      "Shou-Jun Xu"
    ],
    "abstract": "A network can be analyzed by means of many graph theoretical parameters. In the context of networks analysis, closeness is a structural metric that evaluates a node's significance inside a network. A cactus is a connected graph in which any block is either a cut edge or a cycle. This paper analyzes the closeness of cacti, we determine the unique graph that minimizes the closeness over all cacti with fixed numbers of vertices and cycles, which solves an open problem proposed by Poklukar \\& \u017derovnik [Fundam. Inform. 167 (2019) 219--234].\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18671"
  },
  "2311.18670": {
    "title": "Local Geometry Determines Global Landscape in Low-rank Factorization for Synchronization",
    "authors": [
      "Shuyang Ling"
    ],
    "abstract": "The orthogonal group synchronization problem, which focuses on recovering orthogonal group elements from their corrupted pairwise measurements, encompasses examples such as high-dimensional Kuramoto model on general signed networks, $\\mathbb{Z}_2$-synchronization, community detection under stochastic block models, and orthogonal Procrustes problem. The semidefinite relaxation (SDR) has proven its power in solving this problem; however, its expensive computational costs impede its widespread practical applications. We consider the Burer-Monteiro factorization approach to the orthogonal group synchronization, an effective and scalable low-rank factorization to solve large scale SDPs. Despite the significant empirical successes of this factorization approach, it is still a challenging task to understand when the nonconvex optimization landscape is benign, i.e., the optimization landscape possesses only one local minimizer, which is also global. In this work, we demonstrate that if the degree of freedom within the factorization exceeds twice the condition number of the ``Laplacian\" (certificate matrix) at the global minimizer, the optimization landscape is absent of spurious local minima. Our main theorem is purely algebraic and versatile, and it seamlessly applies to all the aforementioned examples: the nonconvex landscape remains benign under almost identical condition that enables the success of the SDR. Additionally, we illustrate that the Burer-Monteiro factorization is robust to ``monotone adversaries\", mirroring the resilience of the SDR. In other words, introducing ``favorable\" adversaries into the data will not result in the emergence of new spurious local minimizers.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18670"
  },
  "2311.18666": {
    "title": "Action Recognition in Video Recordings from Gynecologic Laparoscopy",
    "authors": [
      "Sahar Nasirihaghighi",
      "Negin Ghamsarian",
      "Daniela Stefanics",
      "Klaus Schoeffmann",
      "Heinrich Husslein"
    ],
    "abstract": "Action recognition is a prerequisite for many applications in laparoscopic video analysis including but not limited to surgical training, operation room planning, follow-up surgery preparation, post-operative surgical assessment, and surgical outcome estimation. However, automatic action recognition in laparoscopic surgeries involves numerous challenges such as (I) cross-action and intra-action duration variation, (II) relevant content distortion due to smoke, blood accumulation, fast camera motions, organ movements, object occlusion, and (III) surgical scene variations due to different illuminations and viewpoints. Besides, action annotations in laparoscopy surgeries are limited and expensive due to requiring expert knowledge. In this study, we design and evaluate a CNN-RNN architecture as well as a customized training-inference framework to deal with the mentioned challenges in laparoscopic surgery action recognition. Using stacked recurrent layers, our proposed network takes advantage of inter-frame dependencies to negate the negative effect of content distortion and variation in action recognition. Furthermore, our proposed frame sampling strategy effectively manages the duration variations in surgical actions to enable action recognition with high temporal resolution. Our extensive experiments confirm the superiority of our proposed method in action recognition compared to static CNNs.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18666"
  },
  "2311.18665": {
    "title": "Pose Estimation and Tracking for ASIST",
    "authors": [
      "Ari Goodman",
      "Gurpreet Singh",
      "Ryan O'Shea",
      "Peter Teague",
      "James Hing"
    ],
    "abstract": "Aircraft Ship Integrated Secure and Traverse (ASIST) is a system designed to arrest helicopters safely and efficiently on ships. Originally, a precision Helicopter Position Sensing Equipment (HPSE) tracked and monitored the position of the helicopter relative to the Rapid Securing Device (RSD). However, using the HPSE component was determined to be infeasible in the transition of the ASIST system due to the hardware installation requirements. As a result, sailors track the position of the helicopters with their eyes with no sensor or artificially intelligent decision aid. Manually tracking the helicopter takes additional time and makes recoveries more difficult, especially at high sea states. Performing recoveries without the decision aid leads to higher uncertainty and cognitive load. PETA (Pose Estimation and Tracking for ASIST) is a research effort to create a helicopter tracking system prototype without hardware installation requirements for ASIST system operators. Its overall goal is to improve situational awareness and reduce operator uncertainty with respect to the aircrafts position relative to the RSD, and consequently increase the allowable landing area. The authors produced a prototype system capable of tracking helicopters with respect to the RSD. The software included a helicopter pose estimation component, camera pose estimation component, and a user interface component. PETA demonstrated the potential for state-of-the-art computer vision algorithms Faster R-CNN and HRNet (High-Resolution Network) to be used to estimate the pose of helicopters in real-time, returning ASIST to its originally intended capability. PETA also demonstrated that traditional methods of encoder-decoders could be used to estimate the orientation of the helicopter and could be used to confirm the output from HRNet.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18665"
  },
  "2311.18664": {
    "title": "Multi-task learning with cross-task consistency for improved depth estimation in colonoscopy",
    "authors": [
      "Pedro Esteban Chavarrias Solano",
      "Andrew Bulpitt",
      "Venkataraman Subramanian",
      "Sharib Ali"
    ],
    "abstract": "Colonoscopy screening is the gold standard procedure for assessing abnormalities in the colon and rectum, such as ulcers and cancerous polyps. Measuring the abnormal mucosal area and its 3D reconstruction can help quantify the surveyed area and objectively evaluate disease burden. However, due to the complex topology of these organs and variable physical conditions, for example, lighting, large homogeneous texture, and image modality estimating distance from the camera aka depth) is highly challenging. Moreover, most colonoscopic video acquisition is monocular, making the depth estimation a non-trivial problem. While methods in computer vision for depth estimation have been proposed and advanced on natural scene datasets, the efficacy of these techniques has not been widely quantified on colonoscopy datasets. As the colonic mucosa has several low-texture regions that are not well pronounced, learning representations from an auxiliary task can improve salient feature extraction, allowing estimation of accurate camera depths. In this work, we propose to develop a novel multi-task learning (MTL) approach with a shared encoder and two decoders, namely a surface normal decoder and a depth estimator decoder. Our depth estimator incorporates attention mechanisms to enhance global context awareness. We leverage the surface normal prediction to improve geometric feature extraction. Also, we apply a cross-task consistency loss among the two geometrically related tasks, surface normal and camera depth. We demonstrate an improvement of 14.17% on relative error and 10.4% improvement on $\u03b4_{1}$ accuracy over the most accurate baseline state-of-the-art BTS approach. All experiments are conducted on a recently released C3VD dataset; thus, we provide a first benchmark of state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18664"
  },
  "2311.18663": {
    "title": "Choosing the parameter of the Fermat distance: navigating geometry and noise",
    "authors": [
      "Fr\u00e9d\u00e9ric Chazal",
      "Laure Ferraris",
      "Pablo Groisman",
      "Matthieu Jonckheere",
      "Fr\u00e9d\u00e9ric Pascal",
      "Facundo Sapienza"
    ],
    "abstract": "The Fermat distance has been recently established as a useful tool for machine learning tasks when a natural distance is not directly available to the practitioner or to improve the results given by Euclidean distances by exploding the geometrical and statistical properties of the dataset. This distance depends on a parameter $\u03b1$ that greatly impacts the performance of subsequent tasks. Ideally, the value of $\u03b1$ should be large enough to navigate the geometric intricacies inherent to the problem. At the same, it should remain restrained enough to sidestep any deleterious ramifications stemming from noise during the process of distance estimation. We study both theoretically and through simulations how to select this parameter.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18663"
  },
  "2311.18662": {
    "title": "Solving the Team Orienteering Problem with Transformers",
    "authors": [
      "Daniel Fuertes",
      "Carlos R. del-Blanco",
      "Fernando Jaureguizar",
      "Narciso Garc\u00eda"
    ],
    "abstract": "Route planning for a fleet of vehicles is an important task in applications such as package delivery, surveillance, or transportation. This problem is usually modeled as a Combinatorial Optimization problem named as Team Orienteering Problem. The most popular Team Orienteering Problem solvers are mainly based on either linear programming, which provides accurate solutions by employing a large computation time that grows with the size of the problem, or heuristic methods, which usually find suboptimal solutions in a shorter amount of time. In this paper, a multi-agent route planning system capable of solving the Team Orienteering Problem in a very fast and accurate manner is presented. The proposed system is based on a centralized Transformer neural network that can learn to encode the scenario (modeled as a graph) and the context of the agents to provide fast and accurate solutions. Several experiments have been performed to demonstrate that the presented system can outperform most of the state-of-the-art works in terms of computation speed. In addition, the code is publicly available at http://gti.ssr.upm.es/data.\n        \u25b3 Less",
    "submission_date": "1 December, 2023",
    "eprint_id": "2311.18662"
  },
  "2311.18661": {
    "title": "Learning Part Segmentation from Synthetic Animals",
    "authors": [
      "Jiawei Peng",
      "Ju He",
      "Prakhar Kaushik",
      "Zihao Xiao",
      "Jiteng Mu",
      "Alan Yuille"
    ],
    "abstract": "Semantic part segmentation provides an intricate and interpretable understanding of an object, thereby benefiting numerous downstream tasks. However, the need for exhaustive annotations impedes its usage across diverse object types. This paper focuses on learning part segmentation from synthetic animals, leveraging the Skinned Multi-Animal Linear (SMAL) models to scale up existing synthetic data generated by computer-aided design (CAD) animal models. Compared to CAD models, SMAL models generate data with a wider range of poses observed in real-world scenarios. As a result, our first contribution is to construct a synthetic animal dataset of tigers and horses with more pose diversity, termed Synthetic Animal Parts (SAP). We then benchmark Syn-to-Real animal part segmentation from SAP to PartImageNet, namely SynRealPart, with existing semantic segmentation domain adaptation methods and further improve them as our second contribution. Concretely, we examine three Syn-to-Real adaptation methods but observe relative performance drop due to the innate difference between the two tasks. To address this, we propose a simple yet effective method called Class-Balanced Fourier Data Mixing (CB-FDM). Fourier Data Mixing aligns the spectral amplitudes of synthetic images with real images, thereby making the mixed images have more similar frequency content to real images. We further use Class-Balanced Pseudo-Label Re-Weighting to alleviate the imbalanced class distribution. We demonstrate the efficacy of CB-FDM on SynRealPart over previous methods with significant performance improvements. Remarkably, our third contribution is to reveal that the learned parts from synthetic tiger and horse are transferable across all quadrupeds in PartImageNet, further underscoring the utility and potential applications of animal part segmentation.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18661"
  },
  "2311.18658": {
    "title": "ArcMMLU: A Library and Information Science Benchmark for Large Language Models",
    "authors": [
      "Shitou Zhang",
      "Zuchao Li",
      "Xingshen Liu",
      "Liming Yang",
      "Ping Wang"
    ],
    "abstract": "In light of the rapidly evolving capabilities of large language models (LLMs), it becomes imperative to develop rigorous domain-specific evaluation benchmarks to accurately assess their capabilities. In response to this need, this paper introduces ArcMMLU, a specialized benchmark tailored for the Library & Information Science (LIS) domain in Chinese. This benchmark aims to measure the knowledge and reasoning capability of LLMs within four key sub-domains: Archival Science, Data Science, Library Science, and Information Science. Following the format of MMLU/CMMLU, we collected over 6,000 high-quality questions for the compilation of ArcMMLU. This extensive compilation can reflect the diverse nature of the LIS domain and offer a robust foundation for LLM evaluation. Our comprehensive evaluation reveals that while most mainstream LLMs achieve an average accuracy rate above 50% on ArcMMLU, there remains a notable performance gap, suggesting substantial headroom for refinement in LLM capabilities within the LIS domain. Further analysis explores the effectiveness of few-shot examples on model performance and highlights challenging questions where models consistently underperform, providing valuable insights for targeted improvements. ArcMMLU fills a critical gap in LLM evaluations within the Chinese LIS domain and paves the way for future development of LLMs tailored to this specialized area.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18658"
  },
  "2311.18655": {
    "title": "OISA: Architecting an Optical In-Sensor Accelerator for Efficient Visual Computing",
    "authors": [
      "Mehrdad Morsali",
      "Sepehr Tabrizchi",
      "Deniz Najafi",
      "Mohsen Imani",
      "Mahdi Nikdast",
      "Arman Roohi",
      "Shaahin Angizi"
    ],
    "abstract": "Targeting vision applications at the edge, in this work, we systematically explore and propose a high-performance and energy-efficient Optical In-Sensor Accelerator architecture called OISA for the first time. Taking advantage of the promising efficiency of photonic devices, the OISA intrinsically implements a coarse-grained convolution operation on the input frames in an innovative minimum-conversion fashion in low-bit-width neural networks. Such a design remarkably reduces the power consumption of data conversion, transmission, and processing in the conventional cloud-centric architecture as well as recently-presented edge accelerators. Our device-to-architecture simulation results on various image data-sets demonstrate acceptable accuracy while OISA achieves 6.68 TOp/s/W efficiency. OISA reduces power consumption by a factor of 7.9 and 18.4 on average compared with existing electronic in-/near-sensor and ASIC accelerators.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18655"
  },
  "2311.18654": {
    "title": "Detailed Human-Centric Text Description-Driven Large Scene Synthesis",
    "authors": [
      "Gwanghyun Kim",
      "Dong Un Kang",
      "Hoigi Seo",
      "Hayeon Kim",
      "Se Young Chun"
    ],
    "abstract": "Text-driven large scene image synthesis has made significant progress with diffusion models, but controlling it is challenging. While using additional spatial controls with corresponding texts has improved the controllability of large scene synthesis, it is still challenging to faithfully reflect detailed text descriptions without user-provided controls. Here, we propose DetText2Scene, a novel text-driven large-scale image synthesis with high faithfulness, controllability, and naturalness in a global context for the detailed human-centric text description. Our DetText2Scene consists of 1) hierarchical keypoint-box layout generation from the detailed description by leveraging large language model (LLM), 2) view-wise conditioned joint diffusion process to synthesize a large scene from the given detailed text with LLM-generated grounded keypoint-box layout and 3) pixel perturbation-based pyramidal interpolation to progressively refine the large scene for global coherence. Our DetText2Scene significantly outperforms prior arts in text-to-large scene synthesis qualitatively and quantitatively, demonstrating strong faithfulness with detailed descriptions, superior controllability, and excellent naturalness in a global context.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18654"
  },
  "2311.18651": {
    "title": "LL3DA: Visual Interactive Instruction Tuning for Omni-3D Understanding, Reasoning, and Planning",
    "authors": [
      "Sijin Chen",
      "Xin Chen",
      "Chi Zhang",
      "Mingsheng Li",
      "Gang Yu",
      "Hao Fei",
      "Hongyuan Zhu",
      "Jiayuan Fan",
      "Tao Chen"
    ],
    "abstract": "Recent advances in Large Multimodal Models (LMM) have made it possible for various applications in human-machine interactions. However, developing LMMs that can comprehend, reason, and plan in complex and diverse 3D environments remains a challenging topic, especially considering the demand for understanding permutation-invariant point cloud 3D representations of the 3D scene. Existing works seek help from multi-view images, and project 2D features to 3D space as 3D scene representations. This, however, leads to huge computational overhead and performance degradation. In this paper, we present LL3DA, a Large Language 3D Assistant that takes point cloud as direct input and respond to both textual-instructions and visual-prompts. This help LMMs better comprehend human interactions and further help to remove the ambiguities in cluttered 3D scenes. Experiments show that LL3DA achieves remarkable results, and surpasses various 3D vision-language models on both 3D Dense Captioning and 3D Question Answering.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18651"
  },
  "2311.18646": {
    "title": "Robust-to-Noise Algorithms for Distributed Resource Allocation and Scheduling",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Alireza Aghasi"
    ],
    "abstract": "Efficient resource allocation and scheduling algorithms are essential for various distributed applications, ranging from wireless networks and cloud computing platforms to autonomous multi-agent systems and swarm robotic networks. However, real-world environments are often plagued by uncertainties and noise, leading to sub-optimal performance and increased vulnerability of traditional algorithms. This paper addresses the challenge of robust resource allocation and scheduling in the presence of noise and disturbances. The proposed study introduces a novel sign-based dynamics for developing robust-to-noise algorithms distributed over a multi-agent network that can adaptively handle external disturbances. Leveraging concepts from convex optimization theory, control theory, and network science the framework establishes a principled approach to design algorithms that can maintain key properties such as resource-demand balance and constraint feasibility. Meanwhile, notions of uniform-connectivity and versatile networking conditions are also addressed.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18646"
  },
  "2311.18645": {
    "title": "Stochastic Vision Transformers with Wasserstein Distance-Aware Attention",
    "authors": [
      "Franciskus Xaverius Erick",
      "Mina Rezaei",
      "Johanna Paula M\u00fcller",
      "Bernhard Kainz"
    ],
    "abstract": "Self-supervised learning is one of the most promising approaches to acquiring knowledge from limited labeled data. Despite the substantial advancements made in recent years, self-supervised models have posed a challenge to practitioners, as they do not readily provide insight into the model's confidence and uncertainty. Tackling this issue is no simple feat, primarily due to the complexity involved in implementing techniques that can make use of the latent representations learned during pre-training without relying on explicit labels. Motivated by this, we introduce a new stochastic vision transformer that integrates uncertainty and distance awareness into self-supervised learning (SSL) pipelines. Instead of the conventional deterministic vector embedding, our novel stochastic vision transformer encodes image patches into elliptical Gaussian distributional embeddings. Notably, the attention matrices of these stochastic representational embeddings are computed using Wasserstein distance-based attention, effectively capitalizing on the distributional nature of these embeddings. Additionally, we propose a regularization term based on Wasserstein distance for both pre-training and fine-tuning processes, thereby incorporating distance awareness into latent representations. We perform extensive experiments across different tasks such as in-distribution generalization, out-of-distribution detection, dataset corruption, semi-supervised settings, and transfer learning to other datasets and tasks. Our proposed method achieves superior accuracy and calibration, surpassing the self-supervised baseline in a wide range of experiments on a variety of datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18645"
  },
  "2311.18644": {
    "title": "Exploring the hierarchical structure of human plans via program generation",
    "authors": [
      "Carlos G. Correa",
      "Sophia Sanborn",
      "Mark K. Ho",
      "Frederick Callaway",
      "Nathaniel D. Daw",
      "Thomas L. Griffiths"
    ],
    "abstract": "Human behavior is inherently hierarchical, resulting from the decomposition of a task into subtasks or an abstract action into concrete actions. However, behavior is typically measured as a sequence of actions, which makes it difficult to infer its hierarchical structure. In this paper, we explore how people form hierarchically-structured plans, using an experimental paradigm that makes hierarchical representations observable: participants create programs that produce sequences of actions in a language with explicit hierarchical structure. This task lets us test two well-established principles of human behavior: utility maximization (i.e. using fewer actions) and minimum description length (MDL; i.e. having a shorter program). We find that humans are sensitive to both metrics, but that both accounts fail to predict a qualitative feature of human-created programs, namely that people prefer programs with reuse over and above the predictions of MDL. We formalize this preference for reuse by extending the MDL account into a generative model over programs, modeling hierarchy choice as the induction of a grammar over actions. Our account can explain the preference for reuse and provides the best prediction of human behavior, going beyond simple accounts of compressibility to highlight a principle that guides hierarchical planning.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18644"
  },
  "2311.18641": {
    "title": "CrimeGAT: Leveraging Graph Attention Networks for Enhanced Predictive Policing in Criminal Networks",
    "authors": [
      "Chen Yang"
    ],
    "abstract": "In this paper, we present CrimeGAT, a novel application of Graph Attention Networks (GATs) for predictive policing in criminal networks. Criminal networks pose unique challenges for predictive analytics due to their complex structure, multi-relational links, and dynamic behavior. Traditional methods often fail to capture these complexities, leading to suboptimal predictions. To address these challenges, we propose the use of GATs, which can effectively leverage both node features and graph structure to make predictions. Our proposed CrimeGAT model integrates attention mechanisms to weigh the importance of a node's neighbors, thereby capturing the local and global structures of criminal networks. We formulate the problem as learning a function that maps node features and graph structure to a prediction of future criminal activity. The experimental results on real-world datasets demonstrate that CrimeGAT out-performs conventional methods in predicting criminal activities, thereby providing a powerful tool for law enforcement agencies to proactively deploy resources. Furthermore, the interpretable nature of the attentionmechanism inGATs offers insights into the key players and relationships in criminal networks. This research opens new avenues for applying deep learning techniques in the Aeld of predictive policing and criminal network analysis.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18641"
  },
  "2311.18636": {
    "title": "End-to-end Autonomous Driving using Deep Learning: A Systematic Review",
    "authors": [
      "Apoorv Singh"
    ],
    "abstract": "End-to-end autonomous driving is a fully differentiable machine learning system that takes raw sensor input data and other metadata as prior information and directly outputs the ego vehicle's control signals or planned trajectories. This paper attempts to systematically review all recent Machine Learning-based techniques to perform this end-to-end task, including, but not limited to, object detection, semantic scene understanding, object tracking, trajectory predictions, trajectory planning, vehicle control, social behavior, and communications. This paper focuses on recent fully differentiable end-to-end reinforcement learning and deep learning-based techniques. Our paper also builds taxonomies of the significant approaches by sub-grouping them and showcasing their research trends. Finally, this survey highlights the open challenges and points out possible future directions to enlighten further research on the topic.\n        \u25b3 Less",
    "submission_date": "27 August, 2023",
    "eprint_id": "2311.18636"
  },
  "2311.18630": {
    "title": "SATHUR: Self Augmenting Task Hallucinal Unified Representation for Generalized Class Incremental Learning",
    "authors": [
      "Sathursan Kanagarajah",
      "Thanuja Ambegoda",
      "Ranga Rodrigo"
    ],
    "abstract": "Class Incremental Learning (CIL) is inspired by the human ability to learn new classes without forgetting previous ones. CIL becomes more challenging in real-world scenarios when the samples in each incremental step are imbalanced. This creates another branch of problem, called Generalized Class Incremental Learning (GCIL) where each incremental step is structured more realistically. Grow When Required (GWR) network, a type of Self-Organizing Map (SOM), dynamically create and remove nodes and edges for adaptive learning. GWR performs incremental learning from feature vectors extracted by a Convolutional Neural Network (CNN), which acts as a feature extractor. The inherent ability of GWR to form distinct clusters, each corresponding to a class in the feature vector space, regardless of the order of samples or class imbalances, is well suited to achieving GCIL. To enhance GWR's classification performance, a high-quality feature extractor is required. However, when the convolutional layers are adapted at each incremental step, the GWR nodes corresponding to prior knowledge are subject to near-invalidation. This work introduces the Self Augmenting Task Hallucinal Unified Representation (SATHUR), which re-initializes the GWR network at each incremental step, aligning it with the current feature extractor. Comprehensive experimental results demonstrate that our proposed method significantly outperforms other state-of-the-art GCIL methods on CIFAR-100 and CORe50 datasets.\n        \u25b3 Less",
    "submission_date": "12 August, 2023",
    "eprint_id": "2311.18630"
  },
  "2311.18628": {
    "title": "A Lightweight Clustering Framework for Unsupervised Semantic Segmentation",
    "authors": [
      "Yau Shing Jonathan Cheung",
      "Xi Chen",
      "Lihe Yang",
      "Hengshuang Zhao"
    ],
    "abstract": "Unsupervised semantic segmentation aims to categorize each pixel in an image into a corresponding class without the use of annotated data. It is a widely researched area as obtaining labeled datasets is expensive. While previous works in the field have demonstrated a gradual improvement in model accuracy, most required neural network training. This made segmentation equally expensive, especially when dealing with large-scale datasets. We thus propose a lightweight clustering framework for unsupervised semantic segmentation. We discovered that attention features of the self-supervised Vision Transformer exhibit strong foreground-background differentiability. Therefore, clustering can be employed to effectively separate foreground and background image patches. In our framework, we first perform multilevel clustering across the Dataset-level, Category-level, and Image-level, and maintain consistency throughout. Then, the binary patch-level pseudo-masks extracted are upsampled, refined and finally labeled. Furthermore, we provide a comprehensive analysis of the self-supervised Vision Transformer features and a detailed comparison between DINO and DINOv2 to justify our claims. Our framework demonstrates great promise in unsupervised semantic segmentation and achieves state-of-the-art results on PASCAL VOC and MS COCO datasets.\n        \u25b3 Less",
    "submission_date": "28 December, 2023",
    "eprint_id": "2311.18628"
  },
  "2311.18620": {
    "title": "Data-driven prediction of tool wear using Bayesian-regularized artificial neural networks",
    "authors": [
      "Tam T. Truong",
      "Jay Airao",
      "Panagiotis Karras",
      "Faramarz Hojati",
      "Bahman Azarhoushang",
      "Ramin Aghababaei"
    ],
    "abstract": "The prediction of tool wear helps minimize costs and enhance product quality in manufacturing. While existing data-driven models using machine learning and deep learning have contributed to the accurate prediction of tool wear, they often lack generality and require substantial training data for high accuracy. In this paper, we propose a new data-driven model that uses Bayesian Regularized Artificial Neural Networks (BRANNs) to precisely predict milling tool wear. BRANNs combine the strengths and leverage the benefits of artificial neural networks (ANNs) and Bayesian regularization, whereby ANNs learn complex patterns and Bayesian regularization handles uncertainty and prevents overfitting, resulting in a more generalized model. We treat both process parameters and monitoring sensor signals as BRANN input parameters. We conducted an extensive experimental study featuring four different experimental data sets, including the NASA Ames milling dataset, the 2010 PHM Data Challenge dataset, the NUAA Ideahouse tool wear dataset, and an in-house performed end-milling of the Ti6Al4V dataset. We inspect the impact of input features, training data size, hidden units, training algorithms, and transfer functions on the performance of the proposed BRANN model and demonstrate that it outperforms existing state-of-the-art models in terms of accuracy and reliability.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18620"
  },
  "2311.18618": {
    "title": "JPPF: Multi-task Fusion for Consistent Panoptic-Part Segmentation",
    "authors": [
      "Shishir Muralidhara",
      "Sravan Kumar Jagadeesh",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "abstract": "Part-aware panoptic segmentation is a problem of computer vision that aims to provide a semantic understanding of the scene at multiple levels of granularity. More precisely, semantic areas, object instances, and semantic parts are predicted simultaneously. In this paper, we present our Joint Panoptic Part Fusion (JPPF) that combines the three individual segmentations effectively to obtain a panoptic-part segmentation. Two aspects are of utmost importance for this: First, a unified model for the three problems is desired that allows for mutually improved and consistent representation learning. Second, balancing the combination so that it gives equal importance to all individual results during fusion. Our proposed JPPF is parameter-free and dynamically balances its input. The method is evaluated and compared on the Cityscapes Panoptic Parts (CPP) and Pascal Panoptic Parts (PPP) datasets in terms of PartPQ and Part-Whole Quality (PWQ). In extensive experiments, we verify the importance of our fair fusion, highlight its most significant impact for areas that can be further segmented into parts, and demonstrate the generalization capabilities of our design without fine-tuning on 5 additional datasets.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18618"
  },
  "2311.18614": {
    "title": "Anatomy and Physiology of Artificial Intelligence in PET Imaging",
    "authors": [
      "Tyler J. Bradshaw",
      "Alan B. McMillan"
    ],
    "abstract": "The influence of artificial intelligence (AI) within the field of nuclear medicine has been rapidly growing. Many researchers and clinicians are seeking to apply AI within PET, and clinicians will soon find themselves engaging with AI-based applications all along the chain of molecular imaging, from image reconstruction to enhanced reporting. This expanding presence of AI in PET imaging will result in greater demand for educational resources for those unfamiliar with AI. The objective of this article to is provide an illustrated guide to the core principles of modern AI, with specific focus on aspects that are most likely to be encountered in PET imaging. We describe convolutional neural networks, algorithm training, and explain the components of the commonly used U-Net for segmentation and image synthesis.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18614"
  },
  "2311.18612": {
    "title": "Cancer-Net PCa-Gen: Synthesis of Realistic Prostate Diffusion Weighted Imaging Data via Anatomic-Conditional Controlled Latent Diffusion",
    "authors": [
      "Aditya Sridhar",
      "Chi-en Amy Tai",
      "Hayden Gunraj",
      "Yuhao Chen",
      "Alexander Wong"
    ],
    "abstract": "In Canada, prostate cancer is the most common form of cancer in men and accounted for 20% of new cancer cases for this demographic in 2022. Due to recent successes in leveraging machine learning for clinical decision support, there has been significant interest in the development of deep neural networks for prostate cancer diagnosis, prognosis, and treatment planning using diffusion weighted imaging (DWI) data. A major challenge hindering widespread adoption in clinical use is poor generalization of such networks due to scarcity of large-scale, diverse, balanced prostate imaging datasets for training such networks. In this study, we explore the efficacy of latent diffusion for generating realistic prostate DWI data through the introduction of an anatomic-conditional controlled latent diffusion strategy. To the best of the authors' knowledge, this is the first study to leverage conditioning for synthesis of prostate cancer imaging. Experimental results show that the proposed strategy, which we call Cancer-Net PCa-Gen, enhances synthesis of diverse prostate images through controllable tumour locations and better anatomical and textural fidelity. These crucial features make it well-suited for augmenting real patient data, enabling neural networks to be trained on a more diverse and comprehensive data distribution. The Cancer-Net PCa-Gen framework and sample images have been made publicly available at https://www.kaggle.com/datasets/deetsadi/cancer-net-pca-gen-dataset as a part of a global open-source initiative dedicated to accelerating advancement in machine learning to aid clinicians in the fight against cancer.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18612"
  },
  "2311.18609": {
    "title": "ArthModel: Enhance Arithmetic Skills to Large Language Model",
    "authors": [
      "Yingdi Guo"
    ],
    "abstract": "With the great success of ChatGPT, the research of large language models has become increasingly popular. However, the models have several limitations, such as toxicity and pool performance of arithmetic solving. Meanwhile, LLM may have some potential abilities that have yet to be exploited. In this paper, we choose a different way to enhance the arithmetic ability of LLM. We propose to train LLM to generate a postfix expression related to the arithmetic problem and incorporate it with small pretrained models. Moreover, this small model transfers the token embeddings into real dense numbers and invokes native functions of a deep learning platform to get the correct answer. To generate the final result, we propose prompt injection for adding the result outputs by the small model to LLM. This work provides different ways of thinking, training and using a language model. The codes and models will be released at \\url{https://github.com/eteced/arithmetic_finetuning_v1}.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18609"
  },
  "2311.18604": {
    "title": "Barwise Music Structure Analysis with the Correlation Block-Matching Segmentation Algorithm",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "abstract": "Music Structure Analysis (MSA) is a Music Information Retrieval task consisting of representing a song in a simplified, organized manner by breaking it down into sections typically corresponding to ``chorus'', ``verse'', ``solo'', etc. In this work, we extend an MSA algorithm called the Correlation Block-Matching (CBM) algorithm introduced by (Marmoret et al., 2020, 2022b). The CBM algorithm is a dynamic programming algorithm that segments self-similarity matrices, which are a standard description used in MSA and in numerous other applications. In this work, self-similarity matrices are computed from the feature representation of an audio signal and time is sampled at the bar-scale. This study examines three different standard similarity functions for the computation of self-similarity matrices. Results show that, in optimal conditions, the proposed algorithm achieves a level of performance which is competitive with supervised state-of-the-art methods while only requiring knowledge of bar positions. In addition, the algorithm is made open-source and is highly customizable.\n        \u25b3 Less",
    "submission_date": "30 November, 2023",
    "eprint_id": "2311.18604"
  },
  "2310.09678": {
    "title": "Tree Containment Above Minimum Degree is FPT",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Danil Sagunov",
      "Kirill Simonov"
    ],
    "abstract": "According to the classic Chv{\u00e1}tal's Lemma from 1977, a graph of minimum degree $\u03b4(G)$ contains every tree on $\u03b4(G)+1$ vertices.\n  Our main result is the following algorithmic \"extension\" of Chv\u00e1tal's Lemma: For any $n$-vertex graph $G$, integer $k$, and a tree $T$ on at most $\u03b4(G)+k$ vertices, deciding whether $G$ contains a subgraph isomorphic to $T$, can be done in time $f(k)\\cdot n^{\\mathcal{O}(1)}$ for some function $f$ of $k$ only.\n  The proof of our main result is based on an interplay between extremal graph theory and parameterized algorithms.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09678"
  },
  "2310.09675": {
    "title": "Efficient Model-Agnostic Multi-Group Equivariant Networks",
    "authors": [
      "Razan Baltaji",
      "Sourya Basu",
      "Lav R. Varshney"
    ],
    "abstract": "Constructing model-agnostic group equivariant networks, such as equitune (Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be computationally expensive for large product groups. We address this by providing efficient model-agnostic equivariant designs for two related problems: one where the network has multiple inputs each with potentially different groups acting on them, and another where there is a single input but the group acting on it is a large product group. For the first design, we initially consider a linear model and characterize the entire equivariant space that satisfies this constraint. This characterization gives rise to a novel fusion layer between different channels that satisfies an invariance-symmetry (IS) constraint, which we call an IS layer. We then extend this design beyond linear models, similar to equitune, consisting of equivariant and IS layers. We also show that the IS layer is a universal approximator of invariant-symmetric functions. Inspired by the first design, we use the notion of the IS property to design a second efficient model-agnostic equivariant design for large product groups acting on a single input. For the first design, we provide experiments on multi-image classification where each view is transformed independently with transformations such as rotations. We find equivariant models are robust to such transformations and perform competitively otherwise. For the second design, we consider three applications: language compositionality on the SCAN dataset to product groups; fairness in natural language generation from GPT-2 to address intersectionality; and robust zero-shot image classification with CLIP. Overall, our methods are simple and general, competitive with equitune and its variants, while also being computationally more efficient.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09675"
  },
  "2310.09672": {
    "title": "Towards Semi-Structured Automatic ICD Coding via Tree-based Contrastive Learning",
    "authors": [
      "Chang Lu",
      "Chandan K. Reddy",
      "Ping Wang",
      "Yue Ning"
    ],
    "abstract": "Automatic coding of International Classification of Diseases (ICD) is a multi-label text categorization task that involves extracting disease or procedure codes from clinical notes. Despite the application of state-of-the-art natural language processing (NLP) techniques, there are still challenges including limited availability of data due to privacy constraints and the high variability of clinical notes caused by different writing habits of medical professionals and various pathological features of patients. In this work, we investigate the semi-structured nature of clinical notes and propose an automatic algorithm to segment them into sections. To address the variability issues in existing ICD coding models with limited data, we introduce a contrastive pre-training approach on sections using a soft multi-label similarity metric based on tree edit distance. Additionally, we design a masked section training strategy to enable ICD coding models to locate sections related to ICD codes. Extensive experimental results demonstrate that our proposed training strategies effectively enhance the performance of existing ICD coding methods.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09672"
  },
  "2310.09671": {
    "title": "FPGA Implementation of OTFS Modulation for 6G Communication Systems",
    "authors": [
      "Murat Isik",
      "Malvin Nkomo",
      "Anup Das",
      "Kapil R. Dandekar"
    ],
    "abstract": "Sixth-generation (6G) communication systems are poised to accommodate high data-rate wireless communication services in highly dynamic channels, with applications including high-speed trains, unmanned aerial vehicles, and intelligent transportation systems. Orthogonal frequency-division multiplexing (OFDM) modulation suffers from performance degradation in such high-mobility applications due to high Doppler spread in the channel. The recently proposed Orthogonal Time Frequency Space (OTFS) modulation scheme outperforms OFDM in terms of supporting a higher transmitter (Tx) and receiver (Rx) user velocity. Additionally, the highly-dynamic time-frequency (TF) channel has little effect on OTFS modulated signals, which enables the realization of low-complexity pre-processing architectures for implementing massive-multiple input multiple outputs (MIMO) based OTFS systems. However, while OTFS has received attention in the literature from a theory and simulation perspective, there has been comparatively little work on real-time FPGA implementation of OTFS waveforms. Thus, in this paper, we first present a mathematical overview of OTFS modulation and then describe an FPGA implementation of OTFS implementation on hardware. Power, area, and timing analysis of the implemented design on a Zynq UltraScale+ RFSoC FPGA are provided for benchmarking purposes.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09671"
  },
  "2310.09668": {
    "title": "Beyond Testers' Biases: Guiding Model Testing with Knowledge Bases using LLMs",
    "authors": [
      "Chenyang Yang",
      "Rishabh Rustogi",
      "Rachel Brower-Sinning",
      "Grace A. Lewis",
      "Christian K\u00e4stner",
      "Tongshuang Wu"
    ],
    "abstract": "Current model testing work has mostly focused on creating test cases. Identifying what to test is a step that is largely ignored and poorly supported. We propose Weaver, an interactive tool that supports requirements elicitation for guiding model testing. Weaver uses large language models to generate knowledge bases and recommends concepts from them interactively, allowing testers to elicit requirements for further testing. Weaver provides rich external knowledge to testers and encourages testers to systematically explore diverse concepts beyond their own biases. In a user study, we show that both NLP experts and non-experts identified more, as well as more diverse concepts worth testing when using Weaver. Collectively, they found more than 200 failing test cases for stance detection with zero-shot ChatGPT. Our case studies further show that Weaver can help practitioners test models in real-world settings, where developers define more nuanced application scenarios (e.g., code understanding and transcript summarization) using LLMs.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09668"
  },
  "2310.09667": {
    "title": "Edge-InversionNet: Enabling Efficient Inference of InversionNet on Edge Devices",
    "authors": [
      "Zhepeng Wang",
      "Isaacshubhanand Putla",
      "Weiwen Jiang",
      "Youzuo Lin"
    ],
    "abstract": "Seismic full waveform inversion (FWI) is a widely used technique in geophysics for inferring subsurface structures from seismic data. And InversionNet is one of the most successful data-driven machine learning models that is applied to seismic FWI. However, the high computing costs to run InversionNet have made it challenging to be efficiently deployed on edge devices that are usually resource-constrained. Therefore, we propose to employ the structured pruning algorithm to get a lightweight version of InversionNet, which can make an efficient inference on edge devices. And we also made a prototype with Raspberry Pi to run the lightweight InversionNet. Experimental results show that the pruned InversionNet can achieve up to 98.2 % reduction in computing resources with moderate model performance degradation.\n        \u25b3 Less",
    "submission_date": "18 October, 2023",
    "eprint_id": "2310.09667"
  },
  "2310.09665": {
    "title": "A Blockchain-empowered Multi-Aggregator Federated Learning Architecture in Edge Computing with Deep Reinforcement Learning Optimization",
    "authors": [
      "Xiao Li",
      "Weili Wu"
    ],
    "abstract": "Federated learning (FL) is emerging as a sought-after distributed machine learning architecture, offering the advantage of model training without direct exposure of raw data. With advancements in network infrastructure, FL has been seamlessly integrated into edge computing. However, the limited resources on edge devices introduce security vulnerabilities to FL in the context. While blockchain technology promises to bolster security, practical deployment on resource-constrained edge devices remains a challenge. Moreover, the exploration of FL with multiple aggregators in edge computing is still new in the literature. Addressing these gaps, we introduce the Blockchain-empowered Heterogeneous Multi-Aggregator Federated Learning Architecture (BMA-FL). We design a novel light-weight Byzantine consensus mechanism, namely PBCM, to enable secure and fast model aggregation and synchronization in BMA-FL. We also dive into the heterogeneity problem in BMA-FL that the aggregators are associated with varied number of connected trainers with Non-IID data distributions and diverse training speed. We proposed a multi-agent deep reinforcement learning algorithm to help aggregators decide the best training strategies. The experiments on real-word datasets demonstrate the efficiency of BMA-FL to achieve better models faster than baselines, showing the efficacy of PBCM and proposed deep reinforcement learning algorithm.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09665"
  },
  "2310.09661": {
    "title": "Legend at ArAIEval Shared Task: Persuasion Technique Detection using a Language-Agnostic Text Representation Model",
    "authors": [
      "Olumide E. Ojo",
      "Olaronke O. Adebanji",
      "Hiram Calvo",
      "Damian O. Dieke",
      "Olumuyiwa E. Ojo",
      "Seye E. Akinsanya",
      "Tolulope O. Abiola",
      "Anna Feldman"
    ],
    "abstract": "In this paper, we share our best performing submission to the Arabic AI Tasks Evaluation Challenge (ArAIEval) at ArabicNLP 2023. Our focus was on Task 1, which involves identifying persuasion techniques in excerpts from tweets and news articles. The persuasion technique in Arabic texts was detected using a training loop with XLM-RoBERTa, a language-agnostic text representation model. This approach proved to be potent, leveraging fine-tuning of a multilingual language model. In our evaluation of the test set, we achieved a micro F1 score of 0.64 for subtask A of the competition.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09661"
  },
  "2310.09659": {
    "title": "HAPS in the Non-Terrestrial Network Nexus: Prospective Architectures and Performance Insights",
    "authors": [
      "Zhengying Lou",
      "Baha Eddine Youcef Belmekki",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "High altitude platform stations (HAPS) have recently emerged as a new key stratospheric player in non-terrestrial networks (NTN) alongside satellites and low-altitude platforms. In this paper, we present the main communication links between HAPS and other NTN platforms, their advantages, and their challenges. Then, prospective network architectures in which HAPS plays an indispensable role in the future NTNs are presented such as ad-hoc, cell-free, and integrated access and backhaul. To showcase the importance of HAPS in the NTN, we provide comprehensive performance insights when using HAPS in the prospective architectures with the most suitable communication link. The insights show the HAPS' ability to interconnect the NTN nexus as well as their versatility by incorporating different metrics into the analysis such as routing latency, energy efficiency, coverage probability, and channel capacity. Depending on the architecture, HAPS will play different roles in NTN, such as a UAV network center, satellite relay, and ground network extension. Finally, the performance gain provided by HAPS usage in NTN is further highlighted by comparing the results when no HAPS are used.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09659"
  },
  "2310.09658": {
    "title": "A Generalized Extensive-Form Fictitious Play Algorithm",
    "authors": [
      "Tim P. Schulze"
    ],
    "abstract": "We introduce a simple extensive-form algorithm for finding equilibria of two-player, zero-sum games. The algorithm is realization equivalent to a generalized form of Fictitious Play. We compare its performance to that of a similar extensive-form fictitious play algorithm and a counter-factual regret minimization algorithm. All three algorithms share the same advantages over normal-form fictitious play in terms of reducing storage requirements and computational complexity. The new algorithm is intuitive and straightforward to implement, making it an appealing option for those looking for a quick and easy game solving tool.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09658"
  },
  "2310.09652": {
    "title": "BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries",
    "authors": [
      "Wenjie Lv",
      "Zhen Wang",
      "Yitao Zheng",
      "Zhehua Zhong",
      "Qi Xuan",
      "Tianyi Chen"
    ],
    "abstract": "Machine learning security has recently become a prominent topic in the natural language processing (NLP) area. The existing black-box adversarial attack suffers prohibitively from the high model querying complexity, resulting in easily being captured by anti-attack monitors. Meanwhile, how to eliminate redundant model queries is rarely explored. In this paper, we propose a query-efficient approach BufferSearch to effectively attack general intelligent NLP systems with the minimal number of querying requests. In general, BufferSearch makes use of historical information and conducts statistical test to avoid incurring model queries frequently. Numerically, we demonstrate the effectiveness of BufferSearch on various benchmark text-classification experiments by achieving the competitive attacking performance but with a significant reduction of query quantity. Furthermore, BufferSearch performs multiple times better than competitors within restricted query budget. Our work establishes a strong benchmark for the future study of query-efficiency in NLP adversarial attacks.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09652"
  },
  "2310.09651": {
    "title": "Lexical Entrainment for Conversational Systems",
    "authors": [
      "Zhengxiang Shi",
      "Procheta Sen",
      "Aldo Lipani"
    ],
    "abstract": "Conversational agents have become ubiquitous in assisting with daily tasks, and are expected to possess human-like features. One such feature is lexical entrainment (LE), a phenomenon in which speakers in human-human conversations tend to naturally and subconsciously align their lexical choices with those of their interlocutors, leading to more successful and engaging conversations. As an example, if a digital assistant replies 'Your appointment for Jinling Noodle Pub is at 7 pm' to the question 'When is my reservation for Jinling Noodle Bar today?', it may feel as though the assistant is trying to correct the speaker, whereas a response of 'Your reservation for Jinling Noodle Bar is at 7 pm' would likely be perceived as more positive. This highlights the importance of LE in establishing a shared terminology for maximum clarity and reducing ambiguity in conversations. However, we demonstrate in this work that current response generation models do not adequately address this crucial humanlike phenomenon. To address this, we propose a new dataset, named MULTIWOZ-ENTR, and a measure for LE for conversational systems. Additionally, we suggest a way to explicitly integrate LE into conversational systems with two new tasks, a LE extraction task and a LE generation task. We also present two baseline approaches for the LE extraction task, which aim to detect LE expressions from dialogue contexts.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09651"
  },
  "2310.09647": {
    "title": "Point-DynRF: Point-based Dynamic Radiance Fields from a Monocular Video",
    "authors": [
      "Byeongjun Park",
      "Changick Kim"
    ],
    "abstract": "Dynamic radiance fields have emerged as a promising approach for generating novel views from a monocular video. However, previous methods enforce the geometric consistency to dynamic radiance fields only between adjacent input frames, making it difficult to represent the global scene geometry and degenerates at the viewpoint that is spatio-temporally distant from the input camera trajectory. To solve this problem, we introduce point-based dynamic radiance fields (\\textbf{Point-DynRF}), a novel framework where the global geometric information and the volume rendering process are trained by neural point clouds and dynamic radiance fields, respectively. Specifically, we reconstruct neural point clouds directly from geometric proxies and optimize both radiance fields and the geometric proxies using our proposed losses, allowing them to complement each other. We validate the effectiveness of our method with experiments on the NVIDIA Dynamic Scenes Dataset and several causally captured monocular video clips.\n        \u25b3 Less",
    "submission_date": "24 October, 2023",
    "eprint_id": "2310.09647"
  },
  "2310.09642": {
    "title": "Robot Imitation from Video Demonstration",
    "authors": [
      "Venkat Surya Teja Chereddy"
    ],
    "abstract": "This paper presents an attempt to replicate the robot imitation work conducted by Sermanet et al., with a specific focus on the experiments involving robot joint position prediction. While the original study utilized human poses to predict robot joint positions, this project aimed to achieve robot-to-robot imitation due to the challenges of obtaining human-to-robot translation data. The primary objective was to provide a neural network with robot images and have it predict end-effector positions through regression. The paper discusses the implementation process, including data collection using the open-source RoboSuite, where a Python module was developed to capture randomized action data for four different robots. Challenges in data collection, such as oscillations and limited action variety, were addressed through domain randomization. Results show high testing error and unsatisfactory imitation due to overfitting, necessitating improvements in the project.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09642"
  },
  "2310.09636": {
    "title": "Generative Adversarial Training for Text-to-Speech Synthesis Based on Raw Phonetic Input and Explicit Prosody Modelling",
    "authors": [
      "Tiberiu Boros",
      "Stefan Daniel Dumitrescu",
      "Ionut Mironica",
      "Radu Chivereanu"
    ],
    "abstract": "We describe an end-to-end speech synthesis system that uses generative adversarial training. We train our Vocoder for raw phoneme-to-audio conversion, using explicit phonetic, pitch and duration modeling. We experiment with several pre-trained models for contextualized and decontextualized word embeddings and we introduce a new method for highly expressive character voice matching, based on discreet style tokens.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09636"
  },
  "2310.09635": {
    "title": "On superqubits",
    "authors": [
      "Steven Duplij",
      "Raimund Vogl"
    ],
    "abstract": "We first reconsider the mathematical background of superqubit theory and describe important peculiarities of superspaces and supermatrices which are usually out of attention. Then we study states in super Hilbert spaces using super-bra/super-ket formalism in details. The qubit (qudit) and superqubit (superqudit) are defined as linear spans in the corresponding Hilbert subspaces. A new kind of superqubit carring the odd parity is introduced. The multi-superqubit states are studied, and the superconcurrence which distinguishes separable states is proposed.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09635"
  },
  "2310.09634": {
    "title": "An End-to-End System for Reproducibility Assessment of Source Code Repositories via Their Readmes",
    "authors": [
      "Ey\u00fcp Kaan Akdeniz",
      "Selma Tekir",
      "Malik Nizar Asad Al Hinnawi"
    ],
    "abstract": "Increased reproducibility of machine learning research has been a driving force for dramatic improvements in learning performances. The scientific community further fosters this effort by including reproducibility ratings in reviewer forms and considering them as a crucial factor for the overall evaluation of papers. Accompanying source code is not sufficient to make a work reproducible. The shared codes should meet the ML reproducibility checklist as well. This work aims to support reproducibility evaluations of papers with source codes. We propose an end-to-end system that operates on the Readme file of the source code repositories. The system checks the compliance of a given Readme to a template proposed by a widely used platform for sharing source codes of research. Our system generates scores based on a custom function to combine section scores. We also train a hierarchical transformer model to assign a class label to a given Readme. The experimental results show that the section similarity-based system performs better than the hierarchical transformer. Moreover, it has an advantage regarding explainability since one can directly relate the score to the sections of Readme files.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09634"
  },
  "2310.09633": {
    "title": "Dimma: Semi-supervised Low Light Image Enhancement with Adaptive Dimming",
    "authors": [
      "Wojciech Koz\u0142owski",
      "Micha\u0142 Szachniewicz",
      "Micha\u0142 Stypu\u0142kowski",
      "Maciej Zi\u0119ba"
    ],
    "abstract": "Enhancing low-light images while maintaining natural colors is a challenging problem due to camera processing variations and limited access to photos with ground-truth lighting conditions. The latter is a crucial factor for supervised methods that achieve good results on paired datasets but do not handle out-of-domain data well. On the other hand, unsupervised methods, while able to generalize, often yield lower-quality enhancements. To fill this gap, we propose Dimma, a semi-supervised approach that aligns with any camera by utilizing a small set of image pairs to replicate scenes captured under extreme lighting conditions taken by that specific camera. We achieve that by introducing a convolutional mixture density network that generates distorted colors of the scene based on the illumination differences. Additionally, our approach enables accurate grading of the dimming factor, which provides a wide range of control and flexibility in adjusting the brightness levels during the low-light image enhancement process. To further improve the quality of our results, we introduce an architecture based on a conditional UNet. The lightness value provided by the user serves as the conditional input to generate images with the desired lightness. Our approach using only few image pairs achieves competitive results compared to fully supervised methods. Moreover, when trained on the full dataset, our model surpasses state-of-the-art methods in some metrics and closely approaches them in others.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09633"
  },
  "2310.09632": {
    "title": "Time-based Mapping of Space Using Visual Motion Invariants",
    "authors": [
      "Juan D. Yepes",
      "Daniel Raviv"
    ],
    "abstract": "This paper focuses on visual motion-based invariants that result in a representation of 3D points in which the stationary environment remains invariant, ensuring shape constancy. This is achieved even as the images undergo constant change due to camera motion. Nonlinear functions of measurable optical flow, which are related to geometric 3D invariants, are utilized to create a novel representation. We refer to the resulting optical flow-based invariants as 'Time-Clearance' and the well-known 'Time-to-Contact' (TTC). Since these invariants remain constant over time, it becomes straightforward to detect moving points that do not adhere to the expected constancy. We present simulations of a camera moving relative to a 3D object, snapshots of its projected images captured by a rectilinearly moving camera, and the object as it appears unchanged in the new domain over time. In addition, Unity-based simulations demonstrate color-coded transformations of a projected 3D scene, illustrating how moving objects can be readily identified. This representation is straightforward, relying on simple optical flow functions. It requires only one camera, and there is no need to determine the magnitude of the camera's velocity vector. Furthermore, the representation is pixel-based, making it suitable for parallel processing.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09632"
  },
  "2310.09631": {
    "title": "Landslide Topology Uncovers Failure Movements",
    "authors": [
      "Kamal Rana",
      "Kushanav Bhuyan",
      "Joaquin Vicente Ferrer",
      "Fabrice Cotton",
      "Ugur Ozturk",
      "Filippo Catani",
      "Nishant Malik"
    ],
    "abstract": "The death toll and monetary damages from landslides continue to rise despite advancements in predictive modeling. The predictive capability of these models is limited as landslide databases used in training and assessing the models often have crucial information missing, such as underlying failure types. Here, we present an approach for identifying failure types based on their movements, e.g., slides and flows by leveraging 3D landslide topology. We observe topological proxies reveal prevalent signatures of mass movement mechanics embedded in the landslide's morphology or shape, such as detecting coupled movement styles within complex landslides. We find identical failure types exhibit similar topological properties, and by using them as predictors, we can identify failure types in historic and event-specific landslide databases (including multi-temporal) from various geomorphological and climatic contexts such as Italy, the US Pacific Northwest region, Denmark, Turkey, and China with 80 to 94 % accuracy. To demonstrate the real-world application of the method, we implement it in two undocumented datasets from China and publicly release the datasets. These new insights can considerably improve the performance of landslide predictive models and impact assessments. Moreover, our work introduces a new paradigm for studying landslide shapes to understand underlying processes through the lens of landslide topology.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09631"
  },
  "2310.09630": {
    "title": "Real-Time Traffic Sign Detection: A Case Study in a Santa Clara Suburban Neighborhood",
    "authors": [
      "Harish Loghashankar",
      "Hieu Nguyen"
    ],
    "abstract": "This research project aims to develop a real-time traffic sign detection system using the YOLOv5 architecture and deploy it for efficient traffic sign recognition during a drive in a suburban neighborhood. The project's primary objectives are to train the YOLOv5 model on a diverse dataset of traffic sign images and deploy the model on a suitable hardware platform capable of real-time inference. The project will involve collecting a comprehensive dataset of traffic sign images. By leveraging the trained YOLOv5 model, the system will detect and classify traffic signs from a real-time camera on a dashboard inside a vehicle. The performance of the deployed system will be evaluated based on its accuracy in detecting traffic signs, real-time processing speed, and overall reliability. During a case study in a suburban neighborhood, the system demonstrated a notable 96% accuracy in detecting traffic signs. This research's findings have the potential to improve road safety and traffic management by providing timely and accurate real-time information about traffic signs and can pave the way for further research into autonomous driving.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09630"
  },
  "2310.09629": {
    "title": "Adaptive Online Replanning with Diffusion Models",
    "authors": [
      "Siyuan Zhou",
      "Yilun Du",
      "Shun Zhang",
      "Mengdi Xu",
      "Yikang Shen",
      "Wei Xiao",
      "Dit-Yan Yeung",
      "Chuang Gan"
    ],
    "abstract": "Diffusion models have risen as a promising approach to data-driven planning, and have demonstrated impressive robotic control, reinforcement learning, and video planning performance. Given an effective planner, an important question to consider is replanning -- when given plans should be regenerated due to both action execution error and external environment changes. Direct plan execution, without replanning, is problematic as errors from individual actions rapidly accumulate and environments are partially observable and stochastic. Simultaneously, replanning at each timestep incurs a substantial computational cost, and may prevent successful task execution, as different generated plans prevent consistent progress to any particular goal. In this paper, we explore how we may effectively replan with diffusion models. We propose a principled approach to determine when to replan, based on the diffusion model's estimated likelihood of existing generated plans. We further present an approach to replan existing trajectories to ensure that new plans follow the same goal state as the original trajectory, which may efficiently bootstrap off previously generated plans. We illustrate how a combination of our proposed additions significantly improves the performance of diffusion planners leading to 38\\% gains over past diffusion planning approaches on Maze2D, and further enables the handling of stochastic and long-horizon robotic control tasks. Videos can be found on the anonymous website: \\url{https://vis-www.cs.umass.edu/replandiffuser/}.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09629"
  },
  "2310.09628": {
    "title": "Federated Battery Diagnosis and Prognosis",
    "authors": [
      "Nur Banu Altinpulluk",
      "Deniz Altinpulluk",
      "Paritosh Ramanan",
      "Noah Paulson",
      "Feng Qiu",
      "Susan Babinec",
      "Murat Yildirim"
    ],
    "abstract": "Battery diagnosis, prognosis and health management models play a critical role in the integration of battery systems in energy and mobility fields. However, large-scale deployment of these models is hindered by a myriad of challenges centered around data ownership, privacy, communication, and processing. State-of-the-art battery diagnosis and prognosis methods require centralized collection of data, which further aggravates these challenges. Here we propose a federated battery prognosis model, which distributes the processing of battery standard current-voltage-time-usage data in a privacy-preserving manner. Instead of exchanging raw standard current-voltage-time-usage data, our model communicates only the model parameters, thus reducing communication load and preserving data confidentiality. The proposed model offers a paradigm shift in battery health management through privacy-preserving distributed methods for battery data processing and remaining lifetime prediction.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09628"
  },
  "2310.09627": {
    "title": "Detecting Moving Objects Using a Novel Optical-Flow-Based Range-Independent Invariant",
    "authors": [
      "Daniel Raviv",
      "Juan D. Yepes",
      "Ayush Gowda"
    ],
    "abstract": "This paper focuses on a novel approach for detecting moving objects during camera motion. We present an optical-flow-based transformation that yields a consistent 2D invariant image output regardless of time instants, range of points in 3D, and the speed of the camera. In other words, this transformation generates a lookup image that remains invariant despite the changing projection of the 3D scene and camera motion. In the new domain, projections of 3D points that deviate from the values of the predefined lookup image can be clearly identified as moving relative to the stationary 3D environment, making them seamlessly detectable. The method does not require prior knowledge of the direction of motion or speed of the camera, nor does it necessitate 3D point range information. It is well-suited for real-time parallel processing, rendering it highly practical for implementation. We have validated the effectiveness of the new domain through simulations and experiments, demonstrating its robustness in scenarios involving rectilinear camera motion, both in simulations and with real-world data. This approach introduces new ways for moving objects detection during camera motion, and also lays the foundation for future research in the context of moving object detection during six-degrees-of-freedom camera motion.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09627"
  },
  "2310.09626": {
    "title": "Current and Future Challenges in Humanoid Robotics -- An Empirical Investigation",
    "authors": [
      "Maike Paetzel-Pr\u00fcsmann",
      "Alessandra Rossi",
      "Merel Keijsers"
    ],
    "abstract": "The goal of RoboCup is to make research in the area of robotics measurable over time, and grow a community that works together to solve increasingly difficult challenges over the years. The most ambitious of these challenges it to be able to play against the human world champions in soccer in 2050. To better understand what members of the RoboCup community believes to be the state of the art and the main challenges in the next decade and towards the 2050 game, we developed a survey and distributed it to members of different experience level and background within the community. We present data from 39 responses. Results highlighted that locomotion, awareness and decision-making, and robustness of robots are among those considered of high importance for the community, while human-robot interaction and natural language processing and generation are rated of low in importance and difficulty.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09626"
  },
  "2310.09625": {
    "title": "JSMoCo: Joint Coil Sensitivity and Motion Correction in Parallel MRI with a Self-Calibrating Score-Based Diffusion Model",
    "authors": [
      "Lixuan Chen",
      "Xuanyu Tian",
      "Jiangjie Wu",
      "Ruimin Feng",
      "Guoyan Lao",
      "Yuyao Zhang",
      "Hongjiang Wei"
    ],
    "abstract": "Magnetic Resonance Imaging (MRI) stands as a powerful modality in clinical diagnosis. However, it is known that MRI faces challenges such as long acquisition time and vulnerability to motion-induced artifacts. Despite the success of many existing motion correction algorithms, there has been limited research focused on correcting motion artifacts on the estimated coil sensitivity maps for fast MRI reconstruction. Existing methods might suffer from severe performance degradation due to error propagation resulting from the inaccurate coil sensitivity maps estimation. In this work, we propose to jointly estimate the motion parameters and coil sensitivity maps for under-sampled MRI reconstruction, referred to as JSMoCo. However, joint estimation of motion parameters and coil sensitivities results in a highly ill-posed inverse problem due to an increased number of unknowns. To address this, we introduce score-based diffusion models as powerful priors and leverage the MRI physical principles to efficiently constrain the solution space for this optimization problem. Specifically, we parameterize the rigid motion as three trainable variables and model coil sensitivity maps as polynomial functions. Leveraging the physical knowledge, we then employ Gibbs sampler for joint estimation, ensuring system consistency between sensitivity maps and desired images, avoiding error propagation from pre-estimated sensitivity maps to the reconstructed images. We conduct comprehensive experiments to evaluate the performance of JSMoCo on the fastMRI dataset. The results show that our method is capable of reconstructing high-quality MRI images from sparsely-sampled k-space data, even affected by motion. It achieves this by accurately estimating both motion parameters and coil sensitivities, effectively mitigating motion-related challenges during MRI reconstruction.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09625"
  },
  "2310.09624": {
    "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the Robustness of Large Language Models",
    "authors": [
      "Alex Mei",
      "Sharon Levy",
      "William Yang Wang"
    ],
    "abstract": "As large language models are integrated into society, robustness toward a suite of prompts is increasingly important to maintain reliability in a high-variance environment.Robustness evaluations must comprehensively encapsulate the various settings in which a user may invoke an intelligent system. This paper proposes ASSERT, Automated Safety Scenario Red Teaming, consisting of three methods -- semantically aligned augmentation, target bootstrapping, and adversarial knowledge injection. For robust safety evaluation, we apply these methods in the critical domain of AI safety to algorithmically generate a test suite of prompts covering diverse robustness settings -- semantic equivalence, related scenarios, and adversarial. We partition our prompts into four safety domains for a fine-grained analysis of how the domain affects model performance. Despite dedicated safeguards in existing state-of-the-art models, we find statistically significant performance differences of up to 11% in absolute classification accuracy among semantically related scenarios and error rates of up to 19% absolute error in zero-shot adversarial settings, raising concerns for users' physical safety.\n        \u25b3 Less",
    "submission_date": "11 November, 2023",
    "eprint_id": "2310.09624"
  },
  "2310.09623": {
    "title": "A Digital Language Coherence Marker for Monitoring Dementia",
    "authors": [
      "Dimitris Gkoumas",
      "Adam Tsakalidis",
      "Maria Liakata"
    ],
    "abstract": "The use of spontaneous language to derive appropriate digital markers has become an emergent, promising and non-intrusive method to diagnose and monitor dementia. Here we propose methods to capture language coherence as a cost-effective, human-interpretable digital marker for monitoring cognitive changes in people with dementia. We introduce a novel task to learn the temporal logical consistency of utterances in short transcribed narratives and investigate a range of neural approaches. We compare such language coherence patterns between people with dementia and healthy controls and conduct a longitudinal evaluation against three clinical bio-markers to investigate the reliability of our proposed digital coherence marker. The coherence marker shows a significant difference between people with mild cognitive impairment, those with Alzheimer's Disease and healthy controls. Moreover our analysis shows high association between the coherence marker and the clinical bio-markers as well as generalisability potential to other related conditions.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09623"
  },
  "2310.09621": {
    "title": "Prime Match: A Privacy-Preserving Inventory Matching System",
    "authors": [
      "Antigoni Polychroniadou",
      "Gilad Asharov",
      "Benjamin Diamond",
      "Tucker Balch",
      "Hans Buehler",
      "Richard Hua",
      "Suwen Gu",
      "Greg Gimler",
      "Manuela Veloso"
    ],
    "abstract": "Inventory matching is a standard mechanism/auction for trading financial stocks by which buyers and sellers can be paired. In the financial world, banks often undertake the task of finding such matches between their clients. The related stocks can be traded without adversely impacting the market price for either client. If matches between clients are found, the bank can offer the trade at advantageous rates. If no match is found, the parties have to buy or sell the stock in the public market, which introduces additional costs. A problem with the process as it is presently conducted is that the involved parties must share their order to buy or sell a particular stock, along with the intended quantity (number of shares), to the bank. Clients worry that if this information were to leak somehow, then other market participants would become aware of their intentions and thus cause the price to move adversely against them before their transaction finalizes. We provide a solution, Prime Match, that enables clients to match their orders efficiently with reduced market impact while maintaining privacy. In the case where there are no matches, no information is revealed. Our main cryptographic innovation is a two-round secure linear comparison protocol for computing the minimum between two quantities without preprocessing and with malicious security, which can be of independent interest. We report benchmarks of our Prime Match system, which runs in production and is adopted by J.P. Morgan. The system is designed utilizing a star topology network, which provides clients with a centralized node (the bank) as an alternative to the idealized assumption of point-to-point connections, which would be impractical and undesired for the clients to implement in reality. Prime Match is the first secure multiparty computation solution running live in the traditional financial world.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09621"
  },
  "2310.09620": {
    "title": "Machine Learning for Urban Air Quality Analytics: A Survey",
    "authors": [
      "Jindong Han",
      "Weijia Zhang",
      "Hao Liu",
      "Hui Xiong"
    ],
    "abstract": "The increasing air pollution poses an urgent global concern with far-reaching consequences, such as premature mortality and reduced crop yield, which significantly impact various aspects of our daily lives. Accurate and timely analysis of air pollution is crucial for understanding its underlying mechanisms and implementing necessary precautions to mitigate potential socio-economic losses. Traditional analytical methodologies, such as atmospheric modeling, heavily rely on domain expertise and often make simplified assumptions that may not be applicable to complex air pollution problems. In contrast, Machine Learning (ML) models are able to capture the intrinsic physical and chemical rules by automatically learning from a large amount of historical observational data, showing great promise in various air quality analytical tasks. In this article, we present a comprehensive survey of ML-based air quality analytics, following a roadmap spanning from data acquisition to pre-processing, and encompassing various analytical tasks such as pollution pattern mining, air quality inference, and forecasting. Moreover, we offer a systematic categorization and summary of existing methodologies and applications, while also providing a list of publicly available air quality datasets to ease the research in this direction. Finally, we identify several promising future research directions. This survey can serve as a valuable resource for professionals seeking suitable solutions for their specific challenges and advancing their research at the cutting edge.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09620"
  },
  "2310.09619": {
    "title": "An Expression Tree Decoding Strategy for Mathematical Equation Generation",
    "authors": [
      "Wenqi Zhang",
      "Yongliang Shen",
      "Qingpeng Nong",
      "Zeqi Tan",
      "Yanna Ma",
      "Weiming Lu"
    ],
    "abstract": "Generating mathematical equations from natural language requires an accurate understanding of the relations among math expressions. Existing approaches can be broadly categorized into token-level and expression-level generation. The former treats equations as a mathematical language, sequentially generating math tokens. Expression-level methods generate each expression one by one. However, each expression represents a solving step, and there naturally exist parallel or dependent relations between these steps, which are ignored by current sequential methods. Therefore, we integrate tree structure into the expression-level generation and advocate an expression tree decoding strategy. To generate a tree with expression as its node, we employ a layer-wise parallel decoding strategy: we decode multiple independent expressions (leaf nodes) in parallel at each layer and repeat parallel decoding layer by layer to sequentially generate these parent node expressions that depend on others. Besides, a bipartite matching algorithm is adopted to align multiple predictions with annotations for each layer. Experiments show our method outperforms other baselines, especially for these equations with complex structures.\n        \u25b3 Less",
    "submission_date": "18 October, 2023",
    "eprint_id": "2310.09619"
  },
  "2310.09618": {
    "title": "Moral consensus and divergence in partisan language use",
    "authors": [
      "Nakwon Rim",
      "Marc G. Berman",
      "Yuan Chang Leong"
    ],
    "abstract": "Polarization has increased substantially in political discourse, contributing to a widening partisan divide. In this paper, we analyzed large-scale, real-world language use in Reddit communities (294,476,146 comments) and in news outlets (6,749,781 articles) to uncover psychological dimensions along which partisan language is divided. Using word embedding models that captured semantic associations based on co-occurrences of words in vast textual corpora, we identified patterns of affective polarization present in natural political discourse. We then probed the semantic associations of words related to seven political topics (e.g., abortion, immigration) along the dimensions of morality (moral-to-immoral), threat (threatening-to-safe), and valence (pleasant-to-unpleasant). Across both Reddit communities and news outlets, we identified a small but systematic divergence in the moral associations of words between text sources with different partisan leanings. Moral associations of words were highly correlated between conservative and liberal text sources (average $\u03c1$ = 0.96), but the differences remained reliable to enable us to distinguish text sources along partisan lines with above 85% classification accuracy. These findings underscore that despite a shared moral understanding across the political spectrum, there are consistent differences that shape partisan language and potentially exacerbate political polarization. Our results, drawn from both informal interactions on social media and curated narratives in news outlets, indicate that these trends are widespread. Leveraging advanced computational techniques, this research offers a fresh perspective that complements traditional methods in political attitudes.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09618"
  },
  "2310.09615": {
    "title": "STORM: Efficient Stochastic Transformer based World Models for Reinforcement Learning",
    "authors": [
      "Weipu Zhang",
      "Gang Wang",
      "Jian Sun",
      "Yetian Yuan",
      "Gao Huang"
    ],
    "abstract": "Recently, model-based reinforcement learning algorithms have demonstrated remarkable efficacy in visual input environments. These approaches begin by constructing a parameterized simulation world model of the real environment through self-supervised learning. By leveraging the imagination of the world model, the agent's policy is enhanced without the constraints of sampling from the real environment. The performance of these algorithms heavily relies on the sequence modeling and generation capabilities of the world model. However, constructing a perfectly accurate model of a complex unknown environment is nearly impossible. Discrepancies between the model and reality may cause the agent to pursue virtual goals, resulting in subpar performance in the real environment. Introducing random noise into model-based reinforcement learning has been proven beneficial. In this work, we introduce Stochastic Transformer-based wORld Model (STORM), an efficient world model architecture that combines the strong sequence modeling and generation capabilities of Transformers with the stochastic nature of variational autoencoders. STORM achieves a mean human performance of $126.7\\%$ on the Atari $100$k benchmark, setting a new record among state-of-the-art methods that do not employ lookahead search techniques. Moreover, training an agent with $1.85$ hours of real-time interaction experience on a single NVIDIA GeForce RTX 3090 graphics card requires only $4.3$ hours, showcasing improved efficiency compared to previous methodologies.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09615"
  },
  "2310.09613": {
    "title": "Combinatorial Group Testing in Presence of Deletions",
    "authors": [
      "Venkata Gandikota",
      "Nikita Polyanskii",
      "Haodong Yang"
    ],
    "abstract": "The study in group testing aims to develop strategies to identify a small set of defective items among a large population using a few pooled tests. The established techniques have been highly beneficial in a broad spectrum of applications ranging from channel communication to identifying COVID-19-infected individuals efficiently. Despite significant research on group testing and its variants since the 1940s, testing strategies robust to deletion noise have yet to be studied. Many practical systems exhibit deletion errors, for instance, in wireless communication and data storage systems. Such deletions of test outcomes lead to asynchrony between the tests, which the current group testing strategies cannot handle. In this work, we initiate the study of non-adaptive group testing strategies resilient to deletion noise. We characterize the necessary and sufficient conditions to successfully identify the defective items even after the adversarial deletion of certain test outputs. We also provide constructions of testing matrices along with an efficient recovery algorithm.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09613"
  },
  "2310.09612": {
    "title": "Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations",
    "authors": [
      "Alexa R. Tartaglini",
      "Sheridan Feucht",
      "Michael A. Lepori",
      "Wai Keen Vong",
      "Charles Lovering",
      "Brenden M. Lake",
      "Ellie Pavlick"
    ],
    "abstract": "Although deep neural networks can achieve human-level performance on many object recognition benchmarks, prior work suggests that these same models fail to learn simple abstract relations, such as determining whether two objects are the same or different. Much of this prior work focuses on training convolutional neural networks to classify images of two same or two different abstract shapes, testing generalization on within-distribution stimuli. In this article, we comprehensively study whether deep neural networks can acquire and generalize same-different relations both within and out-of-distribution using a variety of architectures, forms of pretraining, and fine-tuning datasets. We find that certain pretrained transformers can learn a same-different relation that generalizes with near perfect accuracy to out-of-distribution stimuli. Furthermore, we find that fine-tuning on abstract shapes that lack texture or color provides the strongest out-of-distribution generalization. Our results suggest that, with the right approach, deep neural networks can learn generalizable same-different visual relations.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09612"
  },
  "2310.09609": {
    "title": "Towards Intelligent Network Management: Leveraging AI for Network Service Detection",
    "authors": [
      "Khuong N. Nguyen",
      "Abhishek Sehgal",
      "Yuming Zhu",
      "Junsu Choi",
      "Guanbo Chen",
      "Hao Chen",
      "Boon Loong Ng",
      "Charlie Zhang"
    ],
    "abstract": "As the complexity and scale of modern computer networks continue to increase, there has emerged an urgent need for precise traffic analysis, which plays a pivotal role in cutting-edge wireless connectivity technologies. This study focuses on leveraging Machine Learning methodologies to create an advanced network traffic classification system. We introduce a novel data-driven approach that excels in identifying various network service types in real-time, by analyzing patterns within the network traffic. Our method organizes similar kinds of network traffic into distinct categories, referred to as network services, based on latency requirement. Furthermore, it decomposes the network traffic stream into multiple, smaller traffic flows, with each flow uniquely carrying a specific service. Our ML models are trained on a dataset comprised of labeled examples representing different network service types collected on various Wi-Fi network conditions. Upon evaluation, our system demonstrates a remarkable accuracy in distinguishing the network services. These results emphasize the substantial promise of integrating Artificial Intelligence in wireless technologies. Such an approach encourages more efficient energy consumption, enhances Quality of Service assurance, and optimizes the allocation of network resources, thus laying a solid groundwork for the development of advanced intelligent networks.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09609"
  },
  "2310.09607": {
    "title": "Analysis of the Penetration of 5G Wireless RF-EMF on Human Skin",
    "authors": [
      "N. Annalakshmi",
      "S. Umarani"
    ],
    "abstract": "New wireless mobile technology has been released every ten years, improving previous generations' facilities. Even though 5G supports many services on demand nowadays, its higher radiation increases the queries about the safety of humans and other living things. The health effects related to EMF of 5G is still under in discussion. Number of health organizations such as ICNIRP, FCC and WHO have specified the 5G safety guidelines and suggested the minimum distance between UE and BS. But this is unsafe for humans while using high frequencies. The unique position and functions of the skin are not considered by the most recent revisions to the ICNIRP exposure limits. Although 5G radiation has an impact on biological matter, a connection between physiological consequences and health issues is not being investigated. It is time to establish a task force to clarify the consequences of 5G radiation on the skin and overall health, and to change exposure restrictions as necessary. This paper investigates the human Electro Magnetic Field (EMF) exposure from 5G wireless communication. It analyzes the impact of the penetration level of EMF in human skin at 28GHz using the Specific Absorption Rate metric and discusses the reduction of EMF exposure level of 5G.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09607"
  },
  "2310.09604": {
    "title": "Learning Hierarchical Features with Joint Latent Space Energy-Based Prior",
    "authors": [
      "Jiali Cui",
      "Ying Nian Wu",
      "Tian Han"
    ],
    "abstract": "This paper studies the fundamental problem of multi-layer generator models in learning hierarchical representations. The multi-layer generator model that consists of multiple layers of latent variables organized in a top-down architecture tends to learn multiple levels of data abstraction. However, such multi-layer latent variables are typically parameterized to be Gaussian, which can be less informative in capturing complex abstractions, resulting in limited success in hierarchical representation learning. On the other hand, the energy-based (EBM) prior is known to be expressive in capturing the data regularities, but it often lacks the hierarchical structure to capture different levels of hierarchical representations. In this paper, we propose a joint latent space EBM prior model with multi-layer latent variables for effective hierarchical representation learning. We develop a variational joint learning scheme that seamlessly integrates an inference model for efficient inference. Our experiments demonstrate that the proposed joint EBM prior is effective and expressive in capturing hierarchical representations and modelling data distribution.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09604"
  },
  "2310.09603": {
    "title": "B-Spine: Learning B-Spline Curve Representation for Robust and Interpretable Spinal Curvature Estimation",
    "authors": [
      "Hao Wang",
      "Qiang Song",
      "Ruofeng Yin",
      "Rui Ma",
      "Yizhou Yu",
      "Yi Chang"
    ],
    "abstract": "Spinal curvature estimation is important to the diagnosis and treatment of the scoliosis. Existing methods face several issues such as the need of expensive annotations on the vertebral landmarks and being sensitive to the image quality. It is challenging to achieve robust estimation and obtain interpretable results, especially for low-quality images which are blurry and hazy. In this paper, we propose B-Spine, a novel deep learning pipeline to learn B-spline curve representation of the spine and estimate the Cobb angles for spinal curvature estimation from low-quality X-ray images. Given a low-quality input, a novel SegRefine network which employs the unpaired image-to-image translation is proposed to generate a high quality spine mask from the initial segmentation result. Next, a novel mask-based B-spline prediction model is proposed to predict the B-spline curve for the spine centerline. Finally, the Cobb angles are estimated by a hybrid approach which combines the curve slope analysis and a curve-based regression model. We conduct quantitative and qualitative comparisons with the representative and SOTA learning-based methods on the public AASCE2019 dataset and our new proposed CJUH-JLU dataset which contains more challenging low-quality images. The superior performance on both datasets shows our method can achieve both robustness and interpretability for spinal curvature estimation.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09603"
  },
  "2310.09600": {
    "title": "Hawkeye: A PyTorch-based Library for Fine-Grained Image Recognition with Deep Learning",
    "authors": [
      "Jiabei He",
      "Yang Shen",
      "Xiu-Shen Wei",
      "Ye Wu"
    ],
    "abstract": "Fine-Grained Image Recognition (FGIR) is a fundamental and challenging task in computer vision and multimedia that plays a crucial role in Intellectual Economy and Industrial Internet applications. However, the absence of a unified open-source software library covering various paradigms in FGIR poses a significant challenge for researchers and practitioners in the field. To address this gap, we present Hawkeye, a PyTorch-based library for FGIR with deep learning. Hawkeye is designed with a modular architecture, emphasizing high-quality code and human-readable configuration, providing a comprehensive solution for FGIR tasks. In Hawkeye, we have implemented 16 state-of-the-art fine-grained methods, covering 6 different paradigms, enabling users to explore various approaches for FGIR. To the best of our knowledge, Hawkeye represents the first open-source PyTorch-based library dedicated to FGIR. It is publicly available at https://github.com/Hawkeye-FineGrained/Hawkeye/, providing researchers and practitioners with a powerful tool to advance their research and development in the field of FGIR.\n        \u25b3 Less",
    "submission_date": "24 November, 2023",
    "eprint_id": "2310.09600"
  },
  "2310.09593": {
    "title": "Context-aware Session-based Recommendation with Graph Neural Networks",
    "authors": [
      "Zhihui Zhang",
      "JianXiang Yu",
      "Xiang Li"
    ],
    "abstract": "Session-based recommendation (SBR) is a task that aims to predict items based on anonymous sequences of user behaviors in a session. While there are methods that leverage rich context information in sessions for SBR, most of them have the following limitations: 1) they fail to distinguish the item-item edge types when constructing the global graph for exploiting cross-session contexts; 2) they learn a fixed embedding vector for each item, which lacks the flexibility to reflect the variation of user interests across sessions; 3) they generally use the one-hot encoded vector of the target item as the hard label to predict, thus failing to capture the true user preference. To solve these issues, we propose CARES, a novel context-aware session-based recommendation model with graph neural networks, which utilizes different types of contexts in sessions to capture user interests. Specifically, we first construct a multi-relation cross-session graph to connect items according to intra- and cross-session item-level contexts. Further, to encode the variation of user interests, we design personalized item representations. Finally, we employ a label collaboration strategy for generating soft user preference distribution as labels. Experiments on three benchmark datasets demonstrate that CARES consistently outperforms state-of-the-art models in terms of P@20 and MRR@20. Our data and codes are publicly available at https://github.com/brilliantZhang/CARES.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09593"
  },
  "2310.09590": {
    "title": "Solving Math Word Problems with Reexamination",
    "authors": [
      "Yi Bin",
      "Wenhao Shi",
      "Yujuan Ding",
      "Yang Yang",
      "See-Kiong Ng"
    ],
    "abstract": "Math word problem (MWP) solving aims to understand the descriptive math problem and calculate the result, for which previous efforts are mostly devoted to upgrade different technical modules. This paper brings a different perspective of \\textit{reexamination process} during training by introducing a pseudo-dual task to enhance the MWP solving. We propose a pseudo-dual (PseDual) learning scheme to model such process, which is model-agnostic thus can be adapted to any existing MWP solvers. The pseudo-dual task is specifically defined as filling the numbers in the expression back into the original word problem with numbers masked. To facilitate the effective joint learning of the two tasks, we further design a scheduled fusion strategy for the number infilling task, which smoothly switches the input from the ground-truth math expressions to the predicted ones. Our pseudo-dual learning scheme has been tested and proven effective when being equipped in several representative MWP solvers through empirical studies. \\textit{The codes and trained models are available at:} \\url{https://github.com/steven640pixel/PsedualMWP}. \\end{abstract}\n        \u25b3 Less",
    "submission_date": "19 November, 2023",
    "eprint_id": "2310.09590"
  },
  "2310.09589": {
    "title": "Airborne Sense and Detect of Drones using LiDAR and adapted PointPillars DNN",
    "authors": [
      "Manduhu Manduhu",
      "Alexander Dow",
      "Petar Trslic",
      "Gerard Dooly",
      "Benjamin Blanck",
      "James Riordan"
    ],
    "abstract": "The safe operation of drone swarms beyond visual line of sight requires multiple safeguards to mitigate the risk of collision between drones flying in hyper localised scenarios. Cooperative navigation and flight coordination strategies that rely on pre-planned trajectories and require constant network connectivity are brittle to failure. Drone embedded sense and detect offers a comprehensive mode of separation between drones for deconfliction and collision avoidance. This paper presents the first airborne LiDAR based solution for drone-swarm detection and localisation using 3D deep learning. It adapts and embeds the PointPillars deep learning neural network on the drone. To collect training data of close-quarter multi drone operations and safety critical scenarios, a scenario Digital Twin is used to augment real datasets with high fidelity synthetic data. The method has been validated in real-world tests. The trained model achieves over 80% recall and 96% precision when tested on real datasets. By incorporating a detection-by-tracking algorithm the system can reliably monitor the separation distance of multiple drones in challenging environments.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09589"
  },
  "2310.09586": {
    "title": "Causality and Independence Enhancement for Biased Node Classification",
    "authors": [
      "Guoxin Chen",
      "Yongqing Wang",
      "Fangda Guo",
      "Qinglang Guo",
      "Jiangli Shao",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Most existing methods that address out-of-distribution (OOD) generalization for node classification on graphs primarily focus on a specific type of data biases, such as label selection bias or structural bias. However, anticipating the type of bias in advance is extremely challenging, and designing models solely for one specific type may not necessarily improve overall generalization performance. Moreover, limited research has focused on the impact of mixed biases, which are more prevalent and demanding in real-world scenarios. To address these limitations, we propose a novel Causality and Independence Enhancement (CIE) framework, applicable to various graph neural networks (GNNs). Our approach estimates causal and spurious features at the node representation level and mitigates the influence of spurious correlations through the backdoor adjustment. Meanwhile, independence constraint is introduced to improve the discriminability and stability of causal and spurious features in complex biased environments. Essentially, CIE eliminates different types of data biases from a unified perspective, without the need to design separate methods for each bias as before. To evaluate the performance under specific types of data biases, mixed biases, and low-resource scenarios, we conducted comprehensive experiments on five publicly available datasets. Experimental results demonstrate that our approach CIE not only significantly enhances the performance of GNNs but outperforms state-of-the-art debiased node classification methods.\n        \u25b3 Less",
    "submission_date": "4 November, 2023",
    "eprint_id": "2310.09586"
  },
  "2310.09578": {
    "title": "Sparse Index Tracking via Topological Learning",
    "authors": [
      "Anubha Goel",
      "Puneet Pasricha",
      "Juho Kanniainen"
    ],
    "abstract": "In this research, we introduce a novel methodology for the index tracking problem with sparse portfolios by leveraging topological data analysis (TDA). Utilizing persistence homology to measure the riskiness of assets, we introduce a topological method for data-driven learning of the parameters for regularization terms. Specifically, the Vietoris-Rips filtration method is utilized to capture the intricate topological features of asset movements, providing a robust framework for portfolio tracking. Our approach has the advantage of accommodating both $\\ell_1$ and $\\ell_2$ penalty terms without the requirement for expensive estimation procedures. We empirically validate the performance of our methodology against state-of-the-art sparse index tracking techniques, such as Elastic-Net and SLOPE, using a dataset that covers 23 years of S&P500 index and its constituent data. Our out-of-sample results show that this computationally efficient technique surpasses conventional methods across risk metrics, risk-adjusted performance, and trading expenses in varied market conditions. Furthermore, in turbulent markets, it not only maintains but also enhances tracking performance.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09578"
  },
  "2310.09573": {
    "title": "Self-Detoxifying Language Models via Toxification Reversal",
    "authors": [
      "Chak Tou Leong",
      "Yi Cheng",
      "Jiashuo Wang",
      "Jian Wang",
      "Wenjie Li"
    ],
    "abstract": "Language model detoxification aims to minimize the risk of generating offensive or harmful content in pretrained language models (PLMs) for safer deployment. Existing methods can be roughly categorized as finetuning-based and decoding-based. However, the former is often resource-intensive, while the latter relies on additional components and potentially compromises the generation fluency. In this paper, we propose a more lightweight approach that enables the PLM itself to achieve \"self-detoxification\". Our method is built upon the observation that prepending a negative steering prompt can effectively induce PLMs to generate toxic content. At the same time, we are inspired by the recent research in the interpretability field, which formulates the evolving contextualized representations within the PLM as an information stream facilitated by the attention layers. Drawing on this idea, we devise a method to identify the toxification direction from the normal generation process to the one prompted with the negative prefix, and then steer the generation to the reversed direction by manipulating the information movement within the attention layers. Experimental results show that our approach, without any fine-tuning or extra components, can achieve comparable performance with state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09573"
  },
  "2310.09571": {
    "title": "On the Feasibility of Cross-Language Detection of Malicious Packages in npm and PyPI",
    "authors": [
      "Piergiorgio Ladisa",
      "Serena Elisa Ponta",
      "Nicola Ronzoni",
      "Matias Martinez",
      "Olivier Barais"
    ],
    "abstract": "Current software supply chains heavily rely on open-source packages hosted in public repositories. Given the popularity of ecosystems like npm and PyPI, malicious users started to spread malware by publishing open-source packages containing malicious code. Recent works apply machine learning techniques to detect malicious packages in the npm ecosystem. However, the scarcity of samples poses a challenge to the application of machine learning techniques in other ecosystems. Despite the differences between JavaScript and Python, the open-source software supply chain attacks targeting such languages show noticeable similarities (e.g., use of installation scripts, obfuscated strings, URLs).\n  In this paper, we present a novel approach that involves a set of language-independent features and the training of models capable of detecting malicious packages in npm and PyPI by capturing their commonalities. This methodology allows us to train models on a diverse dataset encompassing multiple languages, thereby overcoming the challenge of limited sample availability. We evaluate the models both in a controlled experiment (where labels of data are known) and in the wild by scanning newly uploaded packages for both npm and PyPI for 10 days.\n  We find that our approach successfully detects malicious packages for both npm and PyPI. Over an analysis of 31,292 packages, we reported 58 previously unknown malicious packages (38 for npm and 20 for PyPI), which were consequently removed from the respective repositories.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09571"
  },
  "2310.09570": {
    "title": "Energy-Efficient Multi-Codec Bitrate-Ladder Estimation for Adaptive Video Streaming",
    "authors": [
      "Vignesh V Menon",
      "Reza Farahani",
      "Prajit T Rajendran",
      "Samira Afzal",
      "Klaus Schoeffmann",
      "Christian Timmerer"
    ],
    "abstract": "With the emergence of multiple modern video codecs, streaming service providers are forced to encode, store, and transmit bitrate ladders of multiple codecs separately, consequently suffering from additional energy costs for encoding, storage, and transmission. To tackle this issue, we introduce an online energy-efficient Multi-Codec Bitrate ladder Estimation scheme (MCBE) for adaptive video streaming applications. In MCBE, quality representations within the bitrate ladder of new-generation codecs (e.g., High Efficiency Video Coding (HEVC), Alliance for Open Media Video 1 (AV1)) that lie below the predicted rate-distortion curve of the Advanced Video Coding (AVC) codec are removed. Moreover, perceptual redundancy between representations of the bitrate ladders of the considered codecs is also minimized based on a Just Noticeable Difference (JND) threshold. Therefore, random forest-based models predict the VMAF score of bitrate ladder representations of each codec. In a live streaming session where all clients support the decoding of AVC, HEVC, and AV1, MCBE achieves impressive results, reducing cumulative encoding energy by 56.45%, storage energy usage by 94.99%, and transmission energy usage by 77.61% (considering a JND of six VMAF points). These energy reductions are in comparison to a baseline bitrate ladder encoding based on current industry practice.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09570"
  },
  "2310.09568": {
    "title": "Wafer-scale Computing: Advancements, Challenges, and Future Perspectives",
    "authors": [
      "Yang Hu",
      "Xinhan Lin",
      "Huizheng Wang",
      "Zhen He",
      "Xingmao Yu",
      "Jiahao Zhang",
      "Qize Yang",
      "Zheng Xu",
      "Sihan Guan",
      "Jiahao Fang",
      "Haoran Shang",
      "Xinru Tang",
      "Xu Dai",
      "Shaojun Wei",
      "Shouyi Yin"
    ],
    "abstract": "Nowadays, artificial intelligence (AI) technology with large models plays an increasingly important role in both academia and industry. It also brings a rapidly increasing demand for the computing power of the hardware. As the computing demand for AI continues to grow, the growth of hardware computing power has failed to keep up. This has become a significant factor restricting the development of AI. The augmentation of hardware computing power is mainly propelled by the escalation of transistor density and chip area. However, the former is impeded by the termination of the Moore's Law and Dennard scaling, and the latter is significantly restricted by the challenge of disrupting the legacy fabrication equipment and process.\n  In recent years, advanced packaging technologies that have gradually matured are increasingly used to implement bigger chips that integrate multiple chiplets, while still providing interconnections with chip-level density and bandwidth. Compared to conventional high-performance computing paradigms such as multi-accelerator and datacenter-scale computing, Wafer-scale Computing shows remarkable advantages in communication bandwidth, integration density, and programmability potential. Not surprisingly, disruptive Wafer-scale Computing also brings unprecedented design challenges for hardware architecture, design-system-technology co-optimization, power and cooling systems, and compiler tool chain. At present, there are no comprehensive surveys summarizing the current state and design insights of Wafer-scale Computing. This paper aims to take the first step to help academia and industry review existing wafer-scale chips and essential technologies in a one-stop manner. So that people can conveniently grasp the basic knowledge and key points, understand the achievements and shortcomings of existing research, and contribute to this promising research direction.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09568"
  },
  "2310.09563": {
    "title": "Learning Unified Representations for Multi-Resolution Face Recognition",
    "authors": [
      "Hulingxiao He",
      "Wu Yuan",
      "Yidian Huang",
      "Shilong Zhao",
      "Wen Yuan",
      "Hanqing Li"
    ],
    "abstract": "In this work, we propose Branch-to-Trunk network (BTNet), a representation learning method for multi-resolution face recognition. It consists of a trunk network (TNet), namely a unified encoder, and multiple branch networks (BNets), namely resolution adapters. As per the input, a resolution-specific BNet is used and the output are implanted as feature maps in the feature pyramid of TNet, at a layer with the same resolution. The discriminability of tiny faces is significantly improved, as the interpolation error introduced by rescaling, especially up-sampling, is mitigated on the inputs. With branch distillation and backward-compatible training, BTNet transfers discriminative high-resolution information to multiple branches while guaranteeing representation compatibility. Our experiments demonstrate strong performance on face recognition benchmarks, both for multi-resolution identity matching and feature aggregation, with much less computation amount and parameter storage. We establish new state-of-the-art on the challenging QMUL-SurvFace 1: N face identification task. Our code is available at https://github.com/StevenSmith2000/BTNet.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09563"
  },
  "2310.09561": {
    "title": "Graph Neural Network approaches for single-cell data: A recent overview",
    "authors": [
      "Konstantinos Lazaros",
      "Dimitris E. Koumadorakis",
      "Panagiotis Vlamos",
      "Aristidis G. Vrahatis"
    ],
    "abstract": "Graph Neural Networks (GNN) are reshaping our understanding of biomedicine and diseases by revealing the deep connections among genes and cells. As both algorithmic and biomedical technologies have advanced significantly, we're entering a transformative phase of personalized medicine. While pioneering tools like Graph Attention Networks (GAT) and Graph Convolutional Neural Networks (Graph CNN) are advancing graph-based learning, the rise of single-cell sequencing techniques is reshaping our insights on cellular diversity and function. Numerous studies have combined GNNs with single-cell data, showing promising results. In this work, we highlight the GNN methodologies tailored for single-cell data over the recent years. We outline the diverse range of graph deep learning architectures that center on GAT methodologies. Furthermore, we underscore the several objectives of GNN strategies in single-cell data contexts, ranging from cell-type annotation, data integration and imputation, gene regulatory network reconstruction, clustering and many others. This review anticipates a future where GNNs become central to single-cell analysis efforts, particularly as vast omics datasets are continuously generated and the interconnectedness of cells and genes enhances our depth of knowledge in biomedicine.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09561"
  },
  "2310.09554": {
    "title": "Neural network scoring for efficient computing",
    "authors": [
      "Hugo Waltsburger",
      "Erwan Libessart",
      "Chengfang Ren",
      "Anthony Kolar",
      "Regis Guinvarc'h"
    ],
    "abstract": "Much work has been dedicated to estimating and optimizing workloads in high-performance computing (HPC) and deep learning. However, researchers have typically relied on few metrics to assess the efficiency of those techniques. Most notably, the accuracy, the loss of the prediction, and the computational time with regard to GPUs or/and CPUs characteristics. It is rare to see figures for power consumption, partly due to the difficulty of obtaining accurate power readings. In this paper, we introduce a composite score that aims to characterize the trade-off between accuracy and power consumption measured during the inference of neural networks. For this purpose, we present a new open-source tool allowing researchers to consider more metrics: granular power consumption, but also RAM/CPU/GPU utilization, as well as storage, and network input/output (I/O). To our best knowledge, it is the first fit test for neural architectures on hardware architectures. This is made possible thanks to reproducible power efficiency measurements. We applied this procedure to state-of-the-art neural network architectures on miscellaneous hardware. One of the main applications and novelties is the measurement of algorithmic power efficiency. The objective is to allow researchers to grasp their algorithms' efficiencies better. This methodology was developed to explore trade-offs between energy usage and accuracy in neural networks. It is also useful when fitting hardware for a specific task or to compare two architectures more accurately, with architecture exploration in mind.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09554"
  },
  "2310.09553": {
    "title": "ARTree: A Deep Autoregressive Model for Phylogenetic Inference",
    "authors": [
      "Tianyu Xie",
      "Cheng Zhang"
    ],
    "abstract": "Designing flexible probabilistic models over tree topologies is important for developing efficient phylogenetic inference methods. To do that, previous works often leverage the similarity of tree topologies via hand-engineered heuristic features which would require pre-sampled tree topologies and may suffer from limited approximation capability. In this paper, we propose a deep autoregressive model for phylogenetic inference based on graph neural networks (GNNs), called ARTree. By decomposing a tree topology into a sequence of leaf node addition operations and modeling the involved conditional distributions based on learnable topological features via GNNs, ARTree can provide a rich family of distributions over the entire tree topology space that have simple sampling algorithms and density estimation procedures, without using heuristic features. We demonstrate the effectiveness and efficiency of our method on a benchmark of challenging real data tree topology density estimation and variational Bayesian phylogenetic inference problems.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09553"
  },
  "2310.09550": {
    "title": "Can Large Language Model Comprehend Ancient Chinese? A Preliminary Test on ACLUE",
    "authors": [
      "Yixuan Zhang",
      "Haonan Li"
    ],
    "abstract": "Large language models (LLMs) have showcased remarkable capabilities in understanding and generating language. However, their ability in comprehending ancient languages, particularly ancient Chinese, remains largely unexplored. To bridge this gap, we present ACLUE, an evaluation benchmark designed to assess the capability of language models in comprehending ancient Chinese. ACLUE consists of 15 tasks cover a range of skills, spanning phonetic, lexical, syntactic, semantic, inference and knowledge. Through the evaluation of eight state-of-the-art LLMs, we observed a noticeable disparity in their performance between modern Chinese and ancient Chinese. Among the assessed models, ChatGLM2 demonstrates the most remarkable performance, achieving an average score of 37.4%. We have made our code and data public available.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09550"
  },
  "2310.09549": {
    "title": "Scene Text Recognition Models Explainability Using Local Features",
    "authors": [
      "Mark Vincent Ty",
      "Rowel Atienza"
    ],
    "abstract": "Explainable AI (XAI) is the study on how humans can be able to understand the cause of a model's prediction. In this work, the problem of interest is Scene Text Recognition (STR) Explainability, using XAI to understand the cause of an STR model's prediction. Recent XAI literatures on STR only provide a simple analysis and do not fully explore other XAI methods. In this study, we specifically work on data explainability frameworks, called attribution-based methods, that explain the important parts of an input data in deep learning models. However, integrating them into STR produces inconsistent and ineffective explanations, because they only explain the model in the global context. To solve this problem, we propose a new method, STRExp, to take into consideration the local explanations, i.e. the individual character prediction explanations. This is then benchmarked across different attribution-based methods on different STR datasets and evaluated across different STR models.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09549"
  },
  "2310.09536": {
    "title": "CarExpert: Leveraging Large Language Models for In-Car Conversational Question Answering",
    "authors": [
      "Md Rashad Al Hasan Rony",
      "Christian Suess",
      "Sinchana Ramakanth Bhat",
      "Viju Sudhi",
      "Julia Schneider",
      "Maximilian Vogel",
      "Roman Teucher",
      "Ken E. Friedl",
      "Soumya Sahoo"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance by following natural language instructions without fine-tuning them on domain-specific tasks and data. However, leveraging LLMs for domain-specific question answering suffers from severe limitations. The generated answer tends to hallucinate due to the training data collection time (when using off-the-shelf), complex user utterance and wrong retrieval (in retrieval-augmented generation). Furthermore, due to the lack of awareness about the domain and expected output, such LLMs may generate unexpected and unsafe answers that are not tailored to the target domain. In this paper, we propose CarExpert, an in-car retrieval-augmented conversational question-answering system leveraging LLMs for different tasks. Specifically, CarExpert employs LLMs to control the input, provide domain-specific documents to the extractive and generative answering components, and controls the output to ensure safe and domain-specific answers. A comprehensive empirical evaluation exhibits that CarExpert outperforms state-of-the-art LLMs in generating natural, safe and car-specific answers.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09536"
  },
  "2310.09533": {
    "title": "Towards End-to-End Unsupervised Saliency Detection with Self-Supervised Top-Down Context",
    "authors": [
      "Yicheng Song",
      "Shuyong Gao",
      "Haozhe Xing",
      "Yiting Cheng",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Unsupervised salient object detection aims to detect salient objects without using supervision signals eliminating the tedious task of manually labeling salient objects. To improve training efficiency, end-to-end methods for USOD have been proposed as a promising alternative. However, current solutions rely heavily on noisy handcraft labels and fail to mine rich semantic information from deep features. In this paper, we propose a self-supervised end-to-end salient object detection framework via top-down context. Specifically, motivated by contrastive learning, we exploit the self-localization from the deepest feature to construct the location maps which are then leveraged to learn the most instructive segmentation guidance. Further considering the lack of detailed information in deepest features, we exploit the detail-boosting refiner module to enrich the location labels with details. Moreover, we observe that due to lack of supervision, current unsupervised saliency models tend to detect non-salient objects that are salient in some other samples of corresponding scenarios. To address this widespread issue, we design a novel Unsupervised Non-Salient Suppression (UNSS) method developing the ability to ignore non-salient objects. Extensive experiments on benchmark datasets demonstrate that our method achieves leading performance among the recent end-to-end methods and most of the multi-stage solutions. The code is available.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09533"
  },
  "2310.09532": {
    "title": "Toward Open Repository of Performance Portability of Applications, Benchmarks and Models",
    "authors": [
      "Ami Marowka"
    ],
    "abstract": "The adoption of heterogeneous computing systems based on diverse architectures to achieve exascale computing power has worsened the performance portability problem of scientific applications that were designed to run on these platforms.\n  To cope with the challenges posed by supercomputing, new performance portability frameworks have been developed alongside advanced methods and metrics to evaluate the performance portability of heterogeneous applications. However, many studies have shown that the new methods and metrics do not produce coherent results which yield clear conclusions that are required for designing the hardware and software architectures of tomorrow's supercomputing systems.\n  We outline a proposal to establish an open repository of performance portability of applications, benchmarks and models which will be standardized, objective, and based on strict operating and reporting guidelines. Such guidelines will ensure a fair, comparable and meaningful measure of the performance portability while the requirement for a detailed disclosure of the obtained results and the configuration settings will ensure the reproducibility of the reported results.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09532"
  },
  "2310.09528": {
    "title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural Networks",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Donsub Rim",
      "Noseong Park"
    ],
    "abstract": "In various engineering and applied science applications, repetitive numerical simulations of partial differential equations (PDEs) for varying input parameters are often required (e.g., aircraft shape optimization over many design parameters) and solvers are required to perform rapid execution. In this study, we suggest a path that potentially opens up a possibility for physics-informed neural networks (PINNs), emerging deep-learning-based solvers, to be considered as one such solver. Although PINNs have pioneered a proper integration of deep-learning and scientific computing, they require repetitive time-consuming training of neural networks, which is not suitable for many-query scenarios. To address this issue, we propose a lightweight low-rank PINNs containing only hundreds of model parameters and an associated hypernetwork-based meta-learning algorithm, which allows efficient approximation of solutions of PDEs for varying ranges of PDE input parameters. Moreover, we show that the proposed method is effective in overcoming a challenging issue, known as \"failure modes\" of PINNs.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09528"
  },
  "2310.09525": {
    "title": "TS-ENAS:Two-Stage Evolution for Cell-based Network Architecture Search",
    "authors": [
      "Juan Zou",
      "Shenghong Wu",
      "Yizhang Xia",
      "Weiwei Jiang",
      "Zeping Wu",
      "Jinhua Zheng"
    ],
    "abstract": "Neural network architecture search provides a solution to the automatic design of network structures. However, it is difficult to search the whole network architecture directly. Although using stacked cells to search neural network architectures is an effective way to reduce the complexity of searching, these methods do not able find the global optimal neural network structure since the number of layers, cells and connection methods is fixed. In this paper, we propose a Two-Stage Evolution for cell-based Network Architecture Search(TS-ENAS), including one-stage searching based on stacked cells and second-stage adjusting these cells. In our algorithm, a new cell-based search space and an effective two-stage encoding method are designed to represent cells and neural network structures. In addition, a cell-based weight inheritance strategy is designed to initialize the weight of the network, which significantly reduces the running time of the algorithm. The proposed methods are extensively tested and compared on four image classification dataset, Fashion-MNIST, CIFAR10, CIFAR100 and ImageNet and compared with 22 state-of-the-art algorithms including hand-designed networks and NAS networks. The experimental results show that TS-ENAS can more effectively find the neural network architecture with comparative performance.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09525"
  },
  "2310.09522": {
    "title": "Dynamic Prediction of Full-Ocean Depth SSP by Hierarchical LSTM: An Experimental Result",
    "authors": [
      "Jiajun Lu",
      "Wei Huang",
      "Hao Zhang"
    ],
    "abstract": "SSP distribution is an important parameter for underwater positioning, navigation and timing (PNT) because it affects the propagation mode of underwater acoustic signals. To accurate predict future sound speed distribution, we propose a hierarchical long short--term memory (H--LSTM) neural network for future sound speed prediction, which explore the distribution pattern of sound velocity in the time dimension. To verify the feasibility and effectiveness, we conducted both simulations and real experiments. The ocean experiment was held in the South China Sea in April, 2023. Results show that the accuracy of the proposed method outperforms the state--of--the--art methods.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09522"
  },
  "2310.09519": {
    "title": "Crowd Modeling and Control via Cooperative Adaptive Filtering",
    "authors": [
      "Zirui Wan",
      "Saeid Sanei"
    ],
    "abstract": "This paper introduces a crowd modeling and motion control approach that employs diffusion adaptation within an adaptive network. In the network, nodes collaboratively address specific estimation problems while simultaneously moving as agents governed by certain motion control mechanisms. Our research delves into the behaviors of agents when they encounter spatial constraints. Within this framework, agents pursue several objectives, such as target tracking, coherent motion, and obstacle evasion. Throughout their navigation, they demonstrate a nature of self-organization and self-adjustment that drives them to maintain certain social distances with each other, and adaptively adjust their behaviors in response to the environmental changes. Our findings suggest a promising approach to mitigate the spread of viral pandemics and averting stampedes.\n        \u25b3 Less",
    "submission_date": "24 October, 2023",
    "eprint_id": "2310.09519"
  },
  "2310.09517": {
    "title": "OBSUM: An object-based spatial unmixing model for spatiotemporal fusion of remote sensing images",
    "authors": [
      "Houcai Guo",
      "Dingqi Ye",
      "Lorenzo Bruzzone"
    ],
    "abstract": "Spatiotemporal fusion aims to improve both the spatial and temporal resolution of remote sensing images, thus facilitating time-series analysis at a fine spatial scale. However, there are several important issues that limit the application of current spatiotemporal fusion methods. First, most spatiotemporal fusion methods are based on pixel-level computation, which neglects the valuable object-level information of the land surface. Moreover, many existing methods cannot accurately retrieve strong temporal changes between the available high-resolution image at base date and the predicted one. This study proposes an Object-Based Spatial Unmixing Model (OBSUM), which incorporates object-based image analysis and spatial unmixing, to overcome the two abovementioned problems. OBSUM consists of one preprocessing step and three fusion steps, i.e., object-level unmixing, object-level residual compensation, and pixel-level residual compensation. OBSUM can be applied using only one fine image at the base date and one coarse image at the prediction date, without the need of a coarse image at the base date. The performance of OBSUM was compared with five representative spatiotemporal fusion methods. The experimental results demonstrated that OBSUM outperformed other methods in terms of both accuracy indices and visual effects over time-series. Furthermore, OBSUM also achieved satisfactory results in two typical remote sensing applications. Therefore, it has great potential to generate accurate and high-resolution time-series observations for supporting various remote sensing applications.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09517"
  },
  "2310.09516": {
    "title": "Efficient Link Prediction via GNN Layers Induced by Negative Sampling",
    "authors": [
      "Yuxin Wang",
      "Xiannian Hu",
      "Quan Gan",
      "Xuanjing Huang",
      "Xipeng Qiu",
      "David Wipf"
    ],
    "abstract": "Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, \\emph{node-wise} architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time (since node embeddings are only computed once and repeatedly reused), model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, \\emph{edge-wise} methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with the cost of increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the \\emph{forward pass} explicitly depends on \\emph{both} positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet still cheap node-wise embeddings. This is achieved by recasting the embeddings themselves as minimizers of a forward-pass-specific energy function (distinct from the actual training loss) that favors separation of positive and negative samples. As demonstrated by extensive empirical evaluations, the resulting architecture retains the inference speed of node-wise models, while producing competitive accuracy with edge-wise alternatives.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09516"
  },
  "2310.09512": {
    "title": "Attentive Multi-Layer Perceptron for Non-autoregressive Generation",
    "authors": [
      "Shuyang Jiang",
      "Jun Zhang",
      "Jiangtao Feng",
      "Lin Zheng",
      "Lingpeng Kong"
    ],
    "abstract": "Autoregressive~(AR) generation almost dominates sequence generation for its efficacy. Recently, non-autoregressive~(NAR) generation gains increasing popularity for its efficiency and growing efficacy. However, its efficiency is still bottlenecked by quadratic complexity in sequence lengths, which is prohibitive for scaling to long sequence generation and few works have been done to mitigate this problem. In this paper, we propose a novel MLP variant, \\textbf{A}ttentive \\textbf{M}ulti-\\textbf{L}ayer \\textbf{P}erceptron~(AMLP), to produce a generation model with linear time and space complexity. Different from classic MLP with static and learnable projection matrices, AMLP leverages adaptive projections computed from inputs in an attentive mode. The sample-aware adaptive projections enable communications among tokens in a sequence, and model the measurement between the query and key space. Furthermore, we marry AMLP with popular NAR models, deriving a highly efficient NAR-AMLP architecture with linear time and space complexity. Empirical results show that such marriage architecture surpasses competitive efficient NAR models, by a significant margin on text-to-speech synthesis and machine translation. We also test AMLP's self- and cross-attention ability separately with extensive ablation experiments, and find them comparable or even superior to the other efficient models. The efficiency analysis further shows that AMLP extremely reduces the memory cost against vanilla non-autoregressive models for long sequences.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09512"
  },
  "2310.09511": {
    "title": "Online Parameter Identification of Generalized Non-cooperative Game",
    "authors": [
      "Jianguo Chen",
      "Jinlong Lei",
      "Hongsheng Qi",
      "Yiguang Hong"
    ],
    "abstract": "This work studies the parameter identification problem of a generalized non-cooperative game, where each player's cost function is influenced by an observable signal and some unknown parameters. We consider the scenario where equilibrium of the game at some observable signals can be observed with noises, whereas our goal is to identify the unknown parameters with the observed data. Assuming that the observable signals and the corresponding noise-corrupted equilibriums are acquired sequentially, we construct this parameter identification problem as online optimization and introduce a novel online parameter identification algorithm. To be specific, we construct a regularized loss function that balances conservativeness and correctiveness, where the conservativeness term ensures that the new estimates do not deviate significantly from the current estimates, while the correctiveness term is captured by the Karush-Kuhn-Tucker conditions. We then prove that when the players' cost functions are linear with respect to the unknown parameters and the learning rate of the online parameter identification algorithm satisfies \u03bc_k \\propto 1/\\sqrt{k}, along with other assumptions, the regret bound of the proposed algorithm is O(\\sqrt{K}). Finally, we conduct numerical simulations on a Nash-Cournot problem to demonstrate that the performance of the online identification algorithm is comparable to that of the offline setting.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09511"
  },
  "2310.09510": {
    "title": "Survey on Security Attacks in Connected and Autonomous Vehicular Systems",
    "authors": [
      "S M Mostaq Hossain",
      "Shampa Banik",
      "Trapa Banik",
      "Ashfak Md Shibli"
    ],
    "abstract": "Connected and autonomous vehicles, also known as CAVs, are a general trend in the evolution of the automotive industry that can be utilized to make transportation safer, improve the number of mobility options available, user costs will go down and new jobs will be created. However, as our society grows more automated and networked, criminal actors will have additional opportunities to conduct a variety of attacks, putting CAV security in danger. By providing a brief review of the state of cyber security in the CAVs environment, this study aims to draw attention to the issues and concerns associated with security. The first thing it does is categorize the multiple cybersecurity threats and weaknesses in the context of CAVs into three groups: attacks on the vehicles network, attacks on the Internet at large, and other attacks. This is done in accordance with the various communication networks and targets under attack. Next, it considers the possibility of cyber attacks to be an additional form of threat posed by the environment of CAVs. After that, it details the most uptodate defense tactics for securing CAVs and analyzes how effective they are. In addition, it draws some conclusions about the various cyber security and safety requirements of CAVs that are now available, which is beneficial for the use of CAVs in the real world. At the end, we discussed some implications on Adversary Attacks on Autonomous Vehicles. In conclusion, a number of difficulties and unsolved issues for future research are analyzed and explored.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09510"
  },
  "2310.09508": {
    "title": "Findability: A Novel Measure of Information Accessibility",
    "authors": [
      "Aman Sinha",
      "Priyanshu Raj Mall",
      "Dwaipayan Roy"
    ],
    "abstract": "The overwhelming volume of data generated and indexed by search engines poses a significant challenge in retrieving documents from the index efficiently and effectively. Even with a well-crafted query, several relevant documents often get buried among a multitude of competing documents, resulting in reduced accessibility or `findability' of the desired document. Consequently, it is crucial to develop a robust methodology for assessing this dimension of Information Retrieval (IR) system performance. While previous studies have focused on measuring document accessibility disregarding user queries and document relevance, there exists no metric to quantify the findability of a document within a given IR system without resorting to manual labor. This paper aims to address this gap by defining and deriving a metric to evaluate the findability of documents as perceived by end-users. Through experiments, we demonstrate the varying impact of different retrieval models and collections on the findability of documents. Furthermore, we establish the findability measure as an independent metric distinct from retrievability, an accessibility measure introduced in prior literature.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09508"
  },
  "2310.09507": {
    "title": "Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust Performance",
    "authors": [
      "DongAo Ma",
      "Jiaxuan Pang",
      "Michael B. Gotway",
      "Jianming Liang"
    ],
    "abstract": "Deep learning nowadays offers expert-level and sometimes even super-expert-level performance, but achieving such performance demands massive annotated data for training (e.g., Google's proprietary CXR Foundation Model (CXR-FM) was trained on 821,544 labeled and mostly private chest X-rays (CXRs)). Numerous datasets are publicly available in medical imaging but individually small and heterogeneous in expert labels. We envision a powerful and robust foundation model that can be trained by aggregating numerous small public datasets. To realize this vision, we have developed Ark, a framework that accrues and reuses knowledge from heterogeneous expert annotations in various datasets. As a proof of concept, we have trained two Ark models on 335,484 and 704,363 CXRs, respectively, by merging several datasets including ChestX-ray14, CheXpert, MIMIC-II, and VinDr-CXR, evaluated them on a wide range of imaging tasks covering both classification and segmentation via fine-tuning, linear-probing, and gender-bias analysis, and demonstrated our Ark's superior and robust performance over the SOTA fully/self-supervised baselines and Google's proprietary CXR-FM. This enhanced performance is attributed to our simple yet powerful observation that aggregating numerous public datasets diversifies patient populations and accrues knowledge from diverse experts, yielding unprecedented performance yet saving annotation cost. With all codes and pretrained models released at GitHub.com/JLiangLab/Ark, we hope that Ark exerts an important impact on open science, as accruing and reusing knowledge from expert annotations in public datasets can potentially surpass the performance of proprietary models trained on unusually large data, inspiring many more researchers worldwide to share codes and datasets to build open foundation models, accelerate open science, and democratize deep learning for medical imaging.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09507"
  },
  "2310.09506": {
    "title": "Towards Semantic Communication Protocols for 6G: From Protocol Learning to Language-Oriented Approaches",
    "authors": [
      "Jihong Park",
      "Seung-Woo Ko",
      "Jinho Choi",
      "Seong-Lyun Kim",
      "Mehdi Bennis"
    ],
    "abstract": "The forthcoming 6G systems are expected to address a wide range of non-stationary tasks. This poses challenges to traditional medium access control (MAC) protocols that are static and predefined. In response, data-driven MAC protocols have recently emerged, offering ability to tailor their signaling messages for specific tasks. This article presents a novel categorization of these data-driven MAC protocols into three levels: Level 1 MAC. task-oriented neural protocols constructed using multi-agent deep reinforcement learning (MADRL); Level 2 MAC. neural network-oriented symbolic protocols developed by converting Level 1 MAC outputs into explicit symbols; and Level 3 MAC. language-oriented semantic protocols harnessing large language models (LLMs) and generative models. With this categorization, we aim to explore the opportunities and challenges of each level by delving into their foundational techniques. Drawing from information theory and associated principles as well as selected case studies, this study provides insights into the trajectory of data-driven MAC protocols and sheds light on future research directions.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09506"
  },
  "2310.09505": {
    "title": "Advancing Test-Time Adaptation for Acoustic Foundation Models in Open-World Shifts",
    "authors": [
      "Hongfu Liu",
      "Hengguan Huang",
      "Ye Wang"
    ],
    "abstract": "Test-Time Adaptation (TTA) is a critical paradigm for tackling distribution shifts during inference, especially in visual recognition tasks. However, while acoustic models face similar challenges due to distribution shifts in test-time speech, TTA techniques specifically designed for acoustic modeling in the context of open-world data shifts remain scarce. This gap is further exacerbated when considering the unique characteristics of acoustic foundation models: 1) they are primarily built on transformer architectures with layer normalization and 2) they deal with test-time speech data of varying lengths in a non-stationary manner. These aspects make the direct application of vision-focused TTA methods, which are mostly reliant on batch normalization and assume independent samples, infeasible. In this paper, we delve into TTA for pre-trained acoustic models facing open-world data shifts. We find that noisy, high-entropy speech frames, often non-silent, carry key semantic content. Traditional TTA methods might inadvertently filter out this information using potentially flawed heuristics. In response, we introduce a heuristic-free, learning-based adaptation enriched by confidence enhancement. Noting that speech signals' short-term consistency, we also apply consistency regularization during test-time optimization. Our experiments on synthetic and real-world datasets affirm our method's superiority over existing baselines.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09505"
  },
  "2310.09504": {
    "title": "Node Dissimilarity Index for Complex Network Analysis",
    "authors": [
      "Natarajan Meghanathan"
    ],
    "abstract": "We propose a principal component analysis (PCA)-based approach to quantify (the node dissimilarity index, NDI) the extent of dissimilarity among nodes in a network with respect to values incurred for a suite of node-level metrics (like centrality metrics). We subject the dataset (n nodes and their values incurred for four commonly studied centrality metrics: degree, eigenvector, betweenness and closeness) to PCA and retain the m ( <= 4) principal components (with variance >= 1.0). We construct an n-node dissimilarity matrix whose entries are the absolute difference (if m = 1) or Euclidean distance (if M > 1) of the principal component coordinates of the corresponding nodes. We compute NDI (>= 1.0) to be the ratio of the principal Eigenvalue of the node dissimilarity matrix and average of entries in the node dissimilarity matrix. The larger the NDI, the greater the dissimilarity among the node-level metrics (centrality metrics) values considered for analysis.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09504"
  },
  "2310.09501": {
    "title": "DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit",
    "authors": [
      "Jivnesh Sandhan",
      "Yaswanth Narsupalli",
      "Sreevatsa Muppirala",
      "Sriram Krishnan",
      "Pavankumar Satuluri",
      "Amba Kulkarni",
      "Pawan Goyal"
    ],
    "abstract": "Multi-component compounding is a prevalent phenomenon in Sanskrit, and understanding the implicit structure of a compound's components is crucial for deciphering its meaning. Earlier approaches in Sanskrit have focused on binary compounds and neglected the multi-component compound setting. This work introduces the novel task of nested compound type identification (NeCTI), which aims to identify nested spans of a multi-component compound and decode the implicit semantic relations between them. To the best of our knowledge, this is the first attempt in the field of lexical semantics to propose this task.\n  We present 2 newly annotated datasets including an out-of-domain dataset for this task. We also benchmark these datasets by exploring the efficacy of the standard problem formulations such as nested named entity recognition, constituency parsing and seq2seq, etc. We present a novel framework named DepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the performance of the best baseline with an average absolute improvement of 13.1 points F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement in inference efficiency. In line with the previous findings in the binary Sanskrit compound identification task, context provides benefits for the NeCTI task. The codebase and datasets are publicly available at: https://github.com/yaswanth-iitkgp/DepNeCTI\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09501"
  },
  "2310.09495": {
    "title": "Learning In-between Imagery Dynamics via Physical Latent Spaces",
    "authors": [
      "Jihun Han",
      "Yoonsang Lee",
      "Anne Gelb"
    ],
    "abstract": "We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations (PDEs), our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09495"
  },
  "2310.09494": {
    "title": "Computational analyses of linguistic features with schizophrenic and autistic traits along with formal thought disorders",
    "authors": [
      "Takeshi Saga",
      "Hiroki Tanaka",
      "Satoshi Nakamura"
    ],
    "abstract": "[See full abstract in the pdf] Formal Thought Disorder (FTD), which is a group of symptoms in cognition that affects language and thought, can be observed through language. FTD is seen across such developmental or psychiatric disorders as Autism Spectrum Disorder (ASD) or Schizophrenia, and its related Schizotypal Personality Disorder (SPD). This paper collected a Japanese audio-report dataset with score labels related to ASD and SPD through a crowd-sourcing service from the general population. We measured language characteristics with the 2nd edition of the Social Responsiveness Scale (SRS2) and the Schizotypal Personality Questionnaire (SPQ), including an odd speech subscale from SPQ to quantify the FTD symptoms. We investigated the following four research questions through machine-learning-based score predictions: (RQ1) How are schizotypal and autistic measures correlated? (RQ2) What is the most suitable task to elicit FTD symptoms? (RQ3) Does the length of speech affect the elicitation of FTD symptoms? (RQ4) Which features are critical for capturing FTD symptoms? We confirmed that an FTD-related subscale, odd speech, was significantly correlated with both the total SPQ and SRS scores, although they themselves were not correlated significantly. Our regression analysis indicated that longer speech about a negative memory elicited more FTD symptoms. The ablation study confirmed the importance of function words and both the abstract and temporal features for FTD-related odd speech estimation. In contrast, content words were effective only in the SRS predictions, and content words were effective only in the SPQ predictions, a result that implies the differences between SPD-like and ASD-like symptoms. Data and programs used in this paper can be found here: https://sites.google.com/view/sagatake/resource.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09494"
  },
  "2310.09492": {
    "title": "Perception Reinforcement Using Auxiliary Learning Feature Fusion: A Modified Yolov8 for Head Detection",
    "authors": [
      "Jiezhou Chen",
      "Guankun Wang",
      "Weixiang Liu",
      "Xiaopin Zhong",
      "Yibin Tian",
      "ZongZe Wu"
    ],
    "abstract": "Head detection provides distribution information of pedestrian, which is crucial for scene statistical analysis, traffic management, and risk assessment and early warning. However, scene complexity and large-scale variation in the real world make accurate detection more difficult. Therefore, we present a modified Yolov8 which improves head detection performance through reinforcing target perception. An Auxiliary Learning Feature Fusion (ALFF) module comprised of LSTM and convolutional blocks is used as the auxiliary task to help the model perceive targets. In addition, we introduce Noise Calibration into Distribution Focal Loss to facilitate model fitting and improve the accuracy of detection. Considering the requirements of high accuracy and speed for the head detection task, our method is adapted with two kinds of backbone, namely Yolov8n and Yolov8m. The results demonstrate the superior performance of our approach in improving detection accuracy and robustness.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09492"
  },
  "2310.09488": {
    "title": "ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning",
    "authors": [
      "Jiecheng Lu",
      "Xu Han",
      "Shihao Yang"
    ],
    "abstract": "Long-term time series forecasting (LTSF) is important for various domains but is confronted by challenges in handling the complex temporal-contextual relationships. As multivariate input models underperforming some recent univariate counterparts, we posit that the issue lies in the inefficiency of existing multivariate LTSF Transformers to model series-wise relationships: the characteristic differences between series are often captured incorrectly. To address this, we introduce ARM: a multivariate temporal-contextual adaptive learning method, which is an enhanced architecture specifically designed for multivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning (AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local Smoothing (MKLS), to better handle individual series temporal patterns and correctly learn inter-series dependencies. ARM demonstrates superior performance on multiple benchmarks without significantly increasing computational costs compared to vanilla Transformer, thereby advancing the state-of-the-art in LTSF. ARM is also generally applicable to other LTSF architecture beyond vanilla Transformer.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09488"
  },
  "2310.09483": {
    "title": "Sorting and Selection in Rounds with Adversarial Comparisons",
    "authors": [
      "Christopher Trevisan"
    ],
    "abstract": "We continue the study of selection and sorting of $n$ numbers under the adversarial comparator model, where comparisons can be adversarially tampered with if the arguments are sufficiently close.\n  We derive a randomized sorting algorithm that does $O(n \\log^2 n)$ comparisons and gives a correct answer with high probability, addressing an open problem of Ajtai, Feldman, Hassadim, and Nelson [AFHN15]. Our algorithm also implies a selection algorithm that does $O(n \\log n)$ comparisons and gives a correct answer with high probability. Both of these results are a $\\log$ factor away from the naive lower bound. [AFHN15] shows an $\u03a9(n^{1+\\varepsilon})$ lower bound for both sorting and selection in the deterministic case, so our results also prove a discrepancy between what is possible with deterministic and randomized algorithms in this setting.\n  We also consider both sorting and selection in rounds, exploring the tradeoff between accuracy, number of comparisons, and number of rounds. Using results from sorting networks, we give general algorithms for sorting in $d$ rounds where the number of comparisons increases with $d$ and the accuracy decreases with $d$. Using these algorithms, we derive selection algorithms in $d+O(\\log d)$ rounds that use the same number of comparisons as the corresponding sorting algorithm, but have a constant accuracy. Notably, this gives selection algorithms in $d$ rounds that use $n^{1 + o(1)}$ comparisons and have constant accuracy for all $d = \u03c9(1)$, which still beats the deterministic lower bound of $\u03a9(n^{1+\\varepsilon})$.\n        \u25b3 Less",
    "submission_date": "14 October, 2023",
    "eprint_id": "2310.09483"
  },
  "2310.09479": {
    "title": "Unified High-binding Watermark for Unconditional Image Generation Models",
    "authors": [
      "Ruinan Ma",
      "Yu-an Tan",
      "Shangbo Wu",
      "Tian Chen",
      "Yajie Wang",
      "Yuanzhang Li"
    ],
    "abstract": "Deep learning techniques have implemented many unconditional image generation (UIG) models, such as GAN, Diffusion model, etc. The extremely realistic images (also known as AI-Generated Content, AIGC for short) produced by these models bring urgent needs for intellectual property protection such as data traceability and copyright certification. An attacker can steal the output images of the target model and use them as part of the training data to train a private surrogate UIG model. The implementation mechanisms of UIG models are diverse and complex, and there is no unified and effective protection and verification method at present. To address these issues, we propose a two-stage unified watermark verification mechanism with high-binding effects for such models. In the first stage, we use an encoder to invisibly write the watermark image into the output images of the original AIGC tool, and reversely extract the watermark image through the corresponding decoder. In the second stage, we design the decoder fine-tuning process, and the fine-tuned decoder can make correct judgments on whether the suspicious model steals the original AIGC tool data. Experiments demonstrate our method can complete the verification work with almost zero false positive rate under the condition of only using the model output images. Moreover, the proposed method can achieve data steal verification across different types of UIG models, which further increases the practicality of the method.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09479"
  },
  "2310.09478": {
    "title": "MiniGPT-v2: large language model as a unified interface for vision-language multi-task learning",
    "authors": [
      "Jun Chen",
      "Deyao Zhu",
      "Xiaoqian Shen",
      "Xiang Li",
      "Zechun Liu",
      "Pengchuan Zhang",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra",
      "Yunyang Xiong",
      "Mohamed Elhoseiny"
    ],
    "abstract": "Large language models have shown their remarkable capabilities as a general interface for various language-related applications. Motivated by this, we target to build a unified interface for completing many vision-language tasks including image description, visual question answering, and visual grounding, among others. The challenge is to use a single model for performing diverse vision-language tasks effectively with simple multi-modal instructions. Towards this objective, we introduce MiniGPT-v2, a model that can be treated as a unified interface for better handling various vision-language tasks. We propose using unique identifiers for different tasks when training the model. These identifiers enable our model to better distinguish each task instruction effortlessly and also improve the model learning efficiency for each task. After the three-stage training, the experimental results show that MiniGPT-v2 achieves strong performance on many visual question-answering and visual grounding benchmarks compared to other vision-language generalist models. Our model and codes are available at https://minigpt-v2.github.io/\n        \u25b3 Less",
    "submission_date": "7 November, 2023",
    "eprint_id": "2310.09478"
  },
  "2310.09473": {
    "title": "Can CNNs Accurately Classify Human Emotions? A Deep-Learning Facial Expression Recognition Study",
    "authors": [
      "Ashley Jisue Hong",
      "David DiStefano",
      "Sejal Dua"
    ],
    "abstract": "Emotional Artificial Intelligences are currently one of the most anticipated developments of AI. If successful, these AIs will be classified as one of the most complex, intelligent nonhuman entities as they will possess sentience, the primary factor that distinguishes living humans and mechanical machines. For AIs to be classified as \"emotional,\" they should be able to empathize with others and classify their emotions because without such abilities they cannot normally interact with humans. This study investigates the CNN model's ability to recognize and classify human facial expressions (positive, neutral, negative). The CNN model made for this study is programmed in Python and trained with preprocessed data from the Chicago Face Database. The model is intentionally designed with less complexity to further investigate its ability. We hypothesized that the model will perform better than chance (33.3%) in classifying each emotion class of input data. The model accuracy was tested with novel images. Accuracy was summarized in a percentage report, comparative plot, and confusion matrix. Results of this study supported the hypothesis as the model had 75% accuracy over 10,000 images (data), highlighting the possibility of AIs that accurately analyze human emotions and the prospect of viable Emotional AIs.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09473"
  },
  "2310.09471": {
    "title": "Plug-and-Play Feature Generation for Few-Shot Medical Image Classification",
    "authors": [
      "Qianyu Guo",
      "Huifang Du",
      "Xing Jia",
      "Shuyong Gao",
      "Yan Teng",
      "Haofen Wang",
      "Wenqiang Zhang"
    ],
    "abstract": "Few-shot learning (FSL) presents immense potential in enhancing model generalization and practicality for medical image classification with limited training data; however, it still faces the challenge of severe overfitting in classifier training due to distribution bias caused by the scarce training samples. To address the issue, we propose MedMFG, a flexible and lightweight plug-and-play method designed to generate sufficient class-distinctive features from limited samples. Specifically, MedMFG first re-represents the limited prototypes to assign higher weights for more important information features. Then, the prototypes are variationally generated into abundant effective features. Finally, the generated features and prototypes are together to train a more generalized classifier. Experiments demonstrate that MedMFG outperforms the previous state-of-the-art methods on cross-domain benchmarks involving the transition from natural images to medical images, as well as medical images with different lesions. Notably, our method achieves over 10% performance improvement compared to several baselines. Fusion experiments further validate the adaptability of MedMFG, as it seamlessly integrates into various backbones and baselines, consistently yielding improvements of over 2.9% across all results.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09471"
  },
  "2310.09469": {
    "title": "Towards More Accurate Diffusion Model Acceleration with A Timestep Aligner",
    "authors": [
      "Mengfei Xia",
      "Yujun Shen",
      "Changsong Lei",
      "Yu Zhou",
      "Ran Yi",
      "Deli Zhao",
      "Wenping Wang",
      "Yong-jin Liu"
    ],
    "abstract": "A diffusion model, which is formulated to produce an image using thousands of denoising steps, usually suffers from a slow inference speed. Existing acceleration algorithms simplify the sampling by skipping most steps yet exhibit considerable performance degradation. By viewing the generation of diffusion models as a discretized integrating process, we argue that the quality drop is partly caused by applying an inaccurate integral direction to a timestep interval. To rectify this issue, we propose a timestep aligner that helps find a more accurate integral direction for a particular interval at the minimum cost. Specifically, at each denoising step, we replace the original parameterization by conditioning the network on a new timestep, which is obtained by aligning the sampling distribution to the real distribution. Extensive experiments show that our plug-in design can be trained efficiently and boost the inference performance of various state-of-the-art acceleration methods, especially when there are few denoising steps. For example, when using 10 denoising steps on the popular LSUN Bedroom dataset, we improve the FID of DDIM from 9.65 to 6.07, simply by adopting our method for a more appropriate set of timesteps. Code will be made publicly available.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09469"
  },
  "2310.09468": {
    "title": "Randomized Benchmarking of Local Zeroth-Order Optimizers for Variational Quantum Systems",
    "authors": [
      "Lucas Tecot",
      "Cho-Jui Hsieh"
    ],
    "abstract": "In the field of quantum information, classical optimizers play an important role. From experimentalists optimizing their physical devices to theorists exploring variational quantum algorithms, many aspects of quantum information require the use of a classical optimizer. For this reason, there are many papers that benchmark the effectiveness of different optimizers for specific quantum optimization tasks and choices of parameterized algorithms. However, for researchers exploring new algorithms or physical devices, the insights from these studies don't necessarily translate. To address this concern, we compare the performance of classical optimizers across a series of partially-randomized tasks to more broadly sample the space of quantum optimization problems. We focus on local zeroth-order optimizers due to their generally favorable performance and query-efficiency on quantum systems. We discuss insights from these experiments that can help motivate future works to improve these optimizers for use on quantum systems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09468"
  },
  "2310.09466": {
    "title": "Robust Anti-jamming Communications with DMA-Based Reconfigurable Heterogeneous Array",
    "authors": [
      "Kaizhi Huang",
      "Wenyu Jiang",
      "Yajun Chen",
      "Liang Jin",
      "Qingqing Wu",
      "Xiaoling Hu"
    ],
    "abstract": "In the future commercial and military communication systems, anti-jamming remains a critical issue. Existing homogeneous or heterogeneous arrays with a limited degrees of freedom (DoF) and high consumption are unable to meet the requirements of communication in rapidly changing and intense jamming environments. To address these challenges, we propose a reconfigurable heterogeneous array (RHA) architecture based on dynamic metasurface antenna (DMA), which will increase the DoF and further improve anti-jamming capabilities. We propose a two-step anti-jamming scheme based on RHA, where the multipaths are estimated by an atomic norm minimization (ANM) based scheme, and then the received signal-to-interference-plus-noise ratio (SINR) is maximized by jointly designing the phase shift of each DMA element and the weights of the array elements. To solve the challenging non-convex discrete fractional problem along with the estimation error in the direction of arrival (DoA) and channel state information (CSI), we propose a robust alternative algorithm based on the S-procedure to solve the lower-bound SINR maximization problem. Simulation results demonstrate that the proposed RHA architecture and corresponding schemes have superior performance in terms of jamming immunity and robustness.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09466"
  },
  "2310.09461": {
    "title": "MAC: ModAlity Calibration for Object Detection",
    "authors": [
      "Yutian Lei",
      "Jun Liu",
      "Dong Huang"
    ],
    "abstract": "The flourishing success of Deep Neural Networks(DNNs) on RGB-input perception tasks has opened unbounded possibilities for non-RGB-input perception tasks, such as object detection from wireless signals, lidar scans, and infrared images. Compared to the matured development pipeline of RGB-input (source modality) models, developing non-RGB-input (target-modality) models from scratch poses excessive challenges in the modality-specific network design/training tricks and labor in the target-modality annotation. In this paper, we propose ModAlity Calibration (MAC), an efficient pipeline for calibrating target-modality inputs to the DNN object detection models developed on the RGB (source) modality. We compose a target-modality-input model by adding a small calibrator module ahead of a source-modality model and introduce MAC training techniques to impose dense supervision on the calibrator. By leveraging (1) prior knowledge synthesized from the source-modality model and (2) paired {target, source} data with zero manual annotations, our target-modality models reach comparable or better metrics than baseline models that require 100% manual annotations. We demonstrate the effectiveness of MAC by composing the WiFi-input, Lidar-input, and Thermal-Infrared-input models upon the pre-trained RGB-input models respectively.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09461"
  },
  "2310.09458": {
    "title": "PaintHuman: Towards High-fidelity Text-to-3D Human Texturing via Denoised Score Distillation",
    "authors": [
      "Jianhui Yu",
      "Hao Zhu",
      "Liming Jiang",
      "Chen Change Loy",
      "Weidong Cai",
      "Wayne Wu"
    ],
    "abstract": "Recent advances in zero-shot text-to-3D human generation, which employ the human model prior (eg, SMPL) or Score Distillation Sampling (SDS) with pre-trained text-to-image diffusion models, have been groundbreaking. However, SDS may provide inaccurate gradient directions under the weak diffusion guidance, as it tends to produce over-smoothed results and generate body textures that are inconsistent with the detailed mesh geometry. Therefore, directly leverage existing strategies for high-fidelity text-to-3D human texturing is challenging. In this work, we propose a model called PaintHuman to addresses the challenges from two aspects. We first propose a novel score function, Denoised Score Distillation (DSD), which directly modifies the SDS by introducing negative gradient components to iteratively correct the gradient direction and generate high-quality textures. In addition, we use the depth map as a geometric guidance to ensure the texture is semantically aligned to human mesh surfaces. To guarantee the quality of rendered results, we employ geometry-aware networks to predict surface materials and render realistic human textures. Extensive experiments, benchmarked against state-of-the-art methods, validate the efficacy of our approach.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09458"
  },
  "2310.09454": {
    "title": "LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents",
    "authors": [
      "Yash Shukla",
      "Wenchang Gao",
      "Vasanth Sarathy",
      "Alvaro Velasquez",
      "Robert Wright",
      "Jivko Sinapov"
    ],
    "abstract": "Recent advancements in reasoning abilities of Large Language Models (LLM) has promoted their usage in problems that require high-level planning for robots and artificial agents. However, current techniques that utilize LLMs for such planning tasks make certain key assumptions such as, access to datasets that permit finetuning, meticulously engineered prompts that only provide relevant and essential information to the LLM, and most importantly, a deterministic approach to allow execution of the LLM responses either in the form of existing policies or plan operators. In this work, we propose LgTS (LLM-guided Teacher-Student learning), a novel approach that explores the planning abilities of LLMs to provide a graphical representation of the sub-goals to a reinforcement learning (RL) agent that does not have access to the transition dynamics of the environment. The RL agent uses Teacher-Student learning algorithm to learn a set of successful policies for reaching the goal state from the start state while simultaneously minimizing the number of environmental interactions. Unlike previous methods that utilize LLMs, our approach does not assume access to a propreitary or a fine-tuned LLM, nor does it require pre-trained policies that achieve the sub-goals proposed by the LLM. Through experiments on a gridworld based DoorKey domain and a search-and-rescue inspired domain, we show that generating a graphical structure of sub-goals helps in learning policies for the LLM proposed sub-goals and the Teacher-Student learning algorithm minimizes the number of environment interactions when the transition dynamics are unknown.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09454"
  },
  "2310.09449": {
    "title": "Pairwise Similarity Learning is SimPLE",
    "authors": [
      "Yandong Wen",
      "Weiyang Liu",
      "Yao Feng",
      "Bhiksha Raj",
      "Rita Singh",
      "Adrian Weller",
      "Michael J. Black",
      "Bernhard Sch\u00f6lkopf"
    ],
    "abstract": "In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09449"
  },
  "2310.09446": {
    "title": "Automatic segmentation of lung findings in CT and application to Long COVID",
    "authors": [
      "Diedre S. Carmo",
      "Rosarie A. Tudas",
      "Alejandro P. Comellas",
      "Leticia Rittner",
      "Roberto A. Lotufo",
      "Joseph M. Reinhardt",
      "Sarah E. Gerard"
    ],
    "abstract": "Automated segmentation of lung abnormalities in computed tomography is an important step for diagnosing and characterizing lung disease. In this work, we improve upon a previous method and propose S-MEDSeg, a deep learning based approach for accurate segmentation of lung lesions in chest CT images. S-MEDSeg combines a pre-trained EfficientNet backbone, bidirectional feature pyramid network, and modern network advancements to achieve improved segmentation performance. A comprehensive ablation study was performed to evaluate the contribution of the proposed network modifications. The results demonstrate modifications introduced in S-MEDSeg significantly improves segmentation performance compared to the baseline approach. The proposed method is applied to an independent dataset of long COVID inpatients to study the effect of post-acute infection vaccination on extent of lung findings. Open-source code, graphical user interface and pip package are available at https://github.com/MICLab-Unicamp/medseg.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09446"
  },
  "2310.09444": {
    "title": "Tackling Heterogeneity in Medical Federated learning via Vision Transformers",
    "authors": [
      "Erfan Darzi",
      "Yiqing Shen",
      "Yangming Ou",
      "Nanna M. Sijtsema",
      "P. M. A van Ooijen"
    ],
    "abstract": "Optimization-based regularization methods have been effective in addressing the challenges posed by data heterogeneity in medical federated learning, particularly in improving the performance of underrepresented clients. However, these methods often lead to lower overall model accuracy and slower convergence rates. In this paper, we demonstrate that using Vision Transformers can substantially improve the performance of underrepresented clients without a significant trade-off in overall accuracy. This improvement is attributed to the Vision transformer's ability to capture long-range dependencies within the input data.\n        \u25b3 Less",
    "submission_date": "15 November, 2023",
    "eprint_id": "2310.09444"
  },
  "2310.09443": {
    "title": "G10: Enabling An Efficient Unified GPU Memory and Storage Architecture with Smart Tensor Migrations",
    "authors": [
      "Haoyang Zhang",
      "Yirui Eric Zhou",
      "Yuqi Xue",
      "Yiqi Liu",
      "Jian Huang"
    ],
    "abstract": "To break the GPU memory wall for scaling deep learning workloads, a variety of architecture and system techniques have been proposed recently. Their typical approaches include memory extension with flash memory and direct storage access. However, these techniques still suffer from suboptimal performance and introduce complexity to the GPU memory management, making them hard to meet the scalability requirement of deep learning workloads today. In this paper, we present a unified GPU memory and storage architecture named G10 driven by the fact that the tensor behaviors of deep learning workloads are highly predictable. G10 integrates the host memory, GPU memory, and flash memory into a unified memory space, to scale the GPU memory capacity while enabling transparent data migrations. Based on this unified GPU memory and storage architecture, G10 utilizes compiler techniques to characterize the tensor behaviors in deep learning workloads. Therefore, it can schedule data migrations in advance by considering the available bandwidth of flash memory and host memory. The cooperative mechanism between deep learning compilers and the unified memory architecture enables G10 to hide data transfer overheads in a transparent manner. We implement G10 based on an open-source GPU simulator. Our experiments demonstrate that G10 outperforms state-of-the-art GPU memory solutions by up to 1.75$\\times$, without code modifications to deep learning workloads. With the smart data migration mechanism, G10 can reach 90.3\\% of the performance of the ideal case assuming unlimited GPU memory.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09443"
  },
  "2310.09441": {
    "title": "MEMTRACK: A Deep Learning-Based Approach to Microrobot Tracking in Dense and Low-Contrast Environments",
    "authors": [
      "Medha Sawhney",
      "Bhas Karmarkar",
      "Eric J. Leaman",
      "Arka Daw",
      "Anuj Karpatne",
      "Bahareh Behkam"
    ],
    "abstract": "Tracking microrobots is challenging, considering their minute size and high speed. As the field progresses towards developing microrobots for biomedical applications and conducting mechanistic studies in physiologically relevant media (e.g., collagen), this challenge is exacerbated by the dense surrounding environments with feature size and shape comparable to microrobots. Herein, we report Motion Enhanced Multi-level Tracker (MEMTrack), a robust pipeline for detecting and tracking microrobots using synthetic motion features, deep learning-based object detection, and a modified Simple Online and Real-time Tracking (SORT) algorithm with interpolation for tracking. Our object detection approach combines different models based on the object's motion pattern. We trained and validated our model using bacterial micro-motors in collagen (tissue phantom) and tested it in collagen and aqueous media. We demonstrate that MEMTrack accurately tracks even the most challenging bacteria missed by skilled human annotators, achieving precision and recall of 77% and 48% in collagen and 94% and 35% in liquid media, respectively. Moreover, we show that MEMTrack can quantify average bacteria speed with no statistically significant difference from the laboriously-produced manual tracking data. MEMTrack represents a significant contribution to microrobot localization and tracking, and opens the potential for vision-based deep learning approaches to microrobot control in dense and low-contrast settings. All source code for training and testing MEMTrack and reproducing the results of the paper have been made publicly available https://github.com/sawhney-medha/MEMTrack.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09441"
  },
  "2310.09440": {
    "title": "Target Variable Engineering",
    "authors": [
      "Jessica Clark"
    ],
    "abstract": "How does the formulation of a target variable affect performance within the ML pipeline? The experiments in this study examine numeric targets that have been binarized by comparing against a threshold. We compare the predictive performance of regression models trained to predict the numeric targets vs. classifiers trained to predict their binarized counterparts. Specifically, we make this comparison at every point of a randomized hyperparameter optimization search to understand the effect of computational resource budget on the tradeoff between the two. We find that regression requires significantly more computational effort to converge upon the optimal performance, and is more sensitive to both randomness and heuristic choices in the training process. Although classification can and does benefit from systematic hyperparameter tuning and model selection, the improvements are much less than for regression. This work comprises the first systematic comparison of regression and classification within the framework of computational resource requirements. Our findings contribute to calls for greater replicability and efficiency within the ML pipeline for the sake of building more sustainable and robust AI systems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09440"
  },
  "2310.09436": {
    "title": "Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks",
    "authors": [
      "Zixuan Ke",
      "Bing Liu",
      "Wenhan Xiong",
      "Asli Celikyilmaz",
      "Haoran Li"
    ],
    "abstract": "Continual learning (CL) has two main objectives: preventing catastrophic forgetting (CF) and encouraging knowledge transfer (KT). The existing literature mainly focused on overcoming CF. Some work has also been done on KT when the tasks are similar. To our knowledge, only one method has been proposed to learn a sequence of mixed tasks. However, these techniques still suffer from CF and/or limited KT. This paper proposes a new CL method to achieve both. It overcomes CF by isolating the knowledge of each task via discovering a subnetwork for it. A soft-masking mechanism is also proposed to preserve the previous knowledge and to enable the new task to leverage the past knowledge to achieve KT. Experiments using classification, generation, information extraction, and their mixture (i.e., heterogeneous tasks) show that the proposed method consistently outperforms strong baselines.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09436"
  },
  "2310.09434": {
    "title": "Learning nonlinear integral operators via Recurrent Neural Networks and its application in solving Integro-Differential Equations",
    "authors": [
      "Hardeep Bassi",
      "Yuanran Zhu",
      "Senwei Liang",
      "Jia Yin",
      "Cian C. Reeves",
      "Vojtech Vlcek",
      "Chao Yang"
    ],
    "abstract": "In this paper, we propose using LSTM-RNNs (Long Short-Term Memory-Recurrent Neural Networks) to learn and represent nonlinear integral operators that appear in nonlinear integro-differential equations (IDEs). The LSTM-RNN representation of the nonlinear integral operator allows us to turn a system of nonlinear integro-differential equations into a system of ordinary differential equations for which many efficient solvers are available. Furthermore, because the use of LSTM-RNN representation of the nonlinear integral operator in an IDE eliminates the need to perform a numerical integration in each numerical time evolution step, the overall temporal cost of the LSTM-RNN-based IDE solver can be reduced to $O(n_T)$ from $O(n_T^2)$ if a $n_T$-step trajectory is to be computed. We illustrate the efficiency and robustness of this LSTM-RNN-based numerical IDE solver with a model problem. Additionally, we highlight the generalizability of the learned integral operator by applying it to IDEs driven by different external forces. As a practical application, we show how this methodology can effectively solve the Dyson's equation for quantum many-body systems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09434"
  },
  "2310.09432": {
    "title": "Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence Selection",
    "authors": [
      "Davide Napolitano",
      "Lorenzo Vaiani",
      "Luca Cagliero"
    ],
    "abstract": "The Document-based Visual Question Answering competition addresses the automatic detection of parent-child relationships between elements in multi-page documents. The goal is to identify the document elements that answer a specific question posed in natural language. This paper describes the PoliTo's approach to addressing this task, in particular, our best solution explores a text-only approach, leveraging an ad hoc sampling strategy. Specifically, our approach leverages the Masked Language Modeling technique to fine-tune a BERT model, focusing on sentences containing sensitive keywords that also occur in the questions, such as references to tables or images. Thanks to the effectiveness of this approach, we are able to achieve high performance compared to baselines, demonstrating how our solution contributes positively to this task.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09432"
  },
  "2310.09426": {
    "title": "Offline Reinforcement Learning for Optimizing Production Bidding Policies",
    "authors": [
      "Dmytro Korenkevych",
      "Frank Cheng",
      "Artsiom Balakir",
      "Alex Nikulkov",
      "Lingnan Gao",
      "Zhihao Cen",
      "Zuobing Xu",
      "Zheqing Zhu"
    ],
    "abstract": "The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary base policies with deep neural networks, where only the optimized base policy parameters are eventually deployed, and the neural network part is discarded after training. We demonstrate that such an architecture achieves statistically significant performance gains in both simulated and at-scale production bidding environments. Our approach does not incur additional infrastructure, safety, or explainability costs, as it directly optimizes parameters of existing production routines without replacing them with black box-style models like neural networks.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09426"
  },
  "2310.09424": {
    "title": "SALM: Speech-augmented Language Model with In-context Learning for Speech Recognition and Translation",
    "authors": [
      "Zhehuai Chen",
      "He Huang",
      "Andrei Andrusenko",
      "Oleksii Hrinchuk",
      "Krishna C. Puvvada",
      "Jason Li",
      "Subhankar Ghosh",
      "Jagadeesh Balam",
      "Boris Ginsburg"
    ],
    "abstract": "We present a novel Speech Augmented Language Model (SALM) with {\\em multitask} and {\\em in-context} learning capabilities. SALM comprises a frozen text LLM, a audio encoder, a modality adapter module, and LoRA layers to accommodate speech input and associated task instructions. The unified SALM not only achieves performance on par with task-specific Conformer baselines for Automatic Speech Recognition (ASR) and Speech Translation (AST), but also exhibits zero-shot in-context learning capabilities, demonstrated through keyword-boosting task for ASR and AST. Moreover, {\\em speech supervised in-context training} is proposed to bridge the gap between LLM training and downstream speech tasks, which further boosts the in-context learning ability of speech-to-text models. Proposed model is open-sourced via NeMo toolkit.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09424"
  },
  "2310.09412": {
    "title": "Hybrid Reinforcement Learning for Optimizing Pump Sustainability in Real-World Water Distribution Networks",
    "authors": [
      "Harsh Patel",
      "Yuan Zhou",
      "Alexander P Lamb",
      "Shu Wang",
      "Jieliang Luo"
    ],
    "abstract": "This article addresses the pump-scheduling optimization problem to enhance real-time control of real-world water distribution networks (WDNs). Our primary objectives are to adhere to physical operational constraints while reducing energy consumption and operational costs. Traditional optimization techniques, such as evolution-based and genetic algorithms, often fall short due to their lack of convergence guarantees. Conversely, reinforcement learning (RL) stands out for its adaptability to uncertainties and reduced inference time, enabling real-time responsiveness. However, the effective implementation of RL is contingent on building accurate simulation models for WDNs, and prior applications have been limited by errors in simulation training data. These errors can potentially cause the RL agent to learn misleading patterns and actions and recommend suboptimal operational strategies. To overcome these challenges, we present an improved \"hybrid RL\" methodology. This method integrates the benefits of RL while anchoring it in historical data, which serves as a baseline to incrementally introduce optimal control recommendations. By leveraging operational data as a foundation for the agent's actions, we enhance the explainability of the agent's actions, foster more robust recommendations, and minimize error. Our findings demonstrate that the hybrid RL agent can significantly improve sustainability, operational efficiency, and dynamically adapt to emerging scenarios in real-world WDNs.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09412"
  },
  "2310.09411": {
    "title": "Surveying the Landscape of Text Summarization with Deep Learning: A Comprehensive Review",
    "authors": [
      "Guanghua Wang",
      "Weili Wu"
    ],
    "abstract": "In recent years, deep learning has revolutionized natural language processing (NLP) by enabling the development of models that can learn complex representations of language data, leading to significant improvements in performance across a wide range of NLP tasks. Deep learning models for NLP typically use large amounts of data to train deep neural networks, allowing them to learn the patterns and relationships in language data. This is in contrast to traditional NLP approaches, which rely on hand-engineered features and rules to perform NLP tasks. The ability of deep neural networks to learn hierarchical representations of language data, handle variable-length input sequences, and perform well on large datasets makes them well-suited for NLP applications. Driven by the exponential growth of textual data and the increasing demand for condensed, coherent, and informative summaries, text summarization has been a critical research area in the field of NLP. Applying deep learning to text summarization refers to the use of deep neural networks to perform text summarization tasks. In this survey, we begin with a review of fashionable text summarization tasks in recent years, including extractive, abstractive, multi-document, and so on. Next, we discuss most deep learning-based models and their experimental results on these tasks. The paper also covers datasets and data representation for summarization tasks. Finally, we delve into the opportunities and challenges associated with summarization tasks and their corresponding methodologies, aiming to inspire future research efforts to advance the field further. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific setting.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09411"
  },
  "2310.09398": {
    "title": "An In-Depth Examination of Requirements for Disclosure Risk Assessment",
    "authors": [
      "Ron S. Jarmin",
      "John M. Abowd",
      "Robert Ashmead",
      "Ryan Cumings-Menon",
      "Nathan Goldschlag",
      "Michael B. Hawes",
      "Sallie Ann Keller",
      "Daniel Kifer",
      "Philip Leclerc",
      "Jerome P. Reiter",
      "Rolando A. Rodr\u00edguez",
      "Ian Schmutte",
      "Victoria A. Velkoff",
      "Pavel Zhuravlev"
    ],
    "abstract": "The use of formal privacy to protect the confidentiality of responses in the 2020 Decennial Census of Population and Housing has triggered renewed interest and debate over how to measure the disclosure risks and societal benefits of the published data products. Following long-established precedent in economics and statistics, we argue that any proposal for quantifying disclosure risk should be based on pre-specified, objective criteria. Such criteria should be used to compare methodologies to identify those with the most desirable properties. We illustrate this approach, using simple desiderata, to evaluate the absolute disclosure risk framework, the counterfactual framework underlying differential privacy, and prior-to-posterior comparisons. We conclude that satisfying all the desiderata is impossible, but counterfactual comparisons satisfy the most while absolute disclosure risk satisfies the fewest. Furthermore, we explain that many of the criticisms levied against differential privacy would be levied against any technology that is not equivalent to direct, unrestricted access to confidential data. Thus, more research is needed, but in the near-term, the counterfactual approach appears best-suited for privacy-utility analysis.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09398"
  },
  "2310.09397": {
    "title": "Identifiability of Product of Experts Models",
    "authors": [
      "Spencer L. Gordon",
      "Manav Kant",
      "Eric Ma",
      "Leonard J. Schulman",
      "Andrei Staicu"
    ],
    "abstract": "Product of experts (PoE) are layered networks in which the value at each node is an AND (or product) of the values (possibly negated) at its inputs. These were introduced as a neural network architecture that can efficiently learn to generate high-dimensional data which satisfy many low-dimensional constraints -- thereby allowing each individual expert to perform a simple task. PoEs have found a variety of applications in learning.\n  We study the problem of identifiability of a product of experts model having a layer of binary latent variables, and a layer of binary observables that are iid conditional on the latents. The previous best upper bound on the number of observables needed to identify the model was exponential in the number of parameters. We show: (a) When the latents are uniformly distributed, the model is identifiable with a number of observables equal to the number of parameters (and hence best possible). (b) In the more general case of arbitrarily distributed latents, the model is identifiable for a number of observables that is still linear in the number of parameters (and within a factor of two of best-possible). The proofs rely on root interlacing phenomena for some special three-term recurrences.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09397"
  },
  "2310.09394": {
    "title": "Semantics Alignment via Split Learning for Resilient Multi-User Semantic Communication",
    "authors": [
      "Jinhyuk Choi",
      "Jihong Park",
      "Seung-Woo Ko",
      "Jinho Choi",
      "Mehdi Bennis",
      "Seong-Lyun Kim"
    ],
    "abstract": "Recent studies on semantic communication commonly rely on neural network (NN) based transceivers such as deep joint source and channel coding (DeepJSCC). Unlike traditional transceivers, these neural transceivers are trainable using actual source data and channels, enabling them to extract and communicate semantics. On the flip side, each neural transceiver is inherently biased towards specific source data and channels, making different transceivers difficult to understand intended semantics, particularly upon their initial encounter. To align semantics over multiple neural transceivers, we propose a distributed learning based solution, which leverages split learning (SL) and partial NN fine-tuning techniques. In this method, referred to as SL with layer freezing (SLF), each encoder downloads a misaligned decoder, and locally fine-tunes a fraction of these encoder-decoder NN layers. By adjusting this fraction, SLF controls computing and communication costs. Simulation results confirm the effectiveness of SLF in aligning semantics under different source data and channel dissimilarities, in terms of classification accuracy, reconstruction errors, and recovery time for comprehending intended semantics from misalignment.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09394"
  },
  "2310.09383": {
    "title": "Integrating Symbolic Reasoning into Neural Generative Models for Design Generation",
    "authors": [
      "Maxwell Joseph Jacobson",
      "Yexiang Xue"
    ],
    "abstract": "Design generation requires tight integration of neural and symbolic reasoning, as good design must meet explicit user needs and honor implicit rules for aesthetics, utility, and convenience. Current automated design tools driven by neural networks produce appealing designs, but cannot satisfy user specifications and utility requirements. Symbolic reasoning tools, such as constraint programming, cannot perceive low-level visual information in images or capture subtle aspects such as aesthetics. We introduce the Spatial Reasoning Integrated Generator (SPRING) for design generation. SPRING embeds a neural and symbolic integrated spatial reasoning module inside the deep generative network. The spatial reasoning module decides the locations of objects to be generated in the form of bounding boxes, which are predicted by a recurrent neural network and filtered by symbolic constraint satisfaction. Embedding symbolic reasoning into neural generation guarantees that the output of SPRING satisfies user requirements. Furthermore, SPRING offers interpretability, allowing users to visualize and diagnose the generation process through the bounding boxes. SPRING is also adept at managing novel user specifications not encountered during its training, thanks to its proficiency in zero-shot constraint transfer. Quantitative evaluations and a human study reveal that SPRING outperforms baseline generative models, excelling in delivering high design quality and better meeting user specifications.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09383"
  },
  "2310.09382": {
    "title": "LL-VQ-VAE: Learnable Lattice Vector-Quantization For Efficient Representations",
    "authors": [
      "Ahmed Khalil",
      "Robert Piechocki",
      "Raul Santos-Rodriguez"
    ],
    "abstract": "In this paper we introduce learnable lattice vector quantization and demonstrate its effectiveness for learning discrete representations. Our method, termed LL-VQ-VAE, replaces the vector quantization layer in VQ-VAE with lattice-based discretization. The learnable lattice imposes a structure over all discrete embeddings, acting as a deterrent against codebook collapse, leading to high codebook utilization. Compared to VQ-VAE, our method obtains lower reconstruction errors under the same training conditions, trains in a fraction of the time, and with a constant number of parameters (equal to the embedding dimension $D$), making it a very scalable approach. We demonstrate these results on the FFHQ-1024 dataset and include FashionMNIST and Celeb-A.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09382"
  },
  "2310.09373": {
    "title": "Identifying and examining machine learning biases on Adult dataset",
    "authors": [
      "Sahil Girhepuje"
    ],
    "abstract": "This research delves into the reduction of machine learning model bias through Ensemble Learning. Our rigorous methodology comprehensively assesses bias across various categorical variables, ultimately revealing a pronounced gender attribute bias. The empirical evidence unveils a substantial gender-based wage prediction disparity: wages predicted for males, initially at \\$902.91, significantly decrease to \\$774.31 when the gender attribute is alternated to females. Notably, Kullback-Leibler divergence scores point to gender bias, with values exceeding 0.13, predominantly within tree-based models. Employing Ensemble Learning elucidates the quest for fairness and transparency. Intriguingly, our findings reveal that the stacked model aligns with individual models, confirming the resilience of model bias. This study underscores ethical considerations and advocates the implementation of hybrid models for a data-driven society marked by impartiality and inclusivity.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09373"
  },
  "2310.09370": {
    "title": "Near-optimal Differentially Private Client Selection in Federated Settings",
    "authors": [
      "Syed Eqbal Alam",
      "Dhirendra Shukla",
      "Shrisha Rao"
    ],
    "abstract": "We develop an iterative differentially private algorithm for client selection in federated settings. We consider a federated network wherein clients coordinate with a central server to complete a task; however, the clients decide whether to participate or not at a time step based on their preferences -- local computation and probabilistic intent. The algorithm does not require client-to-client information exchange. The developed algorithm provides near-optimal values to the clients over long-term average participation with a certain differential privacy guarantee. Finally, we present the experimental results to check the algorithm's efficacy.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09370"
  },
  "2310.09361": {
    "title": "Is Certifying $\\ell_p$ Robustness Still Worthwhile?",
    "authors": [
      "Ravi Mangal",
      "Klas Leino",
      "Zifan Wang",
      "Kai Hu",
      "Weicheng Yu",
      "Corina Pasareanu",
      "Anupam Datta",
      "Matt Fredrikson"
    ],
    "abstract": "Over the years, researchers have developed myriad attacks that exploit the ubiquity of adversarial examples, as well as defenses that aim to guard against the security vulnerabilities posed by such attacks. Of particular interest to this paper are defenses that provide provable guarantees against the class of $\\ell_p$-bounded attacks. Certified defenses have made significant progress, taking robustness certification from toy models and datasets to large-scale problems like ImageNet classification. While this is undoubtedly an interesting academic problem, as the field has matured, its impact in practice remains unclear, thus we find it useful to revisit the motivation for continuing this line of research. There are three layers to this inquiry, which we address in this paper: (1) why do we care about robustness research? (2) why do we care about the $\\ell_p$-bounded threat model? And (3) why do we care about certification as opposed to empirical defenses? In brief, we take the position that local robustness certification indeed confers practical value to the field of machine learning. We focus especially on the latter two questions from above. With respect to the first of the two, we argue that the $\\ell_p$-bounded threat model acts as a minimal requirement for safe application of models in security-critical domains, while at the same time, evidence has mounted suggesting that local robustness may lead to downstream external benefits not immediately related to robustness. As for the second, we argue that (i) certification provides a resolution to the cat-and-mouse game of adversarial attacks; and furthermore, that (ii) perhaps contrary to popular belief, there may not exist a fundamental trade-off between accuracy, robustness, and certifiability, while moreover, certified training techniques constitute a particularly promising way for learning robust models.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09361"
  },
  "2310.09360": {
    "title": "Exact Verification of ReLU Neural Control Barrier Functions",
    "authors": [
      "Hongchao Zhang",
      "Junlin Wu",
      "Yevgeniy Vorobeychik",
      "Andrew Clark"
    ],
    "abstract": "Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. Based on this condition, we propose an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigate the complexity by only considering the boundary of the safe region and by pruning the segments with Interval Bound Propagation (IBP) and linear relaxation. We evaluate our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Our code is available at https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09360"
  },
  "2310.09357": {
    "title": "A Computational Approach to Style in American Poetry",
    "authors": [
      "David M. Kaplan",
      "David M. Blei"
    ],
    "abstract": "We develop a quantitative method to assess the style of American poems and to visualize a collection of poems in relation to one another. Qualitative poetry criticism helped guide our development of metrics that analyze various orthographic, syntactic, and phonemic features. These features are used to discover comprehensive stylistic information from a poem's multi-layered latent structure, and to compute distances between poems in this space. Visualizations provide ready access to the analytical components. We demonstrate our method on several collections of poetry, showing that it better delineates poetry style than the traditional word-occurrence features that are used in typical text analysis algorithms. Our method has potential applications to academic research of texts, to research of the intuitive personal response to poetry, and to making recommendations to readers based on their favorite poems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09357"
  },
  "2310.09350": {
    "title": "Unsupervised Domain Adaption for Neural Information Retrieval",
    "authors": [
      "Carlos Dominguez",
      "Jon Ander Campos",
      "Eneko Agirre",
      "Gorka Azkune"
    ],
    "abstract": "Neural information retrieval requires costly annotated data for each target domain to be competitive. Synthetic annotation by query generation using Large Language Models or rule-based string manipulation has been proposed as an alternative, but their relative merits have not been analysed. In this paper, we compare both methods head-to-head using the same neural IR architecture. We focus on the BEIR benchmark, which includes test datasets from several domains with no training data, and explore two scenarios: zero-shot, where the supervised system is trained in a large out-of-domain dataset (MS-MARCO); and unsupervised domain adaptation, where, in addition to MS-MARCO, the system is fine-tuned in synthetic data from the target domain. Our results indicate that Large Language Models outperform rule-based methods in all scenarios by a large margin, and, more importantly, that unsupervised domain adaptation is effective compared to applying a supervised IR system in a zero-shot fashion. In addition we explore several sizes of open Large Language Models to generate synthetic data and find that a medium-sized model suffices. Code and models are publicly available for reproducibility.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09350"
  },
  "2310.09347": {
    "title": "Efficient Apple Maturity and Damage Assessment: A Lightweight Detection Model with GAN and Attention Mechanism",
    "authors": [
      "Yufei Liu",
      "Manzhou Li",
      "Qin Ma"
    ],
    "abstract": "This study proposes a method based on lightweight convolutional neural networks (CNN) and generative adversarial networks (GAN) for apple ripeness and damage level detection tasks. Initially, a lightweight CNN model is designed by optimizing the model's depth and width, as well as employing advanced model compression techniques, successfully reducing the model's parameter and computational requirements, thus enhancing real-time performance in practical applications. Simultaneously, attention mechanisms are introduced, dynamically adjusting the importance of different feature layers to improve the performance in object detection tasks. To address the issues of sample imbalance and insufficient sample size, GANs are used to generate realistic apple images, expanding the training dataset and enhancing the model's recognition capability when faced with apples of varying ripeness and damage levels. Furthermore, by applying the object detection network for damage location annotation on damaged apples, the accuracy of damage level detection is improved, providing a more precise basis for decision-making. Experimental results show that in apple ripeness grading detection, the proposed model achieves 95.6\\%, 93.8\\%, 95.0\\%, and 56.5 in precision, recall, accuracy, and FPS, respectively. In apple damage level detection, the proposed model reaches 95.3\\%, 93.7\\%, and 94.5\\% in precision, recall, and mAP, respectively. In both tasks, the proposed method outperforms other mainstream models, demonstrating the excellent performance and high practical value of the proposed method in apple ripeness and damage level detection tasks.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09347"
  },
  "2310.09346": {
    "title": "HaptiCharger: Robotic Charging of Electric Vehicles Based on Human Haptic Patterns",
    "authors": [
      "Oussama Alyounes",
      "Miguel Altamirano Cabrera",
      "Dzmitry Tsetserukou"
    ],
    "abstract": "The growing demand for electric vehicles requires the development of automated car charging methods. At the moment, the process of charging an electric car is completely manual, and that requires physical effort to accomplish the task, which is not suitable for people with disabilities. Typically, the effort in the automation of the charging task research is focused on detecting the position and orientation of the socket, which resulted in a relatively high accuracy, 5 mm, and 10 degrees. However, this accuracy is not enough to complete the charging process. In this work, we focus on designing a novel methodology for robust robotic plug-in and plug-out based on human haptics to overcome the error in the orientation of the socket. Participants were invited to perform the charging task, and their cognitive capabilities were recognized by measuring the applied forces along with the movements of the charger. Eventually, an algorithm was developed based on the human's best strategies to be applied to a robotic arm.\n        \u25b3 Less",
    "submission_date": "10 November, 2023",
    "eprint_id": "2310.09346"
  },
  "2310.09343": {
    "title": "Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents",
    "authors": [
      "Hyungjoo Chae",
      "Yongho Song",
      "Kai Tzu-iunn Ong",
      "Taeyoon Kwon",
      "Minjin Kim",
      "Youngjae Yu",
      "Dongha Lee",
      "Dongyeop Kang",
      "Jinyoung Yeo"
    ],
    "abstract": "Human-like chatbots necessitate the use of commonsense reasoning in order to effectively comprehend and respond to implicit information present within conversations. Achieving such coherence and informativeness in responses, however, is a non-trivial task. Even for large language models (LLMs), the task of identifying and aggregating key evidence within a single hop presents a substantial challenge. This complexity arises because such evidence is scattered across multiple turns in a conversation, thus necessitating integration over multiple hops. Hence, our focus is to facilitate such multi-hop reasoning over a dialogue context, namely dialogue chain-of-thought (CoT) reasoning. To this end, we propose a knowledge distillation framework that leverages LLMs as unreliable teachers and selectively distills consistent and helpful rationales via alignment filters. We further present DOCTOR, a DialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for response generation. We conduct extensive experiments to show that enhancing dialogue agents with high-quality rationales from DOCTOR significantly improves the quality of their responses.\n        \u25b3 Less",
    "submission_date": "22 October, 2023",
    "eprint_id": "2310.09343"
  },
  "2310.09341": {
    "title": "Addressing the cold start problem in privacy preserving content-based recommender systems using hypercube graphs",
    "authors": [
      "Noa Tuval",
      "Alain Hertz",
      "Tsvi Kuflik"
    ],
    "abstract": "The initial interaction of a user with a recommender system is problematic because, in such a so-called cold start situation, the recommender system has very little information about the user, if any. Moreover, in collaborative filtering, users need to share their preferences with the service provider by rating items while in content-based filtering there is no need for such information sharing. We have recently shown that a content-based model that uses hypercube graphs can determine user preferences with a very limited number of ratings while better preserving user privacy. In this paper, we confirm these findings on the basis of experiments with more than 1,000 users in the restaurant and movie domains. We show that the proposed method outperforms standard machine learning algorithms when the number of available ratings is at most 10, which often happens, and is competitive with larger training sets. In addition, training is simple and does not require large computational efforts.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09341"
  },
  "2310.09340": {
    "title": "Geo-knowledge-guided GPT models improve the extraction of location descriptions from disaster-related social media messages",
    "authors": [
      "Yingjie Hu",
      "Gengchen Mai",
      "Chris Cundy",
      "Kristy Choi",
      "Ni Lao",
      "Wei Liu",
      "Gaurish Lakhanpal",
      "Ryan Zhenqi Zhou",
      "Kenneth Joseph"
    ],
    "abstract": "Social media messages posted by people during natural disasters often contain important location descriptions, such as the locations of victims. Recent research has shown that many of these location descriptions go beyond simple place names, such as city names and street names, and are difficult to extract using typical named entity recognition (NER) tools. While advanced machine learning models could be trained, they require large labeled training datasets that can be time-consuming and labor-intensive to create. In this work, we propose a method that fuses geo-knowledge of location descriptions and a Generative Pre-trained Transformer (GPT) model, such as ChatGPT and GPT-4. The result is a geo-knowledge-guided GPT model that can accurately extract location descriptions from disaster-related social media messages. Also, only 22 training examples encoding geo-knowledge are used in our method. We conduct experiments to compare this method with nine alternative approaches on a dataset of tweets from Hurricane Harvey. Our method demonstrates an over 40% improvement over typically used NER approaches. The experiment results also show that geo-knowledge is indispensable for guiding the behavior of GPT models. The extracted location descriptions can help disaster responders reach victims more quickly and may even save lives.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09340"
  },
  "2310.09338": {
    "title": "Uncertainty Quantification using Generative Approach",
    "authors": [
      "Yunsheng Zhang"
    ],
    "abstract": "We present the Incremental Generative Monte Carlo (IGMC) method, designed to measure uncertainty in deep neural networks using deep generative approaches. IGMC iteratively trains generative models, adding their output to the dataset, to compute the posterior distribution of the expectation of a random variable. We provide a theoretical guarantee of the convergence rate of IGMC relative to the sample size and sampling depth. Due to its compatibility with deep generative approaches, IGMC is adaptable to both neural network classification and regression tasks. We empirically study the behavior of IGMC on the MNIST digit classification task.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09338"
  },
  "2310.09335": {
    "title": "Statistical guarantees for stochastic Metropolis-Hastings",
    "authors": [
      "Sebastian Bieringer",
      "Gregor Kasieczka",
      "Maximilian F. Steffen",
      "Mathias Trabs"
    ],
    "abstract": "A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to those obtained from the classical Metropolis-adjusted Langevin algorithm.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09335"
  },
  "2310.09322": {
    "title": "A Note on Analyzing the Stability of Oscillator Ising Machines",
    "authors": [
      "Mohammad Khairul Bashar",
      "Zongli Lin",
      "Nikhil Shukla"
    ],
    "abstract": "The rich non-linear dynamics of the coupled oscillators (under second harmonic injection) can be leveraged to solve computationally hard problems in combinatorial optimization such as finding the ground state of the Ising Hamiltonian. While prior work on the stability of the so-called Oscillator Ising Machines (OIMs) has used the linearization method, in this letter, we present a complementary method to analyze stability using the second order derivative test of the energy / cost function. We establish the equivalence between the two methods, thus augmenting the tool kit for the design and implementation of OIMs.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09322"
  },
  "2310.09318": {
    "title": "Role of Morphogenetic Competency on Evolution",
    "authors": [
      "Lakshwin Shreesha"
    ],
    "abstract": "The relationship between intelligence and evolution is bidirectional: while evolution can help evolve intelligences, the degree of intelligence itself can impact evolution (Baldwin, 1896). In the field of Evolutionary Computation, the inverse relationship (impact of intelligence on evolution) is approached from the perspective of organism level behaviour (Hinton, 1996). We extend these ideas to the developmental (cellular morphogenetic) level in the context of an expanded view of intelligence as not only the ability of a system to navigate the three-dimensional world, but also as the ability to navigate other arbitrary spaces (transcriptional, anatomical, physiological, etc.). Here, we specifically focus on the intelligence of a minimal model of a system navigating anatomical morphospace, and assess how the degree and manner of problem solving competency during morphogenesis effects evolutionary dynamics. To this end, we evolve populations of artificial embryos using a standard genetic algorithm in silico. Artificial embryos were cellular collectives given the capacity to undergo morphogenetic rearrangement (e.g., regulative development) prior to selection within an evolutionary cycle. Results from our model indicates that morphogenetic competency significantly alters evolutionary dynamics, with evolution preferring to improve anatomical intelligence rather than perfect the structural genes. These observations hint that evolution in the natural world may be leveraging the problem solving competencies of cells at multiple scales to boost evolvability and robustness to novel conditions. We discuss implications of our results for the Developmental Biology and Artificial Life communities.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09318"
  },
  "2310.09314": {
    "title": "Eliciting Model Steering Interactions from Users via Data and Visual Design Probes",
    "authors": [
      "Anamaria Crisan",
      "Maddie Shang",
      "Eric Brochu"
    ],
    "abstract": "Domain experts increasingly use automated data science tools to incorporate machine learning (ML) models in their work but struggle to \"debug\" these models when they are incorrect. For these experts, semantic interactions can provide an accessible avenue to guide and refine ML models without having to programmatically dive into its technical details. In this research, we conduct an elicitation study using data and visual design probes to examine if and how experts with a spectrum of ML expertise use semantic interactions to update a simple classification model. We use our design probes to facilitate an interactive dialogue with 20 participants and codify their interactions as a set of target-interaction pairs. Interestingly, our findings revealed that many targets of semantic interactions do not directly map to ML model parameters, but instead aim to augment the data a model uses for training. We also identify reasons that participants would hesitate to interact with ML models, including burdens of cognitive load and concerns of injecting bias. Unexpectedly participants also saw the value of using semantic interactions to work collaboratively with members of their team. Participants with less ML expertise found this to be a useful mechanism for communicating their concerns to ML experts. This was an especially important observation, as our study also shows the different needs that correspond to diverse ML expertise. Collectively, we demonstrate that design probes are effective tools for proactively gathering the affordances that should be offered in an interactive machine learning system.\n        \u25b3 Less",
    "submission_date": "12 October, 2023",
    "eprint_id": "2310.09314"
  },
  "2310.09299": {
    "title": "Digital Twin Assisted Deep Reinforcement Learning for Online Admission Control in Sliced Network",
    "authors": [
      "Zhenyu Tao",
      "Wei Xu",
      "Xiaohu You"
    ],
    "abstract": "The proliferation of diverse wireless services in 5G and beyond has led to the emergence of network slicing technologies. Among these, admission control plays a crucial role in achieving service-oriented optimization goals through the selective acceptance of service requests. Although deep reinforcement learning (DRL) forms the foundation in many admission control approaches thanks to its effectiveness and flexibility, initial instability with excessive convergence delay of DRL models hinders their deployment in real-world networks. We propose a digital twin (DT) accelerated DRL solution to address this issue. Specifically, we first formulate the admission decision-making process as a semi-Markov decision process, which is subsequently simplified into an equivalent discrete-time Markov decision process to facilitate the implementation of DRL methods. A neural network-based DT is established with a customized output layer for queuing systems, trained through supervised learning, and then employed to assist the training phase of the DRL model. Extensive simulations show that the DT-accelerated DRL improves resource utilization by over 40% compared to the directly trained state-of-the-art dueling deep Q-learning model. This improvement is achieved while preserving the model's capability to optimize the long-term rewards of the admission process.\n        \u25b3 Less",
    "submission_date": "21 November, 2023",
    "eprint_id": "2310.09299"
  },
  "2310.09289": {
    "title": "An Unbiased Look at Datasets for Visuo-Motor Pre-Training",
    "authors": [
      "Sudeep Dasari",
      "Mohan Kumar Srirama",
      "Unnat Jain",
      "Abhinav Gupta"
    ],
    "abstract": "Visual representation learning hold great promise for robotics, but is severely hampered by the scarcity and homogeneity of robotics datasets. Recent works address this problem by pre-training visual representations on large-scale but out-of-domain data (e.g., videos of egocentric interactions) and then transferring them to target robotics tasks. While the field is heavily focused on developing better pre-training algorithms, we find that dataset choice is just as important to this paradigm's success. After all, the representation can only learn the structures or priors present in the pre-training dataset. To this end, we flip the focus on algorithms, and instead conduct a dataset centric analysis of robotic pre-training. Our findings call into question some common wisdom in the field. We observe that traditional vision datasets (like ImageNet, Kinetics and 100 Days of Hands) are surprisingly competitive options for visuo-motor representation learning, and that the pre-training dataset's image distribution matters more than its size. Finally, we show that common simulation benchmarks are not a reliable proxy for real world performance and that simple regularization strategies can dramatically improve real world policy learning. https://data4robotics.github.io\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09289"
  },
  "2310.09285": {
    "title": "SAIR: Learning Semantic-aware Implicit Representation",
    "authors": [
      "Canyu Zhang",
      "Xiaoguang Li",
      "Qing Guo",
      "Song Wang"
    ],
    "abstract": "Implicit representation of an image can map arbitrary coordinates in the continuous domain to their corresponding color values, presenting a powerful capability for image reconstruction. Nevertheless, existing implicit representation approaches only focus on building continuous appearance mapping, ignoring the continuities of the semantic information across pixels. As a result, they can hardly achieve desired reconstruction results when the semantic information within input images is corrupted, for example, a large region misses. To address the issue, we propose to learn semantic-aware implicit representation (SAIR), that is, we make the implicit representation of each pixel rely on both its appearance and semantic information (\\eg, which object does the pixel belong to). To this end, we propose a framework with two modules: (1) building a semantic implicit representation (SIR) for a corrupted image whose large regions miss. Given an arbitrary coordinate in the continuous domain, we can obtain its respective text-aligned embedding indicating the object the pixel belongs. (2) building an appearance implicit representation (AIR) based on the SIR. Given an arbitrary coordinate in the continuous domain, we can reconstruct its color whether or not the pixel is missed in the input. We validate the novel semantic-aware implicit representation method on the image inpainting task, and the extensive experiments demonstrate that our method surpasses state-of-the-art approaches by a significant margin.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09285"
  },
  "2310.09278": {
    "title": "Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning",
    "authors": [
      "Geri Skenderi",
      "Luigi Capogrosso",
      "Andrea Toaiari",
      "Matteo Denitto",
      "Franco Fummi",
      "Simone Melzi",
      "Marco Cristani"
    ],
    "abstract": "In deep learning, auxiliary objectives are often used to facilitate learning in situations where data is scarce, or the principal task is extremely complex. This idea is primarily inspired by the improved generalization capability induced by solving multiple tasks simultaneously, which leads to a more robust shared representation. Nevertheless, finding optimal auxiliary tasks that give rise to the desired improvement is a crucial problem that often requires hand-crafted solutions or expensive meta-learning approaches. In this paper, we propose a novel framework, dubbed Detaux, whereby a weakly supervised disentanglement procedure is used to discover new unrelated classification tasks and the associated labels that can be exploited with the principal task in any Multi-Task Learning (MTL) model. The disentanglement procedure works at a representation level, isolating a subspace related to the principal task, plus an arbitrary number of orthogonal subspaces. In the most disentangled subspaces, through a clustering procedure, we generate the additional classification tasks, and the associated labels become their representatives. Subsequently, the original data, the labels associated with the principal task, and the newly discovered ones can be fed into any MTL framework. Extensive validation on both synthetic and real data, along with various ablation studies, demonstrate promising results, revealing the potential in what has been, so far, an unexplored connection between learning disentangled representations and MTL. The code will be made publicly available upon acceptance.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09278"
  },
  "2310.09277": {
    "title": "A Hybrid Approach for Depression Classification: Random Forest-ANN Ensemble on Motor Activity Signals",
    "authors": [
      "Anket Patil",
      "Dhairya Shah",
      "Abhishek Shah",
      "Mokshit Gala"
    ],
    "abstract": "Regarding the rising number of people suffering from mental health illnesses in today's society, the importance of mental health cannot be overstated. Wearable sensors, which are increasingly widely available, provide a potential way to track and comprehend mental health issues. These gadgets not only monitor everyday activities but also continuously record vital signs like heart rate, perhaps providing information on a person's mental state. Recent research has used these sensors in conjunction with machine learning methods to identify patterns relating to different mental health conditions, highlighting the immense potential of this data beyond simple activity monitoring. In this research, we present a novel algorithm called the Hybrid Random forest - Neural network that has been tailored to evaluate sensor data from depressed patients. Our method has a noteworthy accuracy of 80\\% when evaluated on a special dataset that included both unipolar and bipolar depressive patients as well as healthy controls. The findings highlight the algorithm's potential for reliably determining a person's depression condition using sensor data, making a substantial contribution to the area of mental health diagnostics.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09277"
  },
  "2310.09267": {
    "title": "Genetic algorithms are strong baselines for molecule generation",
    "authors": [
      "Austin Tripp",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "abstract": "Generating molecules, both in a directed and undirected fashion, is a huge part of the drug discovery pipeline. Genetic algorithms (GAs) generate molecules by randomly modifying known molecules. In this paper we show that GAs are very strong algorithms for such tasks, outperforming many complicated machine learning methods: a result which many researchers may find surprising. We therefore propose insisting during peer review that new algorithms must have some clear advantage over GAs, which we call the GA criterion. Ultimately our work suggests that a lot of research in molecule generation should be re-assessed.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09267"
  },
  "2310.09265": {
    "title": "PromptRE: Weakly-Supervised Document-Level Relation Extraction via Prompting-Based Data Programming",
    "authors": [
      "Chufan Gao",
      "Xulin Fan",
      "Jimeng Sun",
      "Xuan Wang"
    ],
    "abstract": "Relation extraction aims to classify the relationships between two entities into pre-defined categories. While previous research has mainly focused on sentence-level relation extraction, recent studies have expanded the scope to document-level relation extraction. Traditional relation extraction methods heavily rely on human-annotated training data, which is time-consuming and labor-intensive. To mitigate the need for manual annotation, recent weakly-supervised approaches have been developed for sentence-level relation extraction while limited work has been done on document-level relation extraction. Weakly-supervised document-level relation extraction faces significant challenges due to an imbalanced number \"no relation\" instances and the failure of directly probing pretrained large language models for document relation extraction. To address these challenges, we propose PromptRE, a novel weakly-supervised document-level relation extraction method that combines prompting-based techniques with data programming. Furthermore, PromptRE incorporates the label distribution and entity types as prior knowledge to improve the performance. By leveraging the strengths of both prompting and data programming, PromptRE achieves improved performance in relation classification and effectively handles the \"no relation\" problem. Experimental results on ReDocRED, a benchmark dataset for document-level relation extraction, demonstrate the superiority of PromptRE over baseline approaches.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09265"
  },
  "2310.09263": {
    "title": "Table-GPT: Table-tuned GPT for Diverse Table Tasks",
    "authors": [
      "Peng Li",
      "Yeye He",
      "Dror Yashar",
      "Weiwei Cui",
      "Song Ge",
      "Haidong Zhang",
      "Danielle Rifinski Fainman",
      "Dongmei Zhang",
      "Surajit Chaudhuri"
    ],
    "abstract": "Language models, such as GPT-3.5 and ChatGPT, demonstrate remarkable abilities to follow diverse human instructions and perform a wide range of tasks. However, when probing language models using a range of basic table-understanding tasks, we observe that today's language models are still sub-optimal in many table-related tasks, likely because they are pre-trained predominantly on \\emph{one-dimensional} natural-language texts, whereas relational tables are \\emph{two-dimensional} objects.\n  In this work, we propose a new \"\\emph{table-tuning}\" paradigm, where we continue to train/fine-tune language models like GPT-3.5 and ChatGPT, using diverse table-tasks synthesized from real tables as training data, with the goal of enhancing language models' ability to understand tables and perform table tasks. We show that our resulting Table-GPT models demonstrate (1) better \\emph{table-understanding} capabilities, by consistently outperforming the vanilla GPT-3.5 and ChatGPT, on a wide-range of table tasks, including holdout unseen tasks, and (2) strong \\emph{generalizability}, in its ability to respond to diverse human instructions to perform new table-tasks, in a manner similar to GPT-3.5 and ChatGPT.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09263"
  },
  "2310.09259": {
    "title": "QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language Models",
    "authors": [
      "Saleh Ashkboos",
      "Ilia Markov",
      "Elias Frantar",
      "Tingxuan Zhong",
      "Xincheng Wang",
      "Jie Ren",
      "Torsten Hoefler",
      "Dan Alistarh"
    ],
    "abstract": "Large Language Models (LLMs) from the GPT family have become extremely popular, leading to a race towards reducing their inference costs to allow for efficient local computation. Yet, the vast majority of existing work focuses on weight-only quantization, which can reduce runtime costs in the memory-bound one-token-at-a-time generative setting, but does not address them in compute-bound scenarios, such as batched inference or prompt processing. In this paper, we address the general quantization problem, where both weights and activations should be quantized. We show, for the first time, that the majority of inference computations for large generative models such as LLaMA, OPT, and Falcon can be performed with both weights and activations being cast to 4 bits, in a way that leads to practical speedups, while at the same time maintaining good accuracy. We achieve this via a hybrid quantization strategy called QUIK, which compresses most of the weights and activations to 4-bit, while keeping some outlier weights and activations in higher-precision. The key feature of our scheme is that it is designed with computational efficiency in mind: we provide GPU kernels matching the QUIK format with highly-efficient layer-wise runtimes, which lead to practical end-to-end throughput improvements of up to 3.4x relative to FP16 execution. We provide detailed studies for models from the OPT, LLaMA-2 and Falcon families, as well as a first instance of accurate inference using quantization plus 2:4 sparsity. Code is available at: https://github.com/IST-DASLab/QUIK.\n        \u25b3 Less",
    "submission_date": "2 November, 2023",
    "eprint_id": "2310.09259"
  },
  "2310.09256": {
    "title": "Political claim identification and categorization in a multilingual setting: First experiments",
    "authors": [
      "Urs Zaberer",
      "Sebastian Pad\u00f3",
      "Gabriella Lapesa"
    ],
    "abstract": "The identification and classification of political claims is an important step in the analysis of political newspaper reports; however, resources for this task are few and far between. This paper explores different strategies for the cross-lingual projection of political claims analysis. We conduct experiments on a German dataset, DebateNet2.0, covering the policy debate sparked by the 2015 refugee crisis. Our evaluation involves two tasks (claim identification and categorization), three languages (German, English, and French) and two methods (machine translation -- the best method in our experiments -- and multilingual embeddings).\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09256"
  },
  "2310.09250": {
    "title": "It's an Alignment, Not a Trade-off: Revisiting Bias and Variance in Deep Models",
    "authors": [
      "Lin Chen",
      "Michal Lukasik",
      "Wittawat Jitkrittum",
      "Chong You",
      "Sanjiv Kumar"
    ],
    "abstract": "Classical wisdom in machine learning holds that the generalization error can be decomposed into bias and variance, and these two terms exhibit a \\emph{trade-off}. However, in this paper, we show that for an ensemble of deep learning based classification models, bias and variance are \\emph{aligned} at a sample level, where squared bias is approximately \\emph{equal} to variance for correctly classified sample points. We present empirical evidence confirming this phenomenon in a variety of deep learning models and datasets. Moreover, we study this phenomenon from two theoretical perspectives: calibration and neural collapse. We first show theoretically that under the assumption that the models are well calibrated, we can observe the bias-variance alignment. Second, starting from the picture provided by the neural collapse theory, we show an approximate correlation between bias and variance.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09250"
  },
  "2310.09247": {
    "title": "Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy",
    "authors": [
      "Anton Baryshnikov",
      "Max Ryabinin"
    ],
    "abstract": "Text-to-image synthesis has recently attracted widespread attention due to rapidly improving quality and numerous practical applications. However, the language understanding capabilities of text-to-image models are still poorly understood, which makes it difficult to reason about prompt formulations that a given model would understand well. In this work, we measure the capability of popular text-to-image models to understand $\\textit{hypernymy}$, or the \"is-a\" relation between words. We design two automatic metrics based on the WordNet semantic hierarchy and existing image classifiers pretrained on ImageNet. These metrics both enable broad quantitative comparison of linguistic capabilities for text-to-image models and offer a way of finding fine-grained qualitative differences, such as words that are unknown to models and thus are difficult for them to draw. We comprehensively evaluate popular text-to-image models, including GLIDE, Latent Diffusion, and Stable Diffusion, showing how our metrics can provide a better understanding of the individual strengths and weaknesses of these models.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09247"
  },
  "2310.09243": {
    "title": "Augmented Computational Design: Methodical Application of Artificial Intelligence in Generative Design",
    "authors": [
      "Pirouz Nourian",
      "Shervin Azadi",
      "Roy Uijtendaal",
      "Nan Bai"
    ],
    "abstract": "This chapter presents methodological reflections on the necessity and utility of artificial intelligence in generative design. Specifically, the chapter discusses how generative design processes can be augmented by AI to deliver in terms of a few outcomes of interest or performance indicators while dealing with hundreds or thousands of small decisions. The core of the performance-based generative design paradigm is about making statistical or simulation-driven associations between these choices and consequences for mapping and navigating such a complex decision space. This chapter will discuss promising directions in Artificial Intelligence for augmenting decision-making processes in architectural design for mapping and navigating complex design spaces.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09243"
  },
  "2310.09241": {
    "title": "Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration",
    "authors": [
      "Yiquan Wu",
      "Siying Zhou",
      "Yifei Liu",
      "Weiming Lu",
      "Xiaozhong Liu",
      "Yating Zhang",
      "Changlong Sun",
      "Fei Wu",
      "Kun Kuang"
    ],
    "abstract": "Legal Judgment Prediction (LJP) has become an increasingly crucial task in Legal AI, i.e., predicting the judgment of the case in terms of case fact description. Precedents are the previous legal cases with similar facts, which are the basis for the judgment of the subsequent case in national legal systems. Thus, it is worthwhile to explore the utilization of precedents in the LJP. Recent advances in deep learning have enabled a variety of techniques to be used to solve the LJP task. These can be broken down into two categories: large language models (LLMs) and domain-specific models. LLMs are capable of interpreting and generating complex natural language, while domain models are efficient in learning task-specific information. In this paper, we propose the precedent-enhanced LJP framework (PLJP), a system that leverages the strength of both LLM and domain models in the context of precedents. Specifically, the domain models are designed to provide candidate labels and find the proper precedents efficiently, and the large models will make the final prediction with an in-context precedents comprehension. Experiments on the real-world dataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a promising direction for LLM and domain-model collaboration that can be generalized to other vertical domains.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09241"
  },
  "2310.09238": {
    "title": "BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts",
    "authors": [
      "Saumajit Saha",
      "Albert Nanda"
    ],
    "abstract": "Bangla is the 7th most widely spoken language globally, with a staggering 234 million native speakers primarily hailing from India and Bangladesh. This morphologically rich language boasts a rich literary tradition, encompassing diverse dialects and language-specific challenges. Despite its linguistic richness and history, Bangla remains categorized as a low-resource language within the natural language processing (NLP) and speech community. This paper presents our submission to Task 2 (Sentiment Analysis of Bangla Social Media Posts) of the BLP Workshop. We experiment with various Transformer-based architectures to solve this task. Our quantitative results show that transfer learning really helps in better learning of the models in this low-resource language scenario. This becomes evident when we further finetune a model which has already been finetuned on twitter data for sentiment analysis task and that finetuned model performs the best among all other models. We also perform a detailed error analysis where we find some instances where ground truth labels need to be relooked at. We obtain a micro-F1 of 67.02\\% on the test set and our performance in this shared task is ranked at 21 in the leaderboard.\n        \u25b3 Less",
    "submission_date": "17 October, 2023",
    "eprint_id": "2310.09238"
  },
  "2310.09237": {
    "title": "Evaluating Machine Perception of Indigeneity: An Analysis of ChatGPT's Perceptions of Indigenous Roles in Diverse Scenarios",
    "authors": [
      "Cecilia Delgado Solorzano",
      "Carlos Toxtli Hernandez"
    ],
    "abstract": "Large Language Models (LLMs), like ChatGPT, are fundamentally tools trained on vast data, reflecting diverse societal impressions. This paper aims to investigate LLMs' self-perceived bias concerning indigeneity when simulating scenarios of indigenous people performing various roles. Through generating and analyzing multiple scenarios, this work offers a unique perspective on how technology perceives and potentially amplifies societal biases related to indigeneity in social computing. The findings offer insights into the broader implications of indigeneity in critical computing.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09237"
  },
  "2310.09236": {
    "title": "Time CNN and Graph Convolution Network for Epileptic Spike Detection in MEG Data",
    "authors": [
      "Pauline Mouches",
      "Thibaut Dejean",
      "Julien Jung",
      "Romain Bouet",
      "Carole Lartizien",
      "Romain Quentin"
    ],
    "abstract": "Magnetoencephalography (MEG) recordings of patients with epilepsy exhibit spikes, a typical biomarker of the pathology. Detecting those spikes allows accurate localization of brain regions triggering seizures. Spike detection is often performed manually. However, it is a burdensome and error prone task due to the complexity of MEG data. To address this problem, we propose a 1D temporal convolutional neural network (Time CNN) coupled with a graph convolutional network (GCN) to classify short time frames of MEG recording as containing a spike or not. Compared to other recent approaches, our models have fewer parameters to train and we propose to use a GCN to account for MEG sensors spatial relationships. Our models produce clinically relevant results and outperform deep learning-based state-of-the-art methods reaching a classification f1-score of 76.7% on a balanced dataset and of 25.5% on a realistic, highly imbalanced dataset, for the spike class.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09236"
  },
  "2310.09233": {
    "title": "AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems",
    "authors": [
      "Junjie Zhang",
      "Yupeng Hou",
      "Ruobing Xie",
      "Wenqi Sun",
      "Julian McAuley",
      "Wayne Xin Zhao",
      "Leyu Lin",
      "Ji-Rong Wen"
    ],
    "abstract": "Recently, there has been an emergence of employing LLM-powered agents as believable human proxies, based on their remarkable decision-making capability. However, existing studies mainly focus on simulating human dialogue. Human non-verbal behaviors, such as item clicking in recommender systems, although implicitly exhibiting user preferences and could enhance the modeling of users, have not been deeply explored. The main reasons lie in the gap between language modeling and behavior modeling, as well as the incomprehension of LLMs about user-item relations.\n  To address this issue, we propose AgentCF for simulating user-item interactions in recommender systems through agent-based collaborative filtering. We creatively consider not only users but also items as agents, and develop a collaborative learning approach that optimizes both kinds of agents together. Specifically, at each time step, we first prompt the user and item agents to interact autonomously. Then, based on the disparities between the agents' decisions and real-world interaction records, user and item agents are prompted to reflect on and adjust the misleading simulations collaboratively, thereby modeling their two-sided relations. The optimized agents can also propagate their preferences to other agents in subsequent interactions, implicitly capturing the collaborative filtering idea. Overall, the optimized agents exhibit diverse interaction behaviors within our framework, including user-item, user-user, item-item, and collective interactions. The results show that these agents can demonstrate personalized behaviors akin to those of real-world individuals, sparking the development of next-generation user behavior simulation.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09233"
  },
  "2310.09232": {
    "title": "Bounds on Guessing Numbers and Secret Sharing Combining Information Theory Methods",
    "authors": [
      "Emirhan G\u00fcrp\u0131nar"
    ],
    "abstract": "This paper is on developing some computer-assisted proof methods involving non-classical inequalities for Shannon entropy. Two areas of the applications of information inequalities are studied: Secret sharing schemes and hat guessing games. In the former a random secret value is transformed into shares distributed among several participants in such a way that only the qualified groups of participants can recover the secret value. In the latter each participant is assigned a hat colour and they try to guess theirs while seeing only some of the others'. The aim is to maximize the probability that every player guesses correctly, the optimal probability depends on the underlying sight graph. We use for both problems the method of non-Shannon-type information inequalities going back to Z. Zhang and R. W. Yeung. We employ the linear programming technique that allows to apply new information inequalities indirectly, without even writing them down explicitly. To reduce the complexity of the problems of linear programming involved in the bounds we extensively use symmetry considerations. Using these tools, we improve lower bounds on the ratio of key size to secret size for the former problem and an upper bound for one of the ten vertex graphs related to an open question by Riis for the latter problem.\n        \u25b3 Less",
    "submission_date": "18 October, 2023",
    "eprint_id": "2310.09232"
  },
  "2310.09229": {
    "title": "Insuring Smiles: Predicting routine dental coverage using Spark ML",
    "authors": [
      "Aishwarya Gupta",
      "Rahul S. Bhogale",
      "Priyanka Thota",
      "Prathushkumar Dathuri",
      "Jongwook Woo"
    ],
    "abstract": "Finding suitable health insurance coverage can be challenging for individuals and small enterprises in the USA. The Health Insurance Exchange Public Use Files (Exchange PUFs) dataset provided by CMS offers valuable information on health and dental policies [1]. In this paper, we leverage machine learning algorithms to predict if a health insurance plan covers routine dental services for adults. By analyzing plan type, region, deductibles, out-of-pocket maximums, and copayments, we employ Logistic Regression, Decision Tree, Random Forest, Gradient Boost, Factorization Model and Support Vector Machine algorithms. Our goal is to provide a clinical strategy for individuals and families to select the most suitable insurance plan based on income and expenses.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09229"
  },
  "2310.09223": {
    "title": "Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation",
    "authors": [
      "Eun Cheol Choi",
      "Emilio Ferrara"
    ],
    "abstract": "In today's digital era, the rapid spread of misinformation poses threats to public well-being and societal trust. As online misinformation proliferates, manual verification by fact checkers becomes increasingly challenging. We introduce FACT-GPT (Fact-checking Augmentation with Claim matching Task-oriented Generative Pre-trained Transformer), a framework designed to automate the claim matching phase of fact-checking using Large Language Models (LLMs). This framework identifies new social media content that either supports or contradicts claims previously debunked by fact-checkers. Our approach employs GPT-4 to generate a labeled dataset consisting of simulated social media posts. This data set serves as a training ground for fine-tuning more specialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media content related to public health. The results indicate that our fine-tuned LLMs rival the performance of larger pre-trained LLMs in claim matching tasks, aligning closely with human annotations. This study achieves three key milestones: it provides an automated framework for enhanced fact-checking; demonstrates the potential of LLMs to complement human expertise; offers public resources, including datasets and models, to further research and applications in the fact-checking domain.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09223"
  },
  "2310.09222": {
    "title": "Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality",
    "authors": [
      "Minn Sein",
      "Fu Shunkai"
    ],
    "abstract": "Structure learning is essential for Bayesian networks (BNs) as it uncovers causal relationships, and enables knowledge discovery, predictions, inferences, and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN, based on the PC algorithm, employ local search strategy and conditional independence tests to learn the causal network structure from data. They incorporate d-separation to infer additional topology information, prioritize conditioning sets, and terminate the search immediately and efficiently. FSBN achieves up to 52% computation cost reduction, while SSBN surpasses it with a remarkable 72% reduction for a 200-node network. SSBN demonstrates further efficiency gains due to its intelligent strategy. Experimental studies show that both algorithms match the induction quality of the PC algorithm while significantly reducing computation costs. This enables them to offer interpretability and adaptability while reducing the computational burden, making them valuable for various applications in big data analytics.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09222"
  },
  "2310.09220": {
    "title": "Univalent Double Categories",
    "authors": [
      "Niels van der Weide",
      "Nima Rasekh",
      "Benedikt Ahrens",
      "Paige Randall North"
    ],
    "abstract": "Category theory is a branch of mathematics that provides a formal framework for understanding the relationship between mathematical structures. To this end, a category not only incorporates the data of the desired objects, but also \"morphisms\", which capture how different objects interact with each other. Category theory has found many applications in mathematics and in computer science, for example in functional programming. Double categories are a natural generalization of categories which incorporate the data of two separate classes of morphisms, allowing a more nuanced representation of relationships and interactions between objects. Similar to category theory, double categories have been successfully applied to various situations in mathematics and computer science, in which objects naturally exhibit two types of morphisms. Examples include categories themselves, but also lenses, petri nets, and spans. While categories have already been formalized in a variety of proof assistants, double categories have received far less attention. In this paper we remedy this situation by presenting a formalization of double categories via the proof assistant Coq, relying on the Coq UniMath library. As part of this work we present two equivalent formalizations of the definition of a double category, an unfolded explicit definition and a second definition which exhibits excellent formal properties via 2-sided displayed categories. As an application of the formal approach we establish a notion of univalent double category along with a univalence principle: equivalences of univalent double categories coincide with their identities\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09220"
  },
  "2310.09217": {
    "title": "Multinational AGI Consortium (MAGIC): A Proposal for International Coordination on AI",
    "authors": [
      "Jason Hausenloy",
      "Andrea Miotti",
      "Claire Dennis"
    ],
    "abstract": "This paper proposes a Multinational Artificial General Intelligence Consortium (MAGIC) to mitigate existential risks from advanced artificial intelligence (AI). MAGIC would be the only institution in the world permitted to develop advanced AI, enforced through a global moratorium by its signatory members on all other advanced AI development. MAGIC would be exclusive, safety-focused, highly secure, and collectively supported by member states, with benefits distributed equitably among signatories. MAGIC would allow narrow AI models to flourish while significantly reducing the possibility of misaligned, rogue, breakout, or runaway outcomes of general-purpose systems. We do not address the political feasibility of implementing a moratorium or address the specific legislative strategies and rules needed to enforce a ban on high-capacity AGI training runs. Instead, we propose one positive vision of the future, where MAGIC, as a global governance regime, can lay the groundwork for long-term, safe regulation of advanced AI.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09217"
  },
  "2310.09210": {
    "title": "Regularization-Based Methods for Ordinal Quantification",
    "authors": [
      "Mirko Bunse",
      "Alejandro Moreo",
      "Fabrizio Sebastiani",
      "Martin Senz"
    ],
    "abstract": "Quantification, i.e., the task of training predictors of the class prevalence values in sets of unlabeled data items, has received increased attention in recent years. However, most quantification research has concentrated on developing algorithms for binary and multiclass problems in which the classes are not ordered. Here, we study the ordinal case, i.e., the case in which a total order is defined on the set of n>2 classes. We give three main contributions to this field. First, we create and make available two datasets for ordinal quantification (OQ) research that overcome the inadequacies of the previously available ones. Second, we experimentally compare the most important OQ algorithms proposed in the literature so far. To this end, we bring together algorithms proposed by authors from very different research fields, such as data mining and astrophysics, who were unaware of each others' developments. Third, we propose a novel class of regularized OQ algorithms, which outperforms existing algorithms in our experiments. The key to this gain in performance is that our regularization prevents ordinally implausible estimates, assuming that ordinal distributions tend to be smooth in practice. We informally verify this assumption for several real-world applications.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09210"
  },
  "2310.09201": {
    "title": "FingerTac -- An Interchangeable and Wearable Tactile Sensor for the Fingertips of Human and Robot Hands",
    "authors": [
      "Prathamesh Sathe",
      "Alexander Schmitz",
      "Satoshi Funabashi",
      "Tito Pradhono Tomo",
      "Sophon Somlor",
      "Sugano Shigeki"
    ],
    "abstract": "Skill transfer from humans to robots is challenging. Presently, many researchers focus on capturing only position or joint angle data from humans to teach the robots. Even though this approach has yielded impressive results for grasping applications, reconstructing motion for object handling or fine manipulation from a human hand to a robot hand has been sparsely explored. Humans use tactile feedback to adjust their motion to various objects, but capturing and reproducing the applied forces is an open research question. In this paper we introduce a wearable fingertip tactile sensor, which captures the distributed 3-axis force vectors on the fingertip. The fingertip tactile sensor is interchangeable between the human hand and the robot hand, meaning that it can also be assembled to fit on a robot hand such as the Allegro hand. This paper presents the structural aspects of the sensor as well as the methodology and approach used to design, manufacture, and calibrate the sensor. The sensor is able to measure forces accurately with a mean absolute error of 0.21, 0.16, and 0.44 Newtons in X, Y, and Z directions, respectively.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09201"
  },
  "2310.09199": {
    "title": "PaLI-3 Vision Language Models: Smaller, Faster, Stronger",
    "authors": [
      "Xi Chen",
      "Xiao Wang",
      "Lucas Beyer",
      "Alexander Kolesnikov",
      "Jialin Wu",
      "Paul Voigtlaender",
      "Basil Mustafa",
      "Sebastian Goodman",
      "Ibrahim Alabdulmohsin",
      "Piotr Padlewski",
      "Daniel Salz",
      "Xi Xiong",
      "Daniel Vlasic",
      "Filip Pavetic",
      "Keran Rong",
      "Tianli Yu",
      "Daniel Keysers",
      "Xiaohua Zhai",
      "Radu Soricut"
    ],
    "abstract": "This paper presents PaLI-3, a smaller, faster, and stronger vision language model (VLM) that compares favorably to similar models that are 10x larger. As part of arriving at this strong performance, we compare Vision Transformer (ViT) models pretrained using classification objectives to contrastively (SigLIP) pretrained ones. We find that, while slightly underperforming on standard image classification benchmarks, SigLIP-based PaLI shows superior performance across various multimodal benchmarks, especially on localization and visually-situated text understanding. We scale the SigLIP image encoder up to 2 billion parameters, and achieves a new state-of-the-art on multilingual cross-modal retrieval. We hope that PaLI-3, at only 5B parameters, rekindles research on fundamental pieces of complex VLMs, and could fuel a new generation of scaled-up models.\n        \u25b3 Less",
    "submission_date": "17 October, 2023",
    "eprint_id": "2310.09199"
  },
  "2310.09195": {
    "title": "AMSwarmX: Safe Swarm Coordination in CompleX Environments via Implicit Non-Convex Decomposition of the Obstacle-Free Space",
    "authors": [
      "Vivek K. Adajania",
      "Siqi Zhou",
      "Arun Kumar Singh",
      "Angela P. Schoellig"
    ],
    "abstract": "Quadrotor motion planning in complex environments leverage the concept of safe flight corridor (SFC) to facilitate static obstacle avoidance. Typically, SFCs are constructed through convex decomposition of the environment's free space into cuboids, convex polyhedra, or spheres. However, when dealing with a quadrotor swarm, such SFCs can be overly conservative, substantially limiting the available free space for quadrotors to coordinate. This paper presents an Alternating Minimization-based approach that does not require building a conservative free-space approximation. Instead, both static and dynamic collision constraints are treated in a unified manner. Dynamic collisions are handled based on shared position trajectories of the quadrotors. Static obstacle avoidance is coupled with distance queries from the Octomap, providing an implicit non-convex decomposition of free space. As a result, our approach is scalable to arbitrary complex environments. Through extensive comparisons in simulation, we demonstrate a $60\\%$ improvement in success rate, an average $1.8\\times$ reduction in mission completion time, and an average $23\\times$ reduction in per-agent computation time compared to SFC-based approaches. We also experimentally validated our approach using a Crazyflie quadrotor swarm of up to 12 quadrotors in obstacle-rich environments. The code, supplementary materials, and videos are released for reference.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09195"
  },
  "2310.09194": {
    "title": "Variational autoencoder with weighted samples for high-dimensional non-parametric adaptive importance sampling",
    "authors": [
      "Julien Demange-Chryst",
      "Fran\u00e7ois Bachoc",
      "J\u00e9r\u00f4me Morio",
      "Timoth\u00e9 Krauth"
    ],
    "abstract": "Probability density function estimation with weighted samples is the main foundation of all adaptive importance sampling algorithms. Classically, a target distribution is approximated either by a non-parametric model or within a parametric family. However, these models suffer from the curse of dimensionality or from their lack of flexibility. In this contribution, we suggest to use as the approximating model a distribution parameterised by a variational autoencoder. We extend the existing framework to the case of weighted samples by introducing a new objective function. The flexibility of the obtained family of distributions makes it as expressive as a non-parametric model, and despite the very high number of parameters to estimate, this family is much more efficient in high dimension than the classical Gaussian or Gaussian mixture families. Moreover, in order to add flexibility to the model and to be able to learn multimodal distributions, we consider a learnable prior distribution for the variational autoencoder latent variables. We also introduce a new pre-training procedure for the variational autoencoder to find good starting weights of the neural networks to prevent as much as possible the posterior collapse phenomenon to happen. At last, we explicit how the resulting distribution can be combined with importance sampling, and we exploit the proposed procedure in existing adaptive importance sampling algorithms to draw points from a target distribution and to estimate a rare event probability in high dimension on two multimodal problems.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09194"
  },
  "2310.09193": {
    "title": "Tikuna: An Ethereum Blockchain Network Security Monitoring System",
    "authors": [
      "Andres Gomez Ramirez",
      "Loui Al Sardy",
      "Francis Gomez Ramirez"
    ],
    "abstract": "Blockchain security is becoming increasingly relevant in today's cyberspace as it extends its influence in many industries. This paper focuses on protecting the lowest level layer in the blockchain, particularly the P2P network that allows the nodes to communicate and share information. The P2P network layer may be vulnerable to several families of attacks, such as Distributed Denial of Service (DDoS), eclipse attacks, or Sybil attacks. This layer is prone to threats inherited from traditional P2P networks, and it must be analyzed and understood by collecting data and extracting insights from the network behavior to reduce those risks. We introduce Tikuna, an open-source tool for monitoring and detecting potential attacks on the Ethereum blockchain P2P network, at an early stage. Tikuna employs an unsupervised Long Short-Term Memory (LSTM) method based on Recurrent Neural Network (RNN) to detect attacks and alert users. Empirical results indicate that the proposed approach significantly improves detection performance, with the ability to detect and classify attacks, including eclipse attacks, Covert Flash attacks, and others that target the Ethereum blockchain P2P network layer, with high accuracy. Our research findings demonstrate that Tikuna is a valuable security tool for assisting operators to efficiently monitor and safeguard the status of Ethereum validators and the wider P2P network\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09193"
  },
  "2310.09192": {
    "title": "Does Graph Distillation See Like Vision Dataset Counterpart?",
    "authors": [
      "Beining Yang",
      "Kai Wang",
      "Qingyun Sun",
      "Cheng Ji",
      "Xingcheng Fu",
      "Hao Tang",
      "Yang You",
      "Jianxin Li"
    ],
    "abstract": "Training on large-scale graphs has achieved remarkable results in graph representation learning, but its cost and storage have attracted increasing concerns. Existing graph condensation methods primarily focus on optimizing the feature matrices of condensed graphs while overlooking the impact of the structure information from the original graphs. To investigate the impact of the structure information, we conduct analysis from the spectral domain and empirically identify substantial Laplacian Energy Distribution (LED) shifts in previous works. Such shifts lead to poor performance in cross-architecture generalization and specific tasks, including anomaly detection and link prediction. In this paper, we propose a novel Structure-broadcasting Graph Dataset Distillation (SGDD) scheme for broadcasting the original structure information to the generation of the synthetic one, which explicitly prevents overlooking the original structure information. Theoretically, the synthetic graphs by SGDD are expected to have smaller LED shifts than previous works, leading to superior performance in both cross-architecture settings and specific tasks. We validate the proposed SGDD across 9 datasets and achieve state-of-the-art results on all of them: for example, on the YelpChi dataset, our approach maintains 98.6% test accuracy of training on the original graph dataset with 1,000 times saving on the scale of the graph. Moreover, we empirically evaluate there exist 17.6% ~ 31.4% reductions in LED shift crossing 9 datasets. Extensive experiments and analysis verify the effectiveness and necessity of the proposed designs. The code is available in the GitHub repository: https://github.com/RingBDStack/SGDD.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09192"
  },
  "2310.09183": {
    "title": "PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning",
    "authors": [
      "Mingjia Shi",
      "Yuhao Zhou",
      "Kai Wang",
      "Huaizheng Zhang",
      "Shudong Huang",
      "Qing Ye",
      "Jiangcheng Lv"
    ],
    "abstract": "Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the PFL with Bregman Divergence (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFedBreD is backed up by a convergence analysis. Sufficient experiments demonstrate that our method reaches the state-of-the-art performances on 5 datasets and outperforms other methods by up to 3.5% across 8 benchmarks. Extensive analyses verify the robustness and necessity of proposed designs.\n        \u25b3 Less",
    "submission_date": "10 November, 2023",
    "eprint_id": "2310.09183"
  },
  "2310.09170": {
    "title": "mnmDTW: An extension to Dynamic Time Warping for Camera-based Movement Error Localization",
    "authors": [
      "Sebastian Dill",
      "Maurice Rohr"
    ],
    "abstract": "In this proof of concept, we use Computer Vision (CV) methods to extract pose information out of exercise videos. We then employ a modified version of Dynamic Time Warping (DTW) to calculate the deviation from a gold standard execution of the exercise. Specifically, we calculate the distance between each body part individually to get a more precise measure for exercise accuracy. We can show that exercise mistakes are clearly visible, identifiable and localizable through this metric.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09170"
  },
  "2310.09168": {
    "title": "Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration",
    "authors": [
      "Fanqi Wan",
      "Xinting Huang",
      "Tao Yang",
      "Xiaojun Quan",
      "Wei Bi",
      "Shuming Shi"
    ],
    "abstract": "Instruction-tuning can be substantially optimized through enhanced diversity, resulting in models capable of handling a broader spectrum of tasks. However, existing data employed for such tuning often exhibit an inadequate coverage of individual domains, limiting the scope for nuanced comprehension and interactions within these areas. To address this deficiency, we propose Explore-Instruct, a novel approach to enhance the data coverage to be used in domain-specific instruction-tuning through active exploration via Large Language Models (LLMs). Built upon representative domain use cases, Explore-Instruct explores a multitude of variations or possibilities by implementing a search algorithm to obtain diversified and domain-focused instruction-tuning data. Our data-centric analysis validates the effectiveness of this proposed approach in improving domain-specific instruction coverage. Moreover, our model's performance demonstrates considerable advancements over multiple baselines, including those utilizing domain-specific data enhancement. Our findings offer a promising opportunity to improve instruction coverage, especially in domain-specific contexts, thereby advancing the development of adaptable language models. Our code, model weights, and data are public at \\url{https://github.com/fanqiwan/Explore-Instruct}.\n        \u25b3 Less",
    "submission_date": "24 October, 2023",
    "eprint_id": "2310.09168"
  },
  "2310.09166": {
    "title": "Developing a Natural Language Understanding Model to Characterize Cable News Bias",
    "authors": [
      "Seth P. Benson",
      "Iain J. Cruickshank"
    ],
    "abstract": "Media bias has been extensively studied by both social and computational sciences. However, current work still has a large reliance on human input and subjective assessment to label biases. This is especially true for cable news research. To address these issues, we develop an unsupervised machine learning method to characterize the bias of cable news programs without any human input. This method relies on the analysis of what topics are mentioned through Named Entity Recognition and how those topics are discussed through Stance Analysis in order to cluster programs with similar biases together. Applying our method to 2020 cable news transcripts, we find that program clusters are consistent over time and roughly correspond to the cable news network of the program. This method reveals the potential for future tools to objectively assess media bias and characterize unfamiliar media environments.\n        \u25b3 Less",
    "submission_date": "17 October, 2023",
    "eprint_id": "2310.09166"
  },
  "2310.09165": {
    "title": "Towards Robust UAV Tracking in GNSS-Denied Environments: A Multi-LiDAR Multi-UAV Dataset",
    "authors": [
      "Iacopo Catalano",
      "Xianjia Yu",
      "Jorge Pena Queralta"
    ],
    "abstract": "With the increasing prevalence of drones in various industries, the navigation and tracking of unmanned aerial vehicles (UAVs) in challenging environments, particularly GNSS-denied areas, have become crucial concerns. To address this need, we present a novel multi-LiDAR dataset specifically designed for UAV tracking. Our dataset includes data from a spinning LiDAR, two solid-state LiDARs with different Field of View (FoV) and scan patterns, and an RGB-D camera. This diverse sensor suite allows for research on new challenges in the field, including limited FoV adaptability and multi-modality data processing.\n  The dataset facilitates the evaluation of existing algorithms and the development of new ones, paving the way for advances in UAV tracking techniques. Notably, we provide data in both indoor and outdoor environments. We also consider variable UAV sizes, from micro-aerial vehicles to more standard commercial UAV platforms. The outdoor trajectories are selected with close proximity to buildings, targeting research in UAV detection in urban areas, e.g., within counter-UAV systems or docking for UAV logistics.\n  In addition to the dataset, we provide a baseline comparison with recent LiDAR-based UAV tracking algorithms, benchmarking the performance with different sensors, UAVs, and algorithms. Importantly, our dataset shows that current methods have shortcomings and are unable to track UAVs consistently across different scenarios.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09165"
  },
  "2310.09162": {
    "title": "Quantum Machine Learning in Climate Change and Sustainability: a Review",
    "authors": [
      "Amal Nammouchi",
      "Andreas Kassler",
      "Andreas Theorachis"
    ],
    "abstract": "Climate change and its impact on global sustainability are critical challenges, demanding innovative solutions that combine cutting-edge technologies and scientific insights. Quantum machine learning (QML) has emerged as a promising paradigm that harnesses the power of quantum computing to address complex problems in various domains including climate change and sustainability. In this work, we survey existing literature that applies quantum machine learning to solve climate change and sustainability-related problems. We review promising QML methodologies that have the potential to accelerate decarbonization including energy systems, climate data forecasting, climate monitoring, and hazardous events predictions. We discuss the challenges and current limitations of quantum machine learning approaches and provide an overview of potential opportunities and future work to leverage QML-based methods in the important area of climate change research.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09162"
  },
  "2310.09151": {
    "title": "BibRank: Automatic Keyphrase Extraction Platform Using~Metadata",
    "authors": [
      "Abdelrhman Eldallal",
      "Eduard Barbu"
    ],
    "abstract": "Automatic Keyphrase Extraction involves identifying essential phrases in a document. These keyphrases are crucial in various tasks such as document classification, clustering, recommendation, indexing, searching, summarization, and text simplification. This paper introduces a platform that integrates keyphrase datasets and facilitates the evaluation of keyphrase extraction algorithms. The platform includes BibRank, an automatic keyphrase extraction algorithm that leverages a rich dataset obtained by parsing bibliographic data in BibTeX format. BibRank combines innovative weighting techniques with positional, statistical, and word co-occurrence information to extract keyphrases from documents. The platform proves valuable for researchers and developers seeking to enhance their keyphrase extraction algorithms and advance the field of natural language processing.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09151"
  },
  "2310.09147": {
    "title": "Exploring Sparse Spatial Relation in Graph Inference for Text-Based VQA",
    "authors": [
      "Sheng Zhou",
      "Dan Guo",
      "Jia Li",
      "Xun Yang",
      "Meng Wang"
    ],
    "abstract": "Text-based visual question answering (TextVQA) faces the significant challenge of avoiding redundant relational inference. To be specific, a large number of detected objects and optical character recognition (OCR) tokens result in rich visual relationships. Existing works take all visual relationships into account for answer prediction. However, there are three observations: (1) a single subject in the images can be easily detected as multiple objects with distinct bounding boxes (considered repetitive objects). The associations between these repetitive objects are superfluous for answer reasoning; (2) two spatially distant OCR tokens detected in the image frequently have weak semantic dependencies for answer reasoning; and (3) the co-existence of nearby objects and tokens may be indicative of important visual cues for predicting answers. Rather than utilizing all of them for answer prediction, we make an effort to identify the most important connections or eliminate redundant ones. We propose a sparse spatial graph network (SSGN) that introduces a spatially aware relation pruning technique to this task. As spatial factors for relation measurement, we employ spatial distance, geometric dimension, overlap area, and DIoU for spatially aware pruning. We consider three visual relationships for graph learning: object-object, OCR-OCR tokens, and object-OCR token relationships. SSGN is a progressive graph learning architecture that verifies the pivotal relations in the correlated object-token sparse graph, and then in the respective object-based sparse graph and token-based sparse graph. Experiment results on TextVQA and ST-VQA datasets demonstrate that SSGN achieves promising performances. And some visualization results further demonstrate the interpretability of our method.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09147"
  },
  "2310.09145": {
    "title": "Lincoln AI Computing Survey (LAICS) Update",
    "authors": [
      "Albert Reuther",
      "Peter Michaleas",
      "Michael Jones",
      "Vijay Gadepally",
      "Siddharth Samsi",
      "Jeremy Kepner"
    ],
    "abstract": "This paper is an update of the survey of AI accelerators and processors from past four years, which is now called the Lincoln AI Computing Survey - LAICS (pronounced \"lace\"). As in past years, this paper collects and summarizes the current commercial accelerators that have been publicly announced with peak performance and peak power consumption numbers. The performance and power values are plotted on a scatter graph, and a number of dimensions and observations from the trends on this plot are again discussed and analyzed. Market segments are highlighted on the scatter plot, and zoomed plots of each segment are also included. Finally, a brief description of each of the new accelerators that have been added in the survey this year is included.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09145"
  },
  "2310.09144": {
    "title": "Goodhart's Law in Reinforcement Learning",
    "authors": [
      "Jacek Karwowski",
      "Oliver Hayman",
      "Xingjian Bai",
      "Klaus Kiendlhofer",
      "Charlie Griffin",
      "Joar Skalse"
    ],
    "abstract": "Implementing a reward function that perfectly captures a complex task in the real world is impractical. As a result, it is often appropriate to think of the reward function as a proxy for the true objective rather than as its definition. We study this phenomenon through the lens of Goodhart's law, which predicts that increasing optimisation of an imperfect proxy beyond some critical point decreases performance on the true objective. First, we propose a way to quantify the magnitude of this effect and show empirically that optimising an imperfect proxy reward often leads to the behaviour predicted by Goodhart's law for a wide range of environments and reward functions. We then provide a geometric explanation for why Goodhart's law occurs in Markov decision processes. We use these theoretical insights to propose an optimal early stopping method that provably avoids the aforementioned pitfall and derive theoretical regret bounds for this method. Moreover, we derive a training method that maximises worst-case reward, for the setting where there is uncertainty about the true reward function. Finally, we evaluate our early stopping method experimentally. Our results support a foundation for a theoretically-principled study of reinforcement learning under reward misspecification.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09144"
  },
  "2310.09143": {
    "title": "An Intrinsic Integrity-Driven Rating Model for a Sustainable Reputation System",
    "authors": [
      "H. Wen",
      "T. Huang",
      "D. Xiao"
    ],
    "abstract": "In the era of digital markets, the challenge for consumers is discerning quality amidst information asymmetry. While traditional markets use brand mechanisms to address this issue, transferring such systems to internet-based P2P markets, where misleading practices like fake ratings are rampant, remains challenging. Current internet platforms strive to counter this through verification algorithms, but these efforts find themselves in a continuous tug-of-war with counterfeit actions.\n  Exploiting the transparency, immutability, and traceability of blockchain technology, this paper introduces a robust reputation voting system grounded in it. Unlike existing blockchain-based reputation systems, our model harnesses an intrinsically economically incentivized approach to bolster agent integrity. We optimize this model to mirror real-world user behavior, preserving the reputation system's foundational sustainability. Through Monte-Carlo simulations, using both uniform and power-law distributions enabled by an innovative inverse transform method, we traverse a broad parameter landscape, replicating real-world complexity. The findings underscore the promise of a sustainable, transparent, and formidable reputation mechanism. Given its structure, our framework can potentially function as a universal, sustainable oracle for offchain-onchain bridging, aiding entities in perpetually cultivating their reputation. Future integration with technologies like Ring Signature and Zero Knowledge Proof could amplify the system's privacy facets, rendering it particularly influential in the ever-evolving digital domain.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09143"
  },
  "2310.09141": {
    "title": "PuoBERTa: Training and evaluation of a curated language model for Setswana",
    "authors": [
      "Vukosi Marivate",
      "Moseli Mots'Oehli",
      "Valencia Wagner",
      "Richard Lastrucci",
      "Isheanesu Dzingirai"
    ],
    "abstract": "Natural language processing (NLP) has made significant progress for well-resourced languages such as English but lagged behind for low-resource languages like Setswana. This paper addresses this gap by presenting PuoBERTa, a customised masked language model trained specifically for Setswana. We cover how we collected, curated, and prepared diverse monolingual texts to generate a high-quality corpus for PuoBERTa's training. Building upon previous efforts in creating monolingual resources for Setswana, we evaluated PuoBERTa across several NLP tasks, including part-of-speech (POS) tagging, named entity recognition (NER), and news categorisation. Additionally, we introduced a new Setswana news categorisation dataset and provided the initial benchmarks using PuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP capabilities for understudied languages like Setswana and paves the way for future research directions.\n        \u25b3 Less",
    "submission_date": "24 October, 2023",
    "eprint_id": "2310.09141"
  },
  "2310.09139": {
    "title": "The Consensus Game: Language Model Generation via Equilibrium Search",
    "authors": [
      "Athul Paul Jacob",
      "Yikang Shen",
      "Gabriele Farina",
      "Jacob Andreas"
    ],
    "abstract": "When applied to question answering and other text generation tasks, language models (LMs) may be queried generatively (by sampling answers from their output distribution) or discriminatively (by using them to score or rank a set of candidate outputs). These procedures sometimes yield very different predictions. How do we reconcile mutually incompatible scoring procedures to obtain coherent LM predictions? We introduce a new, a training-free, game-theoretic procedure for language model decoding. Our approach casts language model decoding as a regularized imperfect-information sequential signaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks to communicate an abstract correctness parameter using natural language sentences to a DISCRIMINATOR. We develop computational procedures for finding approximate equilibria of this game, resulting in a decoding algorithm we call EQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading comprehension, commonsense reasoning, mathematical problem-solving, and dialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially, improves performance over existing LM decoding procedures - on multiple benchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B outperforms the much larger LLaMA-65B and PaLM-540B models. These results highlight the promise of game-theoretic tools for addressing fundamental challenges of truthfulness and consistency in LMs.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09139"
  },
  "2310.09137": {
    "title": "Scaling Performance of Serverless Edge Networking",
    "authors": [
      "Marc Michalke",
      "Francisco Carpio",
      "Admela Jukan"
    ],
    "abstract": "When clustering devices at the edge, inter-node latency poses a significant challenge that directly impacts the application performance. In this paper, we experimentally examine the impact that inter-node latency has on application performance by measuring the throughput of an distributed serverless application in a real world testbed. We deploy Knative over a Kubernetes cluster of nodes and emulate networking delay between them to compare the performance of applications when deployed over a single-site versus multiple distributed computing sites. The results show that multi-site edge networks achieve half the throughput compared to a deployment hosted at a single site under low processing times conditions, whereas the throughput performance significantly improves otherwise.\n        \u25b3 Less",
    "submission_date": "27 October, 2023",
    "eprint_id": "2310.09137"
  },
  "2310.09136": {
    "title": "DocCert: Nostrification, Document Verification and Authenticity Blockchain Solution",
    "authors": [
      "Monther Aldwairi",
      "Mohamad Badra",
      "Rouba Borghol"
    ],
    "abstract": "Many institutions and organizations require nostrification and verification of qualification as a prerequisite for hiring. The idea is to recognize the authenticity of a copy or digital document issued by an institution in a foreign country and detect forgeries. Certificates, financial records, health records, official papers and others are often required to be attested from multiple entities in distinct locations. However, in this digital era where most applications happen online, and document copies are uploaded, the traditional signature and seal methods are obsolete. In a matter of minutes and with a simple photo editor, a certificate or document copy may be plagiarized or forged. Blockchain technology offers a decentralized approach to record and verify transactions without the need for huge infrastructure investment. In this paper, we propose a blockchain based nostrification system, where awarding institutions generate a digital certificate, store in a public but permissioned blockchain, where students and other stakeholders may verify. We present a thorough discussion and formal evaluation of the proposed system.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09136"
  },
  "2310.09135": {
    "title": "HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling",
    "authors": [
      "Junwen Zhang",
      "Yin Zhang"
    ],
    "abstract": "In task-oriented dialogue scenarios, cross-domain zero-shot slot filling plays a vital role in leveraging source domain knowledge to learn a model with high generalization ability in unknown target domain where annotated data is unavailable. However, the existing state-of-the-art zero-shot slot filling methods have limited generalization ability in target domain, they only show effective knowledge transfer on seen slots and perform poorly on unseen slots. To alleviate this issue, we present a novel Hierarchical Contrastive Learning Framework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse- to fine-grained contrastive learning based on Gaussian-distributed embedding to learn the generalized deep semantic relations between utterance-tokens, by optimizing inter- and intra-token distribution distance. This encourages HiCL to generalize to the slot types unseen at training phase. Furthermore, we present a new iterative label set semantics inference method to unbiasedly and separately evaluate the performance of unseen slot types which entangled with their counterparts (i.e., seen slot types) in the previous zero-shot slot filling evaluation methods. The extensive empirical experiments on four datasets demonstrate that the proposed method achieves comparable or even better performance than the current state-of-the-art zero-shot slot filling approaches.\n        \u25b3 Less",
    "submission_date": "20 October, 2023",
    "eprint_id": "2310.09135"
  },
  "2310.09131": {
    "title": "Machine learning-based prediction of Q-voter model in complex networks",
    "authors": [
      "Aruane M. Pineda",
      "Paul Kent",
      "Colm Connaughton",
      "Francisco A. Rodrigues"
    ],
    "abstract": "In this article, we consider machine learning algorithms to accurately predict two variables associated with the $Q$-voter model in complex networks, i.e., (i) the consensus time and (ii) the frequency of opinion changes. Leveraging nine topological measures of the underlying networks, we verify that the clustering coefficient (C) and information centrality (IC) emerge as the most important predictors for these outcomes. Notably, the machine learning algorithms demonstrate accuracy across three distinct initialization methods of the $Q$-voter model, including random selection and the involvement of high- and low-degree agents with positive opinions. By unraveling the intricate interplay between network structure and dynamics, this research sheds light on the underlying mechanisms responsible for polarization effects and other dynamic patterns in social systems. Adopting a holistic approach that comprehends the complexity of network systems, this study offers insights into the intricate dynamics associated with polarization effects and paves the way for investigating the structure and dynamics of complex systems through modern machine learning methods.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09131"
  },
  "2310.09129": {
    "title": "Computing Marginal and Conditional Divergences between Decomposable Models with Applications",
    "authors": [
      "Loong Kuan Lee",
      "Geoffrey I. Webb",
      "Daniel F. Schmidt",
      "Nico Piatkowski"
    ],
    "abstract": "The ability to compute the exact divergence between two high-dimensional distributions is useful in many applications but doing so naively is intractable. Computing the alpha-beta divergence -- a family of divergences that includes the Kullback-Leibler divergence and Hellinger distance -- between the joint distribution of two decomposable models, i.e chordal Markov networks, can be done in time exponential in the treewidth of these models. However, reducing the dissimilarity between two high-dimensional objects to a single scalar value can be uninformative. Furthermore, in applications such as supervised learning, the divergence over a conditional distribution might be of more interest. Therefore, we propose an approach to compute the exact alpha-beta divergence between any marginal or conditional distribution of two decomposable models. Doing so tractably is non-trivial as we need to decompose the divergence between these distributions and therefore, require a decomposition over the marginal and conditional distributions of these models. Consequently, we provide such a decomposition and also extend existing work to compute the marginal and conditional alpha-beta divergence between these decompositions. We then show how our method can be used to analyze distributional changes by first applying it to a benchmark image dataset. Finally, based on our framework, we propose a novel way to quantify the error in contemporary superconducting quantum computers. Code for all experiments is available at: https://lklee.dev/pub/2023-icdm/code\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09129"
  },
  "2310.09127": {
    "title": "On Generalization Bounds for Projective Clustering",
    "authors": [
      "Maria Sofia Bucarelli",
      "Matilde Fjelds\u00f8 Larsen",
      "Chris Schwiegelshohn",
      "Mads Bech Toftrup"
    ],
    "abstract": "Given a set of points, clustering consists of finding a partition of a point set into $k$ clusters such that the center to which a point is assigned is as close as possible. Most commonly, centers are points themselves, which leads to the famous $k$-median and $k$-means objectives. One may also choose centers to be $j$ dimensional subspaces, which gives rise to subspace clustering. In this paper, we consider learning bounds for these problems. That is, given a set of $n$ samples $P$ drawn independently from some unknown, but fixed distribution $\\mathcal{D}$, how quickly does a solution computed on $P$ converge to the optimal clustering of $\\mathcal{D}$? We give several near optimal results. In particular,\n  For center-based objectives, we show a convergence rate of $\\tilde{O}\\left(\\sqrt{{k}/{n}}\\right)$. This matches the known optimal bounds of [Fefferman, Mitter, and Narayanan, Journal of the Mathematical Society 2016] and [Bartlett, Linder, and Lugosi, IEEE Trans. Inf. Theory 1998] for $k$-means and extends it to other important objectives such as $k$-median.\n  For subspace clustering with $j$-dimensional subspaces, we show a convergence rate of $\\tilde{O}\\left(\\sqrt{\\frac{kj^2}{n}}\\right)$. These are the first provable bounds for most of these problems. For the specific case of projective clustering, which generalizes $k$-means, we show a convergence rate of $\u03a9\\left(\\sqrt{\\frac{kj}{n}}\\right)$ is necessary, thereby proving that the bounds from [Fefferman, Mitter, and Narayanan, Journal of the Mathematical Society 2016] are essentially optimal.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09127"
  },
  "2310.09125": {
    "title": "Training and Predicting Visual Error for Real-Time Applications",
    "authors": [
      "Jo\u00e3o Lib\u00f3rio Cardoso",
      "Bernhard Kerbl",
      "Lei Yang",
      "Yury Uralsky",
      "Michael Wimmer"
    ],
    "abstract": "Visual error metrics play a fundamental role in the quantification of perceived image similarity. Most recently, use cases for them in real-time applications have emerged, such as content-adaptive shading and shading reuse to increase performance and improve efficiency. A wide range of different metrics has been established, with the most sophisticated being capable of capturing the perceptual characteristics of the human visual system. However, their complexity, computational expense, and reliance on reference images to compare against prevent their generalized use in real-time, restricting such applications to using only the simplest available metrics. In this work, we explore the abilities of convolutional neural networks to predict a variety of visual metrics without requiring either reference or rendered images. Specifically, we train and deploy a neural network to estimate the visual error resulting from reusing shading or using reduced shading rates. The resulting models account for 70%-90% of the variance while achieving up to an order of magnitude faster computation times. Our solution combines image-space information that is readily available in most state-of-the-art deferred shading pipelines with reprojection from previous frames to enable an adequate estimate of visual errors, even in previously unseen regions. We describe a suitable convolutional network architecture and considerations for data preparation for training. We demonstrate the capability of our network to predict complex error metrics at interactive rates in a real-time application that implements content-adaptive shading in a deferred pipeline. Depending on the portion of unseen image regions, our approach can achieve up to $2\\times$ performance compared to state-of-the-art methods.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09125"
  },
  "2310.09124": {
    "title": "Taking the Shortcut: Actively Incorporating the Virtual Memory Index of the OS to Hardware-Accelerate Database Indexing",
    "authors": [
      "Felix Schuhknecht"
    ],
    "abstract": "Index structures often materialize one or multiple levels of explicit indirections (aka pointers) to allow for a quick traversal to the data of interest. Unfortunately, dereferencing a pointer to go from one level to the other is costly since additionally to following the address, it involves two address translations from virtual memory to physical memory under the hood. In the worst case, such an address translation is resolved by an index access itself, namely by a lookup into the page table, a central hardware-accelerated index structure of the OS. However, if the page table is anyways constantly queried, it raises the question whether we can actively incorporate it into our database indexes and make it work for us. Precisely, instead of materializing indirections in form of pointers, we propose to express these indirections directly in the page table wherever possible. By introducing such shortcuts, we (a) effectively reduce the height of traversal during lookups and (b) exploit the hardware-acceleration of lookups in the page table. In this work, we analyze the strengths and considerations of this approach and showcase its effectiveness at the case of the real-world indexing scheme extendible hashing.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09124"
  },
  "2310.09123": {
    "title": "Automatic Music Playlist Generation via Simulation-based Reinforcement Learning",
    "authors": [
      "Federico Tomasi",
      "Joseph Cauteruccio",
      "Surya Kanoria",
      "Kamil Ciosek",
      "Matteo Rinaldi",
      "Zhenwen Dai"
    ],
    "abstract": "Personalization of playlists is a common feature in music streaming services, but conventional techniques, such as collaborative filtering, rely on explicit assumptions regarding content quality to learn how to make recommendations. Such assumptions often result in misalignment between offline model objectives and online user satisfaction metrics. In this paper, we present a reinforcement learning framework that solves for such limitations by directly optimizing for user satisfaction metrics via the use of a simulated playlist-generation environment. Using this simulator we develop and train a modified Deep Q-Network, the action head DQN (AH-DQN), in a manner that addresses the challenges imposed by the large state and action space of our RL formulation. The resulting policy is capable of making recommendations from large and dynamic sets of candidate items with the expectation of maximizing consumption metrics. We analyze and evaluate agents offline via simulations that use environment models trained on both public and proprietary streaming datasets. We show how these agents lead to better user-satisfaction metrics compared to baseline methods during online A/B tests. Finally, we demonstrate that performance assessments produced from our simulator are strongly correlated with observed online metric results.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09123"
  },
  "2310.09122": {
    "title": "Equirectangular image construction method for standard CNNs for Semantic Segmentation",
    "authors": [
      "Haoqian Chen",
      "Jian Liu",
      "Minghe Li",
      "Kaiwen Jiang",
      "Ziheng Xu",
      "Rencheng Sun",
      "Yi Sui"
    ],
    "abstract": "360\u00b0 spherical images have advantages of wide view field, and are typically projected on a planar plane for processing, which is known as equirectangular image. The object shape in equirectangular images can be distorted and lack translation invariance. In addition, there are few publicly dataset of equirectangular images with labels, which presents a challenge for standard CNNs models to process equirectangular images effectively. To tackle this problem, we propose a methodology for converting a perspective image into equirectangular image. The inverse transformation of the spherical center projection and the equidistant cylindrical projection are employed. This enables the standard CNNs to learn the distortion features at different positions in the equirectangular image and thereby gain the ability to semantically the equirectangular image. The parameter, \u03c6, which determines the projection position of the perspective image, has been analyzed using various datasets and models, such as UNet, UNet++, SegNet, PSPNet, and DeepLab v3+. The experiments demonstrate that an optimal value of \u03c6 for effective semantic segmentation of equirectangular images is 6\u03c0/16 for standard CNNs. Compared with the other three types of methods (supervised learning, unsupervised learning and data augmentation), the method proposed in this paper has the best average IoU value of 43.76%. This value is 23.85%, 10.7% and 17.23% higher than those of other three methods, respectively.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09122"
  },
  "2310.09119": {
    "title": "A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check",
    "authors": [
      "Haojing Huang",
      "Jingheng Ye",
      "Qingyu Zhou",
      "Yinghui Li",
      "Yangning Li",
      "Feng Zhou",
      "Hai-Tao Zheng"
    ],
    "abstract": "In recent years, Chinese Spelling Check (CSC) has been greatly improved by designing task-specific pre-training methods or introducing auxiliary tasks, which mostly solve this task in an end-to-end fashion. In this paper, we propose to decompose the CSC workflow into detection, reasoning, and searching subtasks so that the rich external knowledge about the Chinese language can be leveraged more directly and efficiently. Specifically, we design a plug-and-play detection-and-reasoning module that is compatible with existing SOTA non-autoregressive CSC models to further boost their performance. We find that the detection-and-reasoning module trained for one model can also benefit other models. We also study the primary interpretability provided by the task decomposition. Extensive experiments and detailed analyses demonstrate the effectiveness and competitiveness of the proposed module.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09119"
  },
  "2310.09118": {
    "title": "DSG: An End-to-End Document Structure Generator",
    "authors": [
      "Johannes Rausch",
      "Gentiana Rashiti",
      "Maxim Gusev",
      "Ce Zhang",
      "Stefan Feuerriegel"
    ],
    "abstract": "Information in industry, research, and the public sector is widely stored as rendered documents (e.g., PDF files, scans). Hence, to enable downstream tasks, systems are needed that map rendered documents onto a structured hierarchical format. However, existing systems for this task are limited by heuristics and are not end-to-end trainable. In this work, we introduce the Document Structure Generator (DSG), a novel system for document parsing that is fully end-to-end trainable. DSG combines a deep neural network for parsing (i) entities in documents (e.g., figures, text blocks, headers, etc.) and (ii) relations that capture the sequence and nested structure between entities. Unlike existing systems that rely on heuristics, our DSG is trained end-to-end, making it effective and flexible for real-world applications. We further contribute a new, large-scale dataset called E-Periodica comprising real-world magazines with complex document structures for evaluation. Our results demonstrate that our DSG outperforms commercial OCR tools and, on top of that, achieves state-of-the-art performance. To the best of our knowledge, our DSG system is the first end-to-end trainable system for hierarchical document parsing.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09118"
  },
  "2310.09115": {
    "title": "Determinization of Integral Discounted-Sum Automata is Decidable",
    "authors": [
      "Shaull Almagor",
      "Neta Dafni"
    ],
    "abstract": "Nondeterministic Discounted-Sum Automata (NDAs) are nondeterministic finite automata equipped with a discounting factor $\u03bb>1$, and whose transitions are labelled by weights. The value of a run of an NDA is the discounted sum of the edge weights, where the $i$-th weight is divided by $\u03bb^{i}$. NDAs are a useful tool for modelling systems where the values of future events are less influential than immediate ones.\n  While several problems are undecidable or open for NDA, their deterministic fragment (DDA) admits more tractable algorithms. Therefore, determinization of NDAs (i.e., deciding if an NDA has a functionally-equivalent DDA) is desirable.\n  Previous works establish that when $\u03bb\\in \\mathbb{N}$, then every complete NDA, namely an NDA whose states are all accepting and its transition function is complete, is determinizable. This, however, no longer holds when the completeness assumption is dropped.\n  We show that the problem of whether an NDA has an equivalent DDA is decidable when $\u03bb\\in \\mathbb{N}$.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09115"
  },
  "2310.09114": {
    "title": "Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport",
    "authors": [
      "Songpengcheng Xia",
      "Lei Chu",
      "Ling Pei",
      "Jiarui Yang",
      "Wenxian Yu",
      "Robert C. Qiu"
    ],
    "abstract": "Human activity recognition (HAR) with wearables is one of the serviceable technologies in ubiquitous and mobile computing applications. The sliding-window scheme is widely adopted while suffering from the multi-class windows problem. As a result, there is a growing focus on joint segmentation and recognition with deep-learning methods, aiming at simultaneously dealing with HAR and time-series segmentation issues. However, obtaining the full activity annotations of wearable data sequences is resource-intensive or time-consuming, while unsupervised methods yield poor performance. To address these challenges, we propose a novel method for joint activity segmentation and recognition with timestamp supervision, in which only a single annotated sample is needed in each activity segment. However, the limited information of sparse annotations exacerbates the gap between recognition and segmentation tasks, leading to sub-optimal model performance. Therefore, the prototypes are estimated by class-activation maps to form a sample-to-prototype contrast module for well-structured embeddings. Moreover, with the optimal transport theory, our approach generates the sample-level pseudo-labels that take advantage of unlabeled data between timestamp annotations for further performance improvement. Comprehensive experiments on four public HAR datasets demonstrate that our model trained with timestamp supervision is superior to the state-of-the-art weakly-supervised methods and achieves comparable performance to the fully-supervised approaches.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09114"
  },
  "2310.09107": {
    "title": "GLoRE: Evaluating Logical Reasoning of Large Language Models",
    "authors": [
      "Hanmeng liu",
      "Zhiyang Teng",
      "Ruoxi Ning",
      "Jian Liu",
      "Qiji Zhou",
      "Yue Zhang"
    ],
    "abstract": "Recently, large language models (LLMs), including notable models such as GPT-4 and burgeoning community models, have showcased significant general language understanding abilities. However, there has been a scarcity of attempts to assess the logical reasoning capacities of these LLMs, an essential facet of natural language understanding. To encourage further investigation in this area, we introduce GLoRE, a meticulously assembled General Logical Reasoning Evaluation benchmark comprised of 12 datasets that span three different types of tasks. Our experimental results show that compared to the performance of human and supervised fine-tuning, the logical reasoning capabilities of open LLM models necessitate additional improvement; ChatGPT and GPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing ChatGPT by a large margin. We propose a self-consistency probing method to enhance the accuracy of ChatGPT and a fine-tuned method to boost the performance of an open LLM. We release the datasets and evaluation programs to facilitate future research.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09107"
  },
  "2310.09101": {
    "title": "Privacy-Preserving Encrypted Low-Dose CT Denoising",
    "authors": [
      "Ziyuan Yang",
      "Huijie Huangfu",
      "Maosong Ran",
      "Zhiwen Wang",
      "Hui Yu",
      "Yi Zhang"
    ],
    "abstract": "Deep learning (DL) has made significant advancements in tomographic imaging, particularly in low-dose computed tomography (LDCT) denoising. A recent trend involves servers training powerful models with large amounts of self-collected private data and providing application programming interfaces (APIs) for users, such as Chat-GPT. To avoid model leakage, users are required to upload their data to the server model, but this way raises public concerns about the potential risk of privacy disclosure, especially for medical data. Hence, to alleviate related concerns, in this paper, we propose to directly denoise LDCT in the encrypted domain to achieve privacy-preserving cloud services without exposing private data to the server. To this end, we employ homomorphic encryption to encrypt private LDCT data, which is then transferred to the server model trained with plaintext LDCT for further denoising. However, since traditional operations, such as convolution and linear transformation, in DL methods cannot be directly used in the encrypted domain, we transform the fundamental mathematic operations in the plaintext domain into the operations in the encrypted domain. In addition, we present two interactive frameworks for linear and nonlinear models in this paper, both of which can achieve lossless operating. In this way, the proposed methods can achieve two merits, the data privacy is well protected and the server model is free from the risk of model leakage. Moreover, we provide theoretical proof to validate the lossless property of our framework. Finally, experiments were conducted to demonstrate that the transferred contents are well protected and cannot be reconstructed. The code will be released once the paper is accepted.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09101"
  },
  "2310.09094": {
    "title": "A RISC-V MCU with adaptive reverse body bias and ultra-low-power retention mode in 22 nm FD-SOI",
    "authors": [
      "Heiner Bauer",
      "Marco Stolba",
      "Stefan Scholze",
      "Dennis Walter",
      "Christian Mayr",
      "Alexander Oefelein",
      "Sebastian H\u00f6ppner",
      "Andr\u00e9 Scharfe",
      "Flo Schraut",
      "Holger Eisenreich"
    ],
    "abstract": "We present a low-power, energy efficient 32-bit RISC-V microprocessor unit (MCU) in 22 nm FD-SOI. It achieves ultra-low leakage,even at high temperatures, by using an adaptive reverse body biasing aware sign-off approach, a low-power optimized physical implementation, and custom SRAM macros with retention mode. We demonstrate the robustness of the chip with measurements over the full industrial temperature range, from -40 \u00b0C to 125 \u00b0C. Our results match the state of the art (SOTA) with 4.8 uW / MHz at 50 MHz in active mode and surpass the SOTA in ultra-low-power retention mode.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09094"
  },
  "2310.09092": {
    "title": "iPUNet:Iterative Cross Field Guided Point Cloud Upsampling",
    "authors": [
      "Guangshun Wei",
      "Hao Pan",
      "Shaojie Zhuang",
      "Yuanfeng Zhou",
      "Changjian Li"
    ],
    "abstract": "Point clouds acquired by 3D scanning devices are often sparse, noisy, and non-uniform, causing a loss of geometric features. To facilitate the usability of point clouds in downstream applications, given such input, we present a learning-based point upsampling method, i.e., iPUNet, which generates dense and uniform points at arbitrary ratios and better captures sharp features. To generate feature-aware points, we introduce cross fields that are aligned to sharp geometric features by self-supervision to guide point generation. Given cross field defined frames, we enable arbitrary ratio upsampling by learning at each input point a local parameterized surface. The learned surface consumes the neighboring points and 2D tangent plane coordinates as input, and maps onto a continuous surface in 3D where arbitrary ratios of output points can be sampled. To solve the non-uniformity of input points, on top of the cross field guided upsampling, we further introduce an iterative strategy that refines the point distribution by moving sparse points onto the desired continuous 3D surface in each iteration. Within only a few iterations, the sparse points are evenly distributed and their corresponding dense samples are more uniform and better capture geometric features. Through extensive evaluations on diverse scans of objects and scenes, we demonstrate that iPUNet is robust to handle noisy and non-uniformly distributed inputs, and outperforms state-of-the-art point cloud upsampling methods.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09092"
  },
  "2310.09091": {
    "title": "Insightful analysis of historical sources at scales beyond human capabilities using unsupervised Machine Learning and XAI",
    "authors": [
      "Oliver Eberle",
      "Jochen B\u00fcttner",
      "Hassan El-Hajj",
      "Gr\u00e9goire Montavon",
      "Klaus-Robert M\u00fcller",
      "Matteo Valleriani"
    ],
    "abstract": "Historical materials are abundant. Yet, piecing together how human knowledge has evolved and spread both diachronically and synchronically remains a challenge that can so far only be very selectively addressed. The vast volume of materials precludes comprehensive studies, given the restricted number of human specialists. However, as large amounts of historical materials are now available in digital form there is a promising opportunity for AI-assisted historical analysis. In this work, we take a pivotal step towards analyzing vast historical corpora by employing innovative machine learning (ML) techniques, enabling in-depth historical insights on a grand scale. Our study centers on the evolution of knowledge within the `Sacrobosco Collection' -- a digitized collection of 359 early modern printed editions of textbooks on astronomy used at European universities between 1472 and 1650 -- roughly 76,000 pages, many of which contain astronomic, computational tables. An ML based analysis of these tables helps to unveil important facets of the spatio-temporal evolution of knowledge and innovation in the field of mathematical astronomy in the period, as taught at European universities.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09091"
  },
  "2310.09088": {
    "title": "Dialect Transfer for Swiss German Speech Translation",
    "authors": [
      "Claudio Paonessa",
      "Yanick Schraner",
      "Jan Deriu",
      "Manuela H\u00fcrlimann",
      "Manfred Vogel",
      "Mark Cieliebak"
    ],
    "abstract": "This paper investigates the challenges in building Swiss German speech translation systems, specifically focusing on the impact of dialect diversity and differences between Swiss German and Standard German. Swiss German is a spoken language with no formal writing system, it comprises many diverse dialects and is a low-resource language with only around 5 million speakers. The study is guided by two key research questions: how does the inclusion and exclusion of dialects during the training of speech translation models for Swiss German impact the performance on specific dialects, and how do the differences between Swiss German and Standard German impact the performance of the systems? We show that dialect diversity and linguistic differences pose significant challenges to Swiss German speech translation, which is in line with linguistic hypotheses derived from empirical investigations.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09088"
  },
  "2310.09071": {
    "title": "Online Relocating and Matching of Ride-Hailing Services: A Model-Based Modular Approach",
    "authors": [
      "Chang Gao",
      "Xi Lin",
      "Fang He",
      "Xindi Tang"
    ],
    "abstract": "This study proposes an innovative model-based modular approach (MMA) to dynamically optimize order matching and vehicle relocation in a ride-hailing platform. MMA utilizes a two-layer and modular modeling structure. The upper layer determines the spatial transfer patterns of vehicle flow within the system to maximize the total revenue of the current and future stages. With the guidance provided by the upper layer, the lower layer performs rapid vehicle-to-order matching and vehicle relocation. MMA is interpretable, and equipped with the customized and polynomial-time algorithm, which, as an online order-matching and vehicle-relocation algorithm, can scale past thousands of vehicles. We theoretically prove that the proposed algorithm can achieve the global optimum in stylized networks, while the numerical experiments based on both the toy network and realistic dataset demonstrate that MMA is capable of achieving superior systematic performance compared to batch matching and reinforcement-learning based methods. Moreover, its modular and lightweight modeling structure further enables it to achieve a high level of robustness against demand variation while maintaining a relatively low computational cost.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09071"
  },
  "2310.09070": {
    "title": "Three-Dimensional Sonification as a Surgical Guidance Tool",
    "authors": [
      "Tim Ziemer"
    ],
    "abstract": "Interactive Sonification is a well-known guidance method in navigation tasks. Researchers have repeatedly suggested the use of interactive sonification in neuronavigation and image-guided surgery. The hope is to reduce clinicians' cognitive load through a relief of the visual channel, while preserving the precision provided through image guidance. In this paper, we present a surgical use case, simulating a craniotomy preparation with a skull phantom. Through auditory, visual, and audiovisual guidance, non-clinicians successfully find targets on a skull that provides hardly any visual or haptic landmarks. The results show that interactive sonification enables novice users to navigate through three-dimensional space with a high precision. The precision along the depth axis is highest in the audiovisual guidance mode, but adding audio leads to higher durations and longer motion trajectories.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09070"
  },
  "2310.09069": {
    "title": "ImageManip: Image-based Robotic Manipulation with Affordance-guided Next View Selection",
    "authors": [
      "Xiaoqi Li",
      "Yanzi Wang",
      "Yan Shen",
      "Ponomarenko Iaroslav",
      "Haoran Lu",
      "Qianxu Wang",
      "Boshi An",
      "Jiaming Liu",
      "Hao Dong"
    ],
    "abstract": "In the realm of future home-assistant robots, 3D articulated object manipulation is essential for enabling robots to interact with their environment. Many existing studies make use of 3D point clouds as the primary input for manipulation policies. However, this approach encounters challenges due to data sparsity and the significant cost associated with acquiring point cloud data, which can limit its practicality. In contrast, RGB images offer high-resolution observations using cost effective devices but lack spatial 3D geometric information. To overcome these limitations, we present a novel image-based robotic manipulation framework. This framework is designed to capture multiple perspectives of the target object and infer depth information to complement its geometry. Initially, the system employs an eye-on-hand RGB camera to capture an overall view of the target object. It predicts the initial depth map and a coarse affordance map. The affordance map indicates actionable areas on the object and serves as a constraint for selecting subsequent viewpoints. Based on the global visual prior, we adaptively identify the optimal next viewpoint for a detailed observation of the potential manipulation success area. We leverage geometric consistency to fuse the views, resulting in a refined depth map and a more precise affordance map for robot manipulation decisions. By comparing with prior works that adopt point clouds or RGB images as inputs, we demonstrate the effectiveness and practicality of our method. In the project webpage (https://sites.google.com/view/imagemanip), real world experiments further highlight the potential of our method for practical deployment.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09069"
  },
  "2310.09068": {
    "title": "How to Combine OTFS and OFDM Modulations in Massive MIMO?",
    "authors": [
      "Ruoxi Chong",
      "Mohammadali Mohammadi",
      "Hien Quoc Ngo",
      "Simon L. Cotton",
      "Michail Matthaiou"
    ],
    "abstract": "In this paper, we consider a downlink (DL) massive multiple-input multiple-output (MIMO) system, where different users have different mobility profiles. To support this system, we propose to use a hybrid orthogonal time frequency space (OTFS)/orthogonal frequency division multiplexing (OFDM) modulation scheme, where OTFS is applied for high-mobility users and OFDM is used for low-mobility users. Two precoding designs, namely full zero-forcing (FZF) precoding and partial zero-forcing (PZF) precoding, are considered and analyzed in terms of per-user spectral efficiency (SE). With FZF, interference among users is totally eliminated at the cost of high computational complexity, while PZF can be used to provide a trade-off between complexity and performance. To apply PZF precoding, users are grouped into two disjoint groups according to their mobility profile or channel gain. Then, zero-forcing (ZF) is utilized for high-mobility or strong channel gain users to completely cancel the inter-group interference, while maximum ratio transmission (MRT) is applied for low-mobility users or users with weak channel gain. To shed light on the system performance, the SE for high-mobility and low-mobility users with a minimum-mean-square-error (MMSE)-successive interference cancellation (SIC) detector is investigated. Our numerical results reveal that the PZF precoding with channel gain grouping can guarantee a similar quality of service for all users. In addition, with mobility-based grouping, the hybrid OTFS/OFDM modulation outperforms the conventional OFDM modulation for high-mobility users.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09068"
  },
  "2310.09066": {
    "title": "pose-format: Library for Viewing, Augmenting, and Handling .pose Files",
    "authors": [
      "Amit Moryossef",
      "Mathias M\u00fcller",
      "Rebecka Fahrni"
    ],
    "abstract": "Managing and analyzing pose data is a complex task, with challenges ranging from handling diverse file structures and data types to facilitating effective data manipulations such as normalization and augmentation. This paper presents \\texttt{pose-format}, a comprehensive toolkit designed to address these challenges by providing a unified, flexible, and easy-to-use interface. The library includes a specialized file format that encapsulates various types of pose data, accommodating multiple individuals and an indefinite number of time frames, thus proving its utility for both image and video data. Furthermore, it offers seamless integration with popular numerical libraries such as NumPy, PyTorch, and TensorFlow, thereby enabling robust machine-learning applications. Through benchmarking, we demonstrate that our \\texttt{.pose} file format offers vastly superior performance against prevalent formats like OpenPose, with added advantages like self-contained pose specification. Additionally, the library includes features for data normalization, augmentation, and easy-to-use visualization capabilities, both in Python and Browser environments. \\texttt{pose-format} emerges as a one-stop solution, streamlining the complexities of pose data management and analysis.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09066"
  },
  "2310.09051": {
    "title": "Bots, Elections, and Controversies: Twitter Insights from Brazil's Polarised Elections",
    "authors": [
      "Diogo Pacheco"
    ],
    "abstract": "From 2018 to 2023, Brazil experienced its most fiercely contested elections in history, resulting in the election of far-right candidate Jair Bolsonaro followed by the left-wing, Lula da Silva. This period was marked by a murder attempt, a coup attempt, the pandemic, and a plethora of conspiracy theories and controversies. This paper analyses 437 million tweets originating from 13 million accounts associated with Brazilian politics during these two presidential election cycles. We focus on accounts' behavioural patterns. We noted a quasi-monotonic escalation in bot engagement, marked by notable surges both during COVID-19 and in the aftermath of the 2022 election. The data revealed a strong correlation between bot engagement and the number of replies during a single day ($r=0.66$, $p<0.01$). Furthermore, we identified a range of suspicious activities, including an unusually high number of accounts being created on the same day, with some days witnessing over 20,000 new accounts and super-prolific accounts generating close to 100,000 tweets. Lastly, we uncovered a sprawling network of accounts sharing Twitter handles, with a select few managing to utilise more than 100 distinct handles. This work can be instrumental in dismantling coordinated campaigns and offer valuable insights for the enhancement of bot detection algorithms.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09051"
  },
  "2310.09049": {
    "title": "SAI: Solving AI Tasks with Systematic Artificial Intelligence in Communication Network",
    "authors": [
      "Lei Yao",
      "Yong Zhang",
      "Zilong Yan",
      "Jialu Tian"
    ],
    "abstract": "In the rapid development of artificial intelligence, solving complex AI tasks is a crucial technology in intelligent mobile networks. Despite the good performance of specialized AI models in intelligent mobile networks, they are unable to handle complicated AI tasks. To address this challenge, we propose Systematic Artificial Intelligence (SAI), which is a framework designed to solve AI tasks by leveraging Large Language Models (LLMs) and JSON-format intent-based input to connect self-designed model library and database. Specifically, we first design a multi-input component, which simultaneously integrates Large Language Models (LLMs) and JSON-format intent-based inputs to fulfill the diverse intent requirements of different users. In addition, we introduce a model library module based on model cards which employ model cards to pairwise match between different modules for model composition. Model cards contain the corresponding model's name and the required performance metrics. Then when receiving user network requirements, we execute each subtask for multiple selected model combinations and provide output based on the execution results and LLM feedback. By leveraging the language capabilities of LLMs and the abundant AI models in the model library, SAI can complete numerous complex AI tasks in the communication network, achieving impressive results in network optimization, resource allocation, and other challenging tasks.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09049"
  },
  "2310.09044": {
    "title": "KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection",
    "authors": [
      "Sehyun Choi",
      "Tianqing Fang",
      "Zhaowei Wang",
      "Yangqiu Song"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable human-level natural language generation capabilities. However, their potential to generate misinformation, often called the hallucination problem, poses a significant risk to their deployment. A common approach to address this issue is to retrieve relevant knowledge and fine-tune the LLM with the knowledge in its input. Unfortunately, this method incurs high training costs and may cause catastrophic forgetting for multi-tasking models. To overcome these limitations, we propose a knowledge-constrained decoding method called KCTS (Knowledge-Constrained Tree Search), which guides a frozen LM to generate text aligned with the reference knowledge at each decoding step using a knowledge classifier score and MCTS (Monte-Carlo Tree Search). To adapt the sequence-level knowledge classifier to token-level guidance, we also propose a novel token-level hallucination detection method called RIPA (Reward Inflection Point Approximation). Our empirical results on knowledge-grounded dialogue and abstractive summarization demonstrate the strength of KCTS as a plug-and-play, model-agnostic decoding method that can effectively reduce hallucinations in natural language generation.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09044"
  },
  "2310.09040": {
    "title": "Optimal Scheduling of Electric Vehicle Charging with Deep Reinforcement Learning considering End Users Flexibility",
    "authors": [
      "Christoforos Menos-Aikateriniadis",
      "Stavros Sykiotis",
      "Pavlos S. Georgilakis"
    ],
    "abstract": "The rapid growth of decentralized energy resources and especially Electric Vehicles (EV), that are expected to increase sharply over the next decade, will put further stress on existing power distribution networks, increasing the need for higher system reliability and flexibility. In an attempt to avoid unnecessary network investments and to increase the controllability over distribution networks, network operators develop demand response (DR) programs that incentivize end users to shift their consumption in return for financial or other benefits. Artificial intelligence (AI) methods are in the research forefront for residential load scheduling applications, mainly due to their high accuracy, high computational speed and lower dependence on the physical characteristics of the models under development. The aim of this work is to identify households' EV cost-reducing charging policy under a Time-of-Use tariff scheme, with the use of Deep Reinforcement Learning, and more specifically Deep Q-Networks (DQN). A novel end users flexibility potential reward is inferred from historical data analysis, where households with solar power generation have been used to train and test the designed algorithm. The suggested DQN EV charging policy can lead to more than 20% of savings in end users electricity bills.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09040"
  },
  "2310.09038": {
    "title": "The exponential logic of sequentialization",
    "authors": [
      "Aurore Alcolei",
      "Luc Pellissier",
      "Alexis Saurin"
    ],
    "abstract": "Linear logic has provided new perspectives on proof-theory, denotational semantics and the study of programming languages. One of its main successes are proof-nets, canonical representations of proofs that lie at the intersection between logic and graph theory. In the case of the minimalist proof-system of multiplicative linear logic without units (MLL), these two aspects are completely fused: proof-nets for this system are graphs satisfying a correctness criterion that can be fully expressed in the language of graphs.\n  For more expressive logical systems (containing logical constants, quantifiers and exponential modalities), this is not completely the case. The purely graphical approach of proof-nets deprives them of any sequential structure that is crucial to represent the order in which arguments are presented, which is necessary for these extensions. Rebuilding this order of presentation - sequentializing the graph - is thus a requirement for a graph to be logical. Presentations and study of the artifacts ensuring that sequentialization can be done, such as boxes or jumps, are an integral part of researches on linear logic.\n  Jumps, extensively studied by Faggian and di Giamberardino, can express intermediate degrees of sequentialization between a sequent calculus proof and a fully desequentialized proof-net. We propose to analyze the logical strength of jumps by internalizing them in an extention of MLL where axioms on a specific formula, the jumping formula, introduce constrains on the possible sequentializations. The jumping formula needs to be treated non-linearly, which we do either axiomatically, or by embedding it in a very controlled fragment of multiplicative-exponential linear logic, uncovering the exponential logic of sequentialization.\n        \u25b3 Less",
    "submission_date": "17 November, 2023",
    "eprint_id": "2310.09038"
  },
  "2310.09036": {
    "title": "MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks",
    "authors": [
      "Xiaocui Yang",
      "Wenfang Wu",
      "Shi Feng",
      "Ming Wang",
      "Daling Wang",
      "Yang Li",
      "Qi Sun",
      "Yifei Zhang",
      "Xiaoming Fu",
      "Soujanya Poria"
    ],
    "abstract": "The popularity of multimodal large language models (MLLMs) has triggered a recent surge in research efforts dedicated to evaluating these models. Nevertheless, existing evaluation studies of MLLMs primarily focus on the comprehension and reasoning of unimodal (vision) content, neglecting performance evaluations in the domain of multimodal (vision-language) content understanding. Beyond multimodal reasoning, tasks related to multimodal content comprehension necessitate a profound understanding of multimodal contexts, achieved through the multimodal interaction to obtain a final answer. In this paper, we introduce a comprehensive assessment framework called MM-BigBench, which incorporates a diverse range of metrics to offer an extensive evaluation of the performance of various models and instructions across a wide spectrum of diverse multimodal content comprehension tasks. Consequently, our work complements research on the performance of MLLMs in multimodal comprehension tasks, achieving a more comprehensive and holistic evaluation of MLLMs. To begin, we employ the Best Performance metric to ascertain each model's performance upper bound on different datasets. Subsequently, the Mean Relative Gain metric offers an assessment of the overall performance of various models and instructions, while the Stability metric measures their sensitivity. Furthermore, previous research centers on evaluating models independently or solely assessing instructions, neglecting the adaptability between models and instructions. We propose the Adaptability metric to quantify the adaptability between models and instructions. Our paper evaluates a total of 20 language models (14 MLLMs) on 14 multimodal datasets spanning 6 tasks, with 10 instructions for each task, and derives novel insights. Our code will be released at https://github.com/declare-lab/MM-BigBench.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09036"
  },
  "2310.09032": {
    "title": "Cell-Free Massive MIMO for ISAC: Access Point Operation Mode Selection and Power Control",
    "authors": [
      "Mohamed Elfiatoure",
      "Mohammadali Mohammadi",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "abstract": "This paper considers a cell-free massive multipleinput multiple-output (MIMO) integrated sensing and communication (ISAC) system, where distributed MIMO access points (APs) are used to jointly serve the communication users and detect the presence of a single target. We investigate the problem of AP operation mode selection, wherein some APs are dedicated for downlink communication, while the remaining APs are used for sensing purposes. Closed-form expressions for the individual spectral efficiency (SE) and mainlobe-to-average-sidelobe ratio (MASR) are derived, which are respectively utilized to assess the communication and sensing performances. Accordingly, a maxmin fairness problem is formulated and solved, where the minimum SE of the users is maximized, subject to the per-AP power constraints as well as sensing MASR constraint. Our numerical results show that the proposed AP operation mode selection with power control can significantly improve the communication performance for given sensing requirements.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09032"
  },
  "2310.09028": {
    "title": "Subspace Adaptation Prior for Few-Shot Learning",
    "authors": [
      "Mike Huisman",
      "Aske Plaat",
      "Jan N. van Rijn"
    ],
    "abstract": "Gradient-based meta-learning techniques aim to distill useful prior knowledge from a set of training tasks such that new tasks can be learned more efficiently with gradient descent. While these methods have achieved successes in various scenarios, they commonly adapt all parameters of trainable layers when learning new tasks. This neglects potentially more efficient learning strategies for a given task distribution and may be susceptible to overfitting, especially in few-shot learning where tasks must be learned from a limited number of examples. To address these issues, we propose Subspace Adaptation Prior (SAP), a novel gradient-based meta-learning algorithm that jointly learns good initialization parameters (prior knowledge) and layer-wise parameter subspaces in the form of operation subsets that should be adaptable. In this way, SAP can learn which operation subsets to adjust with gradient descent based on the underlying task distribution, simultaneously decreasing the risk of overfitting when learning new tasks. We demonstrate that this ability is helpful as SAP yields superior or competitive performance in few-shot image classification settings (gains between 0.1% and 3.9% in accuracy). Analysis of the learned subspaces demonstrates that low-dimensional operations often yield high activation strengths, indicating that they may be important for achieving good few-shot learning performance. For reproducibility purposes, we publish all our research code publicly.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09028"
  },
  "2310.09021": {
    "title": "Generative AI-driven Semantic Communication Framework for NextG Wireless Network",
    "authors": [
      "Avi Deb Raha",
      "Md. Shirajum Munir",
      "Apurba Adhikary",
      "Yu Qiao",
      "Choong Seon Hong"
    ],
    "abstract": "This work designs a novel semantic communication (SemCom) framework for the next-generation wireless network to tackle the challenges of unnecessary transmission of vast amounts that cause high bandwidth consumption, more latency, and experience with bad quality of services (QoS). In particular, these challenges hinder applications like intelligent transportation systems (ITS), metaverse, mixed reality, and the Internet of Everything, where real-time and efficient data transmission is paramount. Therefore, to reduce communication overhead and maintain the QoS of emerging applications such as metaverse, ITS, and digital twin creation, this work proposes a novel semantic communication framework. First, an intelligent semantic transmitter is designed to capture the meaningful information (e.g., the rode-side image in ITS) by designing a domain-specific Mobile Segment Anything Model (MSAM)-based mechanism to reduce the potential communication traffic while QoS remains intact. Second, the concept of generative AI is introduced for building the SemCom to reconstruct and denoise the received semantic data frame at the receiver end. In particular, the Generative Adversarial Network (GAN) mechanism is designed to maintain a superior quality reconstruction under different signal-to-noise (SNR) channel conditions. Finally, we have tested and evaluated the proposed semantic communication (SemCom) framework with the real-world 6G scenario of ITS; in particular, the base station equipped with an RGB camera and a mmWave phased array. Experimental results demonstrate the efficacy of the proposed SemCom framework by achieving high-quality reconstruction across various SNR channel conditions, resulting in 93.45% data reduction in communication.\n        \u25b3 Less",
    "submission_date": "13 October, 2023",
    "eprint_id": "2310.09021"
  }
}